{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LS0BC5oErcAP",
    "outputId": "5d8d4c29-cf66-4c68-ba86-cf864227fd86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sT8qQNCSreSW",
    "outputId": "e4c5c056-971f-4bc3-884c-791f5e547d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/apex-codes/entity_sum\n"
     ]
    }
   ],
   "source": [
    "%cd drive/My\\ Drive/Colab\\ Notebooks/apex-codes/entity_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siGsaXrPapi9"
   },
   "source": [
    "## https://pypi.org/project/biobert-embedding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sibEAV7zsR9i",
    "outputId": "f2ba16a0-844f-49c6-d60e-f866e0a36723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biobert-embedding\n",
      "  Downloading biobert-embedding-0.1.2.tar.gz (4.8 kB)\n",
      "Collecting torch==1.2.0\n",
      "  Downloading torch-1.2.0-cp37-cp37m-manylinux1_x86_64.whl (748.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 748.9 MB 621 bytes/s \n",
      "\u001b[?25hCollecting pytorch-pretrained-bert==0.6.2\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 91.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from biobert-embedding) (2.6.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding) (1.19.5)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.18.62-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 75.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding) (2.23.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert==0.6.2->biobert-embedding) (4.62.3)\n",
      "Collecting botocore<1.22.0,>=1.21.62\n",
      "  Downloading botocore-1.21.62-py3-none-any.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 54.3 MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 9.4 MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.62->boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding) (2.8.2)\n",
      "Collecting urllib3<1.27,>=1.25.4\n",
      "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 76.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.62->boto3->pytorch-pretrained-bert==0.6.2->biobert-embedding) (1.15.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding) (2021.5.30)\n",
      "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 72.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert==0.6.2->biobert-embedding) (2.10)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (0.37.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (2.6.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (3.1.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (3.7.4.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (1.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (5.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (3.17.3)\n",
      "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (2.6.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (1.1.2)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (1.41.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->biobert-embedding) (0.12.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow->biobert-embedding) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->biobert-embedding) (0.4.6)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->biobert-embedding) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->biobert-embedding) (57.4.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->biobert-embedding) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->biobert-embedding) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->biobert-embedding) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow->biobert-embedding) (1.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->biobert-embedding) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->biobert-embedding) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->biobert-embedding) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->biobert-embedding) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow->biobert-embedding) (4.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow->biobert-embedding) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow->biobert-embedding) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow->biobert-embedding) (3.6.0)\n",
      "Building wheels for collected packages: biobert-embedding\n",
      "  Building wheel for biobert-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for biobert-embedding: filename=biobert_embedding-0.1.2-py3-none-any.whl size=5701 sha256=9490ba4d55cc23d1cad7e440832fc1fed76715331bc247ad3358517a1232945d\n",
      "  Stored in directory: /root/.cache/pip/wheels/67/26/c2/176e174845e1612a5d607eea1d1876e2c9aca2b5654a5cd681\n",
      "Successfully built biobert-embedding\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, torch, boto3, pytorch-pretrained-bert, biobert-embedding\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.9.0+cu111\n",
      "    Uninstalling torch-1.9.0+cu111:\n",
      "      Successfully uninstalled torch-1.9.0+cu111\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.2.0 which is incompatible.\n",
      "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.2.0 which is incompatible.\n",
      "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Successfully installed biobert-embedding-0.1.2 boto3-1.18.62 botocore-1.21.62 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.5.0 torch-1.2.0 urllib3-1.25.11\n"
     ]
    }
   ],
   "source": [
    "!pip3 install biobert-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaDRjfTmey1o",
    "outputId": "6b09e17e-d579-4de5-81b5-c73c99106731"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  \n",
    "nltk.download('stopwords')\n",
    "import json\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HJDMNeUL6T_"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial import distance\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from biobert_embedding.embedding import BiobertEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCaB1GOQcQCx"
   },
   "source": [
    "## Instantiate a BioBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhTIilWDbXk7"
   },
   "outputs": [],
   "source": [
    "biobert = BiobertEmbedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFHpvcmvD8Ik"
   },
   "source": [
    "### For each cluster in each ICD-11 chapter, generate a biobert embedding and perform document importance computation based on centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJZL28GcD7Dq"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Read abstracts within a cluster generate their biobert embeddings and compute document importance for each\n",
    "# the method returns an abstract with its id and the document importamce score\n",
    "# returns a defaultdict where key is the cluster_id and value is list of abstract, id, doc_importance scores ordered \n",
    "# for each icd_10 chapter, generate something like {'cluster_id_1': (pmid:embedding-1), 'cluster_id_2': (pmid_2:importance_score_2),}\n",
    "\n",
    "def _get_abstract_biobert_embed(icd_chapter, DATA_PATH, OUTPUT_PATH):\n",
    "  for count, cluster_id in enumerate(os.listdir(DATA_PATH)):\n",
    "    # read the pickled dataframe corresponding to the cluster id and icd-11 chapter\n",
    "    df = pd.read_pickle(f\"{DATA_PATH}/{cluster_id}\")\n",
    "    # iterate through each abstract embed using biobert and store the pmid and embedding as a dictionary\n",
    "    dict_pmid_biobert = {}   # this is for each cluster in an icd-11 chapter\n",
    "    if len(df) > 0:\n",
    "      for idx, row in df.iterrows():\n",
    "        pmid = df['PMID'][idx]\n",
    "        abstract = df['Abstract'][idx]\n",
    "        # sentence tokenizer first followed by mean-pooling of the sentence representation after \n",
    "        # biobert embedding is generated for each sentence\n",
    "        sentences = sent_tokenize(abstract)\n",
    "        # generate biobert embedding for each sentence\n",
    "        sentence_embeddings = [biobert.sentence_vector(sent).numpy() for sent in sentences]\n",
    "        abstract_embedding = np.mean(np.array(sentence_embeddings), axis=0)\n",
    "\n",
    "        dict_pmid_biobert[pmid] = abstract_embedding\n",
    "    \n",
    "    # Write the generated pmid to biobert emebdding to the file system for each cluster (as filename) in each ICD-11 chapter\n",
    "    pk.dump(dict_pmid_biobert, open(f\"{OUTPUT_PATH}/{cluster_id}\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HHoaR7ZeqKd",
    "outputId": "439bdaf9-5e5c-4642-8fb8-753e02de22e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/apex-codes/entity_sum\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rongF2cGKyeS"
   },
   "source": [
    "### Call to the above method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40nbNbxkD63y"
   },
   "outputs": [],
   "source": [
    "icd_chapter = \"developmental_anomaly\"\n",
    "# data path corresponding to an ICD-11 chapter\n",
    "DATA_PATH = f\"pubmed_abstracts_clusters_FINAL/{icd_chapter}_Medline\"\n",
    "# First create a folder----this folder contains pubmbed abstracts' pmids and their biobert embeddings (768-d)\n",
    "OUTPUT_PATH = \"PMID_TO_BIOBERT_EMBED\"\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "  os.mkdir(OUTPUT_PATH)\n",
    "\n",
    "if not os.path.exists(f\"{OUTPUT_PATH}/{icd_chapter}\"):\n",
    "  os.mkdir(f\"{OUTPUT_PATH}/{icd_chapter}\")\n",
    "\n",
    "# Final output path corresponding to an icd-11 chapter\n",
    "FINAL_OUTPUT_PATH = f\"PMID_TO_BIOBERT_EMBED/{icd_chapter}\"\n",
    "# Filename of output file will be the correspondig ICD-11 chapter\n",
    "# Call to the method\n",
    "_get_abstract_biobert_embed(icd_chapter, DATA_PATH, FINAL_OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9Fcn8HIffLO"
   },
   "source": [
    "### Read back to verify the PMID to biobert embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3QaLTjsD6xS"
   },
   "outputs": [],
   "source": [
    "icd_chapter = \"developmental_anomaly\"\n",
    "FINAL_OUTPUT_PATH = f\"PMID_TO_BIOBERT_EMBED/{icd_chapter}\"\n",
    "cluster_id = 0\n",
    "\n",
    "\n",
    "dict_pmid_biobert = pk.load(open(f\"{FINAL_OUTPUT_PATH}/{cluster_id}.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAI2onb8D6sE"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Hewv4v_0wFq"
   },
   "source": [
    "## Method to perform document importance ranking for each cluster in the ICD-11 chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur_nwSjy2yj-"
   },
   "outputs": [],
   "source": [
    "def _get_doc_importance(icd_chapter, DATA_PATH, OUTPUT_PATH):\n",
    "  sorted_dict_pmid_imp = {}\n",
    "  for cluster_id in os.listdir(DATA_PATH):\n",
    "    dict_pmid_biobert = pk.load(open(f\"{DATA_PATH}/{cluster_id}\", \"rb\"))\n",
    "    # iterate through the key-value dict\n",
    "    dict_pmid_imp = {}   # to store avg cosine similarity with others within a cluster of an ICD-11 chapter\n",
    "    for pmid_src, embed_src in dict_pmid_biobert.items():\n",
    "      cnt = 0\n",
    "      total_cosine_sum = 0.0\n",
    "      for _, embed_tgt in dict_pmid_biobert.items():\n",
    "        # compute cosine similarity\n",
    "        #total_cosine_sum += cosine_similarity(embed_src.reshape(-1, 1), embed_tgt.reshape(-1, 1))[0][0]\n",
    "        total_cosine_sum += distance.euclidean(embed_src, embed_tgt)\n",
    "        \n",
    "        cnt += 1\n",
    "      # average cosine cosine\n",
    "      avg_cosine_sum = total_cosine_sum / float(cnt)\n",
    "\n",
    "      dict_pmid_imp[pmid_src] = avg_cosine_sum\n",
    "      # sort the dictionary in descending order of value (avg cosine sum)\n",
    "      sorted_dict_pmid_imp = sorted(dict_pmid_imp.items(), key=operator.itemgetter(1))\n",
    "\n",
    "    # write the sorted dict as json to the file system---note that the dict corresponds to a cluster_id in an ICD-11 chapter\n",
    "    # write the dict as a pickle file\n",
    "    pk.dump(sorted_dict_pmid_imp, open(f\"{OUTPUT_PATH}/{cluster_id}\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xfTrDxZfizs"
   },
   "outputs": [],
   "source": [
    "# The document importance based ranking is for each abstract in a cluster in an ICD-11 chapter\n",
    "# The idea is computing aggregate inter-document cosine similarity and sorting based on the cosine scores\n",
    "icd_chapter = \"developmental_anomaly\"\n",
    "\n",
    "# data path corresponding to an ICD-11 chapter\n",
    "DATA_PATH = f\"PMID_TO_BIOBERT_EMBED/{icd_chapter}\"\n",
    "\n",
    "OUTPUT_PATH = \"DOCUMENT_IMPORTANCE\"\n",
    "\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "  os.mkdir(OUTPUT_PATH)\n",
    "\n",
    "if not os.path.exists(f\"{OUTPUT_PATH}/{icd_chapter}\"):\n",
    "  os.mkdir(f\"{OUTPUT_PATH}/{icd_chapter}\")\n",
    "\n",
    "# Final output path corresponding to an icd-11 chapter\n",
    "FINAL_OUTPUT_PATH = f\"DOCUMENT_IMPORTANCE/{icd_chapter}\"\n",
    "\n",
    "\n",
    "# Call to the actual method\n",
    "_get_doc_importance(icd_chapter, DATA_PATH, FINAL_OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZbSAWFIAdOQ"
   },
   "source": [
    "### Verify the generated pickle files (i.e., PMID to importance score mappings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0Gti_vtfixX"
   },
   "outputs": [],
   "source": [
    "icd_chapter = \"neoplasms\"\n",
    "FINAL_OUTPUT_PATH = f\"DOCUMENT_IMPORTANCE/{icd_chapter}\"\n",
    "cluster_id = 0\n",
    "\n",
    "sorted_dict_pmid_imp = pk.load(open(f\"{FINAL_OUTPUT_PATH}/{cluster_id}.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gXXZiwMbfiu8",
    "outputId": "a9857802-c800-40cc-f21a-7d049c1b9a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(33706122, 2.8744233041196257),\n",
       " (33706130, 2.908323534437128),\n",
       " (33706249, 2.9145984005283667),\n",
       " (33705923, 2.916296179230149),\n",
       " (33705918, 2.918151056444323),\n",
       " (33706219, 2.9717274775376192),\n",
       " (33706111, 2.9743940040871903),\n",
       " (33706022, 2.990836749205718),\n",
       " (33705966, 2.9997104889637716),\n",
       " (33705881, 2.999973467878393),\n",
       " (33706097, 3.005936474413485),\n",
       " (33706413, 3.018882939944396),\n",
       " (33705970, 3.024985767699577),\n",
       " (33706124, 3.031220004365251),\n",
       " (33705980, 3.0498031796635807),\n",
       " (33705751, 3.060083376394736),\n",
       " (33706163, 3.0669418750582516),\n",
       " (33705950, 3.0677476831384607),\n",
       " (33705896, 3.1070501014992997),\n",
       " (33705943, 3.111293166070371)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict_pmid_imp[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQ9A4cc5m42A",
    "outputId": "1a994db0-743e-4858-bd54-fb3e2f75b589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_dict_pmid_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1HKbKQUDsq-"
   },
   "source": [
    "## **Next: Entity-aware sentence selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iyUf2OBAbiOt"
   },
   "source": [
    "### Read the abstracts in each cluster under each ICD-11 chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sz6R1GtbA2x3"
   },
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "icd_chapter = \"neoplasms\"\n",
    "DATA_PATH = f\"pubmed_abstracts_clusters_FINAL/{icd_chapter}_Medline\"\n",
    "\n",
    "# changes for each cluster in an ICD-11 chapter\n",
    "cluster_id = 0\n",
    "\n",
    "df_cluster = pd.read_pickle(f\"{DATA_PATH}/{cluster_id}.pk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "3J4HeCuKikJ3",
    "outputId": "7b3a4bac-07ea-4a34-80a1-8623a48dbb69"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Named_Entities_mimic_w_i2b2</th>\n",
       "      <th>Named_Entities_genia_w_BC5CDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33706449</td>\n",
       "      <td>[Short-term and long-term outcomes of tricuspi...</td>\n",
       "      <td>Objective: To examine the short-term and long-...</td>\n",
       "      <td>{'TREATMENT': ['tricuspid valve replacement', ...</td>\n",
       "      <td>{'DISEASE': ['left ventricular dysfunction', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33706443</td>\n",
       "      <td>[A prognostic model of intrahepatic cholangioc...</td>\n",
       "      <td>Objective: To examine a survival prognostic mo...</td>\n",
       "      <td>{'TREATMENT': ['a survival prognostic model', ...</td>\n",
       "      <td>{'DISEASE': ['intrahepatic cholangiocarcinoma'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33706442</td>\n",
       "      <td>[Conversion therapy of biliary tract cancer fr...</td>\n",
       "      <td>Biliary tract cancer is found in the middle an...</td>\n",
       "      <td>{'PROBLEM': ['Biliary tract cancer', 'Biliary ...</td>\n",
       "      <td>{'DISEASE': ['Biliary tract cancer', 'Biliary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33706440</td>\n",
       "      <td>[Attach importance to the standardized diagnos...</td>\n",
       "      <td>Gallbladder carcinoma,characterized by conceal...</td>\n",
       "      <td>{'PROBLEM': ['Gallbladder carcinoma', 'gallbla...</td>\n",
       "      <td>{'DISEASE': ['Gallbladder carcinoma', 'gallbla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33706419</td>\n",
       "      <td>Reproducibility of Lung Nodule Radiomic Featur...</td>\n",
       "      <td>PURPOSE: Recent studies have demonstrated a la...</td>\n",
       "      <td>{'TEST': ['Recent studies', 'CT parameters', '...</td>\n",
       "      <td>{'DISEASE': ['lung cancer', 'lung cancer']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID  ...                      Named_Entities_genia_w_BC5CDR\n",
       "0  33706449  ...  {'DISEASE': ['left ventricular dysfunction', '...\n",
       "1  33706443  ...  {'DISEASE': ['intrahepatic cholangiocarcinoma'...\n",
       "2  33706442  ...  {'DISEASE': ['Biliary tract cancer', 'Biliary ...\n",
       "3  33706440  ...  {'DISEASE': ['Gallbladder carcinoma', 'gallbla...\n",
       "5  33706419  ...        {'DISEASE': ['lung cancer', 'lung cancer']}\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEH7MHbyivjh",
    "outputId": "1ee5f1de-997e-4253-c865-a43cbe9e1e23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZK18G-ZpjUAf"
   },
   "outputs": [],
   "source": [
    "# drop the Named_Entities_mimic_w_i2b2 column\n",
    "df_cluster = df_cluster.drop(columns=['Named_Entities_mimic_w_i2b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Rr9T717-kFZJ",
    "outputId": "c3507e93-5891-47a7-b2f0-69212953350f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Named_Entities_genia_w_BC5CDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33706449</td>\n",
       "      <td>[Short-term and long-term outcomes of tricuspi...</td>\n",
       "      <td>Objective: To examine the short-term and long-...</td>\n",
       "      <td>{'DISEASE': ['left ventricular dysfunction', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33706443</td>\n",
       "      <td>[A prognostic model of intrahepatic cholangioc...</td>\n",
       "      <td>Objective: To examine a survival prognostic mo...</td>\n",
       "      <td>{'DISEASE': ['intrahepatic cholangiocarcinoma'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33706442</td>\n",
       "      <td>[Conversion therapy of biliary tract cancer fr...</td>\n",
       "      <td>Biliary tract cancer is found in the middle an...</td>\n",
       "      <td>{'DISEASE': ['Biliary tract cancer', 'Biliary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33706440</td>\n",
       "      <td>[Attach importance to the standardized diagnos...</td>\n",
       "      <td>Gallbladder carcinoma,characterized by conceal...</td>\n",
       "      <td>{'DISEASE': ['Gallbladder carcinoma', 'gallbla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33706419</td>\n",
       "      <td>Reproducibility of Lung Nodule Radiomic Featur...</td>\n",
       "      <td>PURPOSE: Recent studies have demonstrated a la...</td>\n",
       "      <td>{'DISEASE': ['lung cancer', 'lung cancer']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID  ...                      Named_Entities_genia_w_BC5CDR\n",
       "0  33706449  ...  {'DISEASE': ['left ventricular dysfunction', '...\n",
       "1  33706443  ...  {'DISEASE': ['intrahepatic cholangiocarcinoma'...\n",
       "2  33706442  ...  {'DISEASE': ['Biliary tract cancer', 'Biliary ...\n",
       "3  33706440  ...  {'DISEASE': ['Gallbladder carcinoma', 'gallbla...\n",
       "5  33706419  ...        {'DISEASE': ['lung cancer', 'lung cancer']}\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rs0yUYROkIZS",
    "outputId": "a74e19e4-f4b0-43cc-e86e-4d442c008d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8P2u8nZnHyg",
    "outputId": "5e56d2d0-864c-4ebc-bb39-dc14f4d8e5cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([defaultdict(<class 'list'>, {'DISEASE': ['cancer', 'solid tumors', 'cancer'], 'CHEMICAL': ['ruthenium', 'rofecoxib']})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster[df_cluster['PMID'] == 33706122]['Named_Entities_genia_w_BC5CDR'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7SwCeqBnjav",
    "outputId": "3e097c84-2bd4-4bb8-d253-d099e395c44b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cancer', 'solid tumors', 'cancer'], ['ruthenium', 'rofecoxib']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_cluster[df_cluster['PMID'] == 33706122]['Named_Entities_genia_w_BC5CDR'].values[0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nzg2LKDho03P"
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "newList = list(chain(*list(df_cluster[df_cluster['PMID'] == 33706122]['Named_Entities_genia_w_BC5CDR'].values[0].values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77h-skCJo5VM",
    "outputId": "38aa198f-dc8a-4517-823f-068a48b269ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancer', 'solid tumors', 'cancer', 'ruthenium', 'rofecoxib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FJP3WLG7kLS2"
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Tokenize the abstract into sentences and embed using BioBERT and embed the named entities using BioBERT, too \n",
    "# and perform pairwise cosine similarity\n",
    "# Follow the document importance ordering though in a cluster/\n",
    "\n",
    "import pickle as pk\n",
    "\n",
    "# this method takes in an icd chapter and generates entity-aware sentences for each cluster belonging to the icd chapter\n",
    "def _select_entity_aware_content(icd_chapter, OUTPUT_PATH, percentile_threshold=75):\n",
    "  #icd_chapter = \"neoplasms\"\n",
    "  doc_importance_path = f\"DOCUMENT_IMPORTANCE/{icd_chapter}\"\n",
    "\n",
    "  for cluster_id in os.listdir(doc_importance_path):\n",
    "    cluster_id_wo_pk = cluster_id.replace('.pk', '')   # This to be used as the file name of the pseudo-doc\n",
    "    print(\"Cluster ID: \", cluster_id_wo_pk)\n",
    "\n",
    "    final_entity_aware_sentences = []  # This for each cluster in an icd-11 chapter\n",
    "\n",
    "    sorted_dict_pmid_imp = pk.load(open(f\"{doc_importance_path}/{cluster_id}\", \"rb\"))\n",
    "\n",
    "    for count, pmid_impVal in enumerate(sorted_dict_pmid_imp):\n",
    "      # grab the row from df_cluster with the pmid value\n",
    "      pmid = pmid_impVal[0]\n",
    "      #print(\"PMID: \", pmid)\n",
    "      DATA_PATH = f\"pubmed_abstracts_clusters_FINAL/{icd_chapter}_Medline\"\n",
    "\n",
    "      # changes for each cluster in an ICD-11 chapter\n",
    "      #cluster_id = 0\n",
    "\n",
    "      df_cluster = pd.read_pickle(f\"{DATA_PATH}/{cluster_id}\")\n",
    "\n",
    "      df_ = df_cluster[df_cluster['PMID'] == pmid]['Named_Entities_genia_w_BC5CDR']\n",
    "      try:\n",
    "        lst_of_lst_entities = list(df_.values[0].values())\n",
    "        final_lst_of_entities = list(chain(*lst_of_lst_entities))\n",
    "      except IndexError:\n",
    "        continue\n",
    "\n",
    "      abstract = df_cluster[df_cluster['PMID'] == pmid]['Abstract'].values[0]\n",
    "      sentences = sent_tokenize(abstract)\n",
    "\n",
    "      # entity to sentence embedding cosine similarity computation\n",
    "      dict_sent_cossim_score = {}    # key as the sentence and value as the cumulative cosine similarity score against all entities for a sentence\n",
    "      \n",
    "      if len(final_lst_of_entities) > 0:\n",
    "        for sent in sentences:\n",
    "          total_cosine_sum = 0.0   # total cosine similarity with all entities for a given sentence\n",
    "          sent_embed = biobert.sentence_vector(sent).numpy()\n",
    "\n",
    "          for entity in final_lst_of_entities:\n",
    "            entity_embeddings = [biobert.word_vector(ent)[0].numpy() for ent in entity.split()]\n",
    "            entity_embed = np.mean(np.array(entity_embeddings), axis=0)\n",
    "\n",
    "            # compute cosine similarity between the two\n",
    "            total_cosine_sum += cosine_similarity(sent_embed.reshape(-1, 1), entity_embed.reshape(-1, 1))[0][0]\n",
    "          \n",
    "          tokenized_sent = nltk.word_tokenize(sent)\n",
    "          normalized_count = sum(e1 in final_lst_of_entities for e1 in tokenized_sent) / float(len(tokenized_sent))\n",
    "          normalized_score = total_cosine_sum / float(len(final_lst_of_entities)) + normalized_count\n",
    "          \n",
    "          #if normalized_score >= similarity_threshold:\n",
    "          dict_sent_cossim_score[sent] = float(normalized_score)\n",
    "          \n",
    "        lst_of_scores = list(dict_sent_cossim_score.values())\n",
    "        \n",
    "        similarity_threshold = float(np.percentile(lst_of_scores, percentile_threshold))   # 75th percentile\n",
    "        print(\"similarity threshold: \", similarity_threshold)\n",
    "        dict_sent_cossim_score = { k:v for k,v in dict_sent_cossim_score.items() if v >= similarity_threshold }\n",
    "        print(dict_sent_cossim_score)\n",
    "\n",
    "\n",
    "        #pprint(dict_sent_cossim_score)\n",
    "        #pprint(list(dict_sent_cossim_score.keys()))\n",
    "        final_entity_aware_sentences += list(dict_sent_cossim_score.keys())\n",
    "    print(\"==============================================================================================\")\n",
    "      \n",
    "    # WRITE TO THE FILE SYSTEM THE PSUEOD-DOCUMENT CREATED (SALIENT SENTENCES)\n",
    "    pseudo_doc = \" \".join(final_entity_aware_sentences)\n",
    "    with open(f\"{OUTPUT_PATH}/{cluster_id_wo_pk}.txt\", 'w') as fp:\n",
    "      fp.write(pseudo_doc)\n",
    "    fp.close()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bt93zKS60co9",
    "outputId": "09cf1455-77ed-41c8-b22f-8e2b2e9cb9d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Colab Notebooks/apex-codes/entity_sum\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1ksqr4kXSnI",
    "outputId": "6963e8be-0603-479c-f1b0-8166632063a4"
   },
   "outputs": [],
   "source": [
    "# create a directory to store the psuedo-documents  \n",
    "#(which consistss of sentences with huigh level of entity informativesness in each abstract\n",
    "\n",
    "# First create the directory for entity-aware sentences\n",
    "\n",
    "#icd_chapter = \"certain_conditions_originating_in_the_perinatal_period\"\n",
    "lst_icd_chapters = ['neoplasms',\\\n",
    "                    'developmental_anomaly',\\\n",
    "                    'certain_conditions_originating_in_the_perinatal_period',\\\n",
    "                    'diseases_of_the_blood_and_blood_forming_organs',\\\n",
    "                    'certain_infectious_or_parasitic_diseases',\\\n",
    "                    'disorders_involving_the_immune_mechanism',\\\n",
    "                    'injury_poisoning_or_certain_other_consequences_of_external_cause',\\\n",
    "                    'pregnancy_childbirth_and_the_puerperium']\n",
    "\n",
    "# iterate through the list of icd chapters \n",
    "for icd_chapter in lst_icd_chapters:\n",
    "  print(\"ICD Chapter: \", icd_chapter)\n",
    "  os.makedirs(f\"ENTITY_AWARE_CONTENTS/{icd_chapter}\", exist_ok=True)\n",
    "  OUTPUT_PATH = f\"ENTITY_AWARE_CONTENTS/{icd_chapter}\"\n",
    "\n",
    "  # call to the method above\n",
    "  _select_entity_aware_content(icd_chapter, OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "90MS5LgNfEco"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Entity_aware_content_selection_per_cluster.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
