{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_Summarization_Models_Fine_Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bed8257b0e7c48aaa4325da5fc56d8f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97b022039e5b48eb94b03bf241c27bd0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_67a7a9d7ddcf4dad9b364a0a2ba69190",
              "IPY_MODEL_6cee6cf66a4e4282aa71bc5ea8dc801f",
              "IPY_MODEL_7eb15f1ab28e4202afb6f3a366574542"
            ]
          }
        },
        "97b022039e5b48eb94b03bf241c27bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67a7a9d7ddcf4dad9b364a0a2ba69190": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1134ad754424dfabb832c6214fbb189",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7f696795726463484473ce36952928b"
          }
        },
        "6cee6cf66a4e4282aa71bc5ea8dc801f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f895d852fb974645b0e39d89969691a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231506,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231506,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dee1b3349818462fb8b7319a1869a4d6"
          }
        },
        "7eb15f1ab28e4202afb6f3a366574542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ed0fd5d66eb44aa81c9b96e6ef44535",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 669kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f69e5c6e5236459cb02bfde4db2f8319"
          }
        },
        "c1134ad754424dfabb832c6214fbb189": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7f696795726463484473ce36952928b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f895d852fb974645b0e39d89969691a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dee1b3349818462fb8b7319a1869a4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ed0fd5d66eb44aa81c9b96e6ef44535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f69e5c6e5236459cb02bfde4db2f8319": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b99acfe1c294038b3a4cfc833cbac97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2889626e358a4e17a6c2b15bb8364c7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be2bfc3e58794ff7a7fe824cd7e1ce25",
              "IPY_MODEL_0f26bcaf54e74fbabccf0a267ecbc385",
              "IPY_MODEL_dbbe74058db143fd8563e3427d609670"
            ]
          }
        },
        "2889626e358a4e17a6c2b15bb8364c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be2bfc3e58794ff7a7fe824cd7e1ce25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78601a61795944c48b6b401f941c5100",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cf0cd602f6234335a0c9fd0f1d444797"
          }
        },
        "0f26bcaf54e74fbabccf0a267ecbc385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_849d9d870fd2471aae9dde004a7efe9d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 90,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 90,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bad96226e59743dabd1a72a81b7fdfcd"
          }
        },
        "dbbe74058db143fd8563e3427d609670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f3f0d8ae1d34608bce0b6b12f3b315f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 90.0/90.0 [00:00&lt;00:00, 3.71kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a688ab790f0340089586dffe62949ba5"
          }
        },
        "78601a61795944c48b6b401f941c5100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cf0cd602f6234335a0c9fd0f1d444797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "849d9d870fd2471aae9dde004a7efe9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bad96226e59743dabd1a72a81b7fdfcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f3f0d8ae1d34608bce0b6b12f3b315f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a688ab790f0340089586dffe62949ba5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be304a2a0b004af0805e0450f20b351e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a0eba9c2f674b02904d13ea26fdc0f7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb7eb86abee94853ba39c61cb6d31045",
              "IPY_MODEL_9e6aeee619ca436894b1542ee8d890dd",
              "IPY_MODEL_1793d0b9b8fb4576a894101d5319bb7d"
            ]
          }
        },
        "6a0eba9c2f674b02904d13ea26fdc0f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb7eb86abee94853ba39c61cb6d31045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a64841f4af0463bb134682eac349b6b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e7bc8e06a91493eadeffb7bae5552b2"
          }
        },
        "9e6aeee619ca436894b1542ee8d890dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_731ec3e1d0774649abd2d083e13b654f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 141,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 141,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32555201991b491a8fd0db9bcf9a5ee6"
          }
        },
        "1793d0b9b8fb4576a894101d5319bb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_968648b4af414b169c7d06437f0e8fc7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 141/141 [00:00&lt;00:00, 5.44kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c41ed0fdc7124ae89431c3cc0b364b78"
          }
        },
        "4a64841f4af0463bb134682eac349b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e7bc8e06a91493eadeffb7bae5552b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "731ec3e1d0774649abd2d083e13b654f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32555201991b491a8fd0db9bcf9a5ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "968648b4af414b169c7d06437f0e8fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c41ed0fdc7124ae89431c3cc0b364b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1fa4eb9f80bf4b80a170c479e0a573f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6aaad847bdac443ea428b65701b39ce0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ef80fb9f9f1a4b9886005a9d509b6339",
              "IPY_MODEL_09803a6ec4ed49eb8d4e9607fc5da732",
              "IPY_MODEL_ae2978fbe39c4d79b4e168801e2a8b5c"
            ]
          }
        },
        "6aaad847bdac443ea428b65701b39ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef80fb9f9f1a4b9886005a9d509b6339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_14bd2d3df8134c278ebab4242b505684",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2e3df875960a4a2d87df651cdca99051"
          }
        },
        "09803a6ec4ed49eb8d4e9607fc5da732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_957d69db5aa9439dab90c791813bde79",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1397,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1397,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7de608fe0be14a96a58c25fe39446fa8"
          }
        },
        "ae2978fbe39c4d79b4e168801e2a8b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36ea475979264aa388e71e0c84663ef0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36k/1.36k [00:00&lt;00:00, 49.0kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a154141130e54a1cba79d37ff50bbd1d"
          }
        },
        "14bd2d3df8134c278ebab4242b505684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2e3df875960a4a2d87df651cdca99051": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "957d69db5aa9439dab90c791813bde79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7de608fe0be14a96a58c25fe39446fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36ea475979264aa388e71e0c84663ef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a154141130e54a1cba79d37ff50bbd1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2767fce4b2294ed5840b816993445e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_47798033274049ada1721a5c2b7c48ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_58cee608e0cc43d394e7f13676343f54",
              "IPY_MODEL_8942b43983c0456fbfe90fc1b52b6270",
              "IPY_MODEL_1924706f3d824da7a3081a3c491ea8b0"
            ]
          }
        },
        "47798033274049ada1721a5c2b7c48ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58cee608e0cc43d394e7f13676343f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a91c11b6fc5647ebb26d7711e2dabad1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5de66e9c9f954527a16a4fcb8113fc70"
          }
        },
        "8942b43983c0456fbfe90fc1b52b6270": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0140d9098d1483a8817ee1f40b575c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1565504151,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1565504151,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_378ed071814746f68688e03431110b31"
          }
        },
        "1924706f3d824da7a3081a3c491ea8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9ca4337f27cf4069b63853738698cf6e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.46G/1.46G [00:27&lt;00:00, 56.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5ccf8a86c304666b6a5f77feeb7734b"
          }
        },
        "a91c11b6fc5647ebb26d7711e2dabad1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5de66e9c9f954527a16a4fcb8113fc70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0140d9098d1483a8817ee1f40b575c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "378ed071814746f68688e03431110b31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ca4337f27cf4069b63853738698cf6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5ccf8a86c304666b6a5f77feeb7734b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUEQgb1xL-ok",
        "outputId": "131594f4-0d75-4234-b914-7161cdcc9091"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzQkluMKMBUX",
        "outputId": "b8badf87-7aaa-4f81-ece8-4a15ce6684f5"
      },
      "source": [
        "%cd drive/My\\ Drive/Colab\\ Notebooks/apex-codes/entity_sum"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/apex-codes/entity_sum\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTZ8enuLYhk1",
        "outputId": "e6f7393d-d8a9-4a97-e255-d19685589562"
      },
      "source": [
        "# works for BART and T5 only\n",
        "#!pip3 install transformers==2.8.0\n",
        "\n",
        "# For BART, T5, Pegasus\n",
        "!pip3 install transformers==3.5.0\n",
        "\n",
        "# For Prophetnet\n",
        "#!pip3 install git+https://github.com/huggingface/transformers\n",
        "\n",
        "!pip3 install torch==1.7.0\n",
        "!pip3 install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==3.5.0\n",
            "  Downloading transformers-3.5.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 245 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 286 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 327 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (1.19.5)\n",
            "Collecting tokenizers==0.9.3\n",
            "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 53.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.17.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5.0) (4.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5.0) (3.0.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5.0) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5.0) (1.1.0)\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.46 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.0\n",
            "Collecting torch==1.7.0\n",
            "  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.3 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Installing collected packages: dataclasses, torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed dataclasses-0.6 torch-1.7.0\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.91)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvPxXdKJguYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a95dcf-f5e8-4dfd-cc7c-9427e584c323"
      },
      "source": [
        "# Checking out the GPU we have access to\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jan  8 02:42:25 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzM1_ykHaFur"
      },
      "source": [
        "# Importing stock libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "#from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "#from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
        "from transformers import ProphetNetTokenizer, ProphetNetForConditionalGeneration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLxxwd1scQNv"
      },
      "source": [
        "# # Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "o5I_jCNdMpNp",
        "outputId": "899abaee-168d-4be1-8c5d-328331ed3e77"
      },
      "source": [
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xh0hGwMZ8yG"
      },
      "source": [
        "### Read pubmed dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zo3IEJB4PM0z"
      },
      "source": [
        "import json\n",
        "\n",
        "DATA_PATH = \"pubmed_dataset/pubmed-dataset\"\n",
        "data = []\n",
        "with open(f\"{DATA_PATH}/val.txt\") as f:\n",
        "  for line in f:\n",
        "    data.append(json.loads(line))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWc3YmTlNL3U",
        "outputId": "b45dda14-bdf6-41c1-a983-a7743a21a06d"
      },
      "source": [
        "data[0]['abstract_text']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<S> background and aim : there is lack of substantial indian data on venous thromboembolism ( vte ) . </S>',\n",
              " '<S> the aim of this study was to provide real - world information on patient characteristics , management strategies , clinical outcomes , and temporal trends in vte.subjects and methods : multicentre retrospective registry involving 549 medical records of patients with confirmed diagnosis of vte ( deep vein thrombosis [ dvt ] confirmed by doppler ultrasonography ; pulmonary embolism [ pe ] by computed tomography , pulmonary angiography and/or v / q scan ) from 2006 to 2010 at three indian tertiary care hospitals.results:acute dvt without pe , acute dvt with pe , and pe alone were reported in 64% ( 352/549 ) , 23% ( 124/549 ) , and 13% ( 73/549 ) patients , respectively . </S>',\n",
              " '<S> mean age was 47 ( 16 ) years , and 70% were males . </S>',\n",
              " '<S> h / o dvt ( 34% ) , surgery including orthopedic surgery ( 28% ) , trauma ( 16% ) , and immobilization > 3 days ( 14% ) were the most common risk factors for vte . </S>',\n",
              " '<S> hypertension ( 25% ) , diabetes ( 19% ) , and neurological disease ( other than stroke ) ( 8% ) were the most common co - morbidities . </S>',\n",
              " '<S> most ( 94% ) were treated with heparin alone ( 82% ) or fondaparinux ( 2% ) for initial anticoagulation ; low molecular weight heparin alone ( 5% ) or warfarin / acenocoumarol ( 76% ) for long - term anticoagulation . </S>',\n",
              " '<S> anticoagulant treatment was stopped because of bleeding in 2% ( 9/515 ) patients . </S>',\n",
              " '<S> mortality was 7% among patients diagnosed with vte during hospital stay versus 1% in those hospitalized with diagnosed vte . </S>',\n",
              " '<S> the annual incidence of dvt ( pe ) increased from 2006 to 2010.conclusion:acute dvt alone was responsible for the substantial burden of vte in indian patients . </S>',\n",
              " '<S> bleeding was not the limiting factor for anticoagulant treatment in most patients . </S>']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "IobLhLEoRxyg",
        "outputId": "8eb62615-fada-4d5d-8099-3c70cc631fe3"
      },
      "source": [
        "\"\".join(data[0]['abstract_text']).replace('<S>', '').replace('</S>', '')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' background and aim : there is lack of substantial indian data on venous thromboembolism ( vte ) .  the aim of this study was to provide real - world information on patient characteristics , management strategies , clinical outcomes , and temporal trends in vte.subjects and methods : multicentre retrospective registry involving 549 medical records of patients with confirmed diagnosis of vte ( deep vein thrombosis [ dvt ] confirmed by doppler ultrasonography ; pulmonary embolism [ pe ] by computed tomography , pulmonary angiography and/or v / q scan ) from 2006 to 2010 at three indian tertiary care hospitals.results:acute dvt without pe , acute dvt with pe , and pe alone were reported in 64% ( 352/549 ) , 23% ( 124/549 ) , and 13% ( 73/549 ) patients , respectively .  mean age was 47 ( 16 ) years , and 70% were males .  h / o dvt ( 34% ) , surgery including orthopedic surgery ( 28% ) , trauma ( 16% ) , and immobilization > 3 days ( 14% ) were the most common risk factors for vte .  hypertension ( 25% ) , diabetes ( 19% ) , and neurological disease ( other than stroke ) ( 8% ) were the most common co - morbidities .  most ( 94% ) were treated with heparin alone ( 82% ) or fondaparinux ( 2% ) for initial anticoagulation ; low molecular weight heparin alone ( 5% ) or warfarin / acenocoumarol ( 76% ) for long - term anticoagulation .  anticoagulant treatment was stopped because of bleeding in 2% ( 9/515 ) patients .  mortality was 7% among patients diagnosed with vte during hospital stay versus 1% in those hospitalized with diagnosed vte .  the annual incidence of dvt ( pe ) increased from 2006 to 2010.conclusion:acute dvt alone was responsible for the substantial burden of vte in indian patients .  bleeding was not the limiting factor for anticoagulant treatment in most patients . '"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "kqqGslfcPh3n",
        "outputId": "3a1f7c53-1654-4bc5-ff72-ce407ea4d6f4"
      },
      "source": [
        "\"\".join(data[0]['article_text'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"approximately , one - third of patients with symptomatic vte manifests pe , whereas two - thirds manifest dvt alone .both dvt and pe can be clinically silent ( asymptomatic ) and hence not suspected .if undiagnosed , asymptomatic vte can lead to chronic venous disease or recurrent vte and long - term debilitating sequelae such as postthrombotic syndrome and chronic thromboembolic pulmonary hypertension .vte is not only disabling but also prolongs hospital stay and increases the cost of treatment .along with myocardial infarction and arrhythmia ( due to electrolyte imbalance ) , pe is one of the commonest causes of sudden unexplained deaths in hospitalized patients .it is estimated that 20 million cases of lower extremity dvt occur in the usa alone .the prevailing notion that the incidence of vte in asians is less than that in the western population has been disproved by recent studies .the incidence of postoperative dvt in indian patients undergoing major lower limb surgery is as high ( 43.2% and 60% patients in the groups with and without prophylaxis , respectively ) as seen in the western world .given the growing burden of vte in india and lack of substantial indian data on characteristics of vte patients , use of diagnostics tools , prophylaxis , treatment options , and clinical outcomes in vte , there was a need to systematically collect such data .data on patient characteristics , clinical outcomes , predictors of mortality in acute dvt , management strategies and temporal trends in vte .the intent was to collect and provide data that would reflect actual day - to - day clinical practice , rather than results of highly controlled clinical trials with restricted study populations and imposed experimental intervention .consecutive medical records of inpatients and outpatients between january 2006 and december 2010 , meeting eligibility criteria ( confirmed diagnosis of acute or acute - on - chronic dvt by doppler ultrasound scan and/or pe by chest computed tomography scan , pulmonary angiography or v / q scan ) were identified and collected from the general medical records and/or radiology departments at each of the three participating hospitals .hospital data were used to obtain the total number of patients who were annually registered at the hospital from 2006 to 2010 .data were processed and analyzed using sas ( version 9.1 , statistical analysis system ) . for the purpose of analysis ,  acute - on - chronic descriptive statistics were used to present patient characteristics , management strategies , and clinical outcomes of patients .annual incidence rates ( 95% ci ) of vte per 100,000 hospital registrations over a period of 5 years were reported for each site .fisher 's exact test was used to determine differences in the incidence of acute dvt ( pe ) over the years 20062010 .armitage trend test was used to examine the direction ( positive or negative ) of the trend . as primary analysesthe remaining 41% ( 393/949 ) medical records were not included because they did not satisfy the inclusion criteria .data from seven patients were excluded as there was no radiologically confirmed diagnosis of pe .a total of 64% ( 352/549 ) patients had acute dvt without pe , 23% ( 124/549 ) had acute dvt with pe , and 13% ( 73/549 ) had pe .eighty - seven percent ( 476/549 ) of patients had acute dvt ( pe ) , and 36% ( 197/549 ) had pe (  acute dvt ) [ figure 1 ] .overall distribution of venous thromboembolism patients ( n = 549 ) a total of 21% ( 115/549 ) of patients visited the hospitals directly without being referred by a physician .venous thromboembolism patients referred from different medical specialties ( n=434 ) the demographic characteristics of the vte patients are mentioned in table 2 .demographic characteristics of venous thromboembolism patients ( n=549 ) a total of 182 patients had evidence of one risk factor , 126 had evidence of two risk factors , 70 had evidence of three risk factors and 31 had four or more risk factors recorded .patients undergoing orthopedic surgery constituted 22% ( 33/152 ) of all surgical patients [ table 3 ] .risk factors for venous thromboembolism based on a review of the available records , 157 patients had a single co - morbidity , 81 had two co - morbidities , 23 had three co - morbidities , and 16 had four or more co - morbidities .( myocardial infarction , heart failure , chronic obstructive pulmonary disease , ventilator dependency , sepsis , or pneumonia ) [ table 4 ] .co - morbidities in venous thromboembolism patients of the 476 patients with dvt , 2% ( 9 ) had upper extremity dvt , 97% ( 462 ) had lower extremity dvt and the site of dvt was not known in 5 patients .a total of 31% ( 143/462 ) patients had dvt in the right limb , 54% ( 249/462 ) in the left limb and 9% ( 41/462 ) in both limbs ( site not known in 29 patients ) .of the 462 patients with lower extremity dvt , 61% had proximal dvt , 13% had distal dvt , and 7% had proximal and distal dvt .a total of 39% ( 215/549 ) patients were diagnosed with vte during their hospital stay , 54% ( 296/549 ) were admitted to hospital with a diagnosis of vte , and 7% ( 38/549 ) were diagnosed and continued to be managed in the outpatient department [ figure 2 ] .place of detection of venous thromboembolism ( n = 549 ) duration of hospitalization after diagnosis of venous thromboembolism a smaller proportion of patients ( 15% ; 81/549 ) was diagnosed with vte during the postoperative period .figure 3 shows the proportion of patients with vte at different time points during the postoperative period .of those diagnosed beyond 6 weeks , 21% ( 3/14 ) had orthopedic surgery ( hip fracture surgery ) .diagnosis of venous thromboembolism during the postoperative period ( n = 81 ) the most common ( 73% ) symptom was  swelling of the limb  among patients with vte [ table 6 ] .symptoms in venous thromboembolism patients in merely 4% of all the patients , dvt was also confirmed by venography .pe was confirmed by pulmonary angiography in 27% of all the patients [ table 7 ] .. heparin ( low molecular weight heparin [ lmwh]/unfractionated heparin [ ufh ] ) alone , a combination of heparin ( lmwh / ufh ) and oral anticoagulant ( warfarin ) , and fondaparinux sodium alone were recommended to 82% ( 420/515 ) , 13% ( 66/515 ) , and 2% ( 12/515 ) patients , respectively as initial anticoagulation .five percent ( 25/515 ) of patients were recommended lmwh alone , and 76% ( 393/515 ) were recommended either warfarin or acenocoumarol alone for long - term anticoagulation .the median duration of initial anticoagulation was 5 days while that of long - term anticoagulation was 180 days ( 6 months ) .anticoagulants were needed to be stopped because of bleeding in only 2% ( 9/515 ) patients .clinical outcomes in patients diagnosed with venous thromboembolism during hospital stay clinical outcomes in patients admitted to hospital with a diagnosis of venous thromboembolism the annual incidence of acute dvt ( pe ) increased from 2006 to 2010 at all the three sites [ figure 4 ] .however , a formal site - wise statistical analysis could not be performed to analyse trends in the incidence rates in acute dvt ( pe ) and pe alone as there were zero observations in some instances .incidence of acute deep vein thrombosis ( with or without pulmonary embolism ) over a 5 years period ( 20062010 ) at three sitesdemographic characteristics of venous thromboembolism patients ( n=549 ) a total of 182 patients had evidence of one risk factor , 126 had evidence of two risk factors , 70 had evidence of three risk factors and 31 had four or more risk factors recorded .patients undergoing orthopedic surgery constituted 22% ( 33/152 ) of all surgical patients [ table 3 ] .risk factors for venous thromboembolism based on a review of the available records , 157 patients had a single co - morbidity , 81 had two co - morbidities , 23 had three co - morbidities , and 16 had four or more co - morbidities .( myocardial infarction , heart failure , chronic obstructive pulmonary disease , ventilator dependency , sepsis , or pneumonia ) [ table 4 ] .2% ( 9 ) had upper extremity dvt , 97% ( 462 ) had lower extremity dvt and the site of dvt was not known in 5 patients .a total of 31% ( 143/462 ) patients had dvt in the right limb , 54% ( 249/462 ) in the left limb and 9% ( 41/462 ) in both limbs ( site not known in 29 patients ) . of the 462 patients with lower extremity dvt, 61% had proximal dvt , 13% had distal dvt , and 7% had proximal and distal dvt .a total of 39% ( 215/549 ) patients were diagnosed with vte during their hospital stay , 54% ( 296/549 ) were admitted to hospital with a diagnosis of vte , and 7% ( 38/549 ) were diagnosed and continued to be managed in the outpatient department [ figure 2 ] .place of detection of venous thromboembolism ( n = 549 ) duration of hospitalization after diagnosis of venous thromboembolism a smaller proportion of patients ( 15% ; 81/549 ) was diagnosed with vte during the postoperative period .figure 3 shows the proportion of patients with vte at different time points during the postoperative period . of those diagnosed beyond 6 weeksdiagnosis of venous thromboembolism during the postoperative period ( n = 81 ) the most common ( 73% ) symptom was  swelling of the limb  among patients with vte [ table 6 ] .a total of 182 patients had evidence of one risk factor , 126 had evidence of two risk factors , 70 had evidence of three risk factors and 31 had four or more risk factors recorded .patients undergoing orthopedic surgery constituted 22% ( 33/152 ) of all surgical patients [ table 3 ] .based on a review of the available records , 157 patients had a single co - morbidity , 81 had two co - morbidities , 23 had three co - morbidities , and 16 had four or more co - morbidities .( myocardial infarction , heart failure , chronic obstructive pulmonary disease , ventilator dependency , sepsis , or pneumonia ) [ table 4 ] .of the 476 patients with dvt , 2% ( 9 ) had upper extremity dvt , 97% ( 462 ) had lower extremity dvt and the site of dvt was not known in 5 patients .a total of 31% ( 143/462 ) patients had dvt in the right limb , 54% ( 249/462 ) in the left limb and 9% ( 41/462 ) in both limbs ( site not known in 29 patients ) .of the 462 patients with lower extremity dvt , 61% had proximal dvt , 13% had distal dvt , and 7% had proximal and distal dvt .a total of 39% ( 215/549 ) patients were diagnosed with vte during their hospital stay , 54% ( 296/549 ) were admitted to hospital with a diagnosis of vte , and 7% ( 38/549 ) were diagnosed and continued to be managed in the outpatient department [ figure 2 ] .place of detection of venous thromboembolism ( n = 549 ) duration of hospitalization after diagnosis of venous thromboembolism a smaller proportion of patients ( 15% ; 81/549 ) was diagnosed with vte during the postoperative period .figure 3 shows the proportion of patients with vte at different time points during the postoperative period . of those diagnosed beyond 6 weeksdiagnosis of venous thromboembolism during the postoperative period ( n = 81 ) the most common ( 73% ) symptom was  swelling of the limb  among patients with vte [ table 6 ]pe was confirmed by pulmonary angiography in 27% of all the patients [ table 7 ] .heparin ( low molecular weight heparin [ lmwh]/unfractionated heparin [ ufh ] ) alone , a combination of heparin ( lmwh / ufh ) and oral anticoagulant ( warfarin ) , and fondaparinux sodium alone were recommended to 82% ( 420/515 ) , 13% ( 66/515 ) , and 2% ( 12/515 ) patients , respectively as initial anticoagulation .five percent ( 25/515 ) of patients were recommended lmwh alone , and 76% ( 393/515 ) were recommended either warfarin or acenocoumarol alone for long - term anticoagulation .the median duration of initial anticoagulation was 5 days while that of long - term anticoagulation was 180 days ( 6 months ) .anticoagulants were needed to be stopped because of bleeding in only 2% ( 9/515 ) patients .clinical outcomes in patients diagnosed with venous thromboembolism during hospital stay clinical outcomes in patients admitted to hospital with a diagnosis of venous thromboembolism the annual incidence of acute dvt ( pe ) increased from 2006 to 2010 at all the three sites [ figure 4 ] .however , a formal site - wise statistical analysis could not be performed to analyse trends in the incidence rates in acute dvt ( pe ) and pe alone as there were zero observations in some instances .incidence of acute deep vein thrombosis ( with or without pulmonary embolism ) over a 5 years period ( 20062010 ) at three sitespe was confirmed by pulmonary angiography in 27% of all the patients [ table 7 ] .heparin ( low molecular weight heparin [ lmwh]/unfractionated heparin [ ufh ] ) alone , a combination of heparin ( lmwh / ufh ) and oral anticoagulant ( warfarin ) , and fondaparinux sodium alone were recommended to 82% ( 420/515 ) , 13% ( 66/515 ) , and 2% ( 12/515 ) patients , respectively as initial anticoagulation .five percent ( 25/515 ) of patients were recommended lmwh alone , and 76% ( 393/515 ) were recommended either warfarin or acenocoumarol alone for long - term anticoagulation .the median duration of initial anticoagulation was 5 days while that of long - term anticoagulation was 180 days ( 6 months ) .anticoagulants were needed to be stopped because of bleeding in only 2% ( 9/515 ) patients .clinical outcomes in patients diagnosed with venous thromboembolism during hospital stay clinical outcomes in patients admitted to hospital with a diagnosis of venous thromboembolismthe annual incidence of acute dvt ( pe ) increased from 2006 to 2010 at all the three sites [ figure 4 ] .however , a formal site - wise statistical analysis could not be performed to analyse trends in the incidence rates in acute dvt ( pe ) and pe alone as there were zero observations in some instances .incidence of acute deep vein thrombosis ( with or without pulmonary embolism ) over a 5 years period ( 20062010 ) at three sitesto our knowledge , this is the first multicenter , retrospective registry in india involving patients with vte that reflect real - world clinical practice . in contrast with the western data in which vte is predominantly a disease of older age , 44% patients in our study were between 40 and 59 years of age while 34% were below 40 years , particularly those with pe . in a study from north india ,men constituted 70% of our registry , more than those reported from vellore registry ( 48% ) , but similar to those reported in the endorse ( epidemiologic international day for the evaluation of patients at risk for vte in the acute hospital care setting ) study ( 69% ) .one of the reasons for this could be significantly high levels of homocysteine ( thrombophilia marker ) in males as compared to females as reported in an indian study .fewer indian women use oral contraceptives and postmenopausal hormone replacement therapy , which are known to be risk factors for thrombosis .this is supported by the fact that only 1% of women in this registry reported the use of oral contraceptives , and none reported use of hormonal replacement therapy .a total of 28% of the overall referrals were from cardiologists . the majority ( 82% ) of the referrals were from medical rather than surgical ( 15% ) specialties as against a referral rate of 93% from surgeons at vellore .our finding complements that from the endorse study in which 55% of the medical patients at risk of vte had cardiovascular disease . majority ( 53% ) of patients in our study had co - morbid cardiovascular disease including diabetes mellitus ; it is possible that these patients visited a cardiologist for their cardiovascular ailment ( s ) and were then referred by the cardiologist to vascular disease specialist ( investigator ) .most ( 89% ) of these patients had swelling of the ( lower ) limb .it is possible that these patients may not have felt the need to visit a specialist for a symptom like  swelling of limb ,  instead visited their family physician .it is very encouraging to know that family physicians suspected dvt in these situations and referred the patient to a specialist .patients with a history of vte are about 8 times more likely to develop a new episode during a subsequent high - risk period compared with patients without a history of dvt or pe .prior history of dvt was the most ( 34% ) common risk factor in patients who had only dvt , whereas past history of pe , trauma , and immobilization for more than 3 days were the most common risk factors in patients who had only pe .our results ( major lower limb surgery as a risk factor in 3% patients ) appear to be consistent with those reported in the endorse study , which reported dvt in 4.4% patients undergoing major lower limb surgery .other studies from india have reported a dvt incidence rate ranging from 8% to 20% in major lower limb surgery .however , in our study , only 7% of patients had malignancy as a predisposing factor . among the malignancies , genitourinary cancer had the highest incidence ( 45% ) .hypertension ( 25% ) was the most common co - morbidity followed by diabetes mellitus ( 19% ) in this patient population .in addition , obesity ( 11% ) was a common risk factor in dvt complicated by pe .our findings support an asian ( korean ) study that demonstrated prevalence of the metabolic syndrome in 48% patients with vte .co - morbid neurological disease ( other than stroke ) and ventilator dependency were also commonly found in patients with dvt ( 10% ) and pe ( 11% ) respectively .both these conditions immobilize patients for prolonged periods of time , predisposing them to vte .venography and pulmonary angiography are the gold standard for diagnosis of dvt and pe respectively . in our study, venography was used in just 4% patients and pulmonary angiography in less than one - third of the patients .perhaps the relatively high cost of these tests and limited availability of such procedures may be the limiting factors .overall , most ( 93% ) patients were managed as inpatients ( 39% diagnosed with vte during hospital stay and 54% admitted to hospital with a diagnosis of vte ) .a mean duration of hospitalization of 79 days after diagnosis of vte is supported by published data . in selected low - risk patients , outpatient treatment of dvt and pe may be considered .this approach was observed in a small proportion ( 7% ) of patients who were managed on an outpatient basis , nearly all ( 97% ) of whom had only dvt .the reported prevalence of postsurgical vte in our study ( 15% ) was half of that ( 30% ) reported in vellore registry .this could be explained by higher referral rate from surgeons at vellore compared to that of our sites .most ( 40% ; 32/81 ) dvt cases were diagnosed between 2 and 6 postoperative weeks , but pe in most cases ( 70% ; 7/10 ) was diagnosed during the first postoperative week .we notice that acute dvt complicated by pe was less ( 6% ; 7/124 ) frequently diagnosed during the postoperative period as against 18% ( 64/352 ) and 14% ( 10/73 ) of acute dvt alone and pe alone , respectively .the use and duration of anticoagulants in our registry appears to be consistent with the american college of chest physicians treatment guidelines , which recommend at least 5 days of initial anticoagulation with parenteral anticoagulation ( lmwh , fondaparinux , intravenous ufh , or subcutaneous ufh ) and at least 3 months of long - term anticoagulation treatment with vitamin k antagonist .bleeding is the most serious complication of anticoagulation treatment and is a major concern for clinicians particularly as the patient 's age advances . in this registry ,anticoagulant treatment was needed to be stopped because of bleeding in only 2% of the study population .the prospective reite registry has reported a rate of 3% for major / fatal bleeds .thus , the fear of bleeding complications , which decreases the use of anticoagulant treatment , appears to be minimal .dvt complicated by pe ( 60% ) and pe alone ( 75% ) were more frequently shifted to intensive care unit than those who had dvt alone ( 25% ) . similar to published data in which hospital readmission rate for vte was 5% for primary and 14% for secondary diagnosis , we report a hospital readmission rate of 6% ; however we do not know the cause for readmission .the death rate was 7% among those diagnosed with vte during hospital stay as against a rate of 1% among those who were hospitalized with a diagnosis of vte .over 90% of patients treated on an outpatient basis obtained symptomatic relief with treatment . in our study , the hospital discharge rate ( 97% ) was more than triple and death rate was a quarter of that reported by pandey et al .( hospital discharge rate 31% and death rate 16% ) at a university hospital in delhi .our data show a significant increase in acute dvt ( pe ) from 2006 to 2010 .this can be explained by the increased awareness of vte in india as well as the advent of better diagnostic modalities , such as duplex ultrasonography becoming more readily available and accepted .although there was no significant change in the number of pe cases from 2006 to 2010 , the burden of pe is almost double ( 13% of all vte ) of 7% , rate reported at christian medical college , vellore during a 10-year period from 1996 to 2005 .our finding is consistent with a study from north india that reported a 16% incidence of pe in adult medical autopsies .this study has the expected limitations of any retrospective review including the availability of complete records for all patients , although a robust review of the data on medical charts was conducted .controlling for bias and confounders is difficult as there is no randomization and no blinding .follow - up data of patients after hospital discharge were not available . in cases of death ,further , the clinic charts reviewed in this study included a mix of those from vascular surgery and hematology departments , limiting the generalizability of the study results . despite these limitations ,this study provides large amount of useful information in a short span of time on patient characteristics , clinical outcomes , management strategies , and temporal trends in vte , based on  real world data that reflect actual day - to - day clinical practice over a period of 5 years across three sites in india .we believe that this information will serve as a guide in the optimal implementation of vte prophylaxis and treatment , to improve patient outcomes and to decrease the occurrence of vte in india .real world data reflecting actual day - to - day clinical practice in vte over a period of 5 years across three sites in india showed that vte is not uncommon in indian patients and that acute dvt was responsible for the substantial burden of vte .we believe that this information will serve as a guide in the optimal implementation of vte prophylaxis and treatment , to improve patient outcomes and to decrease the occurrence of vte in india .liesel c. dsilva is and dr . sadhna j. joglekar was full - time employee of glaxosmithkline pharmaceuticals limited .\""
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK3bTYffQVIp"
      },
      "source": [
        "### Parse the article abstract and body (text)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6oWM1j8Qaiw"
      },
      "source": [
        "final_data = []\n",
        "\n",
        "for article in data:\n",
        "  article_abstract = \"\".join(article['abstract_text']).replace('<S>', '').replace('</S>', '')\n",
        "  article_text = \"\".join(article['article_text'])\n",
        "\n",
        "  final_data.append([article_text, article_abstract])\n",
        "\n",
        "df = pd.DataFrame(final_data, columns=['article_text', 'article_abstract'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "geuLZe9UTgMq",
        "outputId": "d31dda4c-5b5e-4a46-ac92-25b9f1838a28"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-34a2957e-d9ea-4a29-9f27-c130f801afe2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_text</th>\n",
              "      <th>article_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>approximately , one - third of patients with s...</td>\n",
              "      <td>background and aim : there is lack of substan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>there is an epidemic of stroke in low and midd...</td>\n",
              "      <td>backgroundthe questionnaire for verifying str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n cardiovascular diseases account for the hig...</td>\n",
              "      <td>\\n background : timely access to cardiovascul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>results of a liquid culturing system ( bd bact...</td>\n",
              "      <td>to determine differences in the ability of my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the need for magnetic resonance imaging ( mri ...</td>\n",
              "      <td>aimsour aim was to evaluate the potential for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34a2957e-d9ea-4a29-9f27-c130f801afe2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34a2957e-d9ea-4a29-9f27-c130f801afe2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34a2957e-d9ea-4a29-9f27-c130f801afe2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                        article_text                                   article_abstract\n",
              "0  approximately , one - third of patients with s...   background and aim : there is lack of substan...\n",
              "1  there is an epidemic of stroke in low and midd...   backgroundthe questionnaire for verifying str...\n",
              "2  \\n cardiovascular diseases account for the hig...   \\n background : timely access to cardiovascul...\n",
              "3  results of a liquid culturing system ( bd bact...   to determine differences in the ability of my...\n",
              "4  the need for magnetic resonance imaging ( mri ...   aimsour aim was to evaluate the potential for..."
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pg-j4MmQkXPN",
        "outputId": "0ce18742-0fd0-4724-c176-ed5429c86076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['article_text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "joCa_a5dlGWI",
        "outputId": "9b334d3a-c0dc-451e-90c2-1c8e803e7654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"approximately , one - third of patients with symptomatic vte manifests pe , whereas two - thirds manifest dvt alone .both dvt and pe can be clinically silent ( asymptomatic ) and hence not suspected .if undiagnosed , asymptomatic vte can lead to chronic venous disease or recurrent vte and long - term debilitating sequelae such as postthrombotic syndrome and chronic thromboembolic pulmonary hypertension .vte is not only disabling but also prolongs hospital stay and increases the cost of treatment .along with myocardial infarction and arrhythmia ( due to electrolyte imbalance ) , pe is one of the commonest causes of sudden unexplained deaths in hospitalized patients .it is estimated that 20 million cases of lower extremity dvt occur in the usa alone .the prevailing notion that the incidence of vte in asians is less than that in the western population has been disproved by recent studies .the incidence of postoperative dvt in indian patients undergoing major lower limb surgery is as high ( 43.2% and 60% patients in the groups with and without prophylaxis , respectively ) as seen in the western world .given the growing burden of vte in india and lack of substantial indian data on characteristics of vte patients , use of diagnostics tools , prophylaxis , treatment options , and clinical outcomes in vte , there was a need to systematically collect such data .data on patient characteristics , clinical outcomes , predictors of mortality in acute dvt , management strategies and temporal trends in vte .the intent was to collect and provide data that would reflect actual day - to - day clinical practice , rather than results of highly controlled clinical trials with restricted study populations and imposed experimental intervention .consecutive medical records of inpatients and outpatients between january 2006 and december 2010 , meeting eligibility criteria ( confirmed diagnosis of acute or acute - on - chronic dvt by doppler ultrasound scan and/or pe by chest computed tomography scan , pulmonary angiography or v / q scan ) were identified and collected from the general medical records and/or radiology departments at each of the three participating hospitals .hospital data were used to obtain the total number of patients who were annually registered at the hospital from 2006 to 2010 .data were processed and analyzed using sas ( version 9.1 , statistical analysis system ) . for the purpose of analysis ,  acute - on - chronic descriptive statistics were used to present patient characteristics , management strategies , and clinical outcomes of patients .annual incidence rates ( 95% ci ) of vte per 100,000 hospital registrations over a period of 5 years were reported for each site .fisher 's exact test was used to determine differences in the incidence of acute dvt ( pe ) over the years 20062010 .armitage trend test was used to examine the direction ( positive or negative ) of the trend . as primary analysesthe remaining 41% ( 393/949 ) medical records were not included because they did not satisfy the inclusion criteria .data from seven patients were excluded as there was no radiologically confirmed diagnosis of pe .a total of 64% ( 352/549 ) patients had acute dvt without pe , 23% ( 124/549 ) had acute dvt with pe , and 13% ( 73/549 ) had pe .eighty - seven percent ( 476/549 ) of patients had acute dvt ( pe ) , and 36% ( 197/549 ) had pe (  acute dvt ) [ figure 1 ] .overall distribution of venous thromboembolism patients ( n = 549 ) a total of 21% ( 115/549 ) of patients visited the hospitals directly without being referred by a physician .venous thromboembolism patients referred from different medical specialties ( n=434 ) the demographic characteristics of the vte patients are mentioned in table 2 .demographic characteristics of venous thromboembolism patients ( n=549 ) a total of 182 patients had evidence of one risk factor , 126 had evidence of two risk factors , 70 had evidence of three risk factors and 31 had four or more risk factors recorded .patients undergoing orthopedic surgery constituted 22% ( 33/152 ) of all surgical patients [ table 3 ] .risk factors for venous thromboembolism based on a review of the available records , 157 patients had a single co - morbidity , 81 had two co - morbidities , 23 had three co - morbidities , and 16 had four or more co - morbidities .( myocardial infarction , heart failure , chronic obstructive pulmonary disease , ventilator dependency , sepsis , or pneumonia ) [ table 4 ] .co - morbidities in venous thromboembolism patients of the 476 patients with dvt , 2% ( 9 ) had upper extremity dvt , 97% ( 462 ) had lower extremity dvt and the site of dvt was not known in 5 patients .a total of 31% ( 143/462 ) patients had dvt in the right limb , 54% ( 249/462 ) in the left limb and 9% ( 41/462 ) in both limbs ( site not known in 29 patients ) .of the 462 patients with lower extremity dvt , 61% had proximal dvt , 13% had distal dvt , and 7% had proximal and distal dvt .a total of 39% ( 215/549 ) patients were diagnosed with vte during their hospital stay , 54% ( 296/549 ) were admitted to hospital with a diagnosis of vte , and 7% ( 38/549 ) were diagnosed and continued to be managed in the outpatient department [ figure 2 ] .place of detection of venous thromboembolism ( n = 549 ) duration of hospitalization after diagnosis of venous thromboembolism a smaller proportion of patients ( 15% ; 81/549 ) was diagnosed with vte during the postoperative period .figure 3 shows the proportion of patients with vte at different time points during the postoperative period .of those diagnosed beyond 6 weeks , 21% ( 3/14 ) had orthopedic surgery ( hip fracture surgery ) .diagnosis of venous thromboembolism during the postoperative period ( n = 81 ) the most common ( 73% ) symptom was  swelling of the limb  among patients with vte [ table 6 ] .symptoms in venous thromboembolism patients in merely 4% of all the patients , dvt was also confirmed by venography .pe was confirmed by pulmonary angiography in 27% of all the patients [ table 7 ] .. heparin ( low molecular weight heparin [ lmwh]/unfractionated heparin [ ufh ] ) alone , a combination of heparin ( lmwh / ufh ) and oral anticoagulant ( warfarin ) , and fondaparinux sodium alone were recommended to 82% ( 420/515 ) , 13% ( 66/515 ) , and 2% ( 12/515 ) patients , respectively as initial anticoagulation .five percent ( 25/515 ) of patients were recommended lmwh alone , and 76% ( 393/515 ) were recommended either warfarin or acenocoumarol alone for long - term anticoagulation .the median duration of initial anticoagulation was 5 days while that of long - term anticoagulation was 180 days ( 6 months ) .anticoagulants were needed to be stopped because of bleeding in only 2% ( 9/515 ) patients .clinical outcomes in patients diagnosed with venous thromboembolism during hospital stay clinical outcomes in patients admitted to hospital with a diagnosis of venous thromboembolism the annual incidence of acute dvt ( pe ) increased from 2006 to 2010 at all the three sites [ figure 4 ] .however , a formal site - wise statistical analysis could not be performed to analyse trends in the incidence rates in acute dvt ( pe ) and pe alone as there were zero observations in some instances .incidence of acute deep vein thrombosis ( with or without pulmonary embolism ) over a 5 years period ( 20062010 ) at three sitesdemographic characteristics of venous thromboembolism patients ( n=549 ) a total of 182 patients had evidence of one risk factor , 126 had evidence of two risk factors , 70 had evidence of three risk factors and 31 had four or more risk factors recorded .patients undergoing orthopedic surgery constituted 22% ( 33/152 ) of all surgical patients [ table 3 ] .risk factors for venous thromboembolism based on a review of the available records , 157 patients had a single co - morbidity , 81 had two co - morbidities , 23 had three co - morbidities , and 16 had four or more co - morbidities .( myocardial infarction , heart failure , chronic obstructive pulmonary disease , ventilator dependency , sepsis , or pneumonia ) [ table 4 ] .2% ( 9 ) had upper extremity dvt , 97% ( 462 ) had lower extremity dvt and the site of dvt was not known in 5 patients .a total of 31% ( 143/462 ) patients had dvt in the right limb , 54% ( 249/462 ) in the left limb and 9% ( 41/462 ) in both limbs ( site not known in 29 patients ) . of the 462 patients with lower extremity dvt, 61% had proximal dvt , 13% had distal dvt , and 7% had proximal and distal dvt .a total of 39% ( 215/549 ) patients were diagnosed with vte during their hospital stay , 54% ( 296/549 ) were admitted to hospital with a diagnosis of vte , and 7% ( 38/549 ) were diagnosed and continued to be managed in the outpatient department [ figure 2 ] .place of detection of venous thromboembolism ( n = 549 ) duration of hospitalization after diagnosis of venous thromboembolism a smaller proportion of patients ( 15% ; 81/549 ) was diagnosed with vte during the postoperative period .figure 3 shows the proportion of patients with vte at different time points during the postoperative period . of those diagnosed beyond 6 weeksdiagnosis of venous thromboembolism during the postoperative period ( n = 81 ) the most common ( 73% ) symptom was  swelling of the limb  among patients with vte [ table 6 ] .a total of 182 patients had evidence of one risk factor , 126 had evidence of two risk factors , 70 had evidence of three risk factors and 31 had four or more risk factors recorded .patients undergoing orthopedic surgery constituted 22% ( 33/152 ) of all surgical patients [ table 3 ] .based on a review of the available records , 157 patients had a single co - morbidity , 81 had two co - morbidities , 23 had three co - morbidities , and 16 had four or more co - morbidities .( myocardial infarction , heart failure , chronic obstructive pulmonary disease , ventilator dependency , sepsis , or pneumonia ) [ table 4 ] .of the 476 patients with dvt , 2% ( 9 ) had upper extremity dvt , 97% ( 462 ) had lower extremity dvt and the site of dvt was not known in 5 patients .a total of 31% ( 143/462 ) patients had dvt in the right limb , 54% ( 249/462 ) in the left limb and 9% ( 41/462 ) in both limbs ( site not known in 29 patients ) .of the 462 patients with lower extremity dvt , 61% had proximal dvt , 13% had distal dvt , and 7% had proximal and distal dvt .a total of 39% ( 215/549 ) patients were diagnosed with vte during their hospital stay , 54% ( 296/549 ) were admitted to hospital with a diagnosis of vte , and 7% ( 38/549 ) were diagnosed and continued to be managed in the outpatient department [ figure 2 ] .place of detection of venous thromboembolism ( n = 549 ) duration of hospitalization after diagnosis of venous thromboembolism a smaller proportion of patients ( 15% ; 81/549 ) was diagnosed with vte during the postoperative period .figure 3 shows the proportion of patients with vte at different time points during the postoperative period . of those diagnosed beyond 6 weeksdiagnosis of venous thromboembolism during the postoperative period ( n = 81 ) the most common ( 73% ) symptom was  swelling of the limb  among patients with vte [ table 6 ]pe was confirmed by pulmonary angiography in 27% of all the patients [ table 7 ] .heparin ( low molecular weight heparin [ lmwh]/unfractionated heparin [ ufh ] ) alone , a combination of heparin ( lmwh / ufh ) and oral anticoagulant ( warfarin ) , and fondaparinux sodium alone were recommended to 82% ( 420/515 ) , 13% ( 66/515 ) , and 2% ( 12/515 ) patients , respectively as initial anticoagulation .five percent ( 25/515 ) of patients were recommended lmwh alone , and 76% ( 393/515 ) were recommended either warfarin or acenocoumarol alone for long - term anticoagulation .the median duration of initial anticoagulation was 5 days while that of long - term anticoagulation was 180 days ( 6 months ) .anticoagulants were needed to be stopped because of bleeding in only 2% ( 9/515 ) patients .clinical outcomes in patients diagnosed with venous thromboembolism during hospital stay clinical outcomes in patients admitted to hospital with a diagnosis of venous thromboembolism the annual incidence of acute dvt ( pe ) increased from 2006 to 2010 at all the three sites [ figure 4 ] .however , a formal site - wise statistical analysis could not be performed to analyse trends in the incidence rates in acute dvt ( pe ) and pe alone as there were zero observations in some instances .incidence of acute deep vein thrombosis ( with or without pulmonary embolism ) over a 5 years period ( 20062010 ) at three sitespe was confirmed by pulmonary angiography in 27% of all the patients [ table 7 ] .heparin ( low molecular weight heparin [ lmwh]/unfractionated heparin [ ufh ] ) alone , a combination of heparin ( lmwh / ufh ) and oral anticoagulant ( warfarin ) , and fondaparinux sodium alone were recommended to 82% ( 420/515 ) , 13% ( 66/515 ) , and 2% ( 12/515 ) patients , respectively as initial anticoagulation .five percent ( 25/515 ) of patients were recommended lmwh alone , and 76% ( 393/515 ) were recommended either warfarin or acenocoumarol alone for long - term anticoagulation .the median duration of initial anticoagulation was 5 days while that of long - term anticoagulation was 180 days ( 6 months ) .anticoagulants were needed to be stopped because of bleeding in only 2% ( 9/515 ) patients .clinical outcomes in patients diagnosed with venous thromboembolism during hospital stay clinical outcomes in patients admitted to hospital with a diagnosis of venous thromboembolismthe annual incidence of acute dvt ( pe ) increased from 2006 to 2010 at all the three sites [ figure 4 ] .however , a formal site - wise statistical analysis could not be performed to analyse trends in the incidence rates in acute dvt ( pe ) and pe alone as there were zero observations in some instances .incidence of acute deep vein thrombosis ( with or without pulmonary embolism ) over a 5 years period ( 20062010 ) at three sitesto our knowledge , this is the first multicenter , retrospective registry in india involving patients with vte that reflect real - world clinical practice . in contrast with the western data in which vte is predominantly a disease of older age , 44% patients in our study were between 40 and 59 years of age while 34% were below 40 years , particularly those with pe . in a study from north india ,men constituted 70% of our registry , more than those reported from vellore registry ( 48% ) , but similar to those reported in the endorse ( epidemiologic international day for the evaluation of patients at risk for vte in the acute hospital care setting ) study ( 69% ) .one of the reasons for this could be significantly high levels of homocysteine ( thrombophilia marker ) in males as compared to females as reported in an indian study .fewer indian women use oral contraceptives and postmenopausal hormone replacement therapy , which are known to be risk factors for thrombosis .this is supported by the fact that only 1% of women in this registry reported the use of oral contraceptives , and none reported use of hormonal replacement therapy .a total of 28% of the overall referrals were from cardiologists . the majority ( 82% ) of the referrals were from medical rather than surgical ( 15% ) specialties as against a referral rate of 93% from surgeons at vellore .our finding complements that from the endorse study in which 55% of the medical patients at risk of vte had cardiovascular disease . majority ( 53% ) of patients in our study had co - morbid cardiovascular disease including diabetes mellitus ; it is possible that these patients visited a cardiologist for their cardiovascular ailment ( s ) and were then referred by the cardiologist to vascular disease specialist ( investigator ) .most ( 89% ) of these patients had swelling of the ( lower ) limb .it is possible that these patients may not have felt the need to visit a specialist for a symptom like  swelling of limb ,  instead visited their family physician .it is very encouraging to know that family physicians suspected dvt in these situations and referred the patient to a specialist .patients with a history of vte are about 8 times more likely to develop a new episode during a subsequent high - risk period compared with patients without a history of dvt or pe .prior history of dvt was the most ( 34% ) common risk factor in patients who had only dvt , whereas past history of pe , trauma , and immobilization for more than 3 days were the most common risk factors in patients who had only pe .our results ( major lower limb surgery as a risk factor in 3% patients ) appear to be consistent with those reported in the endorse study , which reported dvt in 4.4% patients undergoing major lower limb surgery .other studies from india have reported a dvt incidence rate ranging from 8% to 20% in major lower limb surgery .however , in our study , only 7% of patients had malignancy as a predisposing factor . among the malignancies , genitourinary cancer had the highest incidence ( 45% ) .hypertension ( 25% ) was the most common co - morbidity followed by diabetes mellitus ( 19% ) in this patient population .in addition , obesity ( 11% ) was a common risk factor in dvt complicated by pe .our findings support an asian ( korean ) study that demonstrated prevalence of the metabolic syndrome in 48% patients with vte .co - morbid neurological disease ( other than stroke ) and ventilator dependency were also commonly found in patients with dvt ( 10% ) and pe ( 11% ) respectively .both these conditions immobilize patients for prolonged periods of time , predisposing them to vte .venography and pulmonary angiography are the gold standard for diagnosis of dvt and pe respectively . in our study, venography was used in just 4% patients and pulmonary angiography in less than one - third of the patients .perhaps the relatively high cost of these tests and limited availability of such procedures may be the limiting factors .overall , most ( 93% ) patients were managed as inpatients ( 39% diagnosed with vte during hospital stay and 54% admitted to hospital with a diagnosis of vte ) .a mean duration of hospitalization of 79 days after diagnosis of vte is supported by published data . in selected low - risk patients , outpatient treatment of dvt and pe may be considered .this approach was observed in a small proportion ( 7% ) of patients who were managed on an outpatient basis , nearly all ( 97% ) of whom had only dvt .the reported prevalence of postsurgical vte in our study ( 15% ) was half of that ( 30% ) reported in vellore registry .this could be explained by higher referral rate from surgeons at vellore compared to that of our sites .most ( 40% ; 32/81 ) dvt cases were diagnosed between 2 and 6 postoperative weeks , but pe in most cases ( 70% ; 7/10 ) was diagnosed during the first postoperative week .we notice that acute dvt complicated by pe was less ( 6% ; 7/124 ) frequently diagnosed during the postoperative period as against 18% ( 64/352 ) and 14% ( 10/73 ) of acute dvt alone and pe alone , respectively .the use and duration of anticoagulants in our registry appears to be consistent with the american college of chest physicians treatment guidelines , which recommend at least 5 days of initial anticoagulation with parenteral anticoagulation ( lmwh , fondaparinux , intravenous ufh , or subcutaneous ufh ) and at least 3 months of long - term anticoagulation treatment with vitamin k antagonist .bleeding is the most serious complication of anticoagulation treatment and is a major concern for clinicians particularly as the patient 's age advances . in this registry ,anticoagulant treatment was needed to be stopped because of bleeding in only 2% of the study population .the prospective reite registry has reported a rate of 3% for major / fatal bleeds .thus , the fear of bleeding complications , which decreases the use of anticoagulant treatment , appears to be minimal .dvt complicated by pe ( 60% ) and pe alone ( 75% ) were more frequently shifted to intensive care unit than those who had dvt alone ( 25% ) . similar to published data in which hospital readmission rate for vte was 5% for primary and 14% for secondary diagnosis , we report a hospital readmission rate of 6% ; however we do not know the cause for readmission .the death rate was 7% among those diagnosed with vte during hospital stay as against a rate of 1% among those who were hospitalized with a diagnosis of vte .over 90% of patients treated on an outpatient basis obtained symptomatic relief with treatment . in our study , the hospital discharge rate ( 97% ) was more than triple and death rate was a quarter of that reported by pandey et al .( hospital discharge rate 31% and death rate 16% ) at a university hospital in delhi .our data show a significant increase in acute dvt ( pe ) from 2006 to 2010 .this can be explained by the increased awareness of vte in india as well as the advent of better diagnostic modalities , such as duplex ultrasonography becoming more readily available and accepted .although there was no significant change in the number of pe cases from 2006 to 2010 , the burden of pe is almost double ( 13% of all vte ) of 7% , rate reported at christian medical college , vellore during a 10-year period from 1996 to 2005 .our finding is consistent with a study from north india that reported a 16% incidence of pe in adult medical autopsies .this study has the expected limitations of any retrospective review including the availability of complete records for all patients , although a robust review of the data on medical charts was conducted .controlling for bias and confounders is difficult as there is no randomization and no blinding .follow - up data of patients after hospital discharge were not available . in cases of death ,further , the clinic charts reviewed in this study included a mix of those from vascular surgery and hematology departments , limiting the generalizability of the study results . despite these limitations ,this study provides large amount of useful information in a short span of time on patient characteristics , clinical outcomes , management strategies , and temporal trends in vte , based on  real world data that reflect actual day - to - day clinical practice over a period of 5 years across three sites in india .we believe that this information will serve as a guide in the optimal implementation of vte prophylaxis and treatment , to improve patient outcomes and to decrease the occurrence of vte in india .real world data reflecting actual day - to - day clinical practice in vte over a period of 5 years across three sites in india showed that vte is not uncommon in indian patients and that acute dvt was responsible for the substantial burden of vte .we believe that this information will serve as a guide in the optimal implementation of vte prophylaxis and treatment , to improve patient outcomes and to decrease the occurrence of vte in india .liesel c. dsilva is and dr . sadhna j. joglekar was full - time employee of glaxosmithkline pharmaceuticals limited .\""
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(word_tokenize(df['article_abstract'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J24CvUmVkdfG",
        "outputId": "83b002db-346a-483c-cffb-e0a67ea5a03a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "355"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['article_text'].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4JBqhMTkdZR",
        "outputId": "d35e862c-021a-41a3-eda1-512d7831acef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6633"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum_text = 0\n",
        "sum_abstract = 0\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "  sum_text += len(df['article_text'][idx])\n",
        "  sum_abstract += len(df['article_abstract'][idx])\n",
        "\n",
        "avg_text = sum_text / float(6633)\n",
        "avg_abstract = sum_abstract /float(6633)"
      ],
      "metadata": {
        "id": "8PJSI5CflgvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(avg_text)\n",
        "print(avg_abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAtlC34Rlgpq",
        "outputId": "3e2f0256-7788-4c68-918d-f9d6b3eeb45c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17746.687471732246\n",
            "1235.1302578018997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZHMQZdbkkdVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBoPE2bUd_Fx"
      },
      "source": [
        "df.article_text = 'summarize: ' + df.article_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Hgzc2LjpT2P8",
        "outputId": "e913c46f-c244-4a3d-d1ad-96dcba93cb61"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_text</th>\n",
              "      <th>article_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>summarize: approximately , one - third of pati...</td>\n",
              "      <td>background and aim : there is lack of substan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>summarize: there is an epidemic of stroke in l...</td>\n",
              "      <td>backgroundthe questionnaire for verifying str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>summarize: \\n cardiovascular diseases account ...</td>\n",
              "      <td>\\n background : timely access to cardiovascul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>summarize: results of a liquid culturing syste...</td>\n",
              "      <td>to determine differences in the ability of my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>summarize: the need for magnetic resonance ima...</td>\n",
              "      <td>aimsour aim was to evaluate the potential for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_text                                   article_abstract\n",
              "0  summarize: approximately , one - third of pati...   background and aim : there is lack of substan...\n",
              "1  summarize: there is an epidemic of stroke in l...   backgroundthe questionnaire for verifying str...\n",
              "2  summarize: \\n cardiovascular diseases account ...   \\n background : timely access to cardiovascul...\n",
              "3  summarize: results of a liquid culturing syste...   to determine differences in the ability of my...\n",
              "4  summarize: the need for magnetic resonance ima...   aimsour aim was to evaluate the potential for..."
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPOJZsxHmLxD"
      },
      "source": [
        "### Select which model to fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ1Jw1Q4hqEi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "bed8257b0e7c48aaa4325da5fc56d8f9",
            "97b022039e5b48eb94b03bf241c27bd0",
            "67a7a9d7ddcf4dad9b364a0a2ba69190",
            "6cee6cf66a4e4282aa71bc5ea8dc801f",
            "7eb15f1ab28e4202afb6f3a366574542",
            "c1134ad754424dfabb832c6214fbb189",
            "d7f696795726463484473ce36952928b",
            "f895d852fb974645b0e39d89969691a9",
            "dee1b3349818462fb8b7319a1869a4d6",
            "5ed0fd5d66eb44aa81c9b96e6ef44535",
            "f69e5c6e5236459cb02bfde4db2f8319",
            "9b99acfe1c294038b3a4cfc833cbac97",
            "2889626e358a4e17a6c2b15bb8364c7d",
            "be2bfc3e58794ff7a7fe824cd7e1ce25",
            "0f26bcaf54e74fbabccf0a267ecbc385",
            "dbbe74058db143fd8563e3427d609670",
            "78601a61795944c48b6b401f941c5100",
            "cf0cd602f6234335a0c9fd0f1d444797",
            "849d9d870fd2471aae9dde004a7efe9d",
            "bad96226e59743dabd1a72a81b7fdfcd",
            "9f3f0d8ae1d34608bce0b6b12f3b315f",
            "a688ab790f0340089586dffe62949ba5",
            "be304a2a0b004af0805e0450f20b351e",
            "6a0eba9c2f674b02904d13ea26fdc0f7",
            "bb7eb86abee94853ba39c61cb6d31045",
            "9e6aeee619ca436894b1542ee8d890dd",
            "1793d0b9b8fb4576a894101d5319bb7d",
            "4a64841f4af0463bb134682eac349b6b",
            "0e7bc8e06a91493eadeffb7bae5552b2",
            "731ec3e1d0774649abd2d083e13b654f",
            "32555201991b491a8fd0db9bcf9a5ee6",
            "968648b4af414b169c7d06437f0e8fc7",
            "c41ed0fdc7124ae89431c3cc0b364b78",
            "1fa4eb9f80bf4b80a170c479e0a573f2",
            "6aaad847bdac443ea428b65701b39ce0",
            "ef80fb9f9f1a4b9886005a9d509b6339",
            "09803a6ec4ed49eb8d4e9607fc5da732",
            "ae2978fbe39c4d79b4e168801e2a8b5c",
            "14bd2d3df8134c278ebab4242b505684",
            "2e3df875960a4a2d87df651cdca99051",
            "957d69db5aa9439dab90c791813bde79",
            "7de608fe0be14a96a58c25fe39446fa8",
            "36ea475979264aa388e71e0c84663ef0",
            "a154141130e54a1cba79d37ff50bbd1d"
          ]
        },
        "outputId": "99564934-422a-4c19-bfc2-ec5315778e35"
      },
      "source": [
        "# Sections of config\n",
        "\n",
        "# Defining some key variables that will be used later on in the training\n",
        "\n",
        "#tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "#tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
        "#tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "tokenizer = ProphetNetTokenizer.from_pretrained('microsoft/prophetnet-large-uncased')\n",
        "\n",
        "MAX_LEN = 512\n",
        "SUMMARY_LEN = 150\n",
        "TRAIN_BATCH_SIZE = 2\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 1e-4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bed8257b0e7c48aaa4325da5fc56d8f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b99acfe1c294038b3a4cfc833cbac97",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be304a2a0b004af0805e0450f20b351e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/141 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fa4eb9f80bf4b80a170c479e0a573f2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:341: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "932p8NhxeNw4"
      },
      "source": [
        "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage \n",
        "# for finetuning the model and to prepare it for predictions\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.source_len = source_len\n",
        "        self.summ_len = summ_len\n",
        "        self.article_abstract = self.data.article_abstract\n",
        "        self.article_text = self.data.article_text\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.article_abstract)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        article_text = str(self.article_text[index])\n",
        "        article_text = ' '.join(article_text.split())\n",
        "\n",
        "        article_abstract = str(self.article_abstract[index])\n",
        "        article_abstract = ' '.join(article_abstract.split())\n",
        "\n",
        "        source = self.tokenizer.batch_encode_plus([article_text], max_length= self.source_len, pad_to_max_length=True,return_tensors='pt')\n",
        "        target = self.tokenizer.batch_encode_plus([article_abstract], max_length= self.summ_len, pad_to_max_length=True,return_tensors='pt')\n",
        "\n",
        "\n",
        "        source_ids = source['input_ids'].squeeze()\n",
        "        source_mask = source['attention_mask'].squeeze()\n",
        "        target_ids = target['input_ids'].squeeze()\n",
        "        target_mask = target['attention_mask'].squeeze()\n",
        "\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long), \n",
        "            'source_mask': source_mask.to(dtype=torch.long), \n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70YVNa-YiSHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b67171b-4a0a-401c-b019-5ad74599803f"
      },
      "source": [
        "# Creating the dataset and dataloader for the neural network\n",
        "\n",
        "train_size = 0.8\n",
        "train_dataset=df.sample(frac=train_size,random_state=42).reset_index(drop=True)\n",
        "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
        "testing_set = CustomDataset(test_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (6633, 2)\n",
            "TRAIN Dataset: (5306, 2)\n",
            "TEST Dataset: (1327, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ-Spz29idNS"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': False,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51jKmk2eDINe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "2767fce4b2294ed5840b816993445e51",
            "47798033274049ada1721a5c2b7c48ca",
            "58cee608e0cc43d394e7f13676343f54",
            "8942b43983c0456fbfe90fc1b52b6270",
            "1924706f3d824da7a3081a3c491ea8b0",
            "a91c11b6fc5647ebb26d7711e2dabad1",
            "5de66e9c9f954527a16a4fcb8113fc70",
            "a0140d9098d1483a8817ee1f40b575c5",
            "378ed071814746f68688e03431110b31",
            "9ca4337f27cf4069b63853738698cf6e",
            "b5ccf8a86c304666b6a5f77feeb7734b"
          ]
        },
        "outputId": "a24bc1b3-7b6d-421d-fc37-2ae0a7fbaea1"
      },
      "source": [
        "#model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "#model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')\n",
        "model = ProphetNetForConditionalGeneration.from_pretrained('microsoft/prophetnet-large-uncased', )\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:341: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2767fce4b2294ed5840b816993445e51",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wbgnNFCms1O"
      },
      "source": [
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSRiZPvFiKEV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaPAR7TWmxoM"
      },
      "source": [
        "def train(epoch):\n",
        "  model.train()\n",
        "  for _, data in enumerate(training_loader, 0):\n",
        "    y = data['target_ids'].to(device, dtype = torch.long)\n",
        "    y_ids = y[:, :-1].contiguous()\n",
        "    lm_labels = y[:, 1:].clone().detach()\n",
        "    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "    ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "    mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "\n",
        "    loss = outputs[0]\n",
        "    \n",
        "    if _%500==0:\n",
        "        print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YnHeol8M6lB"
      },
      "source": [
        "def _get_config_file(model_path, model_name):\n",
        "    # Name of the file for storing hyperparameter details\n",
        "    return os.path.join(model_path, model_name + \".config\")\n",
        "\n",
        "def _get_model_file(model_path, model_name):\n",
        "    # Name of the file for storing network parameters\n",
        "    return os.path.join(model_path, model_name + \".tar\")\n",
        "\n",
        "def load_model(model_path, model_name, net=None):\n",
        "    \"\"\"\n",
        "    Loads a saved model from disk.\n",
        "\n",
        "    Inputs:\n",
        "        model_path - Path of the checkpoint directory\n",
        "        model_name - Name of the model (str)\n",
        "        net - (Optional) If given, the state dict is loaded into this model. Otherwise, a new model is created.\n",
        "    \"\"\"\n",
        "    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n",
        "    assert os.path.isfile(config_file), f\"Could not find the config file \\\"{config_file}\\\". Are you sure this is the correct path and you have your model config stored here?\"\n",
        "    assert os.path.isfile(model_file), f\"Could not find the model file \\\"{model_file}\\\". Are you sure this is the correct path and you have your model stored here?\"\n",
        "    with open(config_file, \"r\") as f:\n",
        "        config_dict = json.load(f)\n",
        "    if net is None:\n",
        "        act_fn_name = config_dict[\"act_fn\"].pop(\"name\").lower()\n",
        "        act_fn = act_fn_by_name[act_fn_name](**config_dict.pop(\"act_fn\"))\n",
        "        net = BaseNetwork(act_fn=act_fn, **config_dict)\n",
        "    net.load_state_dict(torch.load(model_file, map_location=device))\n",
        "    return net\n",
        "\n",
        "def save_model(model, model_path, model_name):\n",
        "    \"\"\"\n",
        "    Given a model, we save the state_dict and hyperparameters.\n",
        "\n",
        "    Inputs:\n",
        "        model - Network object to save parameters from\n",
        "        model_path - Path of the checkpoint directory\n",
        "        model_name - Name of the model (str)\n",
        "    \"\"\"\n",
        "    config_dict = model.config\n",
        "    os.makedirs(model_path, exist_ok=True)\n",
        "    config_file, model_file = _get_config_file(model_path, model_name), _get_model_file(model_path, model_name)\n",
        "    with open(config_file, \"w\") as f:\n",
        "        json.dump(config_dict, f)\n",
        "    torch.save(model.state_dict(), model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63b-GkN0LiTh"
      },
      "source": [
        "### Call to the train method above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TffFhezb3EDO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFAfLq7WoPqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c07185-2393-4d32-bbba-bd1f00702689"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  train(epoch)\n",
        "\n",
        "#########################\n",
        "# save the trained pytorch model----change the named of the model in accordance with the baseline model currently being worked on\n",
        "model_name = \"pubmed-Prophetnet\"    # changes with each baseline model or the proposed approach's name\n",
        "model_path = f\"pubmed-pytorch_models\"\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "# Save entire model\n",
        "# Specify a path\n",
        "model_path = f\"pubmed-pytorch_models/{model_name}.pt\"\n",
        "torch.save(model, model_path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2218: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss:  4.889352798461914\n",
            "Epoch: 0, Loss:  4.417749881744385\n",
            "Epoch: 0, Loss:  4.777266025543213\n",
            "Epoch: 0, Loss:  5.323818683624268\n",
            "Epoch: 0, Loss:  4.716580867767334\n",
            "Epoch: 0, Loss:  4.053532600402832\n",
            "Epoch: 1, Loss:  4.166281700134277\n",
            "Epoch: 1, Loss:  3.9656007289886475\n",
            "Epoch: 1, Loss:  4.206107139587402\n",
            "Epoch: 1, Loss:  4.481459617614746\n",
            "Epoch: 1, Loss:  4.732577323913574\n",
            "Epoch: 1, Loss:  3.566321611404419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVOANlRiPRvv"
      },
      "source": [
        "## Saving the model as a checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9WCdSgEz1r3"
      },
      "source": [
        "#model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
        "#model = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n",
        "#model = PegasusForConditionalGeneration.from_pretrained('google/pegasus-xsum')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957
        },
        "id": "1JNHDT-M2Jb_",
        "outputId": "42122cf6-dbe6-416d-9e4c-65ef3875544f"
      },
      "source": [
        "!pip3 install torch==1.7.0\n",
        "!pip3 install git+https://github.com/huggingface/transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (1.19.5)\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-3z0_743t\n",
            "  Running command git clone -q https://github.com/huggingface/transformers /tmp/pip-req-build-3z0_743t\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Using cached tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (3.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.0.46)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.62.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (4.8.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (0.1.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.13.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.13.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.13.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.13.0.dev0) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.13.0.dev0) (1.25.11)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.13.0.dev0) (1.15.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.13.0.dev0-py3-none-any.whl size=3101540 sha256=6eb76432068b2d04117e815d98103868d04fc2b0f40f3a8ed600aa97f8534f5d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qyjjme4q/wheels/35/2e/a7/d819e3310040329f0f47e57c9e3e7a7338aa5e74c49acfe522\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.5.2\n",
            "    Uninstalling tokenizers-0.5.2:\n",
            "      Successfully uninstalled tokenizers-0.5.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 2.8.0\n",
            "    Uninstalling transformers-2.8.0:\n",
            "      Successfully uninstalled transformers-2.8.0\n",
            "Successfully installed tokenizers-0.10.3 transformers-4.13.0.dev0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tokenizers",
                  "transformers"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7oFbfS30rgX"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19Rv8xAzPArS"
      },
      "source": [
        "modelName = \"Pegasus\"\n",
        "model_name = f\"pubmed-{modelName}\"\n",
        "\n",
        "# model path\n",
        "model_path = f\"../entity_sum/pubmed-pytorch_models/{model_name}.pt\"\n",
        "\n",
        "model = torch.load(model_path)\n",
        "\n",
        "os.makedirs(f'{modelName}-checkpoints')\n",
        "model.save_pretrained(f'../entity_sum/{modelName}-checkpoints/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqDzYgwqX3Ee"
      },
      "source": [
        "### Saving/Loading entire model to the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfF80XCt_Xom"
      },
      "source": [
        "# save the trained pytorch model----change the named of the model in accordance with the baseline model currently being worked on\n",
        "from torchvision import models\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "model_name = \"pubmed-T5\"\n",
        "model_path = f\"pubmed-pytorch_models\"\n",
        "\n",
        "# model path\n",
        "#model_path = f\"pubmed-pytorch_models/{model_name}.pth\"\n",
        "model_path = f\"pubmed-pytorch_models/{model_name}.pt\"\n",
        "\n",
        "\n",
        "#model = model.load_state_dict(torch.load(model_path))\n",
        "model = torch.load(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8VifEk5dDjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5959f6de-4fc2-4be5-e0fc-8648ee515491"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (3): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (5): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (6): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (7): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (8): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (9): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (10): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (11): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseReluDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDdBEegPuwiC",
        "outputId": "fe5ab9f4-097a-4ac6-9e6d-716790dfc519"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('shared.weight',\n",
              "              tensor([[ -0.7576,   0.6001,  -2.4332,  ...,   1.2522,  -0.7822,   3.5235],\n",
              "                      [ 11.3739,  -4.8733,   9.0615,  ...,   4.8424,  14.3902,  -5.7711],\n",
              "                      [-16.6135,  11.0992, -20.8572,  ...,  10.6604,  22.2536,  24.9938],\n",
              "                      ...,\n",
              "                      [  2.2344,   6.7500, -11.0625,  ..., -11.3125,  13.5625,  16.6250],\n",
              "                      [  4.2500,   5.1250, -12.2500,  ..., -11.9375,  13.5000,  17.0000],\n",
              "                      [  4.0625,   6.9688, -12.2500,  ..., -11.3750,  11.9375,  16.6250]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.embed_tokens.weight',\n",
              "              tensor([[ -0.7576,   0.6001,  -2.4332,  ...,   1.2522,  -0.7822,   3.5235],\n",
              "                      [ 11.3739,  -4.8733,   9.0615,  ...,   4.8424,  14.3902,  -5.7711],\n",
              "                      [-16.6135,  11.0992, -20.8572,  ...,  10.6604,  22.2536,  24.9938],\n",
              "                      ...,\n",
              "                      [  2.2344,   6.7500, -11.0625,  ..., -11.3125,  13.5625,  16.6250],\n",
              "                      [  4.2500,   5.1250, -12.2500,  ..., -11.9375,  13.5000,  17.0000],\n",
              "                      [  4.0625,   6.9688, -12.2500,  ..., -11.3750,  11.9375,  16.6250]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0765, -0.0555,  0.0318,  ...,  0.0127, -0.0441, -0.0502],\n",
              "                      [ 0.0373, -0.0069, -0.0082,  ..., -0.0150, -0.0329, -0.0114],\n",
              "                      [-0.0057, -0.0186, -0.0293,  ..., -0.0283,  0.0554, -0.0529],\n",
              "                      ...,\n",
              "                      [ 0.0140, -0.0585,  0.0413,  ...,  0.0446,  0.0331, -0.0168],\n",
              "                      [-0.0097,  0.0266, -0.0343,  ...,  0.0337, -0.0482, -0.0361],\n",
              "                      [-0.0332,  0.0478,  0.0134,  ..., -0.0210,  0.0498, -0.0246]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.5375, -0.2085, -0.0156,  ...,  0.0928, -0.7496,  0.0856],\n",
              "                      [ 0.3751,  0.1621,  0.1363,  ..., -0.3096, -0.1824, -0.3429],\n",
              "                      [-0.0419, -0.1253,  0.0091,  ..., -0.1141,  0.2633, -0.5768],\n",
              "                      ...,\n",
              "                      [ 0.5001, -0.0539,  0.2575,  ...,  0.2431,  0.2063, -0.0094],\n",
              "                      [-0.1892,  0.5717,  0.2296,  ..., -0.5325,  0.4816,  0.1264],\n",
              "                      [ 0.0993,  0.1887,  0.1351,  ..., -0.0472,  0.0423, -0.2207]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-0.4241,  0.8833, -0.3660,  ...,  0.3354, -0.0127, -0.2407],\n",
              "                      [ 0.2174,  0.0171,  0.0275,  ..., -0.2779,  0.2101,  0.1020],\n",
              "                      [ 0.3235, -0.6925,  0.1381,  ...,  0.2114,  0.2874,  0.3293],\n",
              "                      ...,\n",
              "                      [-0.0874, -0.2660, -0.1613,  ...,  0.1114,  0.0111, -0.2652],\n",
              "                      [-0.4233,  0.3574,  0.4985,  ...,  0.0532,  0.2760,  0.0409],\n",
              "                      [-0.2792, -0.1030,  0.2950,  ...,  0.0078, -0.1735, -0.1133]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 0.5104, -0.1825, -0.5007,  ...,  0.2950,  0.1529, -0.3024],\n",
              "                      [-0.9133, -0.0435,  0.6917,  ...,  0.2470, -0.2760, -0.4495],\n",
              "                      [ 0.2922, -0.0487, -0.1816,  ...,  0.3639,  0.7045,  0.3489],\n",
              "                      ...,\n",
              "                      [-0.3393,  0.0497, -0.2575,  ..., -0.1669, -0.1949,  0.0042],\n",
              "                      [-0.0597, -0.0152, -0.5680,  ...,  0.3081,  0.0440, -0.7330],\n",
              "                      [ 0.3355, -0.3097, -0.4701,  ..., -0.0904,  0.0692,  0.2686]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
              "              tensor([[ 2.8911e+00, -3.1777e+00, -3.3636e-01, -4.3507e-02, -5.7253e+00,\n",
              "                        3.4354e+00, -1.7126e+01, -8.0671e+00,  3.0321e-01, -2.0924e-01,\n",
              "                        8.0568e-01, -8.6834e+00],\n",
              "                      [ 5.5354e-01,  6.4473e+00,  3.4418e+00,  1.7155e+00,  2.9891e+00,\n",
              "                        9.4703e-01, -5.2484e+00,  3.3921e+00,  6.0022e+00, -2.7125e+01,\n",
              "                       -5.1840e+00, -8.4901e-01],\n",
              "                      [ 5.2928e-01,  3.8286e+00,  3.1379e+00,  1.9677e+00,  3.0459e+00,\n",
              "                        5.8419e-01,  1.4080e-01,  3.6083e+00,  5.1519e+00, -1.2616e+01,\n",
              "                       -2.1369e+00,  1.7043e-01],\n",
              "                      [ 4.6412e-01,  2.4010e+00,  2.9627e+00,  1.9236e+00,  2.9535e+00,\n",
              "                        4.2885e-01,  9.3738e-01,  3.5197e+00,  4.4430e+00, -2.1750e+01,\n",
              "                       -1.8006e+00,  7.2329e-01],\n",
              "                      [ 4.4273e-01,  1.4797e+00,  2.7952e+00,  1.8234e+00,  2.8962e+00,\n",
              "                        3.2968e-01,  1.2638e+00,  3.3873e+00,  3.8932e+00, -4.1853e+00,\n",
              "                       -1.7142e+00,  8.8281e-01],\n",
              "                      [ 3.9793e-01,  7.3826e-01,  2.5881e+00,  1.7722e+00,  2.8240e+00,\n",
              "                        2.8257e-01,  1.4597e+00,  3.2305e+00,  3.4452e+00, -3.7514e+00,\n",
              "                       -1.7536e+00,  1.0607e+00],\n",
              "                      [ 3.5351e-01,  2.3752e-01,  2.5055e+00,  1.6338e+00,  2.7291e+00,\n",
              "                        2.4557e-01,  1.5299e+00,  3.1461e+00,  3.0625e+00, -3.9572e+00,\n",
              "                       -1.7328e+00,  1.1415e+00],\n",
              "                      [ 3.4203e-01, -1.1279e-01,  2.3921e+00,  1.5913e+00,  2.6879e+00,\n",
              "                        1.4240e-01,  1.6310e+00,  3.0659e+00,  2.7761e+00, -3.8798e+00,\n",
              "                       -1.8090e+00,  1.2289e+00],\n",
              "                      [ 2.9301e-01, -7.1418e-01,  2.1455e+00,  1.4257e+00,  2.5491e+00,\n",
              "                        1.1245e-01,  1.7612e+00,  2.7329e+00,  2.0075e+00, -4.1242e+00,\n",
              "                       -1.6885e+00,  1.3266e+00],\n",
              "                      [ 1.6673e-01, -1.0691e+00,  1.8564e+00,  1.1970e+00,  2.3714e+00,\n",
              "                       -8.6419e-03,  1.8478e+00,  2.3469e+00,  1.0531e+00, -4.3272e+00,\n",
              "                       -1.8117e+00,  1.3765e+00],\n",
              "                      [ 5.4736e-02, -1.3196e+00,  1.5667e+00,  9.4221e-01,  2.1188e+00,\n",
              "                       -1.1148e-01,  1.9082e+00,  1.9130e+00,  1.2668e-01, -4.5869e+00,\n",
              "                       -1.7525e+00,  1.4339e+00],\n",
              "                      [-3.5954e-02, -1.4914e+00,  1.2458e+00,  5.8500e-01,  1.8885e+00,\n",
              "                       -2.0989e-01,  1.9204e+00,  1.4046e+00, -9.5699e-01, -4.9581e+00,\n",
              "                       -1.8383e+00,  1.4435e+00],\n",
              "                      [-1.5082e-01, -1.7029e+00,  8.0460e-01,  2.7758e-01,  1.5634e+00,\n",
              "                       -3.2531e-01,  1.9099e+00,  8.0581e-01, -2.1339e+00, -5.1450e+00,\n",
              "                       -1.9274e+00,  1.4054e+00],\n",
              "                      [-2.1956e-01, -1.8277e+00,  4.3501e-01, -6.1242e-02,  1.2248e+00,\n",
              "                       -4.2952e-01,  1.8966e+00,  1.5528e-01, -3.2807e+00, -5.4670e+00,\n",
              "                       -1.9411e+00,  1.4181e+00],\n",
              "                      [-3.8106e-01, -1.9692e+00,  4.2789e-02, -3.6545e-01,  9.0969e-01,\n",
              "                       -5.5373e-01,  1.8126e+00, -5.3123e-01, -4.6069e+00, -5.5904e+00,\n",
              "                       -2.1184e+00,  1.3258e+00],\n",
              "                      [-6.7980e-01, -2.1868e+00, -2.8252e+01, -1.1781e+00, -2.1594e-02,\n",
              "                       -7.7360e-01,  1.7692e+00, -1.9551e+00, -7.4152e+00, -6.4551e+00,\n",
              "                       -2.3451e+00,  1.2579e+00],\n",
              "                      [ 3.5742e-01, -2.5977e-01,  3.5352e-01,  9.7656e-02, -3.6328e-01,\n",
              "                        2.5195e-01,  2.6367e-01, -2.6562e-01, -1.2695e-01, -1.2109e-01,\n",
              "                       -3.5742e-01, -5.2734e-02],\n",
              "                      [ 1.3004e+00, -1.6368e+00,  4.5403e+00,  7.0309e-01,  3.1191e+00,\n",
              "                        2.7774e+00, -2.5540e+00, -6.3110e+00, -4.3437e+00,  5.5304e+00,\n",
              "                        7.1691e+00, -9.9713e-01],\n",
              "                      [ 1.5085e+00, -1.6814e+00,  4.0378e+00,  1.0927e+00,  3.2174e+00,\n",
              "                        1.4103e+00,  5.5455e-01, -5.5160e+00, -4.0455e+00,  5.3763e+00,\n",
              "                        5.3385e+00,  1.1245e-01],\n",
              "                      [ 1.4840e+00, -1.5751e+00,  3.7124e+00,  1.2159e+00,  3.1590e+00,\n",
              "                        8.7303e-01,  1.2152e+00, -5.5010e+00, -4.0716e+00,  5.0457e+00,\n",
              "                        4.3050e+00,  6.2521e-01],\n",
              "                      [ 1.4239e+00, -1.5441e+00,  3.5057e+00,  1.1803e+00,  3.0558e+00,\n",
              "                        5.0517e-01,  1.5309e+00, -5.5274e+00, -3.9568e+00,  4.7133e+00,\n",
              "                        3.6105e+00,  8.5686e-01],\n",
              "                      [ 1.3540e+00, -1.6965e+00,  3.3878e+00,  1.1159e+00,  2.9192e+00,\n",
              "                        3.2535e-01,  1.6696e+00, -5.5088e+00, -4.1196e+00,  4.4676e+00,\n",
              "                        3.0629e+00,  1.0371e+00],\n",
              "                      [ 1.3008e+00, -1.6717e+00,  3.2464e+00,  1.0798e+00,  2.8726e+00,\n",
              "                        7.6574e-02,  1.7729e+00, -5.4691e+00, -3.9889e+00,  4.1917e+00,\n",
              "                        2.6375e+00,  1.1037e+00],\n",
              "                      [ 1.2146e+00, -1.6921e+00,  3.1826e+00,  1.0059e+00,  2.8166e+00,\n",
              "                        6.3100e-02,  1.8758e+00, -5.5083e+00, -4.0503e+00,  3.9688e+00,\n",
              "                        2.3299e+00,  1.1481e+00],\n",
              "                      [ 1.1220e+00, -1.6857e+00,  2.9703e+00,  8.9376e-01,  2.7000e+00,\n",
              "                       -1.7426e-02,  1.9597e+00, -5.4064e+00, -3.9893e+00,  3.4835e+00,\n",
              "                        1.5630e+00,  1.2607e+00],\n",
              "                      [ 9.4870e-01, -1.7142e+00,  2.6953e+00,  7.2292e-01,  2.4896e+00,\n",
              "                       -2.2902e-01,  2.0653e+00, -5.2922e+00, -4.0258e+00,  2.8274e+00,\n",
              "                        6.9234e-01,  1.3506e+00],\n",
              "                      [ 7.6834e-01, -1.7526e+00,  2.4028e+00,  4.3598e-01,  2.2141e+00,\n",
              "                       -3.3065e-01,  2.1042e+00, -5.2824e+00, -4.0821e+00,  2.1944e+00,\n",
              "                       -4.3177e-02,  1.3627e+00],\n",
              "                      [ 5.5011e-01, -1.7738e+00,  2.0798e+00,  1.4775e-01,  1.9090e+00,\n",
              "                       -4.4851e-01,  2.0606e+00, -5.1276e+00, -3.9651e+00,  1.3835e+00,\n",
              "                       -5.2487e-01,  1.3776e+00],\n",
              "                      [ 3.4787e-01, -1.8429e+00,  1.6774e+00, -1.2798e-01,  1.5999e+00,\n",
              "                       -5.8212e-01,  2.0827e+00, -5.1093e+00, -3.9407e+00,  6.0253e-01,\n",
              "                       -1.0285e+00,  1.3602e+00],\n",
              "                      [ 1.6042e-01, -1.8686e+00,  1.1796e+00, -3.7226e-01,  1.1936e+00,\n",
              "                       -6.7167e-01,  2.0238e+00, -4.9662e+00, -3.9954e+00, -1.7331e-01,\n",
              "                       -1.3422e+00,  1.2942e+00],\n",
              "                      [-3.7230e-02, -1.8936e+00,  7.2729e-01, -6.6058e-01,  7.8277e-01,\n",
              "                       -7.1957e-01,  1.9397e+00, -4.8847e+00, -4.0013e+00, -8.2601e-01,\n",
              "                       -1.5951e+00,  1.2591e+00],\n",
              "                      [-3.8890e-01, -2.0036e+00, -1.9655e-01, -1.2408e+00, -1.4886e-01,\n",
              "                       -8.0588e-01,  1.9432e+00, -4.7455e+00, -3.9720e+00, -1.6097e+00,\n",
              "                       -1.9019e+00,  1.1998e+00]], device='cuda:0')),\n",
              "             ('encoder.block.0.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.1046,  0.0929,  0.1159,  0.0914,  0.0971,  0.0969,  0.1390,  0.1228,\n",
              "                       0.1182,  0.1101,  0.1002,  0.1245,  0.1257,  0.1147,  0.1035,  0.1153,\n",
              "                       0.1268,  0.1064,  0.1296,  0.1069,  0.0978,  0.0977,  0.1082,  0.0966,\n",
              "                       0.0899,  0.1233,  0.0935,  0.1282,  0.1225,  0.1037,  0.1209,  0.0656,\n",
              "                       0.1060,  0.1013,  0.1365,  0.1170,  0.1466,  0.1086,  0.0975,  0.1429,\n",
              "                       0.1235,  0.1252,  0.1151,  0.1339,  0.1197,  0.0994,  0.1615,  0.0958,\n",
              "                       0.1126,  0.1344,  0.1447,  0.1076,  0.1295,  0.1062,  0.0462,  0.1133,\n",
              "                       0.0932,  0.1062,  0.1287,  0.1065,  0.1105,  0.1035,  0.1235,  0.1061,\n",
              "                       0.1075,  0.0633,  0.1118,  0.0920,  0.2542,  0.0913,  0.1276,  0.1366,\n",
              "                       0.1007,  0.1084,  0.1050,  0.1041,  0.0986,  0.1056,  0.0964,  0.1309,\n",
              "                       0.1204,  0.1145,  0.1056,  0.1479,  0.0956,  0.1097,  0.1481,  0.1160,\n",
              "                       0.1090,  0.1016,  0.1035,  0.0917,  0.1082,  0.1183,  0.1041,  0.1080,\n",
              "                       0.1139,  0.1272,  0.0978,  0.1029,  0.1349,  0.1030,  0.1103,  0.0992,\n",
              "                       0.1066,  0.2149,  0.1036,  0.1066,  0.1021,  0.1339,  0.1108,  0.1045,\n",
              "                       0.1112,  0.1059,  0.0977,  0.1005,  0.1050,  0.0916,  0.4720,  0.1023,\n",
              "                       0.0833,  0.0967,  0.1789,  0.1037,  0.1250,  0.1045,  0.1126,  0.1003,\n",
              "                       0.1039,  0.1344,  0.1139,  0.1306,  0.1061,  0.1002,  0.0775,  0.1442,\n",
              "                       0.1216,  0.1036,  0.1151,  0.1034,  0.0958,  0.1238,  0.1439,  0.1866,\n",
              "                       0.1111,  0.1103,  0.1047,  0.1347,  0.1068,  0.1003,  0.0941,  0.0991,\n",
              "                       0.1164,  0.1760,  0.1051,  0.0962,  0.1250,  0.0884,  0.1429,  0.1013,\n",
              "                       0.0773,  0.1190,  0.1130,  0.1183,  0.0812,  0.0744,  0.1030,  0.1271,\n",
              "                       0.0737,  0.1271,  0.1792,  0.1043,  0.1025,  0.1549,  0.1008,  0.1313,\n",
              "                       0.0944,  0.1442,  0.1184,  0.1190,  0.1120,  0.0802,  0.1205,  0.0970,\n",
              "                       0.1302,  0.1558,  0.1073,  0.1039,  0.1034,  0.1144,  0.1001,  0.0959,\n",
              "                       0.1047,  0.1035,  0.0771,  0.1172,  0.1002,  0.1373,  0.1078,  0.0906,\n",
              "                       0.0981,  0.1251,  0.1211,  0.1120,  0.1021, -0.1466,  0.1051,  0.1089,\n",
              "                       0.0957,  0.1087,  0.1372,  0.0914,  0.1116,  0.1307,  0.1005,  0.1313,\n",
              "                       0.1128,  0.1104,  0.1290,  0.1560,  0.1228,  0.1038,  0.0907,  0.1001,\n",
              "                       0.1016,  0.1128,  0.0851,  0.1383,  0.1013,  0.1272,  0.1147,  0.1248,\n",
              "                       0.1304,  0.1039,  0.1031,  0.1177,  0.1369,  0.1197,  0.0972,  0.1426,\n",
              "                       0.1301,  0.1220,  0.0989,  0.1082,  0.0937,  0.0977,  0.1089,  0.1152,\n",
              "                       0.0902,  0.1341,  0.1303,  0.0936,  0.1021,  0.1019,  0.1047,  0.1006,\n",
              "                       0.1110,  0.0821,  0.1274,  0.0905,  0.1368,  0.1382,  0.1084,  0.1188,\n",
              "                       0.1095,  0.1049,  0.0990,  0.0968,  0.0813,  0.1058,  0.0901,  0.1796,\n",
              "                       0.1267,  0.1201,  0.1479,  0.1115,  0.1177,  0.1357,  0.1158,  0.0983,\n",
              "                      -0.1521,  0.1488,  0.1170,  0.1155,  0.1234,  0.1537,  0.1012,  0.1079,\n",
              "                       0.0981,  0.1851,  0.0954,  0.1062,  0.1031,  0.0946,  0.1198,  0.1025,\n",
              "                       0.1175,  0.1185,  0.0924,  0.1273,  0.1341,  0.1160,  0.1972,  0.1266,\n",
              "                       0.1155,  0.1008,  0.1043,  0.1149,  0.1185,  0.1092,  0.1057,  0.1185,\n",
              "                       0.0910,  0.1493,  0.1221,  0.0934,  0.1417,  0.1474,  0.1072,  0.1006,\n",
              "                       0.0905,  0.1215,  0.1062,  0.0947,  0.1206,  0.0934,  0.1205,  0.1488,\n",
              "                       0.1250,  0.1117,  0.1128,  0.1077,  0.1337,  0.1008,  0.1215,  0.1006,\n",
              "                       0.0996,  0.0913,  0.0989,  0.1803,  0.1225,  0.1280,  0.1148,  0.1096,\n",
              "                       0.1142,  0.1078,  0.1317,  0.1062,  0.0795,  0.1373,  0.1314,  0.0747,\n",
              "                       0.1049,  0.1004,  0.1199,  0.1176,  0.1223,  0.2847,  0.1044,  0.1295,\n",
              "                       0.0981,  0.1464,  0.0762,  0.0925,  0.0936,  0.1149,  0.1252,  0.1250,\n",
              "                       0.0979,  0.0974,  0.1292,  0.1147,  0.1550,  0.0954,  0.1247,  0.0914,\n",
              "                       0.1316,  0.0889,  0.1444,  0.1535,  0.1100,  0.1120,  0.1912,  0.0985,\n",
              "                       0.1108,  0.1575,  0.0925,  0.1439,  0.0882,  0.1091,  0.1017,  0.1336,\n",
              "                       0.1026,  0.1919,  0.1364,  0.1089,  0.1107,  0.1028,  0.1078,  0.1147,\n",
              "                       0.0994,  0.1441,  0.1102,  0.1078,  0.0913,  0.1207,  0.1483,  0.0893,\n",
              "                       0.0908,  0.0998,  0.1021,  0.1037,  0.1169,  0.1046,  0.1042,  0.1077,\n",
              "                       0.1042,  0.0956,  0.0670,  0.1227,  0.1500,  0.1164,  0.0888,  0.2834,\n",
              "                       0.1101,  0.1007,  0.1281,  0.1050,  0.1078,  0.1013,  0.1351,  0.1015,\n",
              "                       0.1552,  0.0900,  0.1403,  0.1025,  0.0950,  0.1076,  0.1319,  0.1454,\n",
              "                       0.1190,  0.1328,  0.1206,  0.1374,  0.1024,  0.1150,  0.1014,  0.1240,\n",
              "                       0.2554,  0.1135, -0.1092,  0.1077,  0.1120,  0.1110,  0.1112,  0.1346,\n",
              "                       0.1633,  0.0723,  0.1227,  0.0975,  0.1077,  0.1068,  0.1031,  0.1185,\n",
              "                       0.1103,  0.1121,  0.1131,  0.1057,  0.0844,  0.1002,  0.0986,  0.0954,\n",
              "                       0.0645,  0.0831,  0.1052,  0.1024,  0.1231,  0.0983,  0.1436,  0.1024,\n",
              "                       0.1147,  0.1345,  0.1100,  0.0902,  0.2325,  0.1028,  0.0945,  0.1011,\n",
              "                       0.1029,  0.1113,  0.1170,  0.1180,  0.1391,  0.1150,  0.1089,  0.1314,\n",
              "                       0.0962,  0.1091,  0.1078,  0.0961,  0.0903,  0.1274,  0.1041,  0.1416,\n",
              "                       0.1124,  0.1372,  0.1119,  0.1315,  0.0935,  0.1202,  0.1019,  0.0975,\n",
              "                       0.1064,  0.0874,  0.1160,  0.1192,  0.1063,  0.1086,  0.2532,  0.1293,\n",
              "                       0.1023,  0.1052,  0.0975,  0.1157,  0.1106,  0.1355,  0.1182,  0.1721,\n",
              "                       0.1194,  0.1186,  0.1340,  0.1093,  0.1197,  0.1049,  0.1255,  0.1277,\n",
              "                       0.1133,  0.1131,  0.1219,  0.1194,  0.1155,  0.1135,  0.1197,  0.1325,\n",
              "                       0.1050,  0.1031,  0.1131,  0.1143,  0.0999,  0.1395,  0.1315,  0.1858,\n",
              "                       0.0986,  0.1982,  0.0934,  0.1101,  0.1266,  0.0884,  0.1083,  0.1208,\n",
              "                       0.1204,  0.0899,  0.1012,  0.1385,  0.1105,  0.1748,  0.1546,  0.1102,\n",
              "                       0.1219,  0.0939,  0.1190,  0.1226,  0.0958,  0.0995,  0.1046,  0.1207,\n",
              "                       0.1228,  0.1357,  0.0980,  0.3347,  0.1008,  0.0902,  0.1098,  0.1076,\n",
              "                       0.0797,  0.1042,  0.1038,  0.0868,  0.0940,  0.1047,  0.1007,  0.1256,\n",
              "                       0.1069,  0.0951,  0.1018,  0.1197,  0.0981,  0.1260,  0.1602,  0.1136,\n",
              "                       0.1172,  0.1014,  0.1037,  0.1069,  0.1430,  0.1023,  0.0964, -0.0970,\n",
              "                       0.1246,  0.1145,  0.1088,  0.0851,  0.1171,  0.0960,  0.0935,  0.1246,\n",
              "                       0.0943,  0.0710,  0.0998,  0.0997,  0.1149,  0.0959,  0.1093,  0.1409,\n",
              "                       0.1021,  0.0937,  0.0938,  0.1241,  0.0991,  0.1334,  0.1122,  0.1013,\n",
              "                       0.1197,  0.1688,  0.1135,  0.1506,  0.1151,  0.1208,  0.1246,  0.0999,\n",
              "                       0.1354,  0.1136,  0.0931,  0.1124,  0.1076,  0.1034,  0.1024,  0.0896,\n",
              "                       0.0907,  0.1122,  0.0901,  0.1072,  0.1087,  0.1211,  0.1406,  0.1465,\n",
              "                       0.0985,  0.1199,  0.1258,  0.1263,  0.1449,  0.1039,  0.1106,  0.1791,\n",
              "                       0.1095,  0.1249,  0.1002,  0.0989,  0.1133,  0.1135,  0.1152,  0.1242,\n",
              "                       0.1068,  0.0865,  0.1023,  0.1037,  0.1101,  0.1057,  0.1025,  0.1235,\n",
              "                       0.1027,  0.0949,  0.1091,  0.0846,  0.0941,  0.1090,  0.1058,  0.1184,\n",
              "                       0.1025,  0.1105,  0.1078,  0.1111,  0.1796,  0.1103,  0.1135,  0.1006,\n",
              "                       0.1277,  0.1002,  0.1207,  0.1092,  0.1099,  0.0997,  0.0998,  0.0949,\n",
              "                       0.1033,  0.1135,  0.1066,  0.1705,  0.1863,  0.1064,  0.1265,  0.1133,\n",
              "                       0.0944,  0.0885,  0.1806,  0.1051,  0.1201,  0.1330,  0.1050,  0.1291,\n",
              "                       0.1051,  0.1232,  0.1378,  0.0979,  0.1182,  0.1047,  0.1183,  0.0676,\n",
              "                       0.1059,  0.1199,  0.1253,  0.1297,  0.1026,  0.0908,  0.1136,  0.1021,\n",
              "                       0.1174,  0.0969,  0.1025,  0.1268,  0.1102,  0.1394,  0.1248,  0.1502,\n",
              "                       0.1025,  0.1267,  0.0960,  0.1001,  0.1404,  0.1067,  0.0993,  0.0895,\n",
              "                       0.1323,  0.1145,  0.1311,  0.1089,  0.1319,  0.0906,  0.1429,  0.1090,\n",
              "                       0.0840,  0.0991,  0.1162,  0.0970,  0.1081,  0.1081,  0.1096,  0.1328],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.1354,  0.1886, -0.0249,  ...,  0.4899, -0.1612,  0.0066],\n",
              "                      [ 0.2031, -0.1736, -0.6437,  ..., -0.6220,  0.1172, -0.4391],\n",
              "                      [-0.1292,  0.1110, -0.1369,  ...,  0.2933, -0.1322,  0.0137],\n",
              "                      ...,\n",
              "                      [ 0.5581, -0.4944, -0.0096,  ..., -0.3660,  0.6417, -0.3751],\n",
              "                      [ 0.2992, -0.0634,  0.2629,  ...,  0.4830, -0.5384, -0.7875],\n",
              "                      [ 0.1145, -0.3707,  0.1601,  ...,  0.2568, -0.3449, -0.1654]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.0150,  0.2307,  0.0777,  ..., -0.1701, -0.1925, -0.4196],\n",
              "                      [-0.1398, -0.1858,  0.2105,  ..., -0.0585,  0.0182,  0.2597],\n",
              "                      [-0.0254,  0.0274,  0.2449,  ...,  0.1310,  0.1543, -0.1931],\n",
              "                      ...,\n",
              "                      [-0.2471, -0.2421, -0.1518,  ...,  0.1627, -0.1273, -0.2467],\n",
              "                      [-0.4633, -0.3586,  0.1889,  ...,  0.1311,  0.1878, -0.2011],\n",
              "                      [ 0.0247,  0.1067, -0.0871,  ..., -0.2026,  0.2326,  0.1026]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.0.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.3151,  0.3853,  0.3675,  0.4967,  0.2404,  0.3092,  0.2546,  0.3183,\n",
              "                       0.3952,  0.2717,  0.3395,  0.2918,  0.3529,  0.3939,  0.2107,  0.2549,\n",
              "                       0.3562,  0.3292, -0.4237,  0.2411,  0.2614,  0.2579,  0.1216,  0.2692,\n",
              "                       0.2347,  0.3589,  0.2347,  0.3967,  0.2609,  0.2166,  0.2591,  0.5481,\n",
              "                       0.3210,  0.2370,  0.3424,  0.2670,  0.3307,  0.5747,  0.2356,  0.3331,\n",
              "                       0.3981,  0.3626,  0.3461,  0.2677, -0.5499,  0.2939,  0.4154,  0.2684,\n",
              "                       0.2887,  0.3497,  0.4213,  0.2786,  0.3219,  0.2421,  0.0587,  0.3123,\n",
              "                       0.3576,  0.2836,  0.2557,  0.2490,  0.2886, -0.2144,  0.2819,  0.2331,\n",
              "                       0.2235,  0.1988,  0.2586,  0.2587,  0.6025,  0.2414,  0.2523,  0.3402,\n",
              "                       0.2233,  0.2839,  0.2415,  0.2278,  0.3939,  0.2927,  0.2586,  0.2947,\n",
              "                       0.2573,  0.3038,  0.2704,  0.5181,  0.2642,  0.2628,  1.1388,  0.2946,\n",
              "                       0.2584,  0.2422,  0.2927,  0.2470,  0.2548,  0.3234,  0.2212,  0.2494,\n",
              "                       0.2347,  0.2468,  0.2285,  0.2606,  0.3696,  0.2589,  0.4104,  0.2104,\n",
              "                       0.2515,  0.5543,  0.2623,  0.2526,  0.2341,  0.3527,  0.2936,  0.2845,\n",
              "                       0.2782,  0.2650,  0.2649,  0.2320,  0.2783,  0.2566,  1.0057,  0.2404,\n",
              "                       0.1867,  0.2360,  0.4883,  0.2578,  0.3354,  0.2715,  0.2905,  0.2996,\n",
              "                       0.3100,  0.4385,  0.4627,  0.3046,  0.2329,  0.2225,  0.2850,  0.4249,\n",
              "                       0.3181,  0.2720,  0.3134,  0.3313,  0.2717,  0.3356,  0.3986,  0.4662,\n",
              "                       0.3130,  0.4271,  0.2342,  0.3656,  0.2454,  0.2970,  0.2479,  0.2778,\n",
              "                       0.3007,  0.4852,  0.2227,  0.2240,  0.3409,  0.2056,  0.4328,  0.3073,\n",
              "                       0.2203,  0.2692,  0.3416,  0.3082,  0.2482,  0.2604,  0.2444,  0.4253,\n",
              "                       0.3281,  0.3406,  0.5174, -0.2822,  0.2636,  0.3590,  0.2644,  0.3276,\n",
              "                       0.2966,  0.3850,  0.4308,  0.0886,  0.2414,  0.2397,  0.2625,  0.2200,\n",
              "                       0.3800,  0.3816,  0.2480,  0.3801,  0.2827,  0.3141,  0.2669,  0.2425,\n",
              "                       0.2409,  0.2679,  0.2225,  0.3397,  0.2702,  0.3067,  0.2922,  0.2616,\n",
              "                       0.2191,  0.3306,  0.2830,  0.2460,  0.2509,  0.4335,  0.3098,  0.2811,\n",
              "                       0.2597,  0.2745,  0.4609,  0.2955,  0.3077,  0.2832,  0.2688,  0.3069,\n",
              "                       0.2795,  0.2448, -0.3059,  1.3490,  0.3697,  0.2928,  0.2256,  0.2978,\n",
              "                       0.2965,  0.2774,  0.4095,  0.3454,  0.2739,  0.3310,  0.3079,  0.3058,\n",
              "                       0.3062,  0.2039,  0.2190, -0.2519,  0.1031,  0.3444,  0.4297,  0.3230,\n",
              "                       1.1197,  0.3289,  0.2461,  0.2523,  0.2391,  0.2695,  0.2546,  0.3211,\n",
              "                       0.2098,  0.3625,  0.3486,  0.2299,  0.2489,  0.2243,  0.2218,  0.2650,\n",
              "                       0.2358,  0.2918,  0.3709,  0.2616,  0.4791,  0.2437,  0.2509,  0.2551,\n",
              "                       0.2620,  0.2825,  0.2626,  0.2718,  0.2622,  0.2608,  0.3705,  0.6143,\n",
              "                       0.3587,  0.3526,  0.5461,  0.3164,  0.2515,  0.3727,  0.2387,  0.3368,\n",
              "                      -0.8148,  0.4796,  0.2515,  0.3144,  0.3095,  0.3832,  0.2118,  0.2231,\n",
              "                       0.2843,  0.5638,  0.2218,  0.2658,  0.2355,  0.2381,  0.2232,  0.1989,\n",
              "                       0.4152,  0.2300,  0.2321,  0.3120,  0.3027,  0.2274,  0.6061,  0.3247,\n",
              "                       0.2834,  0.2257,  0.2970,  0.2462,  0.3229,  0.3536,  0.2704,  0.3340,\n",
              "                       0.2484,  0.3837,  0.3602,  0.2880,  0.3141,  0.6738,  0.2932,  0.2437,\n",
              "                       0.2282,  0.3267,  0.3100,  0.2197,  0.3756,  0.2430,  0.3639,  0.3797,\n",
              "                       0.3191,  0.2618,  0.2412,  0.3828,  0.3466,  0.2599,  0.2442,  0.2602,\n",
              "                       0.2282,  0.2323,  0.3103,  0.6429,  0.2816,  0.3054,  0.3046,  0.2580,\n",
              "                       0.2952,  0.2698,  0.3256,  0.3150,  0.3855,  0.4053,  0.4458,  0.2490,\n",
              "                       0.2963,  0.2499,  0.3689,  0.2738,  0.3002,  0.6096,  0.2226,  0.3610,\n",
              "                       0.2475,  0.4257,  0.5196,  0.2285,  0.2272,  0.2630,  0.3969,  0.2871,\n",
              "                       0.2413,  0.2848,  0.2841,  0.3356,  0.1170,  0.2840,  0.3540,  0.2109,\n",
              "                       0.3712,  0.2522,  0.3471,  0.5023,  0.2545,  0.3064,  0.5051,  0.2531,\n",
              "                       0.2328,  0.4019,  0.2592,  0.3683,  0.2293,  0.3044,  0.2394,  0.3607,\n",
              "                       0.3232,  0.5570,  0.3624,  0.2816,  0.2957,  0.2239,  0.3117,  0.2388,\n",
              "                       0.2653,  0.0486,  0.2133,  0.2259,  0.2546,  0.2633,  0.4317,  0.2586,\n",
              "                       0.2408,  0.2480,  0.2424,  0.2198,  0.3129,  0.3054,  0.2356,  0.2870,\n",
              "                       0.2429,  0.2530,  0.1959,  0.3589,  1.3165,  0.2909,  0.2164,  0.3849,\n",
              "                       0.2998,  0.2632,  0.3367,  0.2472,  0.3139,  0.3542,  0.3609,  0.2368,\n",
              "                       0.3826,  0.2466,  0.3869,  0.2788,  0.2685,  0.2327,  0.2983,  0.3973,\n",
              "                       0.2810,  0.3825,  0.3861,  0.3468,  0.2382,  0.3155,  0.2440,  0.3027,\n",
              "                       0.6714,  0.2904,  0.3142,  0.2338,  0.2679,  0.2373,  0.2977,  0.3601,\n",
              "                       0.5144,  0.3698,  0.3498,  0.2275,  0.2222,  0.2466,  0.2578,  0.2724,\n",
              "                       0.2923,  0.2679,  0.2943,  0.2768,  0.2241,  0.2483,  0.2252,  0.2168,\n",
              "                       0.2491,  0.2294,  0.2765,  0.2341,  0.2449,  0.2370,  0.3050,  0.2852,\n",
              "                       0.3703,  0.4020,  0.2623,  0.2594,  1.0345,  0.2692,  0.2277,  0.3777,\n",
              "                       0.2044,  0.2917,  0.2723,  0.2869,  0.3251,  0.2325,  0.2814,  1.2408,\n",
              "                       0.2961,  0.2786,  0.2591,  0.2413,  0.2291,  0.4373,  0.3083,  0.3575,\n",
              "                       0.2677,  0.3444,  0.3116,  0.3410,  0.2210,  0.3328,  0.3247,  0.2186,\n",
              "                       0.3916,  0.2477,  0.3345,  0.2178,  0.2963,  0.3112,  0.6119,  0.2979,\n",
              "                       0.2458,  0.2996,  0.2260,  0.2811,  0.2619,  0.3978,  0.3403,  0.4175,\n",
              "                       0.2790,  0.3281,  0.4204,  0.2600,  0.3114,  0.2651,  0.3325,  0.2935,\n",
              "                       0.3022,  0.2809,  0.3564,  0.3184,  0.3182,  0.2506,  0.3536,  0.3789,\n",
              "                       0.2584,  0.2336,  0.3303,  0.2507,  0.2674,  0.3573,  0.4692,  0.4638,\n",
              "                       0.2228,  0.7918,  0.2478,  0.2596,  0.3577,  0.2690,  0.3205,  0.3660,\n",
              "                       0.3242,  0.2665,  0.5674,  0.9538,  0.2933,  0.3812,  0.0618,  0.3118,\n",
              "                       0.3582,  0.2462,  0.3039,  0.1701,  0.2042,  0.2641,  0.2863,  0.3412,\n",
              "                       0.2481,  0.3318,  0.2283,  0.7633,  0.3238,  0.2260,  0.2263,  0.2923,\n",
              "                       0.2222,  0.2205,  0.2233,  0.2556,  0.2308,  0.2376,  0.2489,  0.3063,\n",
              "                       0.2423,  0.2891,  0.3158,  0.2614,  0.3755,  0.2866,  0.5539,  0.2843,\n",
              "                       0.4456,  0.2462,  0.3265,  0.3228,  0.3308,  0.2012,  0.2207,  0.3961,\n",
              "                       0.3180,  0.2687, -0.2954,  0.2521,  0.3113,  0.2238,  0.2647,  0.3070,\n",
              "                       0.2634,  0.4001,  0.2630,  0.2963,  0.2999,  0.2367,  0.2547,  0.4232,\n",
              "                       0.2875,  0.2504,  0.2876,  0.3667,  0.3138,  0.3847,  0.3646,  0.2590,\n",
              "                       0.3637,  1.4490,  0.2213,  0.4134,  0.3281,  0.2791,  0.3456,  0.2585,\n",
              "                      -0.4245,  0.2998,  0.2492,  0.2749,  0.3772,  0.3366,  0.3952,  0.2296,\n",
              "                       0.2600,  0.2335,  0.2951,  0.2562,  0.2822,  0.3069,  0.3304,  0.5167,\n",
              "                       0.2635,  0.3419,  0.3211,  0.3529,  0.3322,  0.0826,  0.2915,  0.4814,\n",
              "                       0.2647,  0.3597,  0.2620,  0.2266,  0.2959,  0.2497,  0.2741,  0.2914,\n",
              "                       0.2717,  0.2683,  0.2961,  0.2261,  0.2939,  0.2488,  0.2525,  0.2658,\n",
              "                       0.3008,  0.2508,  0.3234,  0.2334, -0.3102,  0.3631, -0.2813,  0.3509,\n",
              "                       0.2211,  0.2884, -0.2317,  0.3230,  0.5091,  0.2460,  0.2599,  0.2786,\n",
              "                       0.2852,  0.2033,  0.2641,  0.3146,  0.2931, -0.2272,  0.2903,  0.3040,\n",
              "                       0.2760,  0.2090,  0.2496,  0.5654,  0.5301, -0.2197,  0.5372,  0.2861,\n",
              "                       0.2524,  0.2495,  0.3311,  0.3067,  0.3172,  0.3554,  0.3128,  0.3714,\n",
              "                       0.2516,  0.3387,  0.4463,  0.2201,  0.2944,  0.3806,  0.3382,  0.2499,\n",
              "                       0.2342,  0.3375,  0.3111,  0.2341,  0.2487,  0.3105,  0.2839,  0.2586,\n",
              "                       0.2633,  0.2684,  0.2734,  0.3127,  0.2889,  0.4123,  0.3420,  0.3947,\n",
              "                       0.2580,  0.4084,  0.3084,  0.2197,  0.3100,  0.3994,  0.2894,  0.2591,\n",
              "                       0.4716,  0.2897,  0.2979,  0.2455,  0.3499,  0.2315,  0.4077,  0.2955,\n",
              "                       0.3187,  0.2655,  0.2849,  0.2186,  0.2997,  0.3218,  0.2609,  0.3728],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.1.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0123, -0.0293, -0.0080,  ...,  0.0238,  0.0031, -0.0127],\n",
              "                      [ 0.0211,  0.0532,  0.0219,  ..., -0.0350, -0.0210, -0.0186],\n",
              "                      [-0.0602, -0.0153, -0.0827,  ..., -0.0217,  0.0172, -0.0391],\n",
              "                      ...,\n",
              "                      [-0.0174, -0.0285,  0.0138,  ...,  0.0465, -0.0329,  0.0153],\n",
              "                      [ 0.0019, -0.0497, -0.0391,  ..., -0.0378,  0.0469, -0.0163],\n",
              "                      [-0.0370, -0.0127,  0.0086,  ...,  0.0072, -0.0901,  0.0059]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.1.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.1563,  0.3885,  0.2945,  ...,  0.1840,  0.3656,  0.3687],\n",
              "                      [ 0.2240,  0.8148,  0.2885,  ...,  0.1220, -0.4642, -0.3892],\n",
              "                      [-0.2449,  0.1185, -0.4015,  ..., -0.2165, -0.2885, -0.7336],\n",
              "                      ...,\n",
              "                      [ 0.1225, -0.1553, -0.2380,  ...,  0.0351, -0.3425, -0.0228],\n",
              "                      [ 0.0223, -0.1195, -0.6159,  ..., -0.0915,  0.5231,  0.1319],\n",
              "                      [-0.0498, -0.1263, -0.1110,  ...,  0.2780, -0.5026, -0.1463]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.1.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.4042, -0.1478, -0.1703,  ...,  0.1078, -0.0209, -0.1429],\n",
              "                      [-0.5678, -0.0705,  0.2263,  ..., -0.8695,  0.0682,  0.3163],\n",
              "                      [-0.7182, -0.1021,  0.4095,  ..., -0.8119,  0.0394, -0.5211],\n",
              "                      ...,\n",
              "                      [ 0.1583, -0.4760,  0.7033,  ..., -0.3474,  0.1396,  0.1783],\n",
              "                      [ 0.0222, -0.1642,  0.1931,  ..., -0.2484,  0.2314, -0.0770],\n",
              "                      [-0.2967, -0.3399, -0.0483,  ..., -0.2327, -0.3216, -0.3407]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.1.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.1069,  0.0172,  0.0168,  ..., -0.0729, -0.2675,  0.4208],\n",
              "                      [ 0.1608, -0.1390,  0.3481,  ...,  0.7478, -0.5102,  0.4756],\n",
              "                      [ 0.0571, -0.2312, -0.5400,  ..., -0.3440,  0.0666,  0.6265],\n",
              "                      ...,\n",
              "                      [-0.2104,  0.1247,  0.5522,  ...,  0.0342, -0.0921, -0.1482],\n",
              "                      [ 0.1327, -0.1310, -0.1524,  ..., -0.4737,  0.0228, -0.7337],\n",
              "                      [ 0.2705, -0.3223,  0.3557,  ..., -0.9241, -0.5615, -0.3160]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.1.layer.0.layer_norm.weight',\n",
              "              tensor([ 1.4756e-01,  1.6004e-01,  1.5482e-01,  1.7403e-01,  1.3571e-01,\n",
              "                       1.4463e-01,  4.4644e-02,  1.8008e-01,  1.2358e-01,  1.3932e-01,\n",
              "                       1.5645e-01,  1.6628e-01,  1.3095e-01,  1.7444e-01,  1.2663e-01,\n",
              "                       1.5058e-01,  1.7475e-01,  1.5897e-01,  2.1432e-01,  1.3971e-01,\n",
              "                       1.3582e-01,  1.4582e-01,  5.6451e-02,  1.2407e-01,  1.2664e-01,\n",
              "                       1.7607e-01,  1.1652e-01,  1.5535e-01,  1.5534e-01,  1.1970e-01,\n",
              "                       1.5275e-01,  1.2801e-01,  1.3923e-01,  1.1555e-01,  1.8019e-01,\n",
              "                       1.4362e-01,  1.7005e-01,  2.4140e-01,  1.0489e-01,  1.9108e-01,\n",
              "                       1.7605e-01,  1.7461e-01,  1.9163e-01,  1.5653e-01,  9.8699e-02,\n",
              "                       1.3535e-01,  1.8686e-01,  1.4218e-01,  1.6487e-01,  1.6043e-01,\n",
              "                       2.0476e-01,  1.5421e-01,  1.6142e-01,  1.1474e-01,  3.9293e-02,\n",
              "                       1.3504e-01,  7.2369e-02,  1.6060e-01,  1.3602e-01,  1.5218e-01,\n",
              "                       1.7139e-01,  1.1952e-01,  1.4806e-01,  1.2760e-01,  1.3647e-01,\n",
              "                       5.9505e-02,  1.5313e-01,  1.3401e-01,  2.5609e-01,  1.2991e-01,\n",
              "                       1.4403e-01,  1.8469e-01,  1.1930e-01,  1.3897e-01,  1.4324e-01,\n",
              "                       1.2723e-01,  1.7670e-01,  1.4512e-01,  1.1957e-01,  1.7131e-01,\n",
              "                       1.2990e-01,  1.4705e-01,  1.3843e-01,  2.0672e-01,  1.4095e-01,\n",
              "                       1.4570e-01,  2.5952e-01,  1.6231e-01,  1.4538e-01,  1.3803e-01,\n",
              "                       1.5464e-01,  1.1075e-01,  1.2729e-01,  1.6421e-01,  1.2138e-01,\n",
              "                       1.2461e-01,  1.3439e-01,  1.2155e-01,  1.3390e-01,  1.2247e-01,\n",
              "                       1.9329e-01,  1.4280e-01,  1.8245e-01,  1.2038e-01,  1.4540e-01,\n",
              "                       2.4661e-01,  1.3781e-01,  1.3363e-01,  1.1725e-01,  1.8988e-01,\n",
              "                       1.5619e-01,  1.4281e-01,  1.3428e-01,  1.2724e-01,  1.3653e-01,\n",
              "                       1.2429e-01,  1.4844e-01,  1.1621e-01,  3.1253e-01,  1.3761e-01,\n",
              "                       1.2244e-01,  1.3512e-01,  2.0945e-01,  1.3038e-01,  1.9896e-01,\n",
              "                       1.4000e-01,  1.5095e-01,  1.3779e-01,  1.5265e-01,  1.7779e-01,\n",
              "                       1.4281e-01,  1.5891e-01,  1.1753e-01, -1.2054e-01,  1.4789e-01,\n",
              "                       2.0487e-01,  1.6679e-01,  1.3354e-01,  1.5783e-01,  1.6622e-01,\n",
              "                       1.3848e-01,  1.8183e-01,  1.9963e-01,  2.0744e-01,  1.6040e-01,\n",
              "                       1.7484e-01,  1.2500e-01,  1.7937e-01,  1.4106e-01,  1.5884e-01,\n",
              "                       1.4183e-01,  1.4365e-01,  1.4580e-01,  2.2648e-01,  1.3798e-01,\n",
              "                       1.3195e-01,  1.6680e-01,  1.1952e-01,  1.8481e-01,  1.3020e-01,\n",
              "                       1.0449e-01, -1.4878e-01,  1.2972e-01,  1.0301e-01,  1.0723e-01,\n",
              "                       1.1198e-01,  1.4513e-01,  1.7365e-01,  1.3805e-01,  2.1154e-01,\n",
              "                       2.4231e-01,  1.5185e-01,  1.4417e-01,  2.0333e-01,  1.5350e-01,\n",
              "                       1.6613e-01,  1.5964e-01,  2.1766e-01,  1.8893e-01, -2.1279e-04,\n",
              "                       1.4744e-01,  1.2952e-01,  1.3702e-01,  1.1507e-01,  1.6725e-01,\n",
              "                       2.0066e-01,  1.3728e-01,  1.8597e-01,  1.4275e-01,  1.5967e-01,\n",
              "                       1.2866e-01,  1.3172e-01,  9.5071e-02,  1.5216e-01,  1.2190e-01,\n",
              "                       6.2263e-02,  1.4094e-01,  1.7422e-01,  1.5192e-01,  1.1660e-01,\n",
              "                       1.2109e-01,  1.5786e-01,  1.4352e-01,  1.4919e-01,  1.3235e-01,\n",
              "                       2.0039e-01,  1.4900e-01,  1.4451e-01,  1.3621e-01,  1.4320e-01,\n",
              "                       2.0153e-01,  1.3195e-01,  1.7767e-01,  1.6136e-01,  1.3163e-01,\n",
              "                       1.7791e-01,  1.4442e-01,  1.2285e-01,  1.7569e-01,  2.7508e-01,\n",
              "                       1.4521e-01,  1.4818e-01,  1.0245e-01,  1.3813e-01,  1.3806e-01,\n",
              "                       1.3692e-01,  1.7876e-01,  2.2092e-01,  1.4263e-01,  1.8216e-01,\n",
              "                       1.4034e-01,  1.5139e-01,  9.6361e-02,  1.2176e-01,  1.1592e-01,\n",
              "                       8.9145e-02,  6.5196e-02,  1.7866e-01,  1.5304e-01,  1.9548e-01,\n",
              "                       2.4464e-01,  1.7294e-01,  1.3680e-01,  1.3200e-01,  1.1060e-01,\n",
              "                       1.3050e-01,  1.4942e-01,  1.5498e-01,  1.1791e-01,  1.5659e-01,\n",
              "                       1.1103e-01,  1.2828e-01,  1.0908e-01,  1.1619e-01,  1.1678e-01,\n",
              "                       1.2345e-01,  1.3722e-01,  1.3156e-01,  1.7214e-01,  1.4344e-01,\n",
              "                       2.1195e-01,  1.8815e-01,  1.3138e-01,  1.4110e-01,  1.3490e-01,\n",
              "                       1.3850e-01,  1.3494e-01,  1.3303e-01,  1.4692e-01,  1.4662e-01,\n",
              "                       7.1435e-02,  2.5122e-01,  1.8694e-01,  6.7931e-02,  2.3815e-01,\n",
              "                       1.5580e-01,  1.2989e-01,  1.9554e-01,  1.4396e-01,  1.5077e-01,\n",
              "                       2.7856e-01,  2.0807e-01,  1.3923e-01,  1.5374e-01,  1.7611e-01,\n",
              "                       1.9557e-01,  1.1854e-01,  1.2925e-01,  1.3814e-01,  2.1299e-01,\n",
              "                       1.0977e-01,  1.4840e-01,  1.1927e-01,  1.4450e-01,  1.4587e-01,\n",
              "                       1.0538e-01,  1.9502e-01,  1.3108e-01,  1.1521e-01,  1.8244e-01,\n",
              "                       1.6485e-01,  1.2749e-01,  2.7712e-01,  1.6900e-01,  1.4588e-01,\n",
              "                       1.2724e-01,  1.4364e-01,  1.2545e-01,  1.5683e-01,  1.6514e-01,\n",
              "                       1.4442e-01,  1.9897e-01,  1.2911e-01,  1.2859e-01,  1.9075e-01,\n",
              "                       1.6252e-01,  1.2038e-01,  2.8636e-01,  1.2438e-01,  1.1532e-01,\n",
              "                       1.1964e-01,  1.9483e-01,  1.5528e-01,  1.1241e-01,  1.7967e-01,\n",
              "                       1.2132e-01,  1.9549e-01,  2.2484e-01,  1.6809e-01,  1.5027e-01,\n",
              "                       1.2387e-01,  1.6886e-01,  1.6713e-01,  1.3399e-01,  1.4094e-01,\n",
              "                       1.5064e-01,  1.1583e-01,  1.2916e-01,  1.5032e-01,  2.5009e-01,\n",
              "                       1.6194e-01,  1.7078e-01,  1.6160e-01,  1.3938e-01,  1.4205e-01,\n",
              "                       1.5164e-01,  1.7029e-01,  1.5027e-01,  1.5321e-01,  1.7296e-01,\n",
              "                       2.0731e-01,  1.1794e-01,  1.3622e-01,  1.2821e-01,  1.6870e-01,\n",
              "                       1.6074e-01,  1.5885e-01,  2.6635e-01,  1.3906e-01,  1.9741e-01,\n",
              "                       1.3135e-01,  2.0407e-01,  1.8871e-01,  9.2052e-02,  1.2272e-01,\n",
              "                       1.4018e-01,  1.8346e-01,  1.5919e-01,  1.2447e-01,  1.5268e-01,\n",
              "                       1.6402e-01,  1.9005e-01,  1.4784e-02,  1.1952e-01,  1.9770e-01,\n",
              "                       1.0388e-01,  1.9323e-01,  1.2679e-01,  2.0135e-01,  1.9435e-01,\n",
              "                       1.4075e-01,  1.5952e-01,  2.3042e-01,  1.3205e-01,  1.2859e-01,\n",
              "                       1.5632e-01,  1.3952e-01,  1.8809e-01,  9.4959e-02,  1.8057e-01,\n",
              "                       1.3083e-01,  1.8487e-01,  1.5712e-01,  2.3291e-01,  2.0214e-01,\n",
              "                       1.3878e-01,  1.6123e-01,  1.1638e-01,  1.5192e-01,  1.3107e-01,\n",
              "                       1.2797e-01,  3.4503e-02,  1.1360e-01,  1.5273e-01,  1.1489e-01,\n",
              "                       1.3386e-01,  2.0270e-01,  1.2571e-01,  1.4128e-01,  1.3451e-01,\n",
              "                       1.2895e-01,  1.1906e-01,  1.4570e-01,  1.6751e-01,  1.2223e-01,\n",
              "                       1.4183e-01,  1.2044e-01,  1.2947e-01,  5.6496e-02,  1.7540e-01,\n",
              "                       3.0165e-01,  1.4803e-01,  1.1087e-01,  6.3609e-02,  1.5793e-01,\n",
              "                       1.4759e-01,  1.8202e-01,  1.3275e-01,  1.5377e-01,  1.5974e-01,\n",
              "                       1.7153e-01,  1.2121e-01,  1.9624e-01,  1.2209e-01,  2.2145e-01,\n",
              "                       1.2908e-01,  1.4592e-01,  1.1849e-01,  1.9444e-01,  2.1430e-01,\n",
              "                       1.5595e-01,  1.6975e-01,  1.8403e-01,  2.1100e-01,  1.1332e-01,\n",
              "                       1.5613e-01,  1.2684e-01,  1.5856e-01,  2.5096e-01,  1.3528e-01,\n",
              "                       1.5059e-01,  1.3368e-01,  1.5114e-01,  1.2258e-01,  1.6371e-01,\n",
              "                       1.8165e-01,  1.8713e-01,  1.4483e-01,  1.6947e-01,  1.2586e-01,\n",
              "                       1.2640e-01,  1.2633e-01,  1.2854e-01,  1.5399e-01,  1.4803e-01,\n",
              "                       1.5289e-01,  1.1255e-01,  1.4197e-01,  1.1543e-01,  1.3034e-01,\n",
              "                       1.1514e-01,  1.1343e-01,  1.0155e-01,  1.1194e-01,  1.4836e-01,\n",
              "                       1.5376e-01,  1.3867e-01,  1.1916e-01,  1.6805e-01,  1.6859e-01,\n",
              "                       1.6988e-01,  1.8889e-01,  1.5045e-01,  1.4244e-01,  3.4122e-01,\n",
              "                       1.2008e-01,  1.3076e-01,  1.8676e-01,  1.3032e-01,  1.5519e-01,\n",
              "                       1.5813e-01,  1.6440e-01,  1.3888e-01,  1.3525e-01,  1.4923e-01,\n",
              "                       2.2328e-01,  1.5838e-01,  1.3937e-01,  1.4427e-01,  1.1576e-01,\n",
              "                       1.1790e-01,  1.9526e-01,  1.7385e-01,  1.0693e-01,  1.4916e-01,\n",
              "                       1.9078e-01,  1.6639e-01, -1.6618e-01,  1.0607e-01,  1.5569e-01,\n",
              "                       1.5936e-01,  1.2910e-01,  1.0075e-01,  1.2196e-01,  1.6836e-01,\n",
              "                       1.3756e-01,  1.5125e-01,  1.3352e-01,  2.3795e-01,  1.7004e-01,\n",
              "                       1.1897e-01,  1.4306e-01,  1.1689e-01,  1.3565e-01,  1.5550e-01,\n",
              "                       1.9066e-01,  1.6814e-01,  2.2156e-01,  1.5589e-01,  1.7220e-01,\n",
              "                       1.8852e-01,  1.4052e-01,  1.4896e-01,  1.4621e-01,  1.6216e-01,\n",
              "                       1.6598e-01,  1.5991e-01,  1.4046e-01,  1.9183e-01,  1.6002e-01,\n",
              "                       1.6160e-01,  1.3529e-01,  1.6899e-01,  1.9864e-01,  1.3781e-01,\n",
              "                       1.3147e-01,  1.7011e-01,  1.2826e-01,  1.3997e-01,  1.7545e-01,\n",
              "                       2.2453e-01,  2.1816e-01,  1.1513e-01,  1.8791e-01,  1.1942e-01,\n",
              "                       1.5308e-01,  1.6053e-01,  1.3061e-01,  1.4954e-01,  1.8637e-01,\n",
              "                       1.6954e-01,  1.2148e-01,  2.0353e-01,  2.5575e-01,  1.5905e-01,\n",
              "                       2.0566e-01,  1.9854e-02,  1.4293e-01,  1.7522e-01,  1.3535e-01,\n",
              "                       1.7448e-01,  4.8581e-02,  1.1613e-01,  1.4334e-01,  1.4636e-01,\n",
              "                       1.7382e-01,  1.3363e-01,  2.0285e-01,  1.2814e-01,  3.0186e-01,\n",
              "                       1.4535e-01,  1.1897e-01,  1.2364e-01,  1.3580e-01,  1.1955e-01,\n",
              "                       1.2809e-01,  1.1940e-01,  1.2553e-01,  1.0733e-01,  1.3670e-01,\n",
              "                       1.3542e-01,  1.7827e-01,  1.3173e-01,  1.4868e-01,  1.6094e-01,\n",
              "                       1.4905e-01,  1.5876e-01,  1.3669e-01,  2.1697e-01,  1.3475e-01,\n",
              "                       1.8596e-01,  1.2835e-01,  1.4769e-01,  1.0352e-01,  1.8844e-01,\n",
              "                       1.2253e-01,  1.2682e-01,  1.5836e-01,  2.0285e-01,  1.3630e-01,\n",
              "                       1.5744e-01,  1.1242e-01,  1.6196e-01,  1.3955e-01,  1.4602e-01,\n",
              "                       1.8116e-01,  1.2755e-01,  1.5550e-01,  1.2976e-01,  1.4936e-01,\n",
              "                       1.6329e-01,  1.1495e-01,  1.2115e-01,  1.9919e-01,  1.4036e-01,\n",
              "                       1.2768e-01,  1.4887e-01,  1.8039e-01,  1.4411e-01,  1.7488e-01,\n",
              "                       1.7550e-01,  1.4158e-01,  1.8281e-01,  2.6728e-01,  1.2446e-01,\n",
              "                       1.8477e-01,  1.5149e-01,  1.4792e-01,  1.8652e-01,  1.3910e-01,\n",
              "                       1.6236e-01,  1.5671e-01,  1.1876e-01,  1.4871e-01,  1.6086e-01,\n",
              "                       1.6533e-01,  1.6907e-01,  1.1144e-01,  1.2999e-01,  1.1729e-01,\n",
              "                       1.3120e-01,  1.3501e-01,  1.4606e-01,  1.4709e-01,  1.9117e-01,\n",
              "                       1.9550e-01,  1.3148e-01,  1.5225e-01,  1.7318e-01,  1.6348e-01,\n",
              "                       1.8848e-01,  2.5198e-02,  1.4384e-01,  2.6376e-01,  1.3204e-01,\n",
              "                       1.7049e-01,  1.3449e-01,  1.4518e-01,  1.6291e-01,  1.3435e-01,\n",
              "                       1.2712e-01,  1.6019e-01,  1.4054e-01,  1.2617e-01,  1.6472e-01,\n",
              "                       1.2583e-01,  1.4438e-01,  1.3096e-01,  1.2863e-01,  1.3921e-01,\n",
              "                       1.4605e-01,  1.4214e-01,  1.6146e-01,  9.7120e-02,  1.4673e-01,\n",
              "                       1.3242e-01,  1.2795e-01,  1.7884e-01,  1.1468e-01,  1.7011e-01,\n",
              "                       1.1211e-01,  1.8412e-01,  2.4793e-01,  1.2094e-01,  1.3110e-01,\n",
              "                       1.3700e-01,  1.7346e-01,  1.2130e-01,  1.4982e-01,  1.5485e-01,\n",
              "                       1.6187e-01,  1.0873e-01,  1.4813e-01,  1.3409e-01,  1.5055e-01,\n",
              "                       1.3126e-01,  1.2362e-01,  2.1040e-01,  2.7122e-01,  1.3241e-01,\n",
              "                       1.2261e-01,  1.5925e-01,  1.3991e-01,  1.3381e-01,  3.4978e-02,\n",
              "                       1.6345e-01,  1.5984e-01,  1.8685e-01,  1.3150e-01,  2.0368e-01,\n",
              "                       1.3895e-01,  1.3776e-01,  1.9880e-01,  1.2047e-01,  1.6488e-01,\n",
              "                       1.7075e-01,  1.7994e-01,  1.1290e-01,  1.4031e-01,  1.6773e-01,\n",
              "                       1.6069e-01,  1.3524e-01,  1.3486e-01,  1.0923e-01,  1.3661e-01,\n",
              "                       1.4283e-01,  1.4415e-01,  1.3885e-01,  1.3663e-01,  1.7245e-01,\n",
              "                       1.5237e-01,  1.9251e-01,  1.8292e-01,  1.8303e-01,  1.2764e-01,\n",
              "                       1.9139e-01,  1.3775e-01,  1.1591e-01,  1.8301e-01,  1.8404e-01,\n",
              "                       1.5168e-01,  1.3907e-01,  2.1121e-01,  1.5165e-01,  1.7821e-01,\n",
              "                       1.2889e-01,  1.7072e-01,  1.3634e-01,  2.0211e-01,  1.6004e-01,\n",
              "                       1.3348e-01,  1.1587e-01,  1.5377e-01,  1.1658e-01,  1.6137e-01,\n",
              "                       1.8077e-01,  1.5317e-01,  2.0305e-01], device='cuda:0')),\n",
              "             ('encoder.block.1.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.3068,  0.5504,  0.9931,  ..., -0.5882,  0.6719, -0.9903],\n",
              "                      [-0.0744, -0.1044,  0.6084,  ..., -0.1528,  0.4303,  0.0073],\n",
              "                      [-0.0501,  0.4763, -0.5071,  ..., -0.1813,  0.4004, -0.0738],\n",
              "                      ...,\n",
              "                      [ 0.2809, -0.2946,  0.0030,  ..., -0.4842,  0.1329, -0.0491],\n",
              "                      [-0.8032,  0.3178, -0.0443,  ..., -0.1729,  0.0860, -0.5735],\n",
              "                      [-0.1038,  0.7673,  0.4512,  ..., -0.4502,  0.0111,  0.5755]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.1.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.0695, -0.1777,  0.0325,  ..., -0.2277,  0.2201,  0.1417],\n",
              "                      [-0.2757, -0.0805, -0.0442,  ..., -0.2018, -0.1344,  0.0391],\n",
              "                      [-0.1937,  0.2136,  0.1851,  ..., -0.1110, -0.1220, -0.2147],\n",
              "                      ...,\n",
              "                      [-0.0212,  0.3704, -0.2385,  ..., -0.1817, -0.4470,  0.0732],\n",
              "                      [-0.0254, -0.0328, -0.0953,  ...,  0.1089, -0.0718, -0.0036],\n",
              "                      [-0.2421, -0.0887,  0.2192,  ...,  0.0136,  0.1381, -0.2964]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.1.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.5190,  0.6135,  0.5966,  0.6859,  0.3729,  0.5030,  0.2085,  0.5572,\n",
              "                       1.1476,  0.4513,  0.5385,  0.5675,  0.5274,  0.7024,  0.3530,  0.4537,\n",
              "                       0.5613,  0.5228,  0.7302,  0.3872,  0.4265,  0.4828,  0.3842,  0.4034,\n",
              "                       0.3626,  0.6179,  0.3747,  0.6185,  0.4641,  0.3701, -0.4500,  0.5188,\n",
              "                       0.5293,  0.3810,  0.6149,  0.4710,  0.7090,  0.8795,  0.3715,  0.6569,\n",
              "                       0.6640,  0.6412,  0.6200,  0.4902,  1.2219,  0.4666,  0.7206,  0.4563,\n",
              "                       0.4767,  0.6584,  0.6795,  0.4723,  0.6686,  0.4190,  0.4150,  0.4958,\n",
              "                       0.8023,  0.5187,  0.3917,  0.4331,  0.4968,  0.3683,  0.4925,  0.3984,\n",
              "                       0.3899,  0.4137,  0.4396,  0.4345,  0.9007,  0.4161,  0.4248,  0.6263,\n",
              "                       0.3724,  0.4639,  0.4051,  0.3997,  0.7093,  0.4951,  0.3860,  0.5315,\n",
              "                       0.4211,  0.5281,  0.4398,  0.8283,  0.4832,  0.4608,  1.1765,  0.5131,\n",
              "                       0.4444,  0.3628,  0.4845,  0.3811,  0.4128,  0.5344,  0.3776,  0.3969,\n",
              "                       0.4016,  0.3879,  0.3533,  0.3989,  0.6196,  0.4627,  0.7224,  0.3663,\n",
              "                       0.4373,  0.9358,  0.4454,  0.4467,  0.3590,  0.6467,  0.5163,  0.4520,\n",
              "                       0.4651,  0.4317,  0.4153,  0.3664,  0.4721,  0.4152,  1.3139,  0.4275,\n",
              "                       0.3401,  0.3794,  0.8080,  0.3882,  0.6521,  0.4702,  0.4548,  0.4632,\n",
              "                       0.4911,  0.6689,  0.8417,  0.5525,  0.3688,  0.3586,  0.4363,  0.7341,\n",
              "                       0.5413,  0.4170,  0.4975,  0.5663,  0.4982,  0.6232,  0.7320,  0.8081,\n",
              "                       0.5506,  0.6948,  0.3771,  0.6174,  0.4053,  0.5293,  0.4218,  0.4648,\n",
              "                       0.4930,  0.8735,  0.3643,  0.3782,  0.6024,  0.3559,  0.7094,  0.4570,\n",
              "                       0.3663, -0.4464,  0.5231,  0.9473,  0.3814,  0.3873,  0.4339,  0.6062,\n",
              "                       0.5160,  0.6589,  0.8337,  0.4455,  0.4069,  0.7317,  0.4537,  0.5211,\n",
              "                       0.5236,  0.6145,  0.7143,  0.1199,  0.3962,  0.3824,  0.4715,  0.3504,\n",
              "                       0.5832,  0.6689,  0.3905,  0.6266,  0.5009,  0.5187,  0.4324,  0.4008,\n",
              "                       0.3661,  0.4530,  0.3669,  0.2625,  0.4174,  0.5586,  0.4979,  0.3849,\n",
              "                       0.3487,  0.5189,  0.4729,  0.4424,  0.4421,  0.7420,  0.5216,  0.4688,\n",
              "                       0.4230,  0.4694,  0.6986,  0.4782,  0.5686,  0.5674,  0.4377,  0.5416,\n",
              "                       0.4720,  0.4102,  0.5615,  1.8187,  0.5898,  0.4926,  0.3532,  0.4881,\n",
              "                       0.5440,  0.4507,  0.7201,  0.6453,  0.4763,  0.5726,  0.5036,  0.5032,\n",
              "                       0.4137,  0.3485,  0.3549,  0.3275,  0.1887,  0.5876,  0.6508,  0.6487,\n",
              "                       1.0265,  0.5862,  0.4161,  0.4444,  0.3942,  0.4169,  0.4424,  0.5436,\n",
              "                       0.3530,  0.5415,  0.8868,  0.4088,  0.4200,  0.3870,  0.3595,  0.4088,\n",
              "                       0.3880,  0.4458,  0.6962,  0.4453,  0.7842,  0.2856,  0.3910,  0.4383,\n",
              "                       0.4374,  0.4701,  0.4300,  0.4456,  0.4695,  0.4358,  0.6224,  0.9161,\n",
              "                       0.7475,  0.7331,  0.8565,  0.5326,  0.3781,  0.7130,  0.4331,  0.5002,\n",
              "                       1.0164,  0.8461,  0.4051,  0.5935,  0.5440,  0.7074,  0.3639,  0.3945,\n",
              "                       0.5168,  0.9481,  0.3655,  0.4410,  0.3609,  0.3937,  0.4187,  0.3239,\n",
              "                       0.6116,  0.4100,  0.4002,  0.5788,  0.5069,  0.3975,  0.9270,  0.5726,\n",
              "                       0.4596,  0.3729,  0.4443,  0.4124,  0.5361,  0.5873,  0.4252,  0.6149,\n",
              "                       0.3888,  0.5592,  0.6112,  0.4953,  0.5188,  0.9028,  0.5698,  0.3919,\n",
              "                       0.3776,  0.6064,  0.4926,  0.3442,  0.6380,  0.3932,  0.6589,  0.7068,\n",
              "                       0.5262,  0.4463,  0.3930,  0.6617,  0.6227,  0.4514,  0.4118,  0.4308,\n",
              "                       0.3780,  0.4178,  0.5011,  0.9403,  0.5595,  0.5075,  0.5012,  0.4133,\n",
              "                       0.5047,  0.5035,  0.6265,  0.5125,  0.6340,  0.8545,  0.6900,  0.3965,\n",
              "                       0.4666,  0.3929,  0.5856,  0.4872,  0.5516,  0.8490,  0.3749,  0.6596,\n",
              "                       0.4064,  0.7343,  0.9370, -0.3163,  0.3606,  0.4553,  0.7354,  0.5066,\n",
              "                       0.4037,  0.4949,  0.5409,  0.5466, -0.0035,  0.4152,  0.6814,  0.3653,\n",
              "                       0.6484,  0.4152,  0.6848,  0.8226,  0.4573,  0.5207,  0.7959,  0.4395,\n",
              "                       0.4160,  0.7526,  0.4191,  0.6748,  0.3538,  0.5771,  0.4051,  0.7410,\n",
              "                       0.5242,  0.8028,  0.6446,  0.5048,  0.5752,  0.3804,  0.4999,  0.3961,\n",
              "                       0.3967,  0.2840,  0.3402,  0.4139,  0.4107,  0.4495,  0.7316,  0.3969,\n",
              "                       0.3875,  0.3948,  0.4134,  0.3679,  0.5381,  0.5420,  0.3793,  0.4819,\n",
              "                       0.4109,  0.3977,  0.2087,  0.6309,  1.4233,  0.4904,  0.3579,  0.3389,\n",
              "                       0.4836,  0.4299,  0.5835,  0.4053,  0.5103,  0.5796,  0.6187,  0.4226,\n",
              "                       0.7416,  0.4026,  0.7404,  0.4091,  0.4454,  0.3813,  0.5543,  0.6823,\n",
              "                       0.5067,  0.6469,  0.6149,  0.6360,  0.3761,  0.5457,  0.4020,  0.5287,\n",
              "                       0.9534,  0.4835,  0.4999,  0.3814,  0.4626,  0.4072,  0.5355,  0.5926,\n",
              "                       0.6735,  0.5418,  0.6047,  0.3841,  0.3652, -0.3910,  0.4124,  0.4747,\n",
              "                       0.4684,  0.4569, -0.4316,  0.4553,  0.3696,  0.3741,  0.3722,  0.3575,\n",
              "                       0.3558,  0.3577,  0.4659,  0.4070,  0.3888,  0.4039,  0.5799,  0.4756,\n",
              "                       0.6048,  0.8317,  0.4594,  0.3749,  1.2984,  0.4353,  0.3801,  0.7019,\n",
              "                       0.3299,  0.4880,  0.4333,  0.5592,  0.6152,  0.3895,  0.4887,  1.0679,\n",
              "                       0.4801,  0.4580,  0.4036,  0.3535,  0.3974,  0.6819,  0.5682,  0.5845,\n",
              "                       0.4262,  0.6075,  0.5366,  0.6014,  0.3415,  0.5593,  0.5396,  0.3716,\n",
              "                       0.9547,  0.3625,  0.5972,  0.3465,  0.5462,  0.5143,  1.0356,  0.5463,\n",
              "                       0.3835,  0.5164,  0.3586,  0.4658,  0.4552,  0.7908,  0.5962,  0.7706,\n",
              "                       0.4607,  0.5752,  0.6721,  0.4575,  0.5267,  0.4678,  0.5271,  0.5115,\n",
              "                       0.5304,  0.4543,  0.6956,  0.5371,  0.5786,  0.3967,  0.5832,  0.6732,\n",
              "                       0.4476,  0.3936,  0.5583,  0.4493,  0.4378,  0.6124,  0.8373,  0.7981,\n",
              "                       0.3763,  1.4261,  0.4164,  0.4620,  0.6555,  0.3965,  0.5452,  0.6223,\n",
              "                       0.5729,  0.3902,  0.8927,  0.9846,  0.4956,  0.6239,  0.1448,  0.4884,\n",
              "                       0.6063,  0.4210,  0.5373,  0.2191,  0.3475,  0.4589,  0.4407,  0.5774,\n",
              "                       0.4063,  0.6616,  0.3915,  1.1148,  0.5262,  0.3633,  0.4050,  0.4331,\n",
              "                       0.3282,  0.3403,  0.3962,  0.4248,  0.3650,  0.3870,  0.3946,  0.5861,\n",
              "                       0.3681,  0.4722,  0.4762,  0.4297,  0.5603,  0.4625,  0.7802,  0.4374,\n",
              "                       0.6322,  0.3929,  0.5146,  0.4094,  0.5900,  0.3546,  0.3906,  0.5933,\n",
              "                       0.6451,  0.4772,  0.5044,  0.4053,  0.5396,  0.3939,  0.4698,  0.5560,\n",
              "                      -0.4137,  0.5640,  0.4437,  0.4856,  0.5115, -0.3932,  0.4361,  0.7102,\n",
              "                       0.4884,  0.4383,  0.5127,  0.6513,  0.4909,  0.6825,  0.5814,  0.4677,\n",
              "                       0.5931,  1.1874,  0.3782,  0.6727,  0.5106,  0.4767,  0.6274,  0.3992,\n",
              "                       0.6544,  0.4995,  0.4156,  0.4723,  0.5831,  0.5813,  0.6338,  0.3599,\n",
              "                       0.4182,  0.4120,  0.4236,  0.4527,  0.4599,  0.5224,  0.5697,  0.8491,\n",
              "                       0.4423,  0.6208,  0.5281,  0.6088,  0.5777,  0.1247,  0.4878,  0.8432,\n",
              "                       0.4677,  0.6507,  0.4651,  0.3622,  0.4832,  0.4099,  0.4684,  0.6113,\n",
              "                       0.4390,  0.4322,  0.5067,  0.3887,  0.4276,  0.4422,  0.4596,  0.4408,\n",
              "                       0.4756,  0.4216,  0.5364,  0.3520,  0.4674,  0.6919,  0.4737,  0.5752,\n",
              "                       0.3761,  0.5282,  0.3906,  0.5256,  0.8714,  0.3653,  0.4379,  0.4449,\n",
              "                       0.5560,  0.3898,  0.4711,  0.5825,  0.5030,  0.3579,  0.4849,  0.4681,\n",
              "                       0.4886,  0.3665,  0.4063,  0.9630,  0.8183,  0.3957,  1.3084,  0.4717,\n",
              "                       0.4682,  0.3950,  0.2650,  0.5167,  0.5687,  0.6545,  0.4851,  0.7370,\n",
              "                       0.4172, -0.5370,  0.6939,  0.3986,  0.4955,  0.5778,  0.5922,  0.3921,\n",
              "                       0.3987,  0.6200,  0.5396,  0.4088,  0.3913, -0.3659,  0.4642,  0.4269,\n",
              "                       0.4711,  0.4654,  0.4660,  0.5359,  0.4952,  0.6996,  0.5999,  0.6463,\n",
              "                       0.3977,  0.6777,  0.5201,  0.3863,  0.5456,  0.7141,  0.4692,  0.4374,\n",
              "                       0.8375,  0.4864,  0.4921,  0.4441,  0.5546,  0.4105,  0.6144,  0.5333,\n",
              "                       0.5066,  0.3669,  0.4964,  0.3683,  0.5060,  0.5471,  0.4197,  0.6461],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.2.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0051,  0.0029,  0.0024,  ..., -0.0675,  0.0524,  0.0599],\n",
              "                      [-0.0769,  0.0294,  0.0030,  ..., -0.0394, -0.0496,  0.1111],\n",
              "                      [-0.0634,  0.0559,  0.0380,  ...,  0.0407, -0.0276,  0.0050],\n",
              "                      ...,\n",
              "                      [ 0.0498, -0.0389, -0.0200,  ...,  0.0135,  0.0194, -0.0269],\n",
              "                      [ 0.0414,  0.0166,  0.0066,  ..., -0.0138, -0.0081,  0.0277],\n",
              "                      [-0.0714,  0.0102, -0.0423,  ..., -0.0441, -0.0117,  0.0166]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.2.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.2257,  0.5490, -1.0756,  ..., -0.0299,  0.7892,  0.0911],\n",
              "                      [-0.2454,  0.3066,  0.5893,  ..., -0.0608, -0.2543,  0.4894],\n",
              "                      [-0.3897, -0.6179,  0.1199,  ...,  0.7169,  0.1262, -0.1874],\n",
              "                      ...,\n",
              "                      [-0.1908,  0.1040,  0.2478,  ...,  0.0374,  0.1423,  0.2411],\n",
              "                      [ 0.2652, -0.3940,  0.1819,  ..., -0.1376, -0.4659, -0.4057],\n",
              "                      [-0.0954,  0.0590,  0.0451,  ...,  0.6238, -0.1122, -0.0459]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.2.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.1037, -0.0401, -0.2294,  ..., -0.4120, -0.1820, -0.1886],\n",
              "                      [ 0.1351,  0.2078,  0.2520,  ..., -0.3244,  0.3014, -0.2470],\n",
              "                      [-0.3052, -0.1464,  0.1099,  ...,  0.4218, -0.3138, -0.1839],\n",
              "                      ...,\n",
              "                      [ 0.0851,  0.6133,  0.3637,  ...,  0.6142,  0.1097, -1.0667],\n",
              "                      [ 0.4869,  0.2645, -0.5134,  ..., -0.4820, -0.6639,  0.3122],\n",
              "                      [ 1.1520, -0.4200,  0.5349,  ...,  0.4461, -0.8330, -0.4846]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.2.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 0.1108, -0.4415,  0.3022,  ...,  0.3475,  0.1550, -1.0518],\n",
              "                      [-0.5789, -0.5277,  0.0404,  ..., -1.3119, -0.4215,  0.9497],\n",
              "                      [-0.1940, -0.1219,  0.3363,  ..., -0.4576,  0.6911, -0.6015],\n",
              "                      ...,\n",
              "                      [ 0.3895,  0.5887,  0.2244,  ..., -0.0273,  0.2202, -0.0826],\n",
              "                      [ 0.4732,  0.0942,  0.2017,  ...,  0.1898,  0.5041,  0.6201],\n",
              "                      [ 0.9856,  0.2181,  0.0172,  ...,  1.3656, -1.0301,  1.3425]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.2.layer.0.layer_norm.weight',\n",
              "              tensor([ 1.7372e-01,  1.6071e-01,  1.8645e-01,  1.9382e-01,  1.1165e-01,\n",
              "                       1.4178e-01,  5.4566e-02,  1.9032e-01,  1.0217e-01,  1.5245e-01,\n",
              "                       1.7771e-01,  1.5538e-01,  1.0574e-01,  1.8728e-01,  1.1653e-01,\n",
              "                       1.5276e-01,  1.6722e-01,  1.9325e-01,  2.1733e-01,  1.3324e-01,\n",
              "                       1.3464e-01,  1.5714e-01,  2.2174e-04,  1.2122e-01,  1.1926e-01,\n",
              "                       1.8336e-01,  1.1437e-01,  1.5216e-01,  1.5322e-01,  1.1330e-01,\n",
              "                       1.4048e-01,  1.3579e-01,  1.6021e-01,  1.2210e-01,  1.8799e-01,\n",
              "                       1.4823e-01,  1.4536e-01,  2.6343e-01,  1.0958e-01,  2.1516e-01,\n",
              "                       1.6770e-01,  1.6775e-01,  1.9754e-01,  1.5831e-01,  8.9939e-02,\n",
              "                       1.4089e-01,  1.6210e-01,  1.4772e-01,  1.6063e-01,  1.5862e-01,\n",
              "                       2.2312e-01,  1.5341e-01,  1.4700e-01,  1.1543e-01,  3.3955e-02,\n",
              "                       1.3071e-01,  4.7636e-02,  1.4377e-01,  1.4646e-01,  1.3553e-01,\n",
              "                       1.6557e-01,  1.1554e-01,  1.5866e-01,  1.2615e-01,  1.3250e-01,\n",
              "                       5.2267e-02,  1.4301e-01,  1.3301e-01,  2.4661e-01,  1.2449e-01,\n",
              "                       1.4093e-01,  1.9632e-01,  1.2143e-01,  1.5497e-01,  1.3713e-01,\n",
              "                       1.2026e-01,  1.6837e-01,  1.5020e-01,  1.2486e-01,  1.7147e-01,\n",
              "                       1.2531e-01,  1.5707e-01,  1.4344e-01,  1.9489e-01,  1.4995e-01,\n",
              "                       1.6291e-01,  2.5124e-01,  1.6614e-01,  1.5391e-01,  1.3482e-01,\n",
              "                       1.5697e-01,  1.0642e-01,  1.3189e-01,  1.6158e-01,  1.1030e-01,\n",
              "                       1.1756e-01,  1.4571e-01,  1.3568e-01,  1.3430e-01,  1.3946e-01,\n",
              "                       2.0786e-01,  1.4511e-01,  1.6991e-01,  1.2864e-01,  1.5699e-01,\n",
              "                       2.2714e-01,  1.5051e-01,  1.4090e-01,  1.1310e-01,  1.6233e-01,\n",
              "                       1.6776e-01,  1.5776e-01,  1.4670e-01,  1.1505e-01,  1.3285e-01,\n",
              "                       1.2452e-01,  1.4894e-01,  1.3296e-01,  2.8743e-01,  1.2436e-01,\n",
              "                       1.0738e-01,  1.3644e-01,  2.0786e-01,  1.2279e-01,  1.9938e-01,\n",
              "                       1.5184e-01,  1.5212e-01,  1.5989e-01,  1.4593e-01,  1.9946e-01,\n",
              "                       1.2035e-01,  1.8105e-01,  1.2153e-01,  1.0980e-01,  1.4797e-01,\n",
              "                       1.8881e-01,  1.7638e-01,  1.3339e-01,  1.5829e-01,  1.6050e-01,\n",
              "                       1.4648e-01,  1.9934e-01,  1.9730e-01,  1.9393e-01,  1.5840e-01,\n",
              "                       1.8246e-01,  1.2462e-01,  1.8580e-01,  1.2495e-01,  1.6223e-01,\n",
              "                       1.4044e-01,  1.5186e-01,  1.5161e-01,  2.5653e-01,  1.3874e-01,\n",
              "                       1.3202e-01,  1.9296e-01,  1.0959e-01,  1.8099e-01,  1.1961e-01,\n",
              "                       1.1141e-01,  1.4285e-01,  1.2527e-01,  9.1009e-02,  1.1739e-01,\n",
              "                       1.2176e-01,  1.4057e-01,  1.9871e-01,  1.6308e-01,  2.3191e-01,\n",
              "                       2.4365e-01,  1.4963e-01,  1.4034e-01,  1.7429e-01,  1.6161e-01,\n",
              "                       1.5097e-01,  1.7804e-01,  2.1992e-01,  1.7018e-01,  2.0550e-03,\n",
              "                       1.3904e-01,  1.2983e-01,  1.4956e-01,  1.0760e-01,  1.9721e-01,\n",
              "                       2.0626e-01,  1.3115e-01,  1.9834e-01,  1.5067e-01,  1.5305e-01,\n",
              "                       1.2159e-01,  1.3577e-01,  1.0686e-01,  1.4181e-01,  1.1511e-01,\n",
              "                       5.4469e-02,  1.3993e-01,  1.9926e-01,  1.5721e-01,  1.1329e-01,\n",
              "                       1.0994e-01,  1.6615e-01,  1.5231e-01,  1.4742e-01,  1.5318e-01,\n",
              "                       2.1532e-01,  1.3606e-01,  1.4540e-01,  1.3765e-01,  1.5283e-01,\n",
              "                       1.8151e-01,  1.3082e-01,  1.7257e-01,  1.6887e-01,  1.4304e-01,\n",
              "                       1.8300e-01,  1.6929e-01,  1.5057e-01,  1.8348e-01,  2.4594e-01,\n",
              "                       1.3265e-01,  1.5524e-01,  1.1226e-01,  1.5884e-01,  1.4926e-01,\n",
              "                       1.4605e-01,  1.8003e-01,  2.3062e-01,  1.5560e-01,  1.9258e-01,\n",
              "                       1.2614e-01,  1.5274e-01,  8.2063e-02,  1.2433e-01,  1.0973e-01,\n",
              "                       7.9653e-02,  5.7541e-02,  1.8205e-01,  1.5395e-01,  2.0125e-01,\n",
              "                       2.4637e-01,  1.9095e-01,  1.3287e-01,  1.5361e-01,  1.0586e-01,\n",
              "                       1.2559e-01,  1.4420e-01,  1.8505e-01,  1.0419e-01,  1.6164e-01,\n",
              "                       1.0348e-01,  1.2547e-01,  1.2154e-01,  1.2132e-01,  1.1037e-01,\n",
              "                       1.2407e-01,  1.3591e-01,  1.1745e-01,  1.4746e-01,  1.4429e-01,\n",
              "                       2.0516e-01,  1.6030e-01,  1.1330e-01,  1.5553e-01,  1.3213e-01,\n",
              "                       1.2911e-01,  1.4314e-01,  1.3984e-01,  1.3995e-01,  1.3963e-01,\n",
              "                       4.8648e-02,  2.5369e-01,  1.9656e-01,  4.3409e-02,  2.3725e-01,\n",
              "                       1.6035e-01,  1.3555e-01,  1.8698e-01,  1.5298e-01,  1.4056e-01,\n",
              "                       2.6845e-01,  2.1858e-01,  1.3422e-01,  1.4822e-01,  1.7161e-01,\n",
              "                       1.9053e-01,  1.2151e-01,  1.3675e-01,  1.4652e-01,  1.9206e-01,\n",
              "                       1.1470e-01,  1.3441e-01,  1.2431e-01,  1.3219e-01,  1.3530e-01,\n",
              "                       1.1308e-01,  1.9511e-01,  1.3589e-01,  1.2157e-01,  1.7616e-01,\n",
              "                       1.7760e-01,  1.4583e-01,  2.8378e-01,  1.7089e-01,  1.6414e-01,\n",
              "                       1.1811e-01,  1.4605e-01,  1.4797e-01,  1.8027e-01,  1.6994e-01,\n",
              "                       1.5962e-01,  1.9735e-01,  1.3794e-01,  1.2796e-01,  1.8380e-01,\n",
              "                       1.6640e-01,  1.0938e-01,  2.8219e-01,  1.2148e-01,  1.1856e-01,\n",
              "                       1.2855e-01,  1.9348e-01,  1.5428e-01,  1.2486e-01,  1.8569e-01,\n",
              "                       1.4018e-01,  1.8905e-01,  2.3797e-01,  1.6045e-01,  1.5033e-01,\n",
              "                       1.3493e-01,  1.8599e-01,  1.7291e-01,  1.3995e-01,  1.3325e-01,\n",
              "                       1.3707e-01,  1.0801e-01,  1.2609e-01,  1.4934e-01,  2.7194e-01,\n",
              "                       1.6675e-01,  1.8441e-01,  1.4744e-01,  1.2628e-01,  1.6889e-01,\n",
              "                       1.4639e-01,  1.6989e-01,  1.6782e-01,  1.8681e-01,  1.4882e-01,\n",
              "                       2.1352e-01,  1.1268e-01,  1.4951e-01,  1.4058e-01,  1.7350e-01,\n",
              "                       1.6656e-01,  1.7581e-01,  2.3926e-01,  1.3264e-01,  2.0686e-01,\n",
              "                       1.3428e-01,  2.3553e-01,  1.6216e-01,  8.9738e-02,  1.1630e-01,\n",
              "                       1.4053e-01,  1.6310e-01,  1.5225e-01,  1.2055e-01,  1.4895e-01,\n",
              "                       1.5999e-01,  1.9290e-01, -1.6752e-03,  1.2194e-01,  2.1392e-01,\n",
              "                       1.1021e-01,  1.9082e-01,  1.2165e-01,  2.1940e-01,  1.5918e-01,\n",
              "                       1.4867e-01,  1.6791e-01,  2.6120e-01,  1.5137e-01,  1.4997e-01,\n",
              "                       1.4063e-01,  1.4161e-01,  2.2352e-01,  1.0782e-01,  1.9788e-01,\n",
              "                       1.3216e-01,  1.7983e-01,  1.5368e-01,  2.3227e-01,  1.9883e-01,\n",
              "                       1.5013e-01,  1.7863e-01,  1.3241e-01,  1.4545e-01,  1.2798e-01,\n",
              "                       1.2245e-01,  2.3102e-02,  1.0995e-01,  1.6087e-01,  1.2028e-01,\n",
              "                       1.4940e-01,  1.9929e-01,  1.2372e-01,  1.2321e-01,  1.1823e-01,\n",
              "                       1.2712e-01,  1.0680e-01,  1.4741e-01,  1.4812e-01,  1.2072e-01,\n",
              "                       1.4299e-01,  1.1047e-01,  1.1144e-01,  5.7850e-02,  1.7326e-01,\n",
              "                       2.5693e-01,  1.5584e-01,  1.1521e-01,  5.1163e-02,  1.6263e-01,\n",
              "                       1.2671e-01,  1.7288e-01,  1.2569e-01,  1.5797e-01,  1.6959e-01,\n",
              "                       1.9226e-01,  1.2638e-01,  1.8803e-01,  1.1956e-01,  2.3719e-01,\n",
              "                       1.3607e-01,  1.3437e-01,  1.2862e-01,  1.9044e-01,  2.2147e-01,\n",
              "                       1.7161e-01,  1.6085e-01,  2.0714e-01,  2.3334e-01,  1.3614e-01,\n",
              "                       1.7222e-01,  1.2704e-01,  1.5642e-01,  2.3961e-01,  1.5677e-01,\n",
              "                       1.4572e-01,  1.2928e-01,  1.4496e-01,  1.3083e-01,  1.7088e-01,\n",
              "                       1.8103e-01,  1.8530e-01,  1.6868e-01,  1.7302e-01,  1.1978e-01,\n",
              "                       1.2840e-01,  1.2105e-01,  1.3341e-01,  1.6109e-01,  1.5989e-01,\n",
              "                       1.6274e-01,  1.0595e-01,  1.4540e-01,  9.8104e-02,  1.3388e-01,\n",
              "                       1.1488e-01,  1.1406e-01,  9.9059e-02,  1.2068e-01,  1.6287e-01,\n",
              "                       1.5441e-01,  1.4350e-01,  1.3765e-01,  1.5397e-01,  1.6066e-01,\n",
              "                       1.8790e-01,  1.5595e-01,  1.5458e-01,  1.2661e-01,  3.1847e-01,\n",
              "                       1.2724e-01,  1.2864e-01,  1.7941e-01,  1.0882e-01,  1.6489e-01,\n",
              "                       1.4172e-01,  1.6416e-01,  1.2119e-01,  1.3294e-01,  1.4925e-01,\n",
              "                       1.9958e-01,  1.5240e-01,  1.6455e-01,  1.4390e-01,  1.1784e-01,\n",
              "                       1.1664e-01,  2.0974e-01,  1.6746e-01,  6.6253e-02,  1.3813e-01,\n",
              "                       1.8915e-01,  1.6983e-01,  1.9143e-01,  1.0493e-01,  1.7443e-01,\n",
              "                       1.6763e-01,  1.2637e-01,  7.9935e-02,  1.2850e-01,  1.7942e-01,\n",
              "                       1.4325e-01,  1.5466e-01,  1.3300e-01,  1.9376e-01,  1.8608e-01,\n",
              "                       1.1989e-01,  1.4583e-01,  1.0484e-01,  1.4837e-01,  1.5994e-01,\n",
              "                       1.6701e-01,  1.8535e-01,  2.5321e-01,  1.5252e-01,  1.8597e-01,\n",
              "                       2.0722e-01,  1.4019e-01,  1.6328e-01,  1.3389e-01,  1.4680e-01,\n",
              "                       1.6237e-01,  1.5291e-01,  1.4208e-01,  2.1293e-01,  1.5970e-01,\n",
              "                       1.8839e-01,  1.4168e-01,  1.6406e-01,  1.9754e-01,  1.3244e-01,\n",
              "                       1.4746e-01,  1.7610e-01,  1.4829e-01,  1.3378e-01,  1.4329e-01,\n",
              "                       2.2290e-01,  2.3310e-01,  9.7029e-02,  1.6579e-01,  1.3348e-01,\n",
              "                       1.6749e-01,  1.5299e-01,  1.2928e-01,  1.6978e-01,  1.8098e-01,\n",
              "                       1.7760e-01,  1.1572e-01,  2.2525e-01,  2.6241e-01,  1.7457e-01,\n",
              "                       1.9678e-01,  1.8203e-02,  1.3748e-01,  1.8152e-01,  1.2070e-01,\n",
              "                       1.6561e-01,  5.0859e-02,  1.1479e-01,  1.4842e-01,  1.5335e-01,\n",
              "                       1.7508e-01,  1.4219e-01,  2.1950e-01,  1.2117e-01,  2.6215e-01,\n",
              "                       1.5728e-01,  1.1301e-01,  1.3702e-01,  1.3098e-01,  1.1043e-01,\n",
              "                       1.2741e-01,  1.1885e-01,  1.1863e-01,  1.2448e-01,  1.2563e-01,\n",
              "                       1.4774e-01,  1.7912e-01,  1.4414e-01,  1.5093e-01,  1.5427e-01,\n",
              "                       1.5340e-01,  1.5521e-01,  1.4113e-01,  2.1631e-01,  1.5801e-01,\n",
              "                       1.8941e-01,  1.4540e-01,  1.6797e-01,  8.9364e-02,  1.8752e-01,\n",
              "                       1.2148e-01,  1.3319e-01,  1.6724e-01,  1.8651e-01,  1.5693e-01,\n",
              "                       1.5147e-01,  1.1930e-01,  1.5925e-01,  1.3015e-01,  1.4532e-01,\n",
              "                       1.8577e-01,  1.3591e-01,  1.6602e-01,  1.4163e-01,  1.4777e-01,\n",
              "                       1.6097e-01,  1.2387e-01,  1.3644e-01,  2.1954e-01,  1.5293e-01,\n",
              "                       1.2616e-01,  1.5862e-01,  1.6528e-01,  1.3659e-01,  1.7816e-01,\n",
              "                       1.8325e-01,  1.4738e-01,  1.7047e-01,  2.8271e-01,  1.2851e-01,\n",
              "                       1.8206e-01,  1.6179e-01,  1.5616e-01,  2.1223e-01,  1.3904e-01,\n",
              "                       1.6740e-01,  1.6229e-01,  1.2847e-01,  1.5557e-01,  1.7446e-01,\n",
              "                       1.7449e-01,  1.8120e-01,  1.2205e-01,  1.1687e-01,  1.2698e-01,\n",
              "                       1.4016e-01,  1.4882e-01,  1.4644e-01,  1.4133e-01,  1.8146e-01,\n",
              "                       2.0266e-01,  1.5263e-01,  1.4858e-01,  1.9097e-01,  1.7949e-01,\n",
              "                       1.9730e-01, -1.2101e-03,  1.3594e-01,  2.7224e-01,  1.5574e-01,\n",
              "                       1.7062e-01,  1.1487e-01,  1.1676e-01,  1.7307e-01,  1.4232e-01,\n",
              "                       1.4899e-01,  1.2721e-01,  1.3864e-01,  1.2989e-01,  1.5573e-01,\n",
              "                       1.2410e-01,  1.5105e-01,  1.3993e-01,  1.3549e-01,  1.4489e-01,\n",
              "                       1.5098e-01,  1.4011e-01,  1.6270e-01,  1.0892e-01,  1.4647e-01,\n",
              "                       1.0981e-01,  1.3299e-01,  1.8404e-01,  1.2566e-01,  1.6381e-01,\n",
              "                       1.1964e-01,  1.7571e-01,  2.4196e-01,  1.2844e-01,  1.4045e-01,\n",
              "                       1.1583e-01,  1.7929e-01,  1.1821e-01,  1.6515e-01,  1.7108e-01,\n",
              "                       1.5750e-01,  9.0305e-02,  1.5425e-01,  1.3591e-01,  1.4339e-01,\n",
              "                       1.2570e-01,  1.3241e-01,  1.7267e-01,  2.5061e-01,  1.1856e-01,\n",
              "                       1.0272e-01,  1.5753e-01,  1.6156e-01,  1.3251e-01,  4.9392e-02,\n",
              "                       1.6010e-01,  1.7266e-01,  2.0985e-01,  1.4562e-01,  2.1721e-01,\n",
              "                       1.3107e-01,  1.2604e-01,  2.1086e-01,  1.3482e-01,  1.6392e-01,\n",
              "                       1.8314e-01,  1.8399e-01,  1.0919e-01,  1.3388e-01,  1.9082e-01,\n",
              "                       1.6930e-01,  1.3428e-01,  1.3377e-01,  1.0858e-01,  1.4947e-01,\n",
              "                       1.5829e-01,  1.5916e-01,  1.6132e-01,  1.4317e-01,  1.7371e-01,\n",
              "                       1.5694e-01,  2.0105e-01,  1.9142e-01,  1.8679e-01,  1.4789e-01,\n",
              "                       1.8627e-01,  1.6770e-01,  1.1495e-01,  1.8492e-01,  1.9884e-01,\n",
              "                       1.5134e-01,  1.3787e-01,  2.1981e-01,  1.5796e-01,  1.7874e-01,\n",
              "                       1.4268e-01,  1.5238e-01,  1.2838e-01,  1.8872e-01,  1.8916e-01,\n",
              "                       1.6826e-01,  1.0496e-01,  1.6016e-01,  1.1363e-01,  1.7865e-01,\n",
              "                       1.9069e-01,  1.3691e-01,  2.1255e-01], device='cuda:0')),\n",
              "             ('encoder.block.2.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.0013,  0.3475, -0.6679,  ..., -0.1028, -0.5408, -0.1279],\n",
              "                      [-0.3438,  0.0345, -0.4223,  ...,  0.7984, -0.3008, -0.0475],\n",
              "                      [-0.3735,  0.4594, -0.4902,  ...,  0.1528, -0.2916, -0.4061],\n",
              "                      ...,\n",
              "                      [ 0.2713, -0.7556,  0.5724,  ..., -0.1143,  0.7701, -0.0830],\n",
              "                      [ 0.0484, -0.3923, -0.3002,  ...,  0.3534,  0.0704, -0.0654],\n",
              "                      [-0.2667,  0.5601, -0.5588,  ...,  0.3370, -0.0986,  0.0112]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.2.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.1935, -0.1272,  0.2264,  ..., -0.0455, -0.1547,  0.4332],\n",
              "                      [-0.0593,  0.3041,  0.0647,  ...,  0.0084,  0.1808, -0.1340],\n",
              "                      [ 0.1968, -0.3688,  0.0710,  ..., -0.0578, -0.2574, -0.4502],\n",
              "                      ...,\n",
              "                      [ 0.2895, -0.0320,  0.0804,  ...,  0.2806,  0.1693,  0.0889],\n",
              "                      [-0.0449,  0.0612,  0.0796,  ...,  0.0293, -0.0436, -0.3959],\n",
              "                      [ 0.1170, -0.2249,  0.2769,  ..., -0.0828,  0.1490,  0.2795]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.2.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.8214,  0.9169,  0.9021,  1.0339,  0.5912,  0.7974,  0.3528,  0.8321,\n",
              "                       2.1814,  0.6836,  0.8224,  0.8844,  0.7254,  1.0351,  0.5770,  0.7221,\n",
              "                       0.9155,  0.8578,  1.0547,  0.6408,  0.7267,  0.7284,  0.6351,  0.6251,\n",
              "                       0.6065,  0.9234,  0.5830,  0.8228,  0.8049,  0.5790, -0.6893,  0.7194,\n",
              "                       0.7893,  0.5958,  0.9448,  0.7299,  1.1938,  1.2814,  0.5802,  1.0760,\n",
              "                       0.9151,  1.0803,  0.9399,  0.6990,  2.1896,  0.6857,  1.0180,  0.7066,\n",
              "                       0.7508,  1.0516,  1.0328,  0.7174,  1.1293,  0.6285,  0.7841,  0.7440,\n",
              "                       1.1309,  0.8076,  0.6640,  0.6642,  0.7973,  0.5632,  0.7595,  0.6487,\n",
              "                       0.6355,  0.7128,  0.6926,  0.6897,  1.2360,  0.6490,  0.6953,  1.0222,\n",
              "                       0.5772,  0.7325,  0.6751,  0.6209,  1.0260,  0.7535,  0.6157,  0.8065,\n",
              "                       0.6891,  0.7816,  0.6973,  1.2106,  0.7358,  0.7508,  1.4832,  0.8264,\n",
              "                       0.7289,  0.5947,  0.7748,  0.6151,  0.6372,  0.8160,  0.6418,  0.6109,\n",
              "                       0.6172,  0.6265,  0.5674,  0.6472,  1.0284,  0.7045,  1.0506,  0.5818,\n",
              "                       0.7284,  1.2762,  0.6803,  0.6785,  0.5885,  1.0393,  0.8468,  0.7108,\n",
              "                       0.6970,  0.7200,  0.6740,  0.5908,  0.7919,  0.6327,  1.6568,  0.6539,\n",
              "                       0.5355,  0.6077,  1.1703,  0.6310,  1.0006,  0.7302,  0.7176,  0.7385,\n",
              "                       0.7871,  0.9287,  1.3034,  0.8806,  0.5735,  0.5973,  0.6529,  1.1067,\n",
              "                       0.8859,  0.6755,  0.8502,  0.8536,  0.7010,  0.9976,  1.0219,  1.1762,\n",
              "                       0.7832,  1.0323,  0.6298,  0.9037,  0.6686,  0.7637,  0.6815,  0.7587,\n",
              "                       0.7927,  1.1893,  0.5898,  0.6000,  0.9262,  0.5624,  0.9586, -0.7608,\n",
              "                       0.6149,  0.7273,  0.7372,  1.9392,  0.6068,  0.5953,  0.6932,  0.9021,\n",
              "                       0.7427,  1.0665,  1.1310,  0.6835,  0.6493,  1.0818,  0.7049,  0.7632,\n",
              "                       0.7832,  0.8648,  1.0693,  0.2007,  0.6403,  0.6000,  0.7462, -0.5538,\n",
              "                       0.8325,  0.9797,  0.6133,  0.9562,  0.8001,  0.8571,  0.6579,  0.5905,\n",
              "                       0.5670,  0.7400,  0.5797,  0.3043,  0.6565,  0.9128,  0.7326,  0.6177,\n",
              "                       0.5915,  0.8078,  0.7309,  0.6949,  0.6564,  1.0475,  0.7375,  0.7029,\n",
              "                       0.6650,  0.7100,  1.0333,  0.7122,  0.9031,  0.8620,  0.7033,  0.8594,\n",
              "                       0.7369,  0.6947,  0.8626,  2.4034,  0.8211,  0.7663,  0.5712,  0.7577,\n",
              "                       0.8573,  0.6876,  1.0625,  1.0395,  0.7296,  0.8576,  0.7218,  0.8220,\n",
              "                       0.5224,  0.5492,  0.5950,  0.4681,  0.2341,  0.9099,  0.9525,  1.0371,\n",
              "                       1.2803,  0.8781,  0.6451,  0.6958,  0.6062,  0.6333,  0.6931,  0.8626,\n",
              "                       0.5370,  0.8593,  1.6783,  0.5973,  0.6497,  0.6457,  0.5638,  0.6760,\n",
              "                       0.6142,  0.6815,  1.0400,  0.6975,  1.0763,  0.3158,  0.6462,  0.6689,\n",
              "                       0.6425,  0.6996,  0.6942,  0.6975,  0.7144,  0.6520,  0.9248,  1.2651,\n",
              "                       1.1413,  1.2113,  1.1390,  0.7945,  0.6319,  1.0490,  0.7299,  0.8032,\n",
              "                       1.2838,  1.2121,  0.6601,  0.9591,  0.8278,  1.0330,  0.5946,  0.6349,\n",
              "                       0.7533,  1.3916,  0.5551,  0.7304,  0.5946,  0.6100,  0.6692,  0.5553,\n",
              "                       0.9426,  0.6243,  0.6229,  0.8800,  0.8461,  0.6787,  1.2738,  0.8601,\n",
              "                       0.7394,  0.6291,  0.6950,  0.6271,  0.8369,  0.8242,  0.6882,  0.9374,\n",
              "                       0.6638,  0.7384,  0.9151,  0.7818,  0.7078,  1.1279,  0.9454,  0.6212,\n",
              "                       0.5826,  0.9790,  0.7805,  0.5584,  0.9788,  0.6066,  0.9983,  1.0517,\n",
              "                       0.8175,  0.6943,  0.6142,  0.9879,  0.9041,  0.6615,  0.6280,  0.6963,\n",
              "                       0.5990,  0.6491,  0.7986,  1.2498,  0.8568,  0.8118,  0.7577,  0.6896,\n",
              "                       0.7608,  0.8002,  0.9734,  0.7890,  0.9262,  1.2990,  1.0567,  0.5966,\n",
              "                       0.6979,  0.6330,  0.8268,  0.7782,  0.7921,  1.2362,  0.6009,  1.0626,\n",
              "                       0.6552,  1.0734,  1.3018,  0.5032,  0.5616,  0.6283,  1.0444,  0.8359,\n",
              "                       0.6477,  0.8459,  0.8640,  0.8637,  0.0228,  0.6284,  1.0691,  0.5798,\n",
              "                       1.0044,  0.6702,  1.0100,  1.1490,  0.6943,  0.8270,  1.1318,  0.7215,\n",
              "                       0.6376,  1.1376,  0.6793,  0.9987,  0.5023,  0.9080,  0.6221,  1.2111,\n",
              "                       0.8157,  1.1038,  0.9658,  0.8142,  0.8482,  0.6417,  0.7977,  0.6296,\n",
              "                       0.6114,  0.6275,  0.5575,  0.6632,  0.6750,  0.6739,  1.1095,  0.6604,\n",
              "                       0.6100,  0.6627,  0.6186,  0.5641,  0.8069,  0.7970,  0.6180,  0.7669,\n",
              "                       0.6128,  0.6280,  0.2435,  1.0488,  1.6696,  0.7754,  0.5751,  0.4115,\n",
              "                       0.7651,  0.6152,  0.8762,  0.6058,  0.7940,  0.8654,  0.9571,  0.6296,\n",
              "                       1.1455,  0.6370,  1.0875,  0.6189,  0.7446,  0.6205,  0.9000,  0.9161,\n",
              "                       0.8069,  0.8698,  0.9128,  1.0111,  0.5825,  0.8559,  0.5939,  0.7502,\n",
              "                       1.2791,  0.7396,  0.7230,  0.6459,  0.6873,  0.6126,  0.8398,  0.9643,\n",
              "                       0.9643,  0.8088,  0.9077,  0.5979,  0.5727,  0.5971,  0.6334,  0.7488,\n",
              "                       0.7528,  0.7218,  0.5676,  0.7255,  0.5615,  0.6141,  0.6005,  0.5838,\n",
              "                       0.5790,  0.5600,  0.7905,  0.6098,  0.6226,  0.6592,  0.9009,  0.7769,\n",
              "                       0.8877,  1.3886,  0.7398,  0.6002,  1.4653,  0.6485,  0.6014,  0.9673,\n",
              "                       0.5786,  0.7664,  0.7033,  0.8341,  0.9659,  0.5757,  0.7593,  1.2548,\n",
              "                       0.7865,  0.7005,  0.6673,  0.5597,  0.6247,  0.9274,  0.9313,  0.9517,\n",
              "                       0.6744,  0.9262,  0.8199,  0.8899,  0.5304,  0.8623,  0.8207,  0.6118,\n",
              "                       1.7007,  0.5857,  0.8770,  0.5730,  0.7402,  0.7730,  1.3227,  0.8366,\n",
              "                       0.5742,  0.8354,  0.5907,  0.7511,  0.7619,  1.3253,  0.8660,  1.1379,\n",
              "                       0.6744,  0.8716,  1.0308,  0.7058,  0.8090,  0.6968,  0.8010,  0.7847,\n",
              "                       0.7805,  0.6797,  1.0903,  0.7778,  0.8917,  0.6628,  0.8819,  1.0146,\n",
              "                       0.7011,  0.6611,  0.8066,  0.6947,  0.6947,  0.7767,  1.1735,  1.1105,\n",
              "                       0.5781,  1.8584,  0.6168,  0.7592,  0.9137,  0.6483,  0.8489,  0.9981,\n",
              "                       0.8714,  0.6022,  1.2697,  1.2955,  0.7421,  0.9252,  0.2182,  0.7344,\n",
              "                       0.8936,  0.6888,  0.8066,  0.2910,  0.5862,  0.6935,  0.6945,  0.8432,\n",
              "                       0.6787,  0.9754,  0.5666,  1.4652,  0.7986,  0.5662,  0.6553,  0.7102,\n",
              "                       0.5428,  0.5740,  0.6009,  0.6729,  0.6117,  0.6222,  0.6654,  0.8902,\n",
              "                       0.5942,  0.7410,  0.7708,  0.6818,  0.7764,  0.7150,  1.1669,  0.7333,\n",
              "                       0.9663,  0.6233,  0.7492,  0.5439,  0.8234,  0.5765,  0.5760,  0.8009,\n",
              "                       0.9822,  0.7373,  0.7587,  0.6308,  0.8840,  0.6513,  0.7191,  0.8998,\n",
              "                       0.6752,  0.8279,  0.6995,  0.7362,  0.8196,  0.6441,  0.6710,  1.0429,\n",
              "                       0.7461,  0.6628,  0.8151,  1.0721,  0.7251,  0.9374,  0.9104,  0.6978,\n",
              "                       0.8620,  1.4321,  0.5870,  0.9613,  0.8253,  0.7644,  1.0108,  0.6222,\n",
              "                       0.9296,  0.7690,  0.6399,  0.7915,  0.8472,  0.8084,  0.9039,  0.5926,\n",
              "                       0.6337,  0.6206,  0.6673,  0.6849,  0.6960,  0.7827,  0.8652,  1.1291,\n",
              "                       0.6787,  0.8393,  0.8233,  0.9062,  0.8948,  0.1274,  0.6935,  1.2408,\n",
              "                       0.7204,  1.0123,  0.7144, -0.5925,  0.7431,  0.6355,  0.7597,  1.0296,\n",
              "                       0.6640,  0.6690,  0.7640,  0.6401,  0.6873,  0.6697,  0.7037,  0.7174,\n",
              "                       0.7553,  0.6958,  0.8296,  0.6089,  0.7404,  1.0630,  0.7060,  0.9241,\n",
              "                       0.5931,  0.8061,  0.6110,  0.8060,  1.3031,  0.6138,  0.6668,  0.7120,\n",
              "                       0.9113,  0.6087,  0.7417,  0.8458,  0.7920, -0.5356,  0.7683,  0.7221,\n",
              "                       0.7764,  0.5856,  0.6310,  1.2861,  1.1598,  0.5979,  2.0925,  0.7422,\n",
              "                       0.7044,  0.6440,  0.3012,  0.8357,  0.8988,  0.9408,  0.7538,  1.0822,\n",
              "                       0.6094,  0.8350,  1.0263,  0.6593,  0.7956,  0.8241,  0.8913,  0.6249,\n",
              "                       0.6231,  0.9791,  0.8129,  0.6694,  0.5987,  0.5477,  0.7059,  0.7088,\n",
              "                       0.7261,  0.7476,  0.7136,  0.8254,  0.7669,  1.0528,  0.9359,  0.9403,\n",
              "                       0.6445,  0.9876,  0.7798,  0.5806,  0.8275,  1.0525,  0.7613,  0.6788,\n",
              "                       1.1876,  0.7353,  0.8085,  0.6827,  0.7959,  0.6090,  0.8453,  0.8748,\n",
              "                       0.8677,  0.5822,  0.7900,  0.5888,  0.8086,  0.8355,  0.6938,  0.9690],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0084, -0.0076, -0.0064,  ...,  0.0331,  0.0506, -0.0119],\n",
              "                      [ 0.0465,  0.0265, -0.0465,  ...,  0.0041, -0.0090,  0.0098],\n",
              "                      [ 0.0214, -0.0191, -0.0367,  ..., -0.0043, -0.0339, -0.0357],\n",
              "                      ...,\n",
              "                      [ 0.0224,  0.0146, -0.0171,  ...,  0.0263, -0.0095, -0.0045],\n",
              "                      [ 0.0029,  0.0191, -0.0294,  ..., -0.0622,  0.0004, -0.0070],\n",
              "                      [ 0.0748,  0.0145,  0.0123,  ...,  0.0929,  0.0279, -0.0042]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.3601, -0.2459, -0.2321,  ..., -0.2465, -0.0369, -0.0462],\n",
              "                      [-0.0269, -0.0125,  0.0990,  ...,  0.1186, -0.7417,  0.0467],\n",
              "                      [ 0.1178,  0.2875,  0.1002,  ..., -0.4152,  0.0075,  0.1737],\n",
              "                      ...,\n",
              "                      [-0.2181,  0.4291,  0.0563,  ..., -0.4059, -0.0931,  0.1526],\n",
              "                      [-0.1717,  0.4457, -0.2771,  ..., -0.4524, -0.1217, -0.1265],\n",
              "                      [ 0.5166, -0.0528, -0.1197,  ...,  0.5156, -0.0305,  0.0309]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-0.0091, -0.0381,  0.5063,  ..., -0.0897,  0.0718, -0.1031],\n",
              "                      [ 0.7483, -0.6411, -0.1428,  ..., -0.1660, -0.5838, -0.0269],\n",
              "                      [ 0.7696,  0.7758, -0.6872,  ...,  0.1359,  0.2560,  0.0524],\n",
              "                      ...,\n",
              "                      [ 0.4702,  0.5029, -0.5214,  ...,  0.4157,  0.0582,  0.0322],\n",
              "                      [-0.3636,  0.2289, -0.3338,  ..., -0.4579, -0.1648, -0.2797],\n",
              "                      [-0.1609, -0.4974, -0.7064,  ...,  0.7584,  0.2387,  0.0903]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 0.0254, -0.2527, -0.8776,  ...,  0.4441,  0.8068, -0.3837],\n",
              "                      [ 0.2514,  0.7015, -0.7241,  ...,  0.1375, -0.1697,  0.5054],\n",
              "                      [-0.7641, -0.0243,  1.1239,  ..., -0.1431,  0.5964, -0.1851],\n",
              "                      ...,\n",
              "                      [-0.1402, -0.1124, -0.2110,  ..., -0.3639,  0.5750, -0.0380],\n",
              "                      [ 0.1395,  0.3051, -0.7409,  ..., -0.6043, -0.3752, -0.0889],\n",
              "                      [-0.2815, -0.2983, -0.1834,  ..., -0.1058, -0.3235,  0.6982]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2082,  0.1991,  0.2029,  0.2166,  0.1402,  0.1697,  0.0512,  0.2168,\n",
              "                       0.1410,  0.1625,  0.1936,  0.1833,  0.1195,  0.1832,  0.1297,  0.1725,\n",
              "                       0.1851,  0.1905,  0.2400,  0.1425,  0.1390,  0.1661,  0.0298,  0.1538,\n",
              "                       0.1437,  0.1977,  0.1457,  0.1767,  0.1858,  0.1458,  0.1537,  0.1597,\n",
              "                       0.1772,  0.1475,  0.2030,  0.1671,  0.1625,  0.2892,  0.1206,  0.2447,\n",
              "                       0.1911,  0.1995,  0.2017,  0.1832,  0.1206,  0.1613,  0.1678,  0.1455,\n",
              "                       0.1870,  0.1313,  0.2352,  0.1863,  0.1555,  0.1359, -0.0030,  0.1637,\n",
              "                       0.0598,  0.1594,  0.1679,  0.1575,  0.1870,  0.1226,  0.1817,  0.1401,\n",
              "                       0.1605,  0.0660,  0.1510,  0.1426,  0.2492,  0.1403,  0.1717,  0.2240,\n",
              "                       0.1337,  0.1834,  0.1504,  0.1479,  0.1773,  0.1739,  0.1423,  0.1935,\n",
              "                       0.1580,  0.1834,  0.1609,  0.2321,  0.1753,  0.1838,  0.2696,  0.1885,\n",
              "                       0.1689,  0.1376,  0.1794,  0.1234,  0.1352,  0.1832,  0.1375,  0.1506,\n",
              "                       0.1463,  0.1477,  0.1544,  0.1317,  0.2168,  0.1654,  0.1810,  0.1395,\n",
              "                       0.1625,  0.2362,  0.1742,  0.1596,  0.1380,  0.1505,  0.1750,  0.1657,\n",
              "                       0.1568,  0.1386,  0.1470,  0.1449,  0.1715,  0.1280,  0.2936,  0.1551,\n",
              "                       0.1252,  0.1590,  0.2103,  0.1641,  0.2161,  0.1666,  0.1634,  0.1703,\n",
              "                       0.1772,  0.2053,  0.1201,  0.1978,  0.1357,  0.1129,  0.1495,  0.2031,\n",
              "                       0.1946,  0.1545,  0.1791,  0.2018,  0.1571,  0.2229,  0.2166,  0.1909,\n",
              "                       0.1756,  0.2081,  0.1545,  0.1910,  0.1418,  0.1817,  0.1578,  0.1828,\n",
              "                       0.1754,  0.2587,  0.1406,  0.1502,  0.2041,  0.1531,  0.1851,  0.1420,\n",
              "                       0.1402,  0.1646,  0.1290,  0.1362,  0.1418,  0.1424,  0.1581,  0.2105,\n",
              "                       0.1786,  0.2825,  0.2496,  0.1957,  0.1635,  0.1753,  0.1771,  0.1608,\n",
              "                       0.1835,  0.1965,  0.1969,  0.0186,  0.1603,  0.1478,  0.1661,  0.1433,\n",
              "                       0.1984,  0.2412,  0.1539,  0.2277,  0.1848,  0.1678,  0.1287,  0.1495,\n",
              "                       0.1132,  0.1651,  0.1398,  0.0631,  0.1513,  0.2132,  0.1633,  0.1136,\n",
              "                       0.1315,  0.1746,  0.1688,  0.1504,  0.1679,  0.2160,  0.1583,  0.1576,\n",
              "                       0.1494,  0.1814,  0.2037,  0.1390,  0.1937,  0.1993,  0.1555,  0.2072,\n",
              "                       0.1821,  0.1523,  0.2059,  0.2268,  0.1274,  0.1867,  0.1265,  0.1805,\n",
              "                       0.1662,  0.1625,  0.2249,  0.2445,  0.1772,  0.2167,  0.1418,  0.1805,\n",
              "                       0.0901,  0.1402,  0.1387,  0.0905,  0.0591,  0.1974,  0.1902,  0.2253,\n",
              "                       0.2634,  0.2114,  0.1524,  0.1665,  0.1287,  0.1402,  0.1497,  0.1927,\n",
              "                       0.1297,  0.1829,  0.1423,  0.1414,  0.1450,  0.1406,  0.1261,  0.1473,\n",
              "                       0.1431,  0.1379,  0.1430,  0.1456,  0.2303,  0.1438,  0.1418,  0.1520,\n",
              "                       0.1543,  0.1515,  0.1479,  0.1676,  0.1620,  0.1620,  0.0770,  0.2647,\n",
              "                       0.2174,  0.0677,  0.2471,  0.1828,  0.1690,  0.2087,  0.1650,  0.1599,\n",
              "                       0.2843,  0.2358,  0.1636,  0.1694,  0.2042,  0.1934,  0.1502,  0.1550,\n",
              "                       0.1623,  0.2087,  0.1465,  0.1696,  0.1418,  0.1490,  0.1510,  0.1278,\n",
              "                       0.2151,  0.1506,  0.1455,  0.2020,  0.2203,  0.1535,  0.2864,  0.1938,\n",
              "                       0.1711,  0.1429,  0.1648,  0.1495,  0.1789,  0.1806,  0.1783,  0.2273,\n",
              "                       0.1550,  0.1261,  0.2172,  0.1745,  0.1182,  0.3009,  0.1491,  0.1453,\n",
              "                       0.1325,  0.2022,  0.1635,  0.1412,  0.2018,  0.1328,  0.2264,  0.2560,\n",
              "                       0.1784,  0.1687,  0.1580,  0.1918,  0.1767,  0.1552,  0.1569,  0.1568,\n",
              "                       0.1461,  0.1557,  0.1820,  0.2838,  0.2162,  0.2092,  0.1989,  0.1352,\n",
              "                       0.1892,  0.1804,  0.1600,  0.1767,  0.1979,  0.1620,  0.2249,  0.1449,\n",
              "                       0.1632,  0.1601,  0.1977,  0.1818,  0.1915,  0.2520,  0.1444,  0.2167,\n",
              "                       0.1526,  0.2428,  0.1832,  0.1118,  0.1517,  0.1595,  0.1612,  0.1568,\n",
              "                       0.1306,  0.1800,  0.1716,  0.2104,  0.0163,  0.1193,  0.2379,  0.1316,\n",
              "                       0.2012,  0.1582,  0.2605,  0.1613,  0.1582,  0.1891,  0.2321,  0.1584,\n",
              "                       0.1542,  0.1347,  0.1451,  0.2345,  0.1086,  0.2267,  0.1530,  0.1627,\n",
              "                       0.1820,  0.2468,  0.2273,  0.1789,  0.1918,  0.1506,  0.1766,  0.1506,\n",
              "                       0.1496,  0.0396,  0.1376,  0.1633,  0.1377,  0.1525,  0.2238,  0.1529,\n",
              "                       0.1392,  0.1401,  0.1570,  0.1286,  0.1630,  0.1607,  0.1390,  0.1580,\n",
              "                       0.1277,  0.1380,  0.0594,  0.1805,  0.2747,  0.1703,  0.1364,  0.0563,\n",
              "                       0.1744,  0.1623,  0.1799,  0.1488,  0.1768,  0.1763,  0.2042,  0.1604,\n",
              "                       0.1738,  0.1311,  0.2315,  0.1491,  0.1661,  0.1514,  0.2035,  0.2208,\n",
              "                       0.2022,  0.1604,  0.2255,  0.2486,  0.1556,  0.1968,  0.1436,  0.1951,\n",
              "                       0.2532,  0.1710,  0.1670,  0.1502,  0.1886,  0.1331,  0.1732,  0.2032,\n",
              "                       0.2070,  0.1655,  0.1861,  0.1357,  0.1384,  0.1418,  0.1543,  0.1830,\n",
              "                       0.1828,  0.1867,  0.1151,  0.1439,  0.1220,  0.1543,  0.1343,  0.1362,\n",
              "                       0.1234,  0.1228,  0.1896,  0.1631,  0.1498,  0.1538,  0.1397,  0.1677,\n",
              "                       0.2178,  0.1571,  0.1536,  0.1525,  0.3098,  0.1517,  0.1400,  0.2031,\n",
              "                      -0.1350,  0.1858,  0.1804,  0.1934,  0.1180,  0.1530,  0.1684,  0.2215,\n",
              "                       0.1724,  0.1647,  0.1574,  0.1431,  0.1478,  0.2154,  0.1905,  0.0657,\n",
              "                       0.1560,  0.1966,  0.1930,  0.2010,  0.1364,  0.1869,  0.1883,  0.1494,\n",
              "                       0.1160,  0.1556,  0.2065,  0.1492,  0.1719,  0.1506,  0.2135,  0.2012,\n",
              "                       0.1248,  0.1479,  0.1181,  0.1576,  0.1846,  0.1741,  0.2091,  0.2657,\n",
              "                       0.1635,  0.2090,  0.2063,  0.1621,  0.1770,  0.1662,  0.1775,  0.1671,\n",
              "                       0.1678,  0.1606,  0.2128,  0.1711,  0.1982,  0.1537,  0.1909,  0.2516,\n",
              "                       0.1628,  0.1582,  0.2075,  0.1784,  0.1569,  0.1303,  0.2345,  0.2438,\n",
              "                       0.1273,  0.2125,  0.1543,  0.1551,  0.1847,  0.1578,  0.1818,  0.1923,\n",
              "                       0.2018,  0.1271,  0.2545,  0.2756,  0.1875,  0.2097,  0.0297,  0.1626,\n",
              "                       0.1804,  0.1528,  0.1996,  0.0840,  0.1241,  0.1521,  0.1655,  0.1898,\n",
              "                       0.1584,  0.2356,  0.1553,  0.2607,  0.1761,  0.1426,  0.1388,  0.1590,\n",
              "                       0.1413,  0.1454,  0.1469,  0.1445,  0.1369,  0.1494,  0.1654,  0.2100,\n",
              "                       0.1540,  0.1842,  0.1890,  0.1674,  0.1779,  0.1708,  0.2407,  0.1649,\n",
              "                       0.2321,  0.1707,  0.1986,  0.0897,  0.2026,  0.1213,  0.1421,  0.1776,\n",
              "                       0.2059,  0.1638,  0.1656,  0.1344,  0.1794,  0.1464,  0.1551,  0.2064,\n",
              "                       0.1332,  0.1860,  0.1745,  0.1665,  0.1790,  0.1305,  0.1606,  0.2415,\n",
              "                       0.1716,  0.1475,  0.1659,  0.1811,  0.1661,  0.1740,  0.2068,  0.1709,\n",
              "                       0.1758,  0.2973,  0.1346,  0.1852,  0.1690,  0.1793,  0.2506,  0.1572,\n",
              "                       0.1864,  0.1821,  0.1447,  0.1724,  0.2018,  0.1969,  0.1870,  0.1316,\n",
              "                       0.1353,  0.1400,  0.1424,  0.1584,  0.1599,  0.1561,  0.2019,  0.2270,\n",
              "                       0.1652,  0.1678,  0.1995,  0.2065,  0.2019,  0.0149,  0.1548,  0.2748,\n",
              "                       0.1613,  0.1993,  0.1663,  0.1382,  0.1919,  0.1603,  0.1710,  0.1598,\n",
              "                       0.1539,  0.1359,  0.1887,  0.1566,  0.1639,  0.1568,  0.1612,  0.1663,\n",
              "                       0.1685,  0.1495,  0.1853,  0.1125,  0.1596,  0.1183,  0.1573,  0.2125,\n",
              "                       0.1527,  0.1941,  0.1439,  0.2022,  0.2629,  0.1371,  0.1575,  0.1472,\n",
              "                       0.2258,  0.1209,  0.1727,  0.1878,  0.1923,  0.1070,  0.1831,  0.1559,\n",
              "                       0.1762,  0.1332,  0.1522,  0.1944,  0.2623,  0.1379,  0.1312,  0.1797,\n",
              "                       0.1634,  0.1594,  0.0566,  0.1788,  0.1801,  0.2113,  0.1763,  0.2367,\n",
              "                       0.1620,  0.1427,  0.2423,  0.1383,  0.1963,  0.1896,  0.2092,  0.1176,\n",
              "                       0.1475,  0.1962,  0.2032,  0.1607,  0.1432,  0.1226,  0.1600,  0.1682,\n",
              "                       0.1683,  0.1776,  0.1627,  0.1997,  0.1765,  0.2074,  0.2223,  0.2138,\n",
              "                       0.1671,  0.2157,  0.1825,  0.1403,  0.2268,  0.2339,  0.1766,  0.1584,\n",
              "                       0.2428,  0.1590,  0.1925,  0.1637,  0.1623,  0.1372,  0.2113,  0.2049,\n",
              "                       0.1753,  0.1172,  0.1758,  0.1268,  0.1903,  0.2001,  0.1644,  0.2303],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.2715, -0.5155,  0.9333,  ..., -0.4267, -0.6215, -0.6921],\n",
              "                      [-0.1682, -0.3131, -0.2468,  ...,  0.7019, -0.0621, -0.0171],\n",
              "                      [-0.3595,  0.0898,  0.2396,  ..., -0.6055,  0.5818,  0.0386],\n",
              "                      ...,\n",
              "                      [ 0.1392, -0.6224, -0.4400,  ...,  0.2634, -0.4500,  0.1773],\n",
              "                      [-0.2746, -0.0020,  0.5446,  ...,  0.2471, -0.2126, -0.2573],\n",
              "                      [ 0.8004, -0.2288, -0.4141,  ...,  0.6183,  0.2519, -0.3540]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.2481,  0.0472,  0.0613,  ..., -0.1456,  0.0848,  0.1906],\n",
              "                      [-0.0346,  0.1887, -0.1821,  ..., -0.0783,  0.2022, -0.2569],\n",
              "                      [-0.1853, -0.1455,  0.1565,  ..., -0.4033,  0.3268,  0.0049],\n",
              "                      ...,\n",
              "                      [ 0.4069,  0.3578,  0.0154,  ...,  0.2078, -0.3661,  0.0068],\n",
              "                      [ 0.3654,  0.2969, -0.1239,  ..., -0.0790,  0.1144, -0.3564],\n",
              "                      [ 0.0084, -0.1340, -0.0768,  ..., -0.2593,  0.1271, -0.2158]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.3.layer.1.layer_norm.weight',\n",
              "              tensor([ 1.0436,  1.1175,  1.0335,  1.2580,  0.7966,  1.0611,  0.5434,  1.1149,\n",
              "                       3.2007,  0.9799,  1.0910,  1.0896,  0.9467,  1.3216,  0.7994,  0.9547,\n",
              "                       1.0839,  1.0502,  1.2462,  0.9150,  0.9685,  1.0189,  0.9820,  0.8341,\n",
              "                       0.8003,  1.1792,  0.7808,  1.0188,  1.0446,  0.8074,  0.9170,  0.8944,\n",
              "                       1.0231,  0.8283,  1.2126,  0.9626,  1.5602,  1.4048,  0.7824,  1.3932,\n",
              "                       1.1441,  1.3331,  1.2122,  0.9752,  3.2022,  0.9522,  1.1943,  0.9448,\n",
              "                       0.9963,  1.2527,  1.3022,  0.9908,  1.5664,  0.8138,  1.1365,  0.9577,\n",
              "                       1.4779,  0.9973,  0.9041,  0.9073,  1.0345,  0.7598,  0.9973,  0.8378,\n",
              "                       0.8550,  1.0741,  0.9156,  0.9061,  1.4291,  0.8864,  0.9450,  1.3939,\n",
              "                       0.7932,  0.9521,  0.8925,  0.8745,  1.3083,  1.0055,  0.8362,  1.0094,\n",
              "                       0.8541,  1.0359,  0.9598,  1.4527,  1.0097,  0.9629,  1.5972,  1.0261,\n",
              "                       0.9724,  0.8550,  0.9794,  0.8408,  0.8056,  1.0535,  0.8479,  0.8245,\n",
              "                       0.8747,  0.8188,  0.8052,  0.8497,  1.2576,  1.0324,  1.3015,  0.7801,\n",
              "                       0.9378,  1.5986,  0.9123,  0.9614,  0.8017,  1.5000,  1.1207,  0.9104,\n",
              "                       0.9569,  0.9647,  0.9080,  0.8183,  0.9935,  0.8569,  1.8272,  0.8922,\n",
              "                       0.7445,  0.8255,  1.4012,  0.8587,  1.2352,  0.9961,  0.9332,  1.0120,\n",
              "                       1.0182,  1.1077,  1.6862,  1.0900,  0.8092,  0.7637,  0.9139,  1.2914,\n",
              "                       1.1508,  0.8900,  1.1215,  1.1080,  0.9807,  1.3165,  1.3455,  1.3287,\n",
              "                       0.9868,  1.3314,  0.8495,  1.1172,  0.8864,  1.0407,  0.8984,  0.9953,\n",
              "                       1.0128,  1.4624,  0.8113,  0.8112,  1.1349,  0.8177,  1.2056,  0.9726,\n",
              "                       0.7983,  0.9486,  0.9326,  2.9643,  0.8200,  0.7941,  0.9009,  1.1686,\n",
              "                       0.9443,  1.3211,  1.3115,  0.9561,  0.8887,  1.4112,  0.8930,  0.9827,\n",
              "                       1.0547,  0.9896,  1.3230,  0.3073,  0.9147,  0.8524,  0.9858,  0.7674,\n",
              "                       1.0654,  1.2381,  0.8440,  1.2265,  1.0839,  1.0633,  0.8508,  0.8275,\n",
              "                       0.7232,  0.9400,  0.7915,  0.3875,  0.9123,  1.2647,  1.0272,  0.8076,\n",
              "                       0.8355,  1.0454,  0.9433,  0.9511,  0.8930,  1.2870,  0.9822,  0.9644,\n",
              "                       0.8736,  0.9604,  1.2808,  0.9568,  1.1595,  1.1641,  0.9025,  1.1346,\n",
              "                       0.9800,  0.8652,  1.0952,  2.8015,  1.0326,  1.0423,  0.7872,  1.0445,\n",
              "                       1.1800,  0.8874,  1.2952,  1.2959,  0.9690,  1.1077,  0.8892,  1.0727,\n",
              "                      -0.6240,  0.7775,  0.7840,  0.6597,  0.4540,  1.1827,  1.2111,  1.3042,\n",
              "                       1.4824,  1.2070,  0.8971,  0.9353,  0.8249,  0.8885,  0.9684,  1.1274,\n",
              "                       0.7521,  1.0715,  2.6085,  0.8468,  0.8619,  0.8849,  0.7925,  0.8838,\n",
              "                       0.8572,  0.8913,  1.2751,  0.9322,  1.3572,  0.2780,  0.8696,  0.9083,\n",
              "                       0.9059,  0.9536,  0.8972,  0.8944,  0.9635,  0.9154,  1.1741,  1.4523,\n",
              "                       1.4752,  1.7472,  1.2876,  1.1136,  0.9545,  1.2803,  0.9457,  0.9783,\n",
              "                       1.4661,  1.4103,  0.9219,  1.4099,  1.0252,  1.2671,  0.7838,  0.8742,\n",
              "                       0.9291,  1.8273,  0.7842,  0.9834,  0.8091,  0.8391,  0.8881,  0.7988,\n",
              "                       1.1863,  0.9207,  0.8515,  1.2031,  1.1261,  0.8294,  1.5078,  1.1098,\n",
              "                       1.0117,  0.7887,  0.9456,  0.8901,  1.0510,  1.0976,  0.9597,  1.1903,\n",
              "                       0.8858, -0.9044, -1.1693,  1.0592,  0.8724,  1.3862,  1.3090,  0.9056,\n",
              "                       0.7845,  1.2783,  1.0079,  0.7773,  1.2747,  0.8209,  1.2513,  1.3614,\n",
              "                       1.0891,  0.9662,  0.8334,  1.2946,  1.1654,  0.9231,  0.9077,  0.9740,\n",
              "                       0.8259,  0.8180,  0.9670,  1.4166,  1.1119,  1.0178,  1.0633,  0.9020,\n",
              "                       1.0060,  1.0700,  1.3065,  1.0133,  1.1842,  1.8365,  1.2941,  0.8050,\n",
              "                       0.9604,  0.8739,  1.0733,  1.0022,  1.1124,  1.3316,  0.8734,  1.2865,\n",
              "                       0.8819,  1.3267,  1.5739,  0.6477,  0.8218,  0.9034,  1.1943,  1.1023,\n",
              "                       0.8659,  1.0616,  1.1625,  1.1183, -0.0092,  0.8474,  1.2996,  0.7893,\n",
              "                       1.2826,  0.8798,  1.3842,  1.3967,  0.8839,  1.0486,  1.3706,  0.9379,\n",
              "                       0.9024,  1.3876,  0.8695,  1.2324,  0.6845,  1.2049,  0.8824,  1.7689,\n",
              "                       1.0497,  1.2941,  1.1923,  1.0459,  1.1525,  0.8302,  1.0423,  0.8794,\n",
              "                       0.8167,  1.0494,  0.7374,  0.8819,  0.8675,  0.9102,  1.2718,  0.8487,\n",
              "                       0.8639,  0.8815,  0.8506,  0.8533,  1.0284,  1.0306,  0.8298,  0.9889,\n",
              "                       0.8477,  0.8369,  0.3283,  1.3519,  1.9066,  1.0324,  0.7841,  0.4388,\n",
              "                       1.0325,  0.8356,  1.0971,  0.8355,  1.0359,  1.0589,  1.1938,  0.8736,\n",
              "                       1.4819,  0.7842,  1.4180,  0.8732,  1.0164,  0.8407,  1.1580,  1.1810,\n",
              "                       1.0744,  1.0376,  1.1820,  1.2822,  0.8231,  1.0438,  0.8329,  1.0533,\n",
              "                       1.3714,  0.9806,  0.9703,  0.7978,  0.9891,  0.8503,  1.1064,  1.2276,\n",
              "                       1.1479,  1.0190,  1.1467,  0.7843,  0.7696,  0.8377,  0.8703,  1.0025,\n",
              "                       1.0125,  0.9773,  0.7445,  0.9309,  0.7662,  0.8401,  0.8103,  0.7646,\n",
              "                       0.7416,  0.8168,  1.0199,  0.8664,  0.8573,  0.8795,  1.1873,  0.9993,\n",
              "                       1.1815,  1.9160,  0.9970,  0.8631,  1.6077,  0.8765,  0.8679,  1.2014,\n",
              "                       0.7898,  0.9946,  0.9732,  1.0911,  1.3254,  0.8595,  1.0349,  1.4489,\n",
              "                       1.0690,  0.9215,  0.9169,  0.7918,  0.8669,  1.1124,  1.2141,  1.3323,\n",
              "                       0.8836,  1.1466,  1.0173,  1.1099,  0.7356,  1.1233,  1.0641,  0.8524,\n",
              "                       2.5437,  0.8218,  1.1008,  0.8180,  0.9684,  1.0101,  1.5983,  1.0672,\n",
              "                       0.7807,  1.0956,  0.7494,  0.9881,  0.9808,  1.8396,  1.1333,  1.4289,\n",
              "                       0.9111,  1.0855,  1.2983,  0.9367,  1.0582,  0.9826,  1.0522,  1.0148,\n",
              "                       0.9643,  0.9514,  1.3093,  1.0547,  1.1648,  0.9010,  1.1034,  1.2534,\n",
              "                       0.9388,  0.8895,  1.0972,  0.9968,  0.9361,  0.8316,  1.4556,  1.3790,\n",
              "                       0.7595,  1.6492,  0.8492,  0.9971,  1.1882,  0.8864,  1.0899,  1.2222,\n",
              "                       1.1439,  0.7915,  1.5408,  1.4687,  0.9956,  1.1894,  0.0039,  0.9577,\n",
              "                       1.0889,  0.9287,  1.1005,  0.2908,  0.7630,  0.9443,  0.9788,  1.0951,\n",
              "                       0.9535,  1.2345,  0.8175,  1.6444,  0.9880,  0.8553,  0.8703,  0.9004,\n",
              "                       0.7844,  0.7752,  0.8040,  0.8725,  0.8611,  0.8408,  0.8931,  1.1204,\n",
              "                       0.8407,  0.9436,  0.9348,  0.8926,  0.9914,  0.9523,  1.3728,  0.9001,\n",
              "                       1.2851,  0.8842,  0.9802,  0.6860,  1.0743,  0.7825,  0.8247,  1.0428,\n",
              "                       1.3280,  0.9256,  1.0082,  0.8347,  1.1416,  0.8381,  0.9737,  1.2031,\n",
              "                       0.8895,  0.9987,  0.9589,  0.9398,  1.0833,  0.8291,  0.8826,  1.3116,\n",
              "                       1.0335,  0.9182,  1.0178,  1.4092,  0.9903,  1.2019,  1.0955,  0.9622,\n",
              "                       1.1087,  1.6173,  0.8129,  1.1240,  1.0507,  0.9986,  1.2117,  0.8325,\n",
              "                       1.1530,  1.0293,  0.8699,  1.0802,  1.0572,  1.0476,  1.1103,  0.7872,\n",
              "                       0.8434,  0.8655,  0.8435,  0.9364,  0.9343,  0.9645,  1.0519,  1.3477,\n",
              "                       0.8648,  1.0739,  1.0238,  1.2013,  1.1101,  0.0929,  0.9038,  1.4033,\n",
              "                       0.9340,  1.2530,  0.9002,  0.8469,  0.9826,  0.8479,  1.0079,  1.4669,\n",
              "                       0.9439,  0.8825,  0.9845,  0.8685,  0.8860,  0.9192,  0.9168,  0.9316,\n",
              "                       0.9587,  0.9044,  1.0848,  0.7851,  0.9712,  1.4682,  0.9067,  1.1608,\n",
              "                       0.8572,  1.0602,  0.8657,  1.0621,  1.5424,  0.8458,  0.9048,  0.9024,\n",
              "                       1.2031,  0.8003,  0.9020,  1.0451,  1.0718,  0.7723,  0.9795,  0.9693,\n",
              "                       0.9805,  0.8220,  0.8852,  1.6596,  1.4151,  0.7815,  2.9218,  0.9950,\n",
              "                       0.9259,  0.8489,  0.4078,  1.0341,  1.1822,  1.2068,  0.9604,  1.3857,\n",
              "                       0.8872,  1.0123,  1.2410,  0.8681,  1.0140,  0.9618,  1.0611,  0.8220,\n",
              "                       0.8518,  1.2216,  1.0803,  0.8866,  0.8426,  0.7371,  0.9144,  0.9467,\n",
              "                       0.9602,  0.9624,  0.9285,  1.0038,  1.0063,  1.3031,  1.1598,  1.1725,\n",
              "                       0.9275,  1.2465,  1.0526,  0.8010,  1.1163,  1.3958,  0.9937,  0.9331,\n",
              "                       1.4665,  0.9652,  1.0403,  0.8762,  1.0347,  0.8591,  1.0128,  1.0904,\n",
              "                       1.0300,  0.7019,  0.9962,  0.8053,  1.0399,  1.0653,  0.9006,  1.2328],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0221, -0.0346,  0.0186,  ...,  0.0514,  0.0472,  0.0363],\n",
              "                      [-0.0016, -0.0138, -0.0669,  ..., -0.0201,  0.0489, -0.0289],\n",
              "                      [ 0.0672, -0.0112,  0.0299,  ..., -0.0078, -0.0346, -0.0493],\n",
              "                      ...,\n",
              "                      [ 0.0424, -0.0421,  0.0146,  ..., -0.0099, -0.0568, -0.0122],\n",
              "                      [ 0.0379, -0.0218, -0.0420,  ...,  0.0017, -0.0186, -0.0009],\n",
              "                      [-0.0486,  0.0128,  0.0085,  ...,  0.0103,  0.0063,  0.0285]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.0982,  0.2399,  0.0797,  ...,  0.0281,  0.0398, -0.1204],\n",
              "                      [ 0.1327,  0.6179,  0.0710,  ..., -0.1913, -0.1737,  0.0971],\n",
              "                      [-0.0170, -0.0614, -0.1863,  ..., -0.0736,  0.0660, -0.1081],\n",
              "                      ...,\n",
              "                      [ 0.2965, -0.3353,  0.1237,  ...,  0.4458, -0.6312, -0.0738],\n",
              "                      [ 0.3865, -0.1840, -0.5888,  ..., -0.0746, -0.1257, -0.0114],\n",
              "                      [ 0.1646,  0.0086, -0.3237,  ...,  0.0169, -0.0118,  0.0291]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.0329,  0.3076,  0.0273,  ..., -0.0058, -0.2007,  0.5460],\n",
              "                      [ 0.3118, -0.2285,  0.4674,  ...,  0.0286,  0.0299, -0.4143],\n",
              "                      [-0.2958, -0.0417,  0.3200,  ..., -1.0812, -0.1688,  0.1217],\n",
              "                      ...,\n",
              "                      [-0.1569, -0.1875,  0.2801,  ...,  0.1980, -0.2870, -0.0416],\n",
              "                      [ 0.1193,  0.2654,  1.0355,  ...,  0.3807,  0.7543, -0.5143],\n",
              "                      [-0.7985,  0.7397, -0.3426,  ..., -0.2448,  0.3200, -0.1598]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 0.2159, -0.3467,  0.3922,  ...,  0.7886,  0.7347,  0.1408],\n",
              "                      [-0.7183, -0.0536,  0.1373,  ...,  0.2252, -0.4619,  0.2183],\n",
              "                      [ 0.2336, -0.3383, -0.2840,  ...,  1.1236,  0.1559, -0.3127],\n",
              "                      ...,\n",
              "                      [-0.2657,  0.2241,  0.7311,  ...,  0.6851, -0.1193,  0.4816],\n",
              "                      [ 0.2274, -0.2451,  0.3746,  ..., -0.4304,  0.6528,  0.2215],\n",
              "                      [-0.1876,  0.1950,  0.2264,  ...,  0.3136, -0.6447, -0.0386]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.1902,  0.1766,  0.1734,  0.2141,  0.1447,  0.1415,  0.0451,  0.2054,\n",
              "                       0.0946,  0.1598,  0.1875,  0.1770,  0.1035,  0.1700,  0.1432,  0.1810,\n",
              "                       0.1697,  0.1815,  0.2277,  0.1481,  0.1383,  0.1612,  0.0646,  0.1374,\n",
              "                       0.1371,  0.1813,  0.1395,  0.1698,  0.1631,  0.1319,  0.1527,  0.1471,\n",
              "                       0.1708,  0.1347,  0.1749,  0.1569,  0.1361,  0.2651,  0.1184,  0.2282,\n",
              "                       0.1618,  0.1818,  0.1978,  0.1835,  0.0958,  0.1608,  0.1440,  0.1504,\n",
              "                       0.1746,  0.0845,  0.2191,  0.1763,  0.1361,  0.1442, -0.0030,  0.1409,\n",
              "                       0.0509,  0.1656,  0.1709,  0.1631,  0.1981,  0.1397,  0.1764,  0.1425,\n",
              "                       0.1615,  0.0557,  0.1539,  0.1329,  0.2404,  0.1365,  0.1623,  0.2151,\n",
              "                       0.1518,  0.1706,  0.1515,  0.1496,  0.1634,  0.1757,  0.1284,  0.1960,\n",
              "                       0.1385,  0.1820,  0.1591,  0.2087,  0.1694,  0.1833,  0.2446,  0.1813,\n",
              "                       0.1677,  0.1433,  0.1680,  0.1236,  0.1486,  0.1672,  0.1357,  0.1412,\n",
              "                       0.1523,  0.1343,  0.1422,  0.1249,  0.2086,  0.1651,  0.1585,  0.1431,\n",
              "                       0.1584,  0.1655,  0.1548,  0.1437,  0.1390,  0.1176,  0.1819,  0.1578,\n",
              "                       0.1649,  0.1300,  0.1654,  0.1386,  0.1537,  0.1325,  0.2309,  0.1469,\n",
              "                       0.1352,  0.1604,  0.1920,  0.1562,  0.1952,  0.1582,  0.1830,  0.1720,\n",
              "                       0.1646,  0.2003,  0.1018,  0.1886,  0.1528,  0.1173,  0.1467,  0.1719,\n",
              "                       0.1943,  0.1635,  0.1685,  0.1936,  0.1489,  0.2254,  0.1879,  0.1722,\n",
              "                       0.1750,  0.1976,  0.1493,  0.1962,  0.1353,  0.1719,  0.1573,  0.1838,\n",
              "                       0.1667,  0.2282,  0.1408,  0.1500,  0.1747,  0.1294,  0.1693,  0.1563,\n",
              "                       0.1181,  0.1408,  0.1155,  0.0730,  0.1449,  0.1222,  0.1594,  0.1853,\n",
              "                       0.1902,  0.2729,  0.2235,  0.1704,  0.1710,  0.1512,  0.1663,  0.1468,\n",
              "                       0.1886,  0.1586,  0.1634,  0.0007,  0.1491,  0.1378,  0.1772,  0.1384,\n",
              "                       0.1950,  0.2187,  0.1481,  0.1958,  0.1753,  0.1615,  0.1315,  0.1473,\n",
              "                       0.0964,  0.1632,  0.1473,  0.0519,  0.1648,  0.1922,  0.1725,  0.1373,\n",
              "                       0.1494,  0.1789,  0.1570,  0.1608,  0.1613,  0.2264,  0.1411,  0.1640,\n",
              "                       0.1483,  0.1657,  0.1828,  0.1360,  0.1922,  0.1911,  0.1557,  0.1908,\n",
              "                       0.1687,  0.1594,  0.1829,  0.1821,  0.1062,  0.1836,  0.1376,  0.1677,\n",
              "                       0.1487,  0.1656,  0.2082,  0.2334,  0.1521,  0.2027,  0.1247,  0.1670,\n",
              "                       0.0902,  0.1206,  0.1289,  0.0858,  0.0659,  0.1954,  0.1818,  0.1972,\n",
              "                       0.2197,  0.1974,  0.1549,  0.1666,  0.1093,  0.1527,  0.1576,  0.1668,\n",
              "                       0.1339,  0.1675,  0.1226,  0.1242,  0.1327,  0.1314,  0.1211,  0.1386,\n",
              "                       0.1461,  0.1314,  0.1210,  0.1617,  0.2138,  0.1192,  0.1516,  0.1572,\n",
              "                       0.1466,  0.1440,  0.1566,  0.1530,  0.1468,  0.1507,  0.0629,  0.2349,\n",
              "                       0.1819,  0.0413,  0.2270,  0.1946,  0.1517,  0.1844,  0.1701,  0.1537,\n",
              "                       0.2464,  0.2210,  0.1621,  0.1525,  0.1822,  0.1526,  0.1334,  0.1477,\n",
              "                       0.1399,  0.1602,  0.1236,  0.1406,  0.1275,  0.1430,  0.1652,  0.1101,\n",
              "                       0.1990,  0.1642,  0.1421,  0.1921,  0.1996,  0.1595,  0.2436,  0.1773,\n",
              "                       0.1781,  0.1340,  0.1674,  0.1505,  0.1692,  0.1669,  0.1735,  0.2017,\n",
              "                       0.1479,  0.1134,  0.1953,  0.1698,  0.1176,  0.2589,  0.1233,  0.1438,\n",
              "                       0.1394,  0.1869,  0.1546,  0.1394,  0.1798,  0.1321,  0.1969,  0.2405,\n",
              "                       0.1729,  0.1726,  0.1547,  0.1547,  0.1621,  0.1650,  0.1611,  0.1448,\n",
              "                       0.1392,  0.1410,  0.1668,  0.2519,  0.2026,  0.1973,  0.1666,  0.1494,\n",
              "                       0.1709,  0.1742,  0.1504,  0.1734,  0.1773,  0.1274,  0.2060,  0.1317,\n",
              "                       0.1576,  0.1575,  0.1943,  0.1844,  0.1863,  0.2244,  0.1436,  0.2034,\n",
              "                       0.1571,  0.2167,  0.1712,  0.0925,  0.1232,  0.1454,  0.1194,  0.1625,\n",
              "                       0.1447,  0.1684,  0.1721,  0.1931,  0.0268,  0.1245,  0.2203,  0.1239,\n",
              "                       0.1750,  0.1455,  0.2422,  0.1319,  0.1529,  0.1726,  0.2057,  0.1652,\n",
              "                       0.1455,  0.0960,  0.1726,  0.1760,  0.1010,  0.2058,  0.1439,  0.1308,\n",
              "                       0.1758,  0.2123,  0.2158,  0.1699,  0.1842,  0.1370,  0.1783,  0.1377,\n",
              "                       0.1363, -0.0019,  0.1093,  0.1840,  0.1480,  0.1569,  0.1915,  0.1331,\n",
              "                       0.1396,  0.1295,  0.1414,  0.1428,  0.1579,  0.1605,  0.1463,  0.1701,\n",
              "                       0.1201,  0.1464,  0.0547,  0.1768,  0.2278,  0.1665,  0.1238,  0.0566,\n",
              "                       0.1775,  0.1449,  0.1783,  0.1255,  0.1909,  0.1654,  0.1976,  0.1445,\n",
              "                       0.1433,  0.1297,  0.2090,  0.1361,  0.1620,  0.1473,  0.1826,  0.2201,\n",
              "                       0.1777,  0.1451,  0.2010,  0.2435,  0.1458,  0.1881,  0.1270,  0.1741,\n",
              "                       0.2262,  0.1886,  0.1523,  0.1374,  0.1617,  0.1462,  0.1860,  0.1980,\n",
              "                       0.1976,  0.1572,  0.1715,  0.1392,  0.1296,  0.1358,  0.1482,  0.1739,\n",
              "                       0.1731,  0.1794,  0.1125,  0.1393,  0.1269,  0.1480,  0.1291,  0.1331,\n",
              "                       0.1263,  0.1365,  0.1904,  0.1631,  0.1438,  0.1488,  0.1056,  0.1772,\n",
              "                       0.1978,  0.1312,  0.1591,  0.1509,  0.2722,  0.1437,  0.1359,  0.1902,\n",
              "                       0.1216,  0.1661,  0.1755,  0.1953,  0.0902,  0.1503,  0.1599,  0.1941,\n",
              "                       0.1697,  0.1624,  0.1631,  0.1338,  0.1496,  0.1974,  0.1759,  0.0521,\n",
              "                       0.1658,  0.1962,  0.1904,  0.1890,  0.1336,  0.1860,  0.1962,  0.1479,\n",
              "                       0.0884,  0.1545,  0.2011,  0.1392,  0.1429,  0.1345,  0.1816,  0.2066,\n",
              "                       0.1354,  0.1453,  0.1226,  0.1396,  0.1752,  0.1458,  0.1899,  0.2363,\n",
              "                       0.1493,  0.2020,  0.2149,  0.1669,  0.1755,  0.1533,  0.1495,  0.1591,\n",
              "                       0.1746,  0.1661,  0.1963,  0.1682,  0.1912,  0.1475,  0.1856,  0.2283,\n",
              "                       0.1529,  0.1601,  0.1820,  0.1691,  0.1511,  0.0832,  0.2088,  0.2159,\n",
              "                       0.1281,  0.2368,  0.1404,  0.1613,  0.1633,  0.1482,  0.1683,  0.1886,\n",
              "                       0.1832,  0.1164,  0.2137,  0.2393,  0.1869,  0.2026,  0.0255,  0.1549,\n",
              "                       0.1759,  0.1601,  0.1834,  0.0634,  0.1188,  0.1402,  0.1595,  0.1765,\n",
              "                       0.1672,  0.2167,  0.1540,  0.2212,  0.1668,  0.1353,  0.1661,  0.1405,\n",
              "                       0.1361,  0.1383,  0.1353,  0.1304,  0.1393,  0.1497,  0.1689,  0.2001,\n",
              "                       0.1435,  0.1767,  0.1659,  0.1845,  0.1639,  0.1628,  0.2175,  0.1610,\n",
              "                       0.2178,  0.1537,  0.1824,  0.0972,  0.1771,  0.1207,  0.1335,  0.1731,\n",
              "                       0.1930,  0.1575,  0.1797,  0.1342,  0.1801,  0.1497,  0.1569,  0.2257,\n",
              "                       0.1326,  0.1854,  0.1553,  0.1680,  0.1962,  0.1294,  0.1681,  0.2163,\n",
              "                       0.1635,  0.1598,  0.1773,  0.1515,  0.1503,  0.1327,  0.1824,  0.1558,\n",
              "                       0.1702,  0.2603,  0.1397,  0.1573,  0.1705,  0.1833,  0.2566,  0.1578,\n",
              "                       0.1623,  0.1755,  0.1474,  0.1587,  0.1975,  0.1798,  0.1782,  0.1363,\n",
              "                       0.1295,  0.1340,  0.1273,  0.1486,  0.1686,  0.1322,  0.1776,  0.2011,\n",
              "                       0.1610,  0.1581,  0.1949,  0.2029,  0.1588,  0.0160,  0.1468,  0.2531,\n",
              "                       0.1628,  0.1719,  0.1331,  0.1406,  0.1846,  0.1424,  0.1760,  0.1603,\n",
              "                       0.1476,  0.1260,  0.1764,  0.1490,  0.1654,  0.1476,  0.1387,  0.1695,\n",
              "                       0.1634,  0.1563,  0.1877,  0.1144,  0.1608,  0.1167,  0.1377,  0.1927,\n",
              "                       0.1430,  0.1875,  0.1409,  0.1802,  0.2289,  0.1300,  0.1466,  0.1443,\n",
              "                       0.2067,  0.1239,  0.1728,  0.1900,  0.1621,  0.0990,  0.1683,  0.1409,\n",
              "                       0.1466,  0.1435,  0.1530,  0.1615,  0.2270,  0.1368,  0.0803,  0.1604,\n",
              "                       0.1585,  0.1344,  0.0490,  0.1757,  0.1602,  0.1959,  0.1752,  0.2099,\n",
              "                       0.1481,  0.0998,  0.2207,  0.1472,  0.1716,  0.1630,  0.1890,  0.1284,\n",
              "                       0.1542,  0.1844,  0.1704,  0.1587,  0.1337,  0.1054,  0.1392,  0.1705,\n",
              "                       0.1734,  0.1646,  0.1530,  0.1714,  0.1707,  0.1875,  0.2170,  0.2108,\n",
              "                       0.1529,  0.1937,  0.1748,  0.1286,  0.2177,  0.1940,  0.1771,  0.1394,\n",
              "                       0.2201,  0.1763,  0.1856,  0.1525,  0.1671,  0.1465,  0.1835,  0.1928,\n",
              "                       0.1650,  0.1147,  0.1758,  0.1220,  0.1929,  0.1876,  0.1542,  0.2244],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.0080,  0.1542, -0.1635,  ...,  0.1412, -0.3939, -0.1859],\n",
              "                      [ 1.0905,  0.1829, -0.4213,  ..., -0.4063, -0.2259, -0.0074],\n",
              "                      [ 0.1489, -0.3686,  0.1149,  ...,  0.1413,  0.3521,  0.0606],\n",
              "                      ...,\n",
              "                      [ 0.1158,  0.2296, -0.6910,  ...,  0.5437,  0.1388,  0.4152],\n",
              "                      [ 0.0688, -0.5519,  0.2532,  ...,  1.2174, -0.7783, -0.1568],\n",
              "                      [ 0.1576, -0.5087,  0.5737,  ...,  0.3119,  0.3667, -0.2539]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.0317,  0.0871, -0.2333,  ...,  0.1884,  0.1605, -0.0534],\n",
              "                      [ 0.0388,  0.2895, -0.4008,  ..., -0.0729, -0.2783,  0.0119],\n",
              "                      [ 0.1032, -0.1980, -0.0505,  ..., -0.1862, -0.0885, -0.1089],\n",
              "                      ...,\n",
              "                      [ 0.2415, -0.0743,  0.0526,  ..., -0.0596, -0.2590, -0.1362],\n",
              "                      [ 0.3435, -0.4244,  0.0371,  ...,  0.3181, -0.0131, -0.1537],\n",
              "                      [ 0.0150, -0.3016, -0.2454,  ..., -0.3181,  0.2430, -0.0017]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.4.layer.1.layer_norm.weight',\n",
              "              tensor([1.1544, 1.1395, 1.1130, 1.2457, 0.9162, 1.1238, 0.5486, 1.2011, 2.8765,\n",
              "                      1.0005, 1.2173, 1.1973, 0.9523, 1.2441, 0.8751, 1.0472, 1.1980, 1.1498,\n",
              "                      1.2564, 0.9882, 1.0526, 1.0669, 1.5699, 0.9426, 0.9351, 1.2131, 0.8861,\n",
              "                      1.1191, 1.1134, 0.8538, 0.9705, 0.9826, 1.1209, 0.9271, 1.1998, 1.0034,\n",
              "                      1.5717, 1.4235, 0.8842, 1.5697, 1.1552, 1.4127, 1.2497, 1.0956, 3.3479,\n",
              "                      1.0477, 1.1280, 1.0051, 1.0833, 1.1830, 1.3948, 1.0839, 1.7034, 0.8901,\n",
              "                      1.1252, 1.0273, 1.4919, 1.0529, 0.9446, 1.0314, 1.1693, 0.8649, 1.0756,\n",
              "                      0.9826, 0.9559, 1.3938, 0.9844, 0.9836, 1.4284, 0.9468, 1.0320, 1.5743,\n",
              "                      0.8845, 1.0844, 0.9714, 0.9528, 1.3174, 1.1091, 0.9199, 1.1045, 0.9777,\n",
              "                      1.0881, 1.0188, 1.3872, 1.0156, 1.0828, 1.5594, 1.1156, 1.0547, 0.9481,\n",
              "                      1.1403, 0.9335, 0.9094, 1.1652, 0.9749, 0.9152, 0.9807, 0.9252, 0.9354,\n",
              "                      0.9293, 1.2186, 1.0371, 1.2678, 0.9104, 1.0457, 1.6665, 0.9873, 1.0560,\n",
              "                      0.9134, 1.7703, 1.2245, 1.0360, 0.9915, 1.0336, 0.9866, 0.8849, 1.0240,\n",
              "                      0.9029, 1.7638, 1.0246, 0.8502, 0.9307, 1.4948, 0.9725, 1.2823, 0.9933,\n",
              "                      1.0109, 1.0677, 1.0660, 1.2069, 1.5897, 1.1336, 0.8817, 0.8741, 0.9296,\n",
              "                      1.3616, 1.2728, 0.9387, 1.1691, 1.1707, 1.0301, 1.3417, 1.4097, 1.2864,\n",
              "                      1.0318, 1.3294, 0.9987, 1.1342, 0.9260, 1.1334, 0.9935, 1.1168, 1.0919,\n",
              "                      1.3844, 0.9510, 0.9031, 1.1348, 0.9017, 1.2394, 1.0610, 0.8454, 0.9742,\n",
              "                      0.9778, 3.0633, 0.9206, 0.8755, 1.0076, 1.2162, 1.0330, 1.3286, 1.3415,\n",
              "                      0.9612, 0.9655, 1.4256, 1.0260, 1.1438, 1.0848, 0.8462, 1.3259, 0.3446,\n",
              "                      0.9694, 0.9456, 1.0440, 0.8408, 1.1534, 1.3119, 0.9427, 1.2306, 1.1532,\n",
              "                      1.1611, 0.9361, 0.9472, 0.8691, 1.0133, 0.9158, 0.4438, 1.0246, 1.3064,\n",
              "                      1.0349, 0.8882, 0.9238, 1.1181, 1.0179, 1.0572, 0.9456, 1.2686, 1.0422,\n",
              "                      1.0237, 0.9390, 1.0384, 1.2508, 1.0238, 1.1904, 1.2728, 1.0127, 1.1595,\n",
              "                      1.0579, 1.0218, 1.2106, 2.8321, 1.0666, 1.0862, 0.8632, 1.0591, 1.2740,\n",
              "                      1.0491, 1.3224, 1.3665, 1.0647, 1.1625, 0.9851, 1.1080, 0.7152, 0.8618,\n",
              "                      0.8710, 0.7092, 0.4798, 1.2559, 1.2586, 1.2296, 1.4624, 1.2368, 0.9742,\n",
              "                      1.0301, 0.8500, 0.8872, 1.0042, 1.1480, 0.8572, 1.0653, 3.0778, 0.9030,\n",
              "                      1.0022, 0.9502, 0.8226, 0.9339, 0.9320, 0.9257, 1.1749, 1.0136, 1.3251,\n",
              "                      0.2262, 0.9172, 1.0169, 0.9705, 0.9476, 0.9400, 0.9582, 0.9972, 0.9678,\n",
              "                      1.0046, 1.4231, 1.5488, 1.7815, 1.2898, 1.1947, 0.9799, 1.2558, 1.0008,\n",
              "                      1.0119, 1.4883, 1.3824, 0.9864, 1.4696, 1.1808, 1.3487, 0.8641, 0.9706,\n",
              "                      0.9989, 1.9723, 0.8382, 1.0497, 0.9059, 0.8813, 0.9803, 0.9200, 1.2168,\n",
              "                      0.9541, 0.9450, 1.2566, 1.1541, 0.9694, 1.4516, 1.0965, 1.0748, 0.8840,\n",
              "                      0.9679, 0.9512, 1.1211, 1.1541, 0.9925, 1.2908, 0.9527, 0.9296, 1.2012,\n",
              "                      1.1138, 0.9386, 1.4256, 1.3652, 0.9703, 0.8874, 1.2926, 1.0683, 0.8834,\n",
              "                      1.2696, 0.9238, 1.3301, 1.4001, 1.0655, 1.0057, 0.9642, 1.3525, 1.1602,\n",
              "                      0.9623, 0.9567, 1.0345, 0.9190, 0.9087, 1.0504, 1.4184, 1.1407, 1.1269,\n",
              "                      1.1358, 1.0089, 1.0804, 1.0806, 1.3566, 1.0979, 1.2210, 1.9689, 1.3088,\n",
              "                      0.8955, 1.0751, 1.0082, 1.1874, 1.0733, 1.1016, 1.3470, 0.9093, 1.3322,\n",
              "                      0.9433, 1.3798, 1.4073, 0.7554, 0.9026, 1.0194, 1.1585, 1.1461, 0.9107,\n",
              "                      1.1616, 1.1904, 1.1741, 0.1815, 0.9108, 1.3407, 0.8637, 1.3597, 0.9394,\n",
              "                      1.4283, 1.4147, 0.9925, 1.1422, 1.3704, 1.0073, 0.9781, 1.4024, 1.0027,\n",
              "                      1.2138, 0.7823, 1.2695, 1.0155, 2.0935, 1.0538, 1.3231, 1.2380, 1.1122,\n",
              "                      1.1935, 0.8769, 1.1127, 0.9613, 0.8951, 0.9114, 0.8470, 0.9957, 0.9228,\n",
              "                      1.0189, 1.2773, 0.8911, 0.8808, 0.9181, 0.9332, 0.9349, 1.1204, 1.0640,\n",
              "                      0.8829, 1.1135, 0.9347, 0.9278, 0.3213, 1.4110, 1.7833, 1.1312, 0.8457,\n",
              "                      0.4744, 1.0917, 0.9443, 1.1029, 0.9489, 1.0996, 1.1390, 1.2663, 0.9910,\n",
              "                      1.5077, 0.8711, 1.4372, 0.9397, 1.0350, 0.8898, 1.1999, 1.3067, 1.1325,\n",
              "                      1.0741, 1.2818, 1.3580, 0.9069, 1.1319, 0.8917, 1.0777, 1.3468, 1.0564,\n",
              "                      1.0391, 0.8927, 1.0346, 0.9188, 1.1972, 1.2727, 1.2628, 1.1137, 1.2001,\n",
              "                      0.8720, 0.8505, 0.9374, 0.9937, 1.0739, 1.0158, 1.0425, 0.8430, 1.0053,\n",
              "                      0.8619, 0.8961, 0.9053, 0.8733, 0.8551, 0.8439, 1.0588, 0.9042, 0.9399,\n",
              "                      0.9396, 1.2079, 1.0909, 1.2138, 2.1221, 1.0134, 0.9621, 1.5685, 0.9919,\n",
              "                      0.9293, 1.2669, 0.8620, 1.0698, 1.0318, 1.1704, 1.2650, 0.9498, 1.1433,\n",
              "                      1.3429, 1.1123, 0.9804, 0.9858, 0.8690, 0.9631, 1.1602, 1.2713, 1.6351,\n",
              "                      1.0322, 1.1597, 1.1225, 1.1236, 0.8377, 1.1166, 1.1251, 0.8999, 2.5862,\n",
              "                      0.9108, 1.1650, 0.9116, 1.0305, 1.0643, 1.5442, 1.1858, 0.8576, 1.1199,\n",
              "                      0.8638, 1.0696, 1.0831, 2.1748, 1.1961, 1.5241, 0.9953, 1.2278, 1.2682,\n",
              "                      1.0421, 1.0912, 1.1075, 1.1054, 1.1006, 1.0252, 1.0140, 1.3726, 1.0780,\n",
              "                      1.2301, 0.9488, 1.1888, 1.3933, 0.9818, 0.9349, 1.0816, 1.0419, 0.9909,\n",
              "                      0.6442, 1.4385, 1.3641, 0.7766, 1.4609, 0.9454, 1.0581, 1.2632, 0.9062,\n",
              "                      1.1203, 1.1723, 1.2576, 0.8679, 1.4791, 1.4560, 1.0231, 1.1812, 0.0114,\n",
              "                      1.0824, 1.2048, 1.0002, 1.1141, 0.2994, 0.8612, 0.9895, 1.0528, 1.1088,\n",
              "                      0.9929, 1.2916, 0.8956, 1.5758, 1.0085, 0.9098, 1.0348, 1.0043, 0.8399,\n",
              "                      0.8433, 0.9120, 0.9162, 0.9534, 0.9174, 0.9881, 1.1855, 0.8994, 0.9875,\n",
              "                      1.0368, 0.9892, 1.0607, 1.0493, 1.3993, 0.9931, 1.3145, 0.9476, 1.0626,\n",
              "                      0.6429, 1.1213, 0.8734, 0.8559, 1.1190, 1.3643, 1.0316, 1.0998, 0.9360,\n",
              "                      1.1987, 0.9367, 1.0313, 1.3190, 0.9912, 1.0866, 1.0086, 1.0073, 1.1881,\n",
              "                      0.9272, 1.0281, 1.3163, 1.0378, 0.9418, 1.1096, 1.3658, 1.0135, 1.2618,\n",
              "                      1.2258, 1.0047, 1.2186, 1.5763, 0.8552, 0.9993, 1.1328, 1.0329, 1.2803,\n",
              "                      0.9104, 1.1868, 1.0899, 0.9964, 1.1481, 1.1773, 1.1058, 1.1197, 0.8808,\n",
              "                      0.9621, 0.9490, 0.9610, 1.0658, 1.0765, 1.0670, 1.1132, 1.3494, 0.9231,\n",
              "                      1.1101, 1.1346, 1.2941, 1.0922, 0.1059, 0.9970, 1.4242, 1.0740, 1.3152,\n",
              "                      1.0484, 0.9789, 1.0099, 1.0074, 1.0764, 1.6056, 1.0100, 0.9829, 1.0591,\n",
              "                      0.9707, 0.9726, 0.9776, 0.9607, 0.9660, 1.1177, 1.0543, 1.1158, 0.8701,\n",
              "                      1.0299, 1.4493, 0.9559, 1.1874, 0.9134, 1.1263, 0.9471, 1.1480, 1.4885,\n",
              "                      0.8706, 1.0431, 1.0295, 1.2103, 0.8581, 0.9647, 1.1251, 1.1853, 0.8583,\n",
              "                      1.0489, 1.0501, 1.1169, 0.9109, 0.9779, 1.5302, 1.4115, 0.9159, 2.9070,\n",
              "                      1.0169, 0.9883, 0.9178, 0.4014, 1.1532, 1.2146, 1.2668, 1.0083, 1.3094,\n",
              "                      0.9051, 1.0883, 1.3138, 0.9420, 1.1447, 1.0785, 1.1133, 0.9479, 0.9588,\n",
              "                      1.2968, 1.1479, 1.0071, 0.9262, 0.7919, 0.9864, 1.0079, 1.0331, 1.0642,\n",
              "                      1.0142, 1.1147, 1.0981, 1.3397, 1.2292, 1.1923, 1.0300, 1.2218, 1.1118,\n",
              "                      0.8801, 1.2571, 1.4254, 1.0923, 1.0380, 1.4613, 1.0561, 1.1069, 1.0289,\n",
              "                      1.0860, 0.9517, 1.1099, 1.2146, 1.0748, 0.8011, 1.1343, 0.9028, 1.1103,\n",
              "                      1.1520, 1.0179, 1.3083], device='cuda:0')),\n",
              "             ('encoder.block.5.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0473, -0.0394,  0.0284,  ...,  0.0179,  0.0007,  0.0339],\n",
              "                      [ 0.0242,  0.0715, -0.0161,  ..., -0.0571,  0.0240,  0.0486],\n",
              "                      [ 0.0146,  0.0283, -0.0216,  ...,  0.0143,  0.0447,  0.0288],\n",
              "                      ...,\n",
              "                      [-0.0509, -0.0249, -0.0105,  ...,  0.0301,  0.0543, -0.0026],\n",
              "                      [ 0.0020, -0.0387,  0.0339,  ...,  0.0636,  0.0162, -0.0083],\n",
              "                      [ 0.0300,  0.0313, -0.0467,  ..., -0.0403, -0.0366, -0.0296]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.5.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.3749,  0.0962, -0.2226,  ...,  0.2486,  0.4718,  0.4185],\n",
              "                      [ 0.3152,  0.0255, -0.4843,  ...,  0.0458,  0.0646,  0.3703],\n",
              "                      [-0.0432, -0.2788, -0.2780,  ...,  0.0797,  0.5084,  0.2095],\n",
              "                      ...,\n",
              "                      [-0.2524, -0.1899,  0.2054,  ...,  0.2807,  0.2226,  0.0393],\n",
              "                      [ 0.0791,  0.1558, -0.1496,  ..., -0.0467,  0.1384, -0.0210],\n",
              "                      [-0.0268,  0.1185, -0.0872,  ...,  0.0732, -0.4377, -0.2127]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.5.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-0.0165,  0.6559,  0.0876,  ...,  0.0544,  0.1953, -0.0361],\n",
              "                      [ 0.2194, -0.0424, -0.5562,  ..., -0.3065, -0.0378,  0.1900],\n",
              "                      [ 0.1827, -1.0328, -0.0348,  ...,  0.2903,  0.9591, -0.6518],\n",
              "                      ...,\n",
              "                      [ 0.1368, -0.6222,  0.2488,  ...,  0.2964, -0.6051, -0.7565],\n",
              "                      [ 0.0158,  0.0876,  0.6712,  ...,  0.1275, -0.4200, -0.0233],\n",
              "                      [-0.5102,  0.5258, -0.2918,  ..., -0.3816,  0.1600, -0.0271]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.5.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.2500, -0.4112, -0.7421,  ..., -0.6680, -0.6169, -0.2283],\n",
              "                      [-0.2611,  0.0824,  1.9041,  ..., -0.2754,  0.4052,  0.3239],\n",
              "                      [-0.3846,  0.7572,  0.1528,  ...,  0.4974,  0.6073, -0.2257],\n",
              "                      ...,\n",
              "                      [ 0.0575, -0.2812, -0.5197,  ..., -0.2745,  0.0777, -0.1223],\n",
              "                      [ 0.2573, -0.2575, -0.4372,  ...,  0.9913, -0.3870, -0.3562],\n",
              "                      [ 0.3016,  0.0206,  0.4458,  ...,  0.6464,  0.3950,  0.6473]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.5.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2043,  0.1860,  0.1883,  0.2132,  0.1610,  0.1616,  0.0485,  0.2170,\n",
              "                       0.0844,  0.1781,  0.2069,  0.1920,  0.1186,  0.1848,  0.1446,  0.1864,\n",
              "                       0.1739,  0.1877,  0.2076,  0.1715,  0.1552,  0.1841,  0.0733,  0.1675,\n",
              "                       0.1554,  0.2063,  0.1340,  0.1627,  0.1810,  0.1421,  0.1450,  0.1660,\n",
              "                       0.1937,  0.1319,  0.2071,  0.1681,  0.1564,  0.2590,  0.1370,  0.2262,\n",
              "                       0.1868,  0.1819,  0.1995,  0.1879, -0.0699,  0.1740,  0.1472,  0.1610,\n",
              "                       0.2032,  0.0609,  0.2099,  0.1942,  0.1505,  0.1596, -0.0016,  0.1549,\n",
              "                       0.0733,  0.1624,  0.1812,  0.1720,  0.1942,  0.1262,  0.1875,  0.1503,\n",
              "                       0.1659,  0.0691,  0.1638,  0.1540,  0.2202,  0.1623,  0.1693,  0.2114,\n",
              "                       0.1524,  0.1819,  0.1623,  0.1716,  0.1549,  0.1920,  0.1370,  0.2057,\n",
              "                       0.1472,  0.1849,  0.1790,  0.2191,  0.1826,  0.1934,  0.2343,  0.1982,\n",
              "                       0.1721,  0.1501,  0.1919,  0.1385,  0.1516,  0.1680,  0.1468,  0.1488,\n",
              "                       0.1742,  0.1576,  0.1566,  0.1378,  0.2139,  0.1777,  0.1479,  0.1451,\n",
              "                       0.1770,  0.1835,  0.1717,  0.1527,  0.1530,  0.1027,  0.1794,  0.1746,\n",
              "                       0.1652,  0.1349,  0.1677,  0.1463,  0.1799,  0.1479,  0.2238,  0.1635,\n",
              "                       0.1330,  0.1777,  0.2053,  0.1597,  0.1831,  0.1868,  0.1898,  0.1851,\n",
              "                       0.1803,  0.2096,  0.1044,  0.1906,  0.1569,  0.1349,  0.1843,  0.1798,\n",
              "                       0.2037,  0.1765,  0.1773,  0.2145,  0.1571,  0.2207,  0.2078,  0.1901,\n",
              "                       0.1846,  0.2126,  0.1564,  0.2078,  0.1588,  0.1806,  0.1665,  0.1810,\n",
              "                       0.1737,  0.2253,  0.1500,  0.1562,  0.1894, -0.1397,  0.1743,  0.1597,\n",
              "                       0.1535,  0.1561,  0.1162,  0.0796,  0.1553,  0.1427,  0.1728,  0.1987,\n",
              "                       0.1926,  0.2432,  0.2304,  0.1799,  0.1943,  0.1518,  0.1791,  0.1628,\n",
              "                       0.1985,  0.1247,  0.1673,  0.0190,  0.1653,  0.1449,  0.1709,  0.1579,\n",
              "                       0.2075,  0.2113,  0.1530,  0.2244,  0.1907,  0.1863,  0.1406,  0.1697,\n",
              "                       0.1158,  0.1839,  0.1484,  0.0639,  0.1707,  0.2154,  0.1812,  0.1062,\n",
              "                       0.1394,  0.1855,  0.1643,  0.1671,  0.1705,  0.2165,  0.1505,  0.1623,\n",
              "                       0.1585,  0.1762,  0.1829,  0.1561,  0.2091,  0.1965,  0.1647,  0.2108,\n",
              "                       0.1907,  0.1716,  0.1960,  0.1766,  0.1021,  0.1894,  0.1445,  0.1728,\n",
              "                       0.1434,  0.1762,  0.2228,  0.2551,  0.1699,  0.2138,  0.1411,  0.1714,\n",
              "                       0.0885,  0.1503,  0.1492,  0.0986,  0.0831,  0.1984,  0.1869,  0.1880,\n",
              "                       0.2276,  0.2146,  0.1680,  0.1726,  0.1329,  0.1588,  0.1679,  0.1848,\n",
              "                       0.1349,  0.1839,  0.1210,  0.1281,  0.1440, -0.1451,  0.1359,  0.1442,\n",
              "                       0.1628,  0.1353,  0.0951,  0.1651,  0.2214,  0.1136,  0.1458,  0.1841,\n",
              "                       0.1453,  0.1584,  0.1497,  0.1649,  0.1732,  0.1656,  0.0783,  0.2546,\n",
              "                       0.1815,  0.0529,  0.2295,  0.1888,  0.1811,  0.1694,  0.1713,  0.1634,\n",
              "                       0.2484,  0.2374,  0.1609,  0.1650,  0.1857,  0.1562,  0.1496,  0.1655,\n",
              "                       0.1606,  0.1641,  0.1380,  0.1732,  0.1446,  0.1618,  0.1506,  0.1440,\n",
              "                       0.1957,  0.1655,  0.1481,  0.1896,  0.2130,  0.1590,  0.2492,  0.1921,\n",
              "                       0.1771,  0.1438,  0.1873,  0.1709,  0.1746,  0.1671,  0.1758,  0.2082,\n",
              "                       0.1472,  0.1296,  0.2101,  0.1721,  0.1098,  0.2625,  0.1331,  0.1763,\n",
              "                       0.1489,  0.2043,  0.1634,  0.1600,  0.1949,  0.1405,  0.1951,  0.2431,\n",
              "                       0.1873,  0.1825,  0.1624,  0.1629,  0.1698,  0.1508,  0.1552,  0.1689,\n",
              "                       0.1219,  0.1583,  0.1713,  0.2450,  0.2052,  0.1994,  0.1785,  0.1648,\n",
              "                       0.1857,  0.2001,  0.1528,  0.1839,  0.1777,  0.1284,  0.2107,  0.1436,\n",
              "                       0.1729,  0.1673,  0.1904,  0.1922,  0.1961,  0.2213,  0.1605,  0.1940,\n",
              "                       0.1568,  0.2176,  0.1916,  0.1039,  0.1535,  0.1622,  0.0944,  0.1498,\n",
              "                       0.1444,  0.1758,  0.1664,  0.2057,  0.0319,  0.1341,  0.2164,  0.1496,\n",
              "                       0.1652,  0.1636,  0.2328,  0.1421,  0.1692,  0.1784,  0.2267,  0.1832,\n",
              "                       0.1640,  0.0899,  0.1654,  0.1622,  0.1128,  0.2258,  0.1584,  0.1207,\n",
              "                       0.1937,  0.2144,  0.2069,  0.1581,  0.1969,  0.1687,  0.1868,  0.1425,\n",
              "                       0.1603, -0.0010,  0.1272,  0.1753,  0.1572,  0.1547,  0.1981,  0.1604,\n",
              "                       0.1552,  0.1542,  0.1677,  0.1350,  0.1650,  0.1706,  0.1568,  0.1606,\n",
              "                       0.1280,  0.1427,  0.0570,  0.1768,  0.2216,  0.1666,  0.1421,  0.0487,\n",
              "                       0.1901,  0.1743,  0.1981,  0.1580,  0.1957,  0.1761,  0.2089,  0.1762,\n",
              "                       0.1435,  0.1360,  0.1995,  0.1504,  0.1673,  0.1483,  0.2013,  0.2198,\n",
              "                       0.1971,  0.1385,  0.2156,  0.2330,  0.1536,  0.1893,  0.1459,  0.1981,\n",
              "                       0.2137,  0.1953,  0.1528,  0.1652,  0.1774,  0.1634,  0.2039,  0.2173,\n",
              "                       0.2045,  0.1887,  0.1754,  0.1377,  0.1405,  0.1482,  0.1577,  0.1951,\n",
              "                       0.1962,  0.1975,  0.1166,  0.1566,  0.1216,  0.1770,  0.1335,  0.1406,\n",
              "                       0.1305,  0.1430,  0.1848,  0.1708,  0.1566,  0.1597,  0.1048,  0.1804,\n",
              "                       0.1995,  0.1319,  0.1731,  0.1601,  0.2657,  0.1591,  0.1500,  0.2065,\n",
              "                       0.1394,  0.1819,  0.2009,  0.1847,  0.0751,  0.1792,  0.1551,  0.2056,\n",
              "                       0.1982,  0.1786,  0.1657,  0.1401,  0.1573,  0.2273,  0.1816,  0.0682,\n",
              "                       0.1686,  0.2146,  0.1992,  0.1959,  0.1329,  0.2002,  0.2085,  0.1476,\n",
              "                       0.0977,  0.1588,  0.1983,  0.1620,  0.1581,  0.1611,  0.1782,  0.2017,\n",
              "                       0.1400,  0.1629,  0.1304,  0.1485,  0.1862,  0.1548,  0.1951,  0.2370,\n",
              "                       0.1578,  0.2049,  0.2214,  0.1697,  0.1793,  0.1663,  0.1788,  0.1729,\n",
              "                       0.1760,  0.1795,  0.2215,  0.1758,  0.2014,  0.1705,  0.2011,  0.2296,\n",
              "                       0.1688,  0.1726,  0.1862,  0.1720,  0.1706,  0.0825,  0.2165,  0.2373,\n",
              "                       0.1221,  0.2454,  0.1434,  0.1747,  0.1792,  0.1649,  0.1766,  0.1740,\n",
              "                       0.1795,  0.1263,  0.2229,  0.2338,  0.1941,  0.2062,  0.0233,  0.1639,\n",
              "                       0.1866,  0.1806,  0.2049,  0.0763,  0.1315,  0.1597,  0.1878,  0.1903,\n",
              "                       0.1712,  0.2292,  0.1580,  0.2046,  0.1805,  0.1467,  0.1676,  0.1521,\n",
              "                       0.1455,  0.1344,  0.1396,  0.1430,  0.1512,  0.1634,  0.1888,  0.2015,\n",
              "                       0.1556,  0.1694,  0.1741,  0.1839,  0.1736,  0.1692,  0.2066,  0.1700,\n",
              "                       0.2252,  0.1788,  0.1985,  0.0898,  0.2039,  0.1478,  0.1568,  0.1690,\n",
              "                       0.1916,  0.1681,  0.1832,  0.1477,  0.1888,  0.1736,  0.1610,  0.2144,\n",
              "                       0.1508,  0.1953,  0.1825,  0.1683,  0.2121,  0.1305,  0.1721,  0.2321,\n",
              "                       0.1942,  0.1794,  0.1769,  0.1682,  0.1811,  0.1295,  0.1955,  0.1565,\n",
              "                       0.2066,  0.2616,  0.1523,  0.1525,  0.1880,  0.1802,  0.2564,  0.1692,\n",
              "                       0.1729,  0.1886,  0.1538,  0.1591,  0.2178,  0.1988,  0.1997,  0.1415,\n",
              "                       0.1419,  0.1310,  0.1501,  0.1799,  0.1690,  0.1648,  0.1823,  0.2065,\n",
              "                       0.1686,  0.1487,  0.1865,  0.2094,  0.1728,  0.0155,  0.1695,  0.2533,\n",
              "                       0.1646,  0.1960,  0.1483,  0.1616,  0.2030,  0.1836,  0.1710,  0.1463,\n",
              "                       0.1812,  0.1513,  0.1847,  0.1700,  0.1630,  0.1617,  0.1602,  0.1711,\n",
              "                       0.1758,  0.1587,  0.1964,  0.1411,  0.1709,  0.1086,  0.1447,  0.2026,\n",
              "                       0.1575,  0.2151,  0.1546,  0.2012,  0.2154,  0.1479,  0.1506,  0.1536,\n",
              "                       0.2170,  0.1425,  0.1880,  0.1929,  0.1861,  0.1256,  0.1813,  0.1591,\n",
              "                       0.1707,  0.1480,  0.1585,  0.1993,  0.2309,  0.1496,  0.0817,  0.1822,\n",
              "                       0.1790,  0.1560,  0.0600,  0.1934,  0.1863,  0.1969,  0.1814,  0.2147,\n",
              "                       0.1498,  0.1304,  0.2135,  0.1508,  0.1963,  0.1846,  0.2011,  0.1192,\n",
              "                       0.1614,  0.1902,  0.1826,  0.1635,  0.1450,  0.1167,  0.1635,  0.1750,\n",
              "                       0.1788,  0.1933,  0.1782,  0.1945,  0.1879,  0.1909,  0.2269,  0.2123,\n",
              "                       0.1747,  0.1948,  0.1815,  0.1491,  0.2197,  0.2110,  0.1803,  0.1731,\n",
              "                       0.2250,  0.1709,  0.2048,  0.1655,  0.1843,  0.1688,  0.1796,  0.2305,\n",
              "                       0.1786,  0.1145,  0.1925,  0.1302,  0.1974,  0.1939,  0.1579,  0.2300],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.5.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.3033,  0.8331,  0.3338,  ..., -0.7156, -0.1506,  0.0986],\n",
              "                      [-0.5993,  0.4115,  0.3124,  ..., -0.0524, -1.0460,  0.2737],\n",
              "                      [ 0.2409, -0.4943, -0.5340,  ...,  0.5930, -0.3040,  0.9533],\n",
              "                      ...,\n",
              "                      [-0.2030, -0.0284, -0.0581,  ..., -0.3725, -0.6737, -0.1701],\n",
              "                      [ 0.2878, -0.0510, -0.4156,  ...,  0.0063, -0.6990,  0.6077],\n",
              "                      [-0.1703, -0.2881,  0.0737,  ..., -0.3877,  0.2710,  0.0484]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.5.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.0298, -0.1665, -0.1678,  ..., -0.0413, -0.2268, -0.3383],\n",
              "                      [ 0.3191, -0.3260, -0.6849,  ...,  0.1495, -0.0288,  0.0278],\n",
              "                      [ 0.2323, -0.4332,  0.0537,  ...,  0.3348, -0.0262,  0.1445],\n",
              "                      ...,\n",
              "                      [-0.3566, -0.1909,  0.1520,  ..., -0.0361,  0.0755,  0.0140],\n",
              "                      [ 0.3083,  0.2558,  0.3129,  ...,  0.3353,  0.0350, -0.1287],\n",
              "                      [ 0.1299,  0.1370,  0.1547,  ..., -0.1189, -0.0072,  0.1970]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.5.layer.1.layer_norm.weight',\n",
              "              tensor([ 1.1493,  1.1475,  1.0630,  1.1321,  0.9284,  1.1074,  0.5142,  1.2671,\n",
              "                       2.4152,  1.0457,  1.2046,  1.1737,  1.0037,  1.2562,  0.9367,  1.0632,\n",
              "                       1.1811,  1.1408,  1.1934,  1.0038,  1.0531,  1.0893,  1.8385,  0.9704,\n",
              "                       0.9391,  1.2360,  0.9735,  1.0453,  1.1665,  0.9321,  1.0195,  0.9965,\n",
              "                       1.1141,  0.9747,  1.1898,  1.0583,  1.4666,  1.3105,  0.9295,  1.6063,\n",
              "                       1.0963,  1.4111,  1.1999,  1.1318,  2.9790,  1.0784,  1.1100,  1.0687,\n",
              "                       1.0851,  0.9713,  1.2789,  1.1219,  1.6430,  0.9316,  1.0226,  1.0304,\n",
              "                       1.4642,  1.0660,  1.0542,  1.0285,  1.1487,  0.9329,  1.0943,  1.0124,\n",
              "                       0.9342,  1.4705,  1.0043,  1.0118,  1.3467,  0.9847,  1.0475,  1.5490,\n",
              "                       0.9338,  1.1569,  0.9882,  0.9809,  1.2967,  1.0721,  0.9763,  1.0760,\n",
              "                       0.9722,  1.0415,  1.0365,  1.3230,  1.0423,  1.1010,  1.4103,  1.1518,\n",
              "                       1.0571,  0.9952,  1.0906,  0.9477,  0.9472,  1.1746,  0.9930,  0.9043,\n",
              "                       0.9460,  1.0008,  0.9535,  0.9276,  1.2492,  1.0461,  1.1476,  0.9591,\n",
              "                       1.0949,  1.5908,  0.9973,  1.0496,  0.9722,  1.7718,  1.1951,  1.0160,\n",
              "                       0.9913,  1.0236,  1.0122,  0.9612,  1.0416,  0.9285,  1.5601,  0.9985,\n",
              "                       0.9082,  0.9750,  1.3880,  0.9723,  1.1883,  1.0618,  1.0827,  1.0686,\n",
              "                       1.0645,  1.1678,  1.4406,  1.0958,  0.9490,  0.9360,  0.9630,  1.2635,\n",
              "                       1.2974,  0.9970,  1.1904,  1.1169,  0.9797,  1.3052,  1.3024,  1.2700,\n",
              "                       1.0745,  1.3344,  0.9890,  1.1613,  0.9866,  1.0898,  1.0174,  1.1382,\n",
              "                       1.0628,  1.3468,  0.9567,  0.9285,  1.1524,  0.9381,  1.1600,  1.0286,\n",
              "                       0.9654,  1.0051,  0.9533,  2.9762,  0.9848,  0.9081,  1.0151,  1.1804,\n",
              "                       1.0268,  1.2335,  1.2395,  1.0279,  0.9968,  1.3587,  1.0506,  1.0492,\n",
              "                       1.0643,  0.6675,  1.2004,  0.4304,  0.9975,  0.9510,  1.0773,  0.9239,\n",
              "                       1.1236,  1.2946,  0.9571,  1.1977,  1.1623,  1.0968,  0.9620,  0.9891,\n",
              "                       0.8884,  1.0407,  0.9415,  0.4447,  1.0154,  1.2677,  1.0691,  0.9551,\n",
              "                       0.9218,  1.1331,  1.0461,  1.1164,  0.9951,  1.2628,  1.0629,  1.0316,\n",
              "                       1.0155,  1.0767,  1.1944,  1.0027,  1.1412,  1.2060,  1.0450,  1.1906,\n",
              "                       1.0823,  1.0224,  1.1885,  2.5222,  1.0340,  1.0453,  0.9388,  1.0582,\n",
              "                       1.2245,  1.0164,  1.2520,  1.2473,  1.0850,  1.1855,  0.9741,  1.0901,\n",
              "                       0.7206,  0.9209,  0.9362,  0.7272,  0.6582,  1.2093,  1.2285,  1.1746,\n",
              "                       1.3204,  1.2098,  1.0452,  1.0610,  0.8943,  0.9796,  1.1041,  1.1691,\n",
              "                       0.8809,  1.0983,  3.0949,  0.9632,  0.9760,  1.0149,  0.9597,  0.9791,\n",
              "                       1.0093,  0.9535,  0.9776,  1.0743,  1.2463,  0.2064,  1.0324,  1.0249,\n",
              "                       1.0517,  1.0405,  0.9885,  0.9937,  1.0725,  0.9715,  0.8749,  1.2987,\n",
              "                       1.5180,  1.6628,  1.2572,  1.1538,  1.0526,  1.1477,  0.9920,  1.0094,\n",
              "                       1.3866,  1.3827,  1.0060,  1.3092,  1.1253,  1.2429,  0.8640,  1.0461,\n",
              "                       0.9857,  1.8942,  0.9099,  1.0914,  0.9840,  0.9381,  1.0770,  0.9464,\n",
              "                       1.1392,  0.9855,  0.9901,  1.2536,  1.2462,  0.9712,  1.3549,  1.1187,\n",
              "                       1.0683,  0.9366,  1.0108,  1.0092,  1.0947,  1.1118,  1.0815,  1.2763,\n",
              "                       0.9678,  0.9294,  1.1873,  1.0973,  0.9523,  1.2225,  1.2995,  0.9670,\n",
              "                       0.9511,  1.3055,  1.0522,  0.9099,  1.2881,  0.8974,  1.2954,  1.2682,\n",
              "                       1.0800,  1.1056,  1.0051,  1.2663,  1.1560,  1.0220,  1.0065,  1.0824,\n",
              "                       0.9763,  0.9593,  1.0557,  1.2559,  1.1721,  1.1231,  1.1191,  1.0467,\n",
              "                       1.1183,  1.1022,  1.2768,  1.1267,  1.2009,  1.9230,  1.2434,  0.9307,\n",
              "                       1.0434,  1.0111,  1.1232,  1.0341,  1.0964,  1.2055,  0.9755,  1.2651,\n",
              "                       1.0164,  1.2758,  1.3197,  0.8079,  0.9729,  0.9979,  1.0159,  1.2025,\n",
              "                       0.9813,  1.1736,  1.2155,  1.2068,  0.2516,  0.9408,  1.3316,  0.9249,\n",
              "                       1.2284,  1.0093,  1.3500,  1.3434,  1.0679,  1.1557,  1.3066,  1.0467,\n",
              "                       0.9792,  1.3384,  0.9794,  1.0826,  0.7908,  1.2792,  1.0409,  2.2196,\n",
              "                       1.0746,  1.2759,  1.2124,  1.1416,  1.1639,  0.9660,  1.0874,  0.9237,\n",
              "                       0.9146,  0.7126,  0.8838,  1.0279,  0.9640,  1.0254,  1.2632,  0.9491,\n",
              "                       0.9519,  0.9343,  1.0050,  0.9497,  1.1821,  1.0785,  0.9499,  1.0624,\n",
              "                       0.9741,  0.9886,  0.3600,  1.4308,  1.5385,  1.1011,  0.9243,  0.4468,\n",
              "                       1.1085,  0.9774,  1.1283,  0.9290,  1.1199,  1.0504,  1.2147,  0.9982,\n",
              "                       1.3626,  0.9118,  1.3791,  0.9961,  1.0995,  0.9593,  1.2266,  1.2314,\n",
              "                       1.1467,  1.0309,  1.1996,  1.2194,  0.9558,  1.0747,  0.9577,  1.1402,\n",
              "                       1.1857,  1.0513,  1.0290,  0.9853,  1.0604,  0.9507,  1.2303,  1.3051,\n",
              "                       1.1593,  1.0414,  1.2171,  0.9150,  0.9401,  0.9264,  0.9721,  1.0708,\n",
              "                       1.0882,  1.0450,  0.8977,  0.9963,  0.8943,  0.9118,  0.9311,  0.9303,\n",
              "                       0.8611,  0.9200,  1.1083,  1.0227,  1.0501,  1.0180,  1.3057,  1.0266,\n",
              "                       1.1652,  2.0168,  1.0833,  1.0318,  1.4300,  0.9591,  0.9497,  1.2434,\n",
              "                       0.9112,  1.1057,  1.0673,  1.1599,  1.3307,  0.9494,  1.1172,  1.2692,\n",
              "                       1.1217,  1.0036,  0.9889,  0.9461,  1.0253,  1.1940,  1.1925,  1.7525,\n",
              "                       1.0775,  1.1412,  1.1289,  1.1077,  0.8938,  1.1796,  1.1490,  0.9297,\n",
              "                       2.2396,  0.9240,  1.1646,  0.9512,  1.0454,  1.0500,  1.3519,  1.1638,\n",
              "                       0.9376,  1.1503,  0.8917,  1.0209,  1.0990,  2.0672,  1.1344,  1.4188,\n",
              "                       1.0056,  1.1567,  1.2244,  1.0031,  1.0887,  1.0622,  1.1264,  1.1130,\n",
              "                       1.0148,  1.0757,  1.3278,  1.1048,  1.1595,  0.9603,  1.1504,  1.2356,\n",
              "                       1.0062,  0.9671,  1.1100,  1.0966,  0.9740,  0.5281,  1.3884,  1.2526,\n",
              "                       0.8983,  1.3690,  0.9690,  1.0490,  1.1069,  0.9701,  1.1074,  1.1699,\n",
              "                       1.2854,  0.8695,  1.3353,  1.4080,  1.0669,  1.1782, -0.0052,  1.0570,\n",
              "                       1.1861,  1.0393,  1.1496,  0.3067,  0.8983,  1.0839,  1.0519,  1.0918,\n",
              "                       1.0264,  1.1759,  0.9464,  1.3368,  1.1152,  1.0065,  1.0520,  0.9824,\n",
              "                       0.9103,  0.9018,  0.9115,  0.9472,  0.9832,  0.9811,  1.0300,  1.0875,\n",
              "                       0.9681,  1.0432,  1.0635,  1.0082,  1.0807,  1.0984,  1.3092,  1.0097,\n",
              "                       1.2659,  1.0054,  1.1745,  0.6895,  1.1397,  0.9193,  0.9046,  1.0724,\n",
              "                       1.2869,  1.0197,  1.0235,  1.0060,  1.1840,  0.9628,  1.0037,  1.3133,\n",
              "                       1.0277,  1.0518,  1.0608,  1.0516,  1.2203,  0.9978,  0.9919,  1.2638,\n",
              "                       1.0873,  1.0149,  1.0781,  1.3378,  1.0288,  1.1636,  1.2114,  1.0962,\n",
              "                       1.1657,  1.4221,  0.9158,  0.8987,  1.0945,  1.0359,  1.2214,  0.9556,\n",
              "                       1.1736,  1.1377,  1.0034,  1.1636,  1.1458,  1.0579,  1.1353,  0.8893,\n",
              "                       0.9826,  1.0165,  0.9460,  1.0850,  1.0622,  1.0991,  1.0472,  1.2124,\n",
              "                       1.0033,  1.1153,  1.0202,  1.2542,  0.9805,  0.2135,  0.9725,  1.2847,\n",
              "                       1.0072,  1.2532,  1.0138,  0.9531,  1.0449,  1.0395,  1.1033,  1.5292,\n",
              "                       1.0462,  0.9999,  1.0486,  1.0012,  0.9627,  1.0167,  0.9878,  1.0345,\n",
              "                       1.0737,  1.0213,  1.1125,  0.8718,  1.0405,  1.5020,  1.0387,  1.1781,\n",
              "                       0.9830,  1.1110,  0.9780,  1.1356,  1.3790,  0.9810,  1.0625,  1.0311,\n",
              "                       1.2368,  0.9829,  1.0387,  1.1366,  1.1952,  0.9000,  1.0715,  1.0336,\n",
              "                       1.1016,  0.9922,  1.0037,  1.4271,  1.3364,  0.9511,  2.5432,  1.0730,\n",
              "                       1.0999,  0.9761,  0.4544,  1.1190,  1.2071,  1.1960,  1.0207,  1.2054,\n",
              "                       0.9417,  1.0925,  1.2376,  1.0007,  1.1605,  1.0095,  1.1110,  0.9086,\n",
              "                       0.9793,  1.2067,  1.1398,  1.0278,  0.9628,  0.7996,  0.9962,  1.0063,\n",
              "                       1.0806,  1.0902,  1.0062,  1.0955,  1.1071,  1.2003,  1.1804,  1.1491,\n",
              "                       1.0187,  1.1971,  1.0280,  0.9627,  1.2204,  1.3061,  1.0846,  1.0492,\n",
              "                       1.4096,  1.0742,  1.1481,  0.9839,  1.0983,  1.0396,  1.0698,  1.1497,\n",
              "                       1.0069,  0.7645,  1.1065,  0.9755,  1.0643,  1.1072,  1.0408,  1.1868],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.6.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0515,  0.0236, -0.0171,  ...,  0.0020, -0.0468,  0.0671],\n",
              "                      [ 0.0242, -0.0081,  0.0229,  ...,  0.0362,  0.0678, -0.0206],\n",
              "                      [-0.0395,  0.0572,  0.0213,  ..., -0.0025, -0.0377, -0.0132],\n",
              "                      ...,\n",
              "                      [-0.0172, -0.0135, -0.0439,  ..., -0.0206,  0.0767, -0.0314],\n",
              "                      [ 0.0148,  0.0131, -0.0242,  ...,  0.0155,  0.0475,  0.0367],\n",
              "                      [-0.0023, -0.0264,  0.0029,  ...,  0.0519, -0.0400, -0.0163]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.6.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.1595, -0.0959,  0.1227,  ..., -0.1670, -0.0148,  0.1542],\n",
              "                      [ 0.2656, -0.1934,  0.2053,  ..., -0.2435, -0.3666,  0.1476],\n",
              "                      [ 0.4413,  0.2398,  0.0699,  ..., -0.1902,  0.1922,  0.1877],\n",
              "                      ...,\n",
              "                      [-0.4216, -0.0730,  0.0109,  ..., -0.3638,  0.2539, -0.1139],\n",
              "                      [ 0.1965,  0.3415, -0.4001,  ...,  0.0692,  0.1471, -0.1883],\n",
              "                      [-0.1311,  0.0371, -0.1971,  ...,  0.5102, -0.2905, -0.0293]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.6.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-0.4854, -0.8525, -0.1823,  ..., -0.2658,  0.1693,  0.7299],\n",
              "                      [ 0.5571, -0.1460,  0.4161,  ..., -0.9606,  0.2883,  0.1633],\n",
              "                      [ 0.8958,  0.3553,  0.6218,  ..., -0.2300,  0.7676,  0.1484],\n",
              "                      ...,\n",
              "                      [-0.6284, -0.5264,  0.2385,  ...,  0.2389, -0.1494,  0.7316],\n",
              "                      [-0.3991, -0.6523, -0.0969,  ..., -0.8759,  0.0177, -0.1301],\n",
              "                      [-0.6799,  0.9523, -0.7608,  ...,  0.0236,  0.0690, -0.4112]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.6.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 0.1807, -0.6882, -1.1123,  ...,  0.5351, -0.4205, -0.8954],\n",
              "                      [ 0.7669, -0.0964, -0.4544,  ...,  1.2123, -0.6646,  0.7866],\n",
              "                      [ 0.1992, -0.0986, -0.6509,  ..., -0.8637,  0.2923,  0.8786],\n",
              "                      ...,\n",
              "                      [ 0.0545,  1.3972,  0.5893,  ..., -0.1369, -0.4011,  0.9073],\n",
              "                      [-0.4398, -0.2963, -0.6240,  ..., -0.2186,  0.2722, -0.5680],\n",
              "                      [-1.1422, -0.4577, -0.0099,  ..., -0.5909, -0.6474, -0.2468]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.6.layer.0.layer_norm.weight',\n",
              "              tensor([ 1.8756e-01,  1.8230e-01,  1.8964e-01,  2.0616e-01,  1.6957e-01,\n",
              "                       1.7868e-01,  3.3390e-02,  2.0981e-01, -8.9937e-02,  1.8844e-01,\n",
              "                       2.2690e-01,  2.0246e-01,  1.2437e-01,  1.7747e-01,  1.3636e-01,\n",
              "                       1.9060e-01,  1.7616e-01,  1.9043e-01,  2.0839e-01,  1.6658e-01,\n",
              "                       1.4032e-01,  1.8280e-01,  8.7120e-05,  1.6688e-01,  1.6705e-01,\n",
              "                       1.7800e-01,  1.4641e-01,  1.7371e-01,  1.7843e-01,  1.4614e-01,\n",
              "                       1.5542e-01,  1.6562e-01,  1.9294e-01,  1.5347e-01,  1.8814e-01,\n",
              "                       1.7474e-01,  1.5343e-01,  2.3836e-01,  1.4941e-01,  2.2363e-01,\n",
              "                       1.7478e-01,  1.6785e-01,  1.8368e-01,  1.8784e-01, -6.0260e-02,\n",
              "                       1.7792e-01,  1.3370e-01,  1.8101e-01,  1.8865e-01,  4.8512e-02,\n",
              "                       2.0740e-01,  1.9209e-01,  1.3580e-01,  1.6000e-01,  1.4096e-02,\n",
              "                       1.6299e-01,  5.7420e-02, -1.7402e-01,  2.0181e-01,  1.7258e-01,\n",
              "                       2.1084e-01,  1.3781e-01,  1.9277e-01,  1.6901e-01,  1.6152e-01,\n",
              "                       5.8350e-02,  1.6122e-01,  1.6635e-01,  2.1580e-01,  1.6742e-01,\n",
              "                       1.7367e-01,  1.9437e-01,  1.5753e-01,  1.8744e-01,  1.6756e-01,\n",
              "                       1.5456e-01,  1.4120e-01,  1.9653e-01,  1.4386e-01,  2.0965e-01,\n",
              "                       1.6381e-01,  1.9665e-01,  1.8493e-01,  2.1187e-01,  1.8341e-01,\n",
              "                       1.8780e-01,  2.2177e-01,  1.9741e-01,  1.9255e-01,  1.7039e-01,\n",
              "                       1.9801e-01,  1.4139e-01,  1.5214e-01,  1.6535e-01,  1.4133e-01,\n",
              "                       1.5908e-01,  1.8751e-01,  1.7237e-01,  1.7518e-01,  1.3164e-01,\n",
              "                       1.9631e-01,  1.9369e-01,  1.2535e-01,  1.7369e-01,  1.8972e-01,\n",
              "                       1.6200e-01,  1.6234e-01,  1.7902e-01,  1.5151e-01,  8.9053e-02,\n",
              "                       1.8669e-01,  1.8428e-01,  1.7167e-01,  1.4145e-01,  1.7488e-01,\n",
              "                       1.7039e-01,  1.9023e-01,  1.4725e-01,  1.9636e-01,  1.7770e-01,\n",
              "                       1.4777e-01,  1.7604e-01,  1.9418e-01,  1.6716e-01,  1.7154e-01,\n",
              "                       1.9303e-01,  2.0685e-01,  1.8751e-01,  1.8570e-01,  1.9240e-01,\n",
              "                       9.7401e-02,  2.0787e-01,  1.6316e-01,  1.3625e-01,  1.7985e-01,\n",
              "                      -1.7130e-01,  2.0203e-01,  1.5346e-01,  1.8723e-01,  1.9243e-01,\n",
              "                       1.5501e-01,  2.2317e-01,  2.0095e-01,  1.8466e-01,  1.8591e-01,\n",
              "                       2.1827e-01,  1.7221e-01,  1.9816e-01,  1.6827e-01,  1.8881e-01,\n",
              "                       1.7710e-01,  1.9248e-01,  1.8333e-01,  2.0379e-01,  1.5441e-01,\n",
              "                       1.6225e-01,  1.8224e-01,  1.4587e-01,  1.7617e-01,  1.5654e-01,\n",
              "                       1.6099e-01,  1.5298e-01,  1.3105e-01,  6.1834e-02,  1.4802e-01,\n",
              "                       1.4531e-01,  1.8644e-01,  1.8823e-01,  1.8899e-01,  2.3483e-01,\n",
              "                       2.3913e-01,  1.9544e-01,  1.9990e-01,  1.3716e-01,  1.8680e-01,\n",
              "                       1.5549e-01,  1.9528e-01,  8.4883e-02,  1.7225e-01,  2.5635e-02,\n",
              "                       1.6908e-01,  1.5281e-01,  1.8721e-01,  1.6234e-01,  2.1476e-01,\n",
              "                       2.1016e-01,  1.5508e-01,  1.9673e-01,  1.8423e-01,  1.7329e-01,\n",
              "                       1.5719e-01,  1.7319e-01,  1.2291e-01,  1.7512e-01,  1.6612e-01,\n",
              "                       5.7043e-02,  1.7892e-01,  2.0665e-01,  1.6763e-01, -1.2859e-01,\n",
              "                       1.5060e-01,  1.9438e-01,  1.8806e-01,  1.7342e-01,  1.6709e-01,\n",
              "                       2.0782e-01,  1.5894e-01,  1.6482e-01,  1.6641e-01,  1.8102e-01,\n",
              "                       1.8856e-01,  1.6279e-01,  1.9077e-01,  1.8987e-01,  1.7748e-01,\n",
              "                       2.0226e-01,  1.8285e-01,  1.7238e-01,  1.8662e-01,  1.4997e-01,\n",
              "                       1.0679e-01,  1.8300e-01,  1.4161e-01,  1.8778e-01,  1.5480e-01,\n",
              "                       1.8322e-01,  2.1155e-01,  2.0109e-01,  1.8636e-01,  2.1948e-01,\n",
              "                       1.4387e-01,  1.8765e-01,  1.0452e-01,  1.4397e-01,  1.5490e-01,\n",
              "                       1.0618e-01,  9.9688e-02,  2.0505e-01,  1.9086e-01,  1.6256e-01,\n",
              "                       2.0755e-01,  1.9872e-01,  1.8329e-01,  1.7116e-01,  1.4281e-01,\n",
              "                       1.5692e-01,  1.9614e-01,  1.8974e-01,  1.4153e-01,  1.7585e-01,\n",
              "                       1.0636e-01,  1.4941e-01,  1.6237e-01,  1.4123e-01,  1.4207e-01,\n",
              "                       1.5127e-01,  1.6675e-01,  1.3933e-01,  8.8673e-02,  1.6586e-01,\n",
              "                       2.1003e-01,  1.1499e-01,  1.5645e-01,  1.8095e-01,  1.6800e-01,\n",
              "                       1.6519e-01,  1.6968e-01,  1.5208e-01,  1.8056e-01,  1.6748e-01,\n",
              "                       6.6006e-02,  2.2871e-01,  1.6635e-01,  3.9329e-02,  2.3017e-01,\n",
              "                       1.9097e-01,  1.8457e-01,  1.5572e-01,  1.8460e-01,  1.7125e-01,\n",
              "                       2.2341e-01,  2.4266e-01,  1.6494e-01,  1.7532e-01,  1.7901e-01,\n",
              "                       1.5931e-01,  1.4049e-01,  1.7974e-01,  1.4683e-01,  1.3431e-01,\n",
              "                       1.4764e-01,  1.7236e-01,  1.6027e-01,  1.7591e-01,  1.7895e-01,\n",
              "                       1.4047e-01,  1.9512e-01,  1.9121e-01,  1.6780e-01,  1.9512e-01,\n",
              "                       2.2055e-01,  1.5928e-01,  2.3008e-01,  1.9693e-01,  1.8093e-01,\n",
              "                       1.6023e-01,  1.9476e-01,  1.7035e-01,  1.8382e-01,  1.7427e-01,\n",
              "                       1.9798e-01,  2.0964e-01,  1.6970e-01,  1.1318e-01,  2.0635e-01,\n",
              "                       1.8119e-01,  1.2659e-01,  2.2852e-01,  1.2795e-01,  1.8379e-01,\n",
              "                       1.5348e-01,  1.8833e-01,  1.7924e-01,  1.5305e-01,  1.9087e-01,\n",
              "                       1.4998e-01,  1.9951e-01,  2.3547e-01,  1.8362e-01,  1.8498e-01,\n",
              "                       1.7799e-01,  1.3895e-01,  1.7731e-01,  1.6408e-01,  1.7474e-01,\n",
              "                       1.6806e-01,  1.5038e-01,  1.7092e-01,  1.8357e-01,  2.2416e-01,\n",
              "                       2.1380e-01,  1.9250e-01,  1.7454e-01,  1.6326e-01,  1.8523e-01,\n",
              "                       1.8630e-01,  1.6341e-01,  1.7981e-01,  1.8197e-01,  1.1399e-01,\n",
              "                       2.0118e-01,  1.5855e-01,  1.7433e-01,  1.8178e-01,  1.7893e-01,\n",
              "                       1.8907e-01,  1.7986e-01,  2.1410e-01,  1.7198e-01,  1.7309e-01,\n",
              "                       1.7251e-01,  2.0616e-01,  1.9292e-01,  1.0959e-01,  1.5435e-01,\n",
              "                       1.6579e-01,  8.6625e-02,  1.5297e-01,  1.4760e-01,  1.6696e-01,\n",
              "                       1.6339e-01,  1.9997e-01,  3.4566e-02,  1.3378e-01,  2.1071e-01,\n",
              "                       1.5594e-01,  1.5345e-01,  1.6728e-01,  2.2496e-01,  1.2738e-01,\n",
              "                       1.8142e-01,  1.8214e-01,  2.1943e-01,  1.7939e-01,  1.6313e-01,\n",
              "                       6.3506e-02,  1.7316e-01,  1.5137e-01,  1.0680e-01,  2.0233e-01,\n",
              "                       1.8032e-01,  9.5447e-02,  1.8293e-01,  2.1504e-01,  2.0998e-01,\n",
              "                       1.6266e-01,  2.0586e-01,  1.7617e-01,  1.8242e-01,  1.6417e-01,\n",
              "                       1.6048e-01,  5.7857e-04,  1.4441e-01,  1.7509e-01,  1.7728e-01,\n",
              "                       1.6922e-01,  1.8761e-01,  1.6332e-01,  1.6533e-01,  1.4490e-01,\n",
              "                       1.6056e-01,  1.6053e-01,  1.5918e-01,  1.6332e-01,  1.6297e-01,\n",
              "                       1.6512e-01, -1.3520e-01,  1.4640e-01,  6.3905e-02,  1.7626e-01,\n",
              "                       1.8787e-01,  1.8729e-01,  1.4441e-01,  6.3718e-02,  1.9893e-01,\n",
              "                       1.7695e-01,  1.8374e-01,  1.5942e-01,  1.9825e-01,  1.9203e-01,\n",
              "                       2.0933e-01,  1.7058e-01,  1.2984e-01,  1.6116e-01,  1.7835e-01,\n",
              "                       1.5373e-01,  1.7395e-01,  1.6112e-01,  1.9309e-01,  2.3320e-01,\n",
              "                       1.8589e-01,  1.3121e-01,  2.0354e-01,  2.1722e-01,  1.5641e-01,\n",
              "                       1.9861e-01,  1.6304e-01,  2.0312e-01,  2.0776e-01,  1.9009e-01,\n",
              "                       1.5973e-01,  1.7495e-01,  1.8489e-01,  1.8377e-01,  1.8772e-01,\n",
              "                       2.1303e-01,  1.8220e-01,  1.7616e-01,  1.8906e-01,  1.5970e-01,\n",
              "                       1.4014e-01,  1.4827e-01,  1.6344e-01,  1.8734e-01,  2.0163e-01,\n",
              "                       1.7405e-01,  1.2320e-01,  1.5702e-01,  1.2344e-01,  1.6271e-01,\n",
              "                       1.4753e-01,  1.4650e-01, -1.5093e-01,  1.5003e-01,  1.8594e-01,\n",
              "                       1.7208e-01,  1.7998e-01,  1.6349e-01,  8.1357e-02,  1.8474e-01,\n",
              "                       2.0519e-01,  1.1486e-01,  1.6476e-01,  1.5460e-01,  2.5518e-01,\n",
              "                       1.5713e-01,  1.5557e-01,  1.7602e-01,  1.5559e-01,  1.8162e-01,\n",
              "                       1.8989e-01,  1.7770e-01,  7.3562e-02,  1.7284e-01,  1.7077e-01,\n",
              "                       1.9850e-01,  1.8073e-01,  1.7557e-01,  1.6788e-01,  1.5461e-01,\n",
              "                       1.5450e-01,  2.0398e-01,  1.8019e-01,  5.9306e-02,  1.7327e-01,\n",
              "                       2.0215e-01,  1.9018e-01,  1.9908e-01,  1.3211e-01,  1.8932e-01,\n",
              "                       2.0940e-01,  1.6004e-01,  8.1070e-02,  1.6668e-01,  2.0279e-01,\n",
              "                       1.5952e-01,  1.6756e-01,  1.4312e-01,  1.6805e-01,  2.0099e-01,\n",
              "                       1.5788e-01,  1.5107e-01,  1.3108e-01,  1.6004e-01,  1.8129e-01,\n",
              "                       1.3516e-01,  2.0403e-01,  2.0544e-01,  1.6661e-01,  2.1314e-01,\n",
              "                       2.0419e-01,  1.9064e-01,  1.8175e-01,  1.7724e-01,  1.7241e-01,\n",
              "                       1.9185e-01,  1.9012e-01,  1.7889e-01,  1.9770e-01,  1.8021e-01,\n",
              "                       1.9166e-01,  1.8101e-01,  1.8229e-01,  2.1604e-01,  1.6381e-01,\n",
              "                       1.6569e-01,  1.9716e-01,  1.8280e-01,  1.7374e-01,  6.7727e-02,\n",
              "                       2.0459e-01,  2.1786e-01,  1.3477e-01,  2.3806e-01,  1.5879e-01,\n",
              "                       1.8995e-01,  1.8245e-01,  1.3996e-01,  1.7732e-01,  1.5539e-01,\n",
              "                       1.8720e-01,  1.3236e-01,  2.0410e-01,  1.9593e-01,  2.0791e-01,\n",
              "                       2.0480e-01,  1.9229e-02,  1.7595e-01,  1.9776e-01,  1.6331e-01,\n",
              "                       2.0948e-01,  7.3849e-02,  1.5499e-01,  1.8447e-01,  1.8589e-01,\n",
              "                       1.9381e-01,  1.9405e-01,  2.2103e-01,  1.5308e-01,  1.8240e-01,\n",
              "                       1.7594e-01,  1.5482e-01,  1.7446e-01,  1.6245e-01,  1.5075e-01,\n",
              "                       1.4224e-01,  1.4856e-01,  1.5628e-01,  1.6233e-01,  1.5617e-01,\n",
              "                       1.8577e-01,  2.2696e-01,  1.6026e-01,  1.9252e-01,  1.9281e-01,\n",
              "                       1.9407e-01,  1.4933e-01,  1.6429e-01,  1.8664e-01,  1.7309e-01,\n",
              "                       2.2837e-01,  1.8694e-01,  2.0291e-01,  9.6321e-02,  2.0663e-01,\n",
              "                       1.4997e-01,  1.6160e-01,  1.8536e-01,  1.6805e-01,  1.7512e-01,\n",
              "                       1.9614e-01,  1.5860e-01,  1.8637e-01,  1.5764e-01,  1.7872e-01,\n",
              "                       2.1135e-01,  1.5341e-01,  2.0371e-01,  1.8061e-01,  1.6022e-01,\n",
              "                       2.0306e-01,  1.3518e-01,  1.7374e-01,  2.1338e-01,  1.9756e-01,\n",
              "                       1.5661e-01,  1.8504e-01,  1.5757e-01,  1.7908e-01,  1.2475e-01,\n",
              "                       1.9934e-01,  1.6650e-01,  1.9339e-01,  2.4214e-01,  1.5570e-01,\n",
              "                       1.4835e-01,  1.7849e-01,  1.9227e-01,  2.4480e-01,  1.6139e-01,\n",
              "                       1.6657e-01,  1.9099e-01,  1.5938e-01,  1.6512e-01,  2.1949e-01,\n",
              "                       1.9635e-01,  1.9193e-01,  1.5286e-01,  1.5435e-01,  1.5966e-01,\n",
              "                       1.5202e-01,  1.7435e-01,  1.8166e-01,  1.6254e-01,  1.6369e-01,\n",
              "                       2.1548e-01,  1.7840e-01,  1.6231e-01,  1.7434e-01,  1.8973e-01,\n",
              "                       1.4730e-01, -6.1135e-04,  1.7413e-01,  2.4304e-01,  1.6456e-01,\n",
              "                       1.8557e-01,  1.6143e-01,  1.4971e-01,  2.0186e-01,  1.7099e-01,\n",
              "                       1.8913e-01,  1.5479e-01,  1.7603e-01,  1.5688e-01,  1.9570e-01,\n",
              "                       1.7692e-01,  1.6967e-01,  1.6792e-01,  1.5581e-01,  1.8447e-01,\n",
              "                       1.7919e-01,  1.6951e-01,  1.8097e-01,  1.3237e-01,  1.7814e-01,\n",
              "                       9.9614e-02,  1.6101e-01,  1.9304e-01,  1.6250e-01,  1.9902e-01,\n",
              "                       1.4666e-01,  2.0532e-01,  1.7748e-01,  1.4507e-01,  1.8556e-01,\n",
              "                       1.6014e-01,  2.2138e-01,  1.5093e-01,  1.9397e-01,  1.9356e-01,\n",
              "                       1.9084e-01,  1.2130e-01,  1.8238e-01,  1.6921e-01,  1.9050e-01,\n",
              "                       1.4430e-01,  1.5841e-01,  1.5985e-01,  2.1689e-01,  1.7476e-01,\n",
              "                       5.2140e-02,  1.8769e-01,  2.0288e-01,  1.6538e-01,  6.0319e-02,\n",
              "                       1.9783e-01,  1.8430e-01,  1.8508e-01,  1.9038e-01,  2.1665e-01,\n",
              "                       1.7336e-01,  1.1436e-01,  1.9269e-01,  1.4254e-01,  1.9515e-01,\n",
              "                       1.8439e-01,  1.9916e-01,  1.1970e-01,  1.7806e-01,  1.8627e-01,\n",
              "                       1.9092e-01,  1.7680e-01,  1.5301e-01,  1.2290e-01,  1.5364e-01,\n",
              "                       1.7357e-01,  1.8449e-01,  1.7793e-01,  1.8221e-01,  2.0151e-01,\n",
              "                       1.9321e-01,  1.9238e-01,  2.1235e-01,  1.9991e-01,  1.6670e-01,\n",
              "                       2.0073e-01,  1.8387e-01,  1.4911e-01,  2.0293e-01,  2.0251e-01,\n",
              "                       1.6614e-01,  1.7691e-01,  2.1341e-01,  1.6724e-01,  2.0543e-01,\n",
              "                       1.7108e-01,  1.8800e-01,  1.7833e-01,  1.8775e-01,  2.2407e-01,\n",
              "                       1.7856e-01,  1.2689e-01,  1.7868e-01,  1.5850e-01,  2.0049e-01,\n",
              "                       1.8438e-01,  1.7288e-01,  2.2115e-01], device='cuda:0')),\n",
              "             ('encoder.block.6.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.3245, -0.0349,  0.7804,  ...,  0.0654,  0.2181, -0.4733],\n",
              "                      [ 0.3060,  0.3397,  0.0541,  ..., -0.5327, -0.4306,  0.0307],\n",
              "                      [-1.2117,  0.1922, -0.0288,  ..., -1.2575,  1.5229,  0.3742],\n",
              "                      ...,\n",
              "                      [-0.0278,  0.0701,  1.1325,  ..., -1.1951, -0.1976, -0.1273],\n",
              "                      [-0.5531, -0.1573,  0.9574,  ..., -0.3806, -0.3320, -0.3207],\n",
              "                      [ 0.1193, -0.2872, -0.7051,  ..., -0.6445, -0.9913,  0.7957]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.6.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.0132,  0.6816, -0.1502,  ..., -0.0301, -0.1215,  0.1531],\n",
              "                      [ 0.4209,  0.6186,  0.9701,  ...,  0.7828, -0.3988, -0.2626],\n",
              "                      [ 0.4510, -0.3890, -0.6180,  ..., -0.5054, -0.1564,  0.0817],\n",
              "                      ...,\n",
              "                      [-0.2899, -0.2215, -0.1579,  ..., -0.0925,  0.0747, -0.1403],\n",
              "                      [ 0.1295,  0.2384,  0.5396,  ...,  0.5230, -0.3618, -0.1155],\n",
              "                      [-0.0708, -0.8836,  0.0626,  ...,  0.5498,  0.1933, -0.3128]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.6.layer.1.layer_norm.weight',\n",
              "              tensor([ 1.2057,  1.0859,  1.1308,  1.1473,  1.0171,  1.1687,  0.3856,  1.2611,\n",
              "                       2.1837,  1.1396,  1.1794,  1.2193,  0.9996,  1.2377,  0.9854,  1.1381,\n",
              "                       1.1858,  1.1506,  1.0318,  1.0541,  1.0898,  1.1566,  2.0141,  1.0540,\n",
              "                       1.0439,  1.2283,  0.9991,  1.0338,  1.1872,  0.9766,  1.1207,  1.0358,\n",
              "                       1.2002,  1.0401,  1.1624,  1.1208,  1.3744,  1.2710,  1.0338,  1.6273,\n",
              "                       1.1282,  1.3342,  1.1857,  1.1669,  2.9214,  1.1497,  1.0768,  1.1058,\n",
              "                       1.0992,  0.7368,  1.2943,  1.0957,  1.6589,  1.0100,  1.1290,  1.1050,\n",
              "                       1.6532,  1.0881,  1.0844,  1.1670,  1.1741,  1.0286,  1.1229,  1.0021,\n",
              "                       1.0609,  1.4494,  1.1320,  1.1187,  1.2809,  1.0264,  1.0956,  1.5154,\n",
              "                       1.0310,  1.1591,  1.0334,  1.0733,  1.2912,  1.0794,  1.0193,  1.1786,\n",
              "                       1.0485,  1.1221,  1.0698,  1.2634,  1.0678,  1.1442,  1.3545,  1.1194,\n",
              "                       1.1869,  1.0097,  1.1507,  1.0868,  1.0110,  1.1793,  1.0753,  1.0084,\n",
              "                       1.1112,  1.0226,  1.0225,  1.0272,  1.2184,  1.0540,  1.0970,  1.0669,\n",
              "                       1.0889,  1.5316,  1.1476,  1.1669,  1.0583,  1.8773,  1.1742,  1.0776,\n",
              "                       1.0895,  1.0961,  1.0891,  1.0322,  1.0920,  0.9722,  1.4252,  1.0907,\n",
              "                       0.9381,  1.0539,  1.3892,  1.0788,  1.0780,  1.1307,  1.1049,  1.1377,\n",
              "                       1.0743,  1.1538,  1.3870,  1.1652,  1.0593,  0.9936,  0.9991,  1.1696,\n",
              "                       1.3485,  1.0078,  1.1764,  1.1439,  1.0643,  1.3098,  1.2579,  1.2072,\n",
              "                       1.0175,  1.2828,  1.1022,  1.1656,  1.0249,  1.1729,  1.0761,  1.1584,\n",
              "                       1.1078,  1.2993,  1.0711,  1.0258,  1.1439,  1.0442,  1.1345,  1.1177,\n",
              "                       1.0175,  1.1079,  0.9829,  3.0567,  1.0717,  0.9795,  1.0832,  1.1713,\n",
              "                       1.0370,  1.1412,  1.2471,  1.0919,  1.0960,  1.3446,  1.0807,  1.0878,\n",
              "                       1.1443,  0.5862,  1.1878,  0.5382,  1.1131,  1.0175,  1.1120,  0.9948,\n",
              "                       1.1491,  1.3340,  0.9900,  1.2027,  1.1547,  1.1607,  1.0648,  1.0806,\n",
              "                       0.9682,  1.0633,  1.0343,  0.4181,  1.1098,  1.3320,  1.1420,  1.0148,\n",
              "                       0.9963,  1.1165,  1.0789,  1.1845,  1.0449,  1.2195,  1.0745,  1.0946,\n",
              "                       1.1092,  1.0926,  1.1774,  1.0398,  1.1570,  1.2214,  1.0633,  1.2260,\n",
              "                       1.0377,  1.0781,  1.2072,  2.3632,  1.0384,  1.1119,  0.9785,  1.0585,\n",
              "                       1.1820,  1.0620,  1.2675,  1.2661,  1.1164,  1.2186,  1.0630,  1.1527,\n",
              "                       0.7600,  0.9797,  0.9860,  0.7981,  0.7558,  1.1988,  1.2324,  1.0638,\n",
              "                       1.3504,  1.2099,  1.1081,  1.1292,  0.9451,  0.9968,  1.1525,  1.1564,\n",
              "                       1.0128,  1.1129,  3.0768,  0.9882,  1.0974,  1.0765,  1.0268,  1.0526,\n",
              "                       1.0753,  0.9846,  0.8131,  1.0865,  1.1716,  0.4419,  1.0287,  1.1065,\n",
              "                       1.0957,  1.0476,  1.0707,  1.0286,  1.0609,  1.0715,  0.8975,  1.2629,\n",
              "                       1.4246,  1.5136,  1.2191,  1.2502,  1.1026,  1.1439,  1.1018,  1.0292,\n",
              "                       1.2953,  1.3542,  1.1126,  1.3765,  1.1303,  1.1941,  0.9627,  1.0863,\n",
              "                       0.9752,  1.7754,  1.0094,  1.1243,  1.0124,  1.0640,  1.0453,  1.1067,\n",
              "                       1.1598,  1.1033,  1.1137,  1.2288,  1.2012,  1.0656,  1.2667,  1.0993,\n",
              "                       1.1026,  1.0495,  1.0554,  1.0617,  1.1070,  1.1170,  1.1247,  1.2196,\n",
              "                       1.0783,  0.9175,  1.2202,  1.1165,  0.9848,  1.2775,  1.3187,  1.0578,\n",
              "                       0.9897,  1.2417,  1.0986,  1.0353,  1.2076,  1.0183,  1.2207,  1.2724,\n",
              "                       1.0910,  1.0890,  1.1047,  1.2741,  1.1047,  1.0621,  1.0717,  1.0622,\n",
              "                       1.0677,  1.0383,  1.0843,  1.2851,  1.2190,  1.1692,  1.2130,  1.1550,\n",
              "                       1.1604,  1.1510,  1.1892,  1.1123,  1.1970,  1.8915,  1.1985,  0.9893,\n",
              "                       1.1285,  1.0611,  1.1134,  1.1006,  1.0686,  1.1943,  1.0554,  1.2138,\n",
              "                       1.0307,  1.2273,  1.2611,  0.9039,  1.0265,  1.0381,  0.8926,  1.2482,\n",
              "                       1.0092,  1.2537,  1.2836,  1.1577,  0.2781,  0.9957,  1.2911,  1.0002,\n",
              "                       1.1783,  0.9984,  1.2416,  1.2350,  1.1301,  1.1131,  1.2216,  1.0977,\n",
              "                       1.0972,  1.2147,  1.1169,  0.9643,  0.8843,  1.2600,  1.1173,  2.3668,\n",
              "                       1.0818,  1.2387,  1.2130,  1.1919,  1.2122,  1.0720,  1.1494,  1.0469,\n",
              "                       1.0073,  0.6738,  0.9890,  1.0898,  1.0495,  1.1059,  1.3428,  1.0644,\n",
              "                       1.0039,  1.0184,  1.0997,  1.0280,  1.1657,  1.1327,  1.0264,  1.0601,\n",
              "                       0.9992,  1.0228,  0.3647,  1.4260,  1.3858,  1.1631,  1.0241,  0.4417,\n",
              "                       1.1939,  1.0794,  1.1167,  1.0601,  1.1752,  1.1059,  1.1780,  1.0983,\n",
              "                       1.2590,  0.9772,  1.3191,  1.0482,  1.1955,  1.0408,  1.2329,  1.2199,\n",
              "                       1.2130,  1.0269,  1.2200,  1.1727,  1.0233,  1.0942,  1.0164,  1.1075,\n",
              "                       1.1782,  1.1153,  1.1089,  1.0112,  1.0684,  1.0415,  1.2890,  1.2384,\n",
              "                       1.1891,  1.0822,  1.2392,  1.0256,  0.9937,  1.0513,  1.0345,  1.1286,\n",
              "                       1.1567,  1.1343,  0.9584,  1.0585,  0.9371,  1.1167,  1.0094,  0.9994,\n",
              "                       0.9561,  0.9896,  1.1726,  1.0656,  1.0859,  1.0439,  1.2844,  1.1252,\n",
              "                       1.2147,  1.9700,  1.1775,  1.0895,  1.3219,  1.0967,  1.0780,  1.2886,\n",
              "                       0.9405,  1.1390,  1.1225,  1.1827,  1.3169,  1.0731,  1.1007,  1.2591,\n",
              "                       1.1053,  1.1137,  1.0199,  0.9885,  1.0715,  1.1811,  1.2065,  1.8578,\n",
              "                       1.1721,  1.1858,  1.1293,  1.1535,  0.9847,  1.1975,  1.1691,  1.0409,\n",
              "                       1.9840,  1.0096,  1.1898,  1.0470,  1.1098,  1.0822,  1.2303,  1.1953,\n",
              "                       1.0513,  1.2214,  0.9789,  1.0856,  1.1224,  2.0777,  1.1912,  1.4224,\n",
              "                       1.0775,  1.1137,  1.1962,  1.1129,  1.0399,  1.1698,  1.1673,  1.1178,\n",
              "                       1.0521,  1.0696,  1.3083,  1.1665,  1.1626,  1.0363,  1.1396,  1.2206,\n",
              "                       1.0520,  1.0760,  1.1247,  1.1159,  1.0348,  0.4344,  1.2664,  1.2425,\n",
              "                      -0.9481,  1.3213,  1.1029,  1.1317,  1.1443,  1.0148,  1.1352,  1.1384,\n",
              "                       1.2116,  0.9343,  1.3554,  1.3222,  1.0954,  1.1491, -0.0069,  1.1188,\n",
              "                       1.2035,  1.0408,  1.1464,  0.3479,  0.9721,  1.0666,  1.0578,  1.1336,\n",
              "                       1.0662,  1.1594,  0.9622,  1.1742,  1.1156,  1.0382,  1.0653,  1.0463,\n",
              "                       0.9807,  1.0134,  1.0629,  0.9966,  1.0386,  1.0674,  1.1024,  1.1352,\n",
              "                       1.0637,  1.0710,  1.0958,  1.0601,  1.0510,  1.1407,  1.2565,  1.0757,\n",
              "                       1.2695,  1.0891,  1.1126,  0.6565,  1.1394,  1.0188,  0.9871,  1.0900,\n",
              "                       1.2410,  1.1157,  1.1859,  1.0311,  1.2669,  1.0147,  1.0612,  1.3176,\n",
              "                       1.0649,  1.0166,  1.0801,  1.1101,  1.2309,  1.0186,  1.0933,  1.2401,\n",
              "                       1.1343,  1.0364,  1.1306,  1.2607,  1.0436,  1.0648,  1.1697,  1.1064,\n",
              "                       1.1042,  1.3810,  1.0009,  0.8013,  1.1129,  1.0849,  1.2402,  1.0328,\n",
              "                       1.1498,  1.1495,  1.0309,  1.2072,  1.2157,  1.1167,  1.1113,  1.0310,\n",
              "                       1.0228,  1.0106,  1.0347,  1.0845,  1.0747,  1.1022,  1.0617,  1.2182,\n",
              "                       0.9800,  1.1696,  1.0728,  1.2034,  0.9398,  0.3049,  1.0070,  1.2974,\n",
              "                       1.1006,  1.2452,  1.1180,  0.9974,  1.0296,  1.0904,  1.1962,  1.5573,\n",
              "                       1.0749,  1.1200,  1.0949,  1.0848,  0.9972,  1.0780,  1.0744,  1.1153,\n",
              "                       1.1067,  1.1143,  1.1431,  1.0472,  1.0771,  1.5524,  1.0749,  1.2121,\n",
              "                       1.0398,  1.1584,  1.0432,  1.1881,  1.2750,  1.0573,  1.1422,  1.0878,\n",
              "                       1.2509,  1.0475,  1.1133,  1.1877,  1.2744,  0.9604,  1.0993,  1.0809,\n",
              "                       1.1661,  1.0691,  1.0217,  1.3403,  1.3105,  1.0134,  2.2819,  1.1225,\n",
              "                       1.0637,  1.0663,  0.4831,  1.1737,  1.1855,  1.2301,  1.0822,  1.1908,\n",
              "                       1.0676,  1.1203,  1.2171,  1.0884,  1.2130,  1.0066,  1.0890,  0.9889,\n",
              "                       1.0658,  1.2072,  1.1621,  1.1168,  1.0390,  0.8398,  1.0475,  1.0769,\n",
              "                       1.0925,  1.1328,  1.1204,  1.1790,  1.1551,  1.2357,  1.1868,  1.1213,\n",
              "                       1.1282,  1.2079,  1.0193,  1.0152,  1.2392,  1.3308,  1.1432,  1.1052,\n",
              "                       1.3290,  1.1419,  1.0854,  1.0893,  1.1204,  1.0652,  1.0525,  1.1713,\n",
              "                       1.0403,  0.7954,  1.1330,  1.0723,  1.1325,  1.0960,  1.1404,  1.2688],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.7.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0328, -0.0318, -0.0613,  ..., -0.0265, -0.0491, -0.0108],\n",
              "                      [ 0.0236, -0.0072,  0.0209,  ...,  0.0283,  0.0084, -0.0118],\n",
              "                      [-0.0592,  0.0146,  0.0380,  ..., -0.0383,  0.0083,  0.0285],\n",
              "                      ...,\n",
              "                      [-0.0833,  0.0160,  0.0308,  ..., -0.0193,  0.0326,  0.0172],\n",
              "                      [-0.0458,  0.0008,  0.0039,  ..., -0.0454,  0.0198, -0.0378],\n",
              "                      [ 0.0108, -0.0043, -0.0035,  ...,  0.0249, -0.0142,  0.0351]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.7.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.0140, -0.0874, -0.2462,  ..., -0.0198,  0.3169,  0.0173],\n",
              "                      [ 0.1128, -0.0982, -0.2583,  ...,  0.0092,  0.1613,  0.0126],\n",
              "                      [-0.1450,  0.0322,  0.0285,  ..., -0.1778, -0.1518,  0.1491],\n",
              "                      ...,\n",
              "                      [-0.8004,  0.0211,  0.2179,  ..., -0.2473,  0.2650, -0.1660],\n",
              "                      [-0.3826, -0.0714,  0.1710,  ...,  0.0372,  0.1028,  0.0899],\n",
              "                      [ 0.0883, -0.1867, -0.2011,  ...,  0.2982,  0.0179, -0.0268]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.7.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 1.2713,  0.0544,  1.0366,  ..., -0.3779, -0.1699, -0.5198],\n",
              "                      [ 0.0477, -0.0622, -0.3691,  ...,  0.7558, -0.9212, -0.1993],\n",
              "                      [-0.3510,  0.1983,  0.7571,  ..., -0.7399,  1.2558, -0.4865],\n",
              "                      ...,\n",
              "                      [-0.1625,  0.4107,  0.2733,  ...,  0.1169, -0.3362,  0.1122],\n",
              "                      [ 0.7077, -0.0155, -0.9136,  ...,  1.1711, -0.0429,  0.0296],\n",
              "                      [-0.9586,  0.3421,  0.1703,  ..., -0.1255, -0.0932, -0.0256]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.7.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-1.4014, -0.0592,  0.4034,  ...,  0.7806,  0.1536, -0.3106],\n",
              "                      [-0.7087,  0.0135, -0.1787,  ..., -0.0683,  0.8159,  1.2304],\n",
              "                      [-0.7651,  0.0573,  0.1042,  ...,  0.0059,  1.2301, -1.0111],\n",
              "                      ...,\n",
              "                      [-0.3356, -1.5801,  1.1838,  ..., -0.9593,  1.3001,  0.9401],\n",
              "                      [ 0.2142,  0.4377, -0.7687,  ..., -0.3205,  0.1136,  0.3700],\n",
              "                      [ 0.1956, -0.1442,  0.2788,  ...,  0.9217,  0.3672,  0.0973]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.7.layer.0.layer_norm.weight',\n",
              "              tensor([ 1.8101e-01,  1.8000e-01,  1.7493e-01,  2.0306e-01,  1.7652e-01,\n",
              "                       1.7611e-01,  3.1750e-02,  1.9835e-01,  9.8187e-02,  1.8321e-01,\n",
              "                       1.9569e-01,  1.8675e-01,  1.2276e-01,  1.5883e-01,  1.5777e-01,\n",
              "                       1.9274e-01,  1.7090e-01,  1.8499e-01,  1.8586e-01,  1.7738e-01,\n",
              "                       1.4592e-01,  1.7515e-01,  3.9140e-02,  1.6069e-01,  1.7190e-01,\n",
              "                       1.7065e-01,  1.4948e-01,  1.6496e-01,  1.7779e-01,  1.6095e-01,\n",
              "                       1.5570e-01,  1.6607e-01,  1.9470e-01,  1.5685e-01,  1.8338e-01,\n",
              "                       1.8114e-01,  1.4036e-01,  2.0826e-01,  1.5295e-01,  1.9712e-01,\n",
              "                       1.6349e-01,  1.7065e-01,  1.6797e-01,  1.7808e-01, -6.5094e-02,\n",
              "                       1.7173e-01,  1.3047e-01,  1.5522e-01,  1.7496e-01,  5.0675e-02,\n",
              "                       1.9418e-01,  1.9021e-01,  1.4151e-01,  1.4953e-01, -6.8637e-04,\n",
              "                       1.6170e-01,  7.6672e-02,  1.7313e-01,  1.9946e-01,  1.7277e-01,\n",
              "                       1.9380e-01,  1.5650e-01,  1.8447e-01,  1.6727e-01,  1.7480e-01,\n",
              "                       5.2875e-02,  1.4654e-01,  1.6347e-01,  1.8938e-01,  1.6402e-01,\n",
              "                       1.7071e-01,  1.8297e-01,  1.5641e-01,  1.8214e-01,  1.6011e-01,\n",
              "                       1.4962e-01,  1.5095e-01,  1.8161e-01,  1.6702e-01,  1.9061e-01,\n",
              "                       1.4998e-01,  1.7281e-01,  1.6973e-01,  2.0173e-01,  1.7467e-01,\n",
              "                       1.8415e-01,  2.0406e-01,  1.9817e-01,  1.9303e-01,  1.6177e-01,\n",
              "                       1.7943e-01,  1.5344e-01,  1.6803e-01,  1.6195e-01,  1.5525e-01,\n",
              "                       1.5338e-01,  1.7255e-01,  1.6923e-01,  1.6465e-01,  1.3186e-01,\n",
              "                       1.9915e-01,  1.8473e-01,  1.3147e-01,  1.5701e-01,  1.7771e-01,\n",
              "                       1.4509e-01,  1.7347e-01,  1.6290e-01,  1.4563e-01,  8.6596e-02,\n",
              "                       1.7873e-01,  1.8472e-01,  1.7291e-01,  1.3049e-01,  1.5839e-01,\n",
              "                       1.6627e-01,  1.7086e-01,  1.3586e-01,  1.6011e-01,  1.5388e-01,\n",
              "                       1.3882e-01,  1.8131e-01,  1.8656e-01,  1.6880e-01,  1.3819e-01,\n",
              "                       1.7292e-01,  1.8743e-01,  1.6540e-01,  1.7698e-01,  1.9215e-01,\n",
              "                       1.0909e-01,  2.0524e-01,  1.5912e-01,  1.4194e-01,  1.6348e-01,\n",
              "                       1.4531e-01,  2.0790e-01,  1.5716e-01,  1.8359e-01,  1.8804e-01,\n",
              "                       1.6027e-01,  2.0360e-01,  1.8240e-01,  1.7078e-01,  1.7884e-01,\n",
              "                       2.0130e-01,  1.6854e-01,  1.8597e-01,  1.6607e-01,  1.8092e-01,\n",
              "                       1.7650e-01,  1.9513e-01,  1.6480e-01,  2.0406e-01,  1.5398e-01,\n",
              "                       1.6921e-01,  1.7485e-01,  1.5072e-01,  1.6902e-01,  1.7496e-01,\n",
              "                       1.4757e-01,  1.6669e-01,  1.2779e-01,  6.9623e-02,  1.4850e-01,\n",
              "                       1.4095e-01,  1.7560e-01,  1.7418e-01,  1.8044e-01,  1.9657e-01,\n",
              "                       1.9404e-01,  1.8202e-01,  1.6700e-01,  1.3480e-01,  1.8784e-01,\n",
              "                       1.4971e-01,  1.8155e-01,  7.7262e-02,  1.6322e-01,  2.4609e-02,\n",
              "                       1.7780e-01,  1.5670e-01,  1.7037e-01,  1.5557e-01,  1.9597e-01,\n",
              "                       2.0049e-01,  1.5260e-01,  1.7639e-01,  1.6432e-01,  1.6680e-01,\n",
              "                       1.5684e-01,  1.7738e-01,  1.1614e-01,  1.7841e-01,  1.4559e-01,\n",
              "                       4.8036e-02,  1.8242e-01,  1.9025e-01,  1.7121e-01,  1.2970e-01,\n",
              "                       1.5606e-01,  1.9132e-01,  1.6911e-01,  1.7807e-01,  1.6648e-01,\n",
              "                       1.9600e-01,  1.7314e-01,  1.6480e-01,  1.5500e-01,  1.7986e-01,\n",
              "                       1.7074e-01,  1.5850e-01,  1.8427e-01,  1.9594e-01,  1.6407e-01,\n",
              "                       1.9345e-01,  1.7426e-01,  1.7778e-01,  1.7242e-01,  1.4262e-01,\n",
              "                       1.1070e-01,  1.8082e-01,  1.4993e-01,  1.7531e-01,  1.4073e-01,\n",
              "                       1.8249e-01,  2.0604e-01,  1.9926e-01,  1.8537e-01,  2.0363e-01,\n",
              "                       1.3831e-01,  1.7803e-01,  1.1582e-01,  1.5351e-01,  1.5523e-01,\n",
              "                       1.0508e-01,  1.1193e-01,  1.8567e-01,  1.9761e-01,  1.6373e-01,\n",
              "                       1.8223e-01,  2.1094e-01,  1.7140e-01,  1.7225e-01,  1.4412e-01,\n",
              "                       1.7445e-01,  1.8045e-01,  1.8764e-01,  1.5240e-01,  1.7660e-01,\n",
              "                       1.0713e-01,  1.4372e-01,  1.4352e-01,  1.4906e-01,  1.6285e-01,\n",
              "                       1.6448e-01,  1.4368e-01,  1.2764e-01,  8.6967e-02,  1.6566e-01,\n",
              "                       1.8780e-01,  1.2520e-01,  1.6141e-01,  1.7050e-01,  1.6105e-01,\n",
              "                       1.6704e-01,  1.7220e-01,  1.6682e-01,  1.6063e-01,  1.6471e-01,\n",
              "                       7.4877e-02,  2.2090e-01,  1.6452e-01,  2.4032e-02,  2.1268e-01,\n",
              "                       1.8315e-01,  1.8545e-01,  1.5804e-01,  1.7704e-01,  1.6536e-01,\n",
              "                       2.1088e-01,  2.0319e-01,  1.7604e-01,  1.9302e-01,  1.8779e-01,\n",
              "                       1.4707e-01,  1.3850e-01,  1.8025e-01,  1.3698e-01,  1.2913e-01,\n",
              "                       1.5995e-01,  1.6603e-01,  1.4571e-01,  1.5738e-01,  1.7503e-01,\n",
              "                       1.6260e-01,  1.8323e-01,  1.8655e-01,  1.6562e-01,  1.9267e-01,\n",
              "                       1.9497e-01,  1.5384e-01,  2.1827e-01,  1.6204e-01,  1.7338e-01,\n",
              "                       1.4495e-01,  1.8527e-01,  1.7984e-01,  1.7398e-01,  1.6739e-01,\n",
              "                       1.8020e-01,  1.9278e-01,  1.5309e-01,  1.2507e-01,  1.8788e-01,\n",
              "                       1.7616e-01,  1.2350e-01,  1.9838e-01,  1.4734e-01,  1.7097e-01,\n",
              "                       1.5462e-01,  1.7801e-01,  1.6940e-01,  1.6078e-01,  1.8189e-01,\n",
              "                       1.5801e-01,  1.7794e-01,  2.0989e-01,  1.7867e-01,  1.7549e-01,\n",
              "                       1.6483e-01,  1.4318e-01,  1.6631e-01,  1.6200e-01,  1.7308e-01,\n",
              "                       1.7512e-01,  1.5770e-01,  1.6867e-01,  1.5950e-01,  1.9406e-01,\n",
              "                       2.1136e-01,  1.9362e-01,  1.8465e-01,  1.6169e-01,  1.8286e-01,\n",
              "                       1.8559e-01,  1.6266e-01,  1.6632e-01,  1.6164e-01,  1.2467e-01,\n",
              "                       2.0664e-01,  1.6734e-01,  1.6774e-01,  1.6938e-01,  1.7105e-01,\n",
              "                       1.9987e-01,  1.7437e-01,  1.8398e-01,  1.6765e-01,  1.5145e-01,\n",
              "                       1.7256e-01,  1.8284e-01,  1.8768e-01,  1.2683e-01,  1.5799e-01,\n",
              "                       1.7146e-01,  7.9829e-02,  1.5610e-01,  1.6079e-01,  1.7344e-01,\n",
              "                       1.7713e-01,  2.0046e-01,  3.9961e-02,  1.4418e-01,  2.0146e-01,\n",
              "                       1.5525e-01,  1.4422e-01,  1.7238e-01,  2.1405e-01,  1.3365e-01,\n",
              "                       1.8157e-01,  1.7529e-01,  2.0123e-01,  1.7578e-01,  1.7008e-01,\n",
              "                       7.0456e-02,  1.7070e-01,  1.2968e-01,  1.2526e-01,  1.9268e-01,\n",
              "                       1.7193e-01,  7.9415e-02,  1.8902e-01,  2.1022e-01,  1.9429e-01,\n",
              "                       1.6556e-01,  1.8390e-01,  1.6574e-01,  1.7448e-01,  1.5734e-01,\n",
              "                       1.4125e-01, -6.5652e-05,  1.4553e-01,  1.8670e-01,  1.6389e-01,\n",
              "                       1.6188e-01,  1.9010e-01,  1.5283e-01,  1.6547e-01,  1.5881e-01,\n",
              "                       1.7342e-01,  1.6260e-01,  1.5866e-01,  1.7213e-01,  1.6814e-01,\n",
              "                       1.7136e-01,  1.3799e-01,  1.4496e-01,  5.4490e-02,  1.7951e-01,\n",
              "                       1.6705e-01,  1.9192e-01,  1.5905e-01,  5.0575e-02,  1.8701e-01,\n",
              "                       1.7470e-01,  1.7788e-01,  1.6070e-01,  1.7539e-01,  1.7713e-01,\n",
              "                       1.9575e-01,  1.7067e-01,  1.2987e-01,  1.5863e-01,  1.6466e-01,\n",
              "                       1.5220e-01,  1.6379e-01,  1.5395e-01,  1.7650e-01,  2.1020e-01,\n",
              "                       1.7341e-01,  1.3773e-01,  2.0205e-01,  2.0515e-01,  1.5576e-01,\n",
              "                       1.8005e-01,  1.5409e-01,  1.9690e-01,  1.8535e-01,  1.8964e-01,\n",
              "                       1.6853e-01,  1.5728e-01,  1.7691e-01,  1.7376e-01,  1.8813e-01,\n",
              "                       1.9478e-01,  1.7920e-01,  1.7284e-01,  1.8206e-01,  1.3450e-01,\n",
              "                       1.5677e-01,  1.6745e-01,  1.5906e-01,  1.9055e-01,  1.9624e-01,\n",
              "                       1.8302e-01,  1.2088e-01,  1.5541e-01,  1.2803e-01,  1.5655e-01,\n",
              "                       1.4528e-01,  1.5015e-01,  1.3688e-01,  1.4189e-01,  1.8285e-01,\n",
              "                       1.5627e-01,  1.6205e-01,  1.6472e-01,  7.3888e-02,  1.7225e-01,\n",
              "                       1.7988e-01,  1.1902e-01,  1.7379e-01,  1.4860e-01,  2.2683e-01,\n",
              "                       1.6778e-01,  1.6525e-01,  1.7761e-01,  1.4939e-01,  1.9126e-01,\n",
              "                       1.9208e-01,  1.8037e-01,  8.2032e-02,  1.7555e-01,  1.6392e-01,\n",
              "                       1.7613e-01,  1.6654e-01,  1.6159e-01,  1.6886e-01,  1.5058e-01,\n",
              "                       1.5931e-01,  1.8880e-01,  1.6628e-01,  4.9036e-02,  1.6184e-01,\n",
              "                       1.9977e-01,  1.8539e-01,  1.8789e-01,  1.4653e-01,  1.9054e-01,\n",
              "                       1.9630e-01,  1.5255e-01,  7.7092e-02,  1.7340e-01,  1.9325e-01,\n",
              "                       1.6096e-01,  1.5357e-01,  1.5306e-01,  1.4982e-01,  1.8768e-01,\n",
              "                       1.4878e-01,  1.4982e-01,  1.3953e-01,  1.6631e-01,  1.8189e-01,\n",
              "                       1.3842e-01,  2.0473e-01,  1.8293e-01,  1.5900e-01,  1.8347e-01,\n",
              "                       1.8883e-01,  1.7815e-01,  1.8157e-01,  1.8004e-01,  1.6927e-01,\n",
              "                       1.8727e-01,  1.8450e-01,  1.7140e-01,  1.8780e-01,  1.7078e-01,\n",
              "                       1.8979e-01,  1.5986e-01,  1.8122e-01,  1.9881e-01,  1.7466e-01,\n",
              "                       1.7302e-01,  1.9625e-01,  1.8753e-01,  1.7290e-01,  6.2986e-02,\n",
              "                       1.7985e-01,  2.0623e-01,  1.4994e-01,  2.2345e-01,  1.6503e-01,\n",
              "                       1.8642e-01,  1.6143e-01,  1.5847e-01,  1.6888e-01,  1.5187e-01,\n",
              "                       1.7538e-01,  1.3928e-01,  1.9450e-01,  1.9191e-01,  1.8948e-01,\n",
              "                       1.9997e-01,  2.9182e-02,  1.7497e-01,  1.7851e-01,  1.7243e-01,\n",
              "                       1.9944e-01,  7.1563e-02,  1.4580e-01,  1.8291e-01,  1.8381e-01,\n",
              "                       1.7739e-01,  1.7377e-01,  2.0764e-01,  1.5783e-01,  1.6855e-01,\n",
              "                       1.8542e-01,  1.6748e-01,  1.7339e-01,  1.5426e-01,  1.5650e-01,\n",
              "                       1.4859e-01,  1.6011e-01,  1.6615e-01,  1.5585e-01,  1.5066e-01,\n",
              "                       1.7844e-01,  1.7785e-01,  1.7584e-01,  1.9599e-01,  1.8392e-01,\n",
              "                       1.9162e-01,  1.6188e-01,  1.6110e-01,  1.7475e-01,  1.6481e-01,\n",
              "                       2.1181e-01,  1.7260e-01,  1.8130e-01,  9.2274e-02,  1.9322e-01,\n",
              "                       1.6112e-01,  1.5481e-01,  1.6609e-01,  1.7700e-01,  1.6905e-01,\n",
              "                       1.7890e-01,  1.6421e-01,  1.7707e-01,  1.5532e-01,  1.7562e-01,\n",
              "                       1.9588e-01,  1.4839e-01,  1.8596e-01,  1.8367e-01,  1.6587e-01,\n",
              "                       1.9065e-01,  1.5161e-01,  1.6081e-01,  1.9939e-01,  1.8836e-01,\n",
              "                       1.7178e-01,  1.7362e-01,  1.5313e-01,  1.5877e-01,  1.1873e-01,\n",
              "                       1.8761e-01,  1.6309e-01,  1.8187e-01,  2.1799e-01,  1.6480e-01,\n",
              "                       1.3106e-01,  1.7181e-01,  1.6684e-01,  2.2807e-01,  1.6579e-01,\n",
              "                       1.6612e-01,  1.8099e-01,  1.5399e-01,  1.7253e-01,  2.0908e-01,\n",
              "                       1.9012e-01,  1.7098e-01,  1.5925e-01,  1.5461e-01,  1.5929e-01,\n",
              "                       1.5078e-01,  1.7393e-01,  1.7786e-01,  1.6837e-01,  1.5696e-01,\n",
              "                       1.9776e-01,  1.7296e-01,  1.6542e-01,  1.8616e-01,  1.6850e-01,\n",
              "                       1.4123e-01,  1.2475e-02,  1.6877e-01,  2.0993e-01,  1.7005e-01,\n",
              "                       1.8977e-01,  1.4398e-01,  1.4927e-01,  1.8789e-01,  1.6366e-01,\n",
              "                       1.8079e-01,  1.3056e-01,  1.5950e-01,  1.6206e-01,  1.7305e-01,\n",
              "                       1.8042e-01,  1.6330e-01,  1.6534e-01,  1.6576e-01,  1.7160e-01,\n",
              "                       1.7664e-01,  1.6127e-01,  1.8367e-01,  1.5060e-01,  1.7685e-01,\n",
              "                       1.1732e-01,  1.4657e-01,  1.9044e-01,  1.7049e-01,  1.9053e-01,\n",
              "                       1.5117e-01,  1.8141e-01,  1.6373e-01,  1.5337e-01,  1.8321e-01,\n",
              "                       1.6710e-01,  2.0157e-01,  1.5150e-01,  1.9058e-01,  1.8133e-01,\n",
              "                       1.8042e-01,  1.2458e-01,  1.7442e-01,  1.6268e-01,  1.9055e-01,\n",
              "                       1.5296e-01,  1.7867e-01,  1.5886e-01,  1.9530e-01,  1.5250e-01,\n",
              "                       4.4999e-02,  1.8792e-01,  1.7637e-01,  1.6520e-01,  6.6209e-02,\n",
              "                       1.8889e-01,  1.6709e-01,  1.9061e-01,  1.7398e-01,  1.8633e-01,\n",
              "                       1.7666e-01,  1.2891e-01,  1.9859e-01,  1.5666e-01,  1.9075e-01,\n",
              "                       1.8091e-01,  1.8148e-01,  1.3853e-01,  1.7216e-01,  1.7880e-01,\n",
              "                       1.7994e-01,  1.7430e-01,  1.5725e-01,  1.3448e-01,  1.6213e-01,\n",
              "                       1.7797e-01,  1.6743e-01,  1.7223e-01,  1.7801e-01,  1.8171e-01,\n",
              "                       1.8037e-01,  1.6601e-01,  2.1573e-01,  1.9649e-01,  1.8462e-01,\n",
              "                       1.9507e-01,  1.7507e-01,  1.6378e-01,  1.8887e-01,  2.0684e-01,\n",
              "                       1.7027e-01,  1.7595e-01,  2.0311e-01,  1.6123e-01,  1.8088e-01,\n",
              "                       1.7448e-01,  1.9384e-01,  1.7451e-01,  1.9688e-01,  2.1040e-01,\n",
              "                       1.6844e-01,  1.3686e-01,  1.9371e-01,  1.5557e-01,  1.8920e-01,\n",
              "                       1.8503e-01,  1.7806e-01,  1.9425e-01], device='cuda:0')),\n",
              "             ('encoder.block.7.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.5817,  0.9007, -0.2413,  ..., -0.1211,  0.3594,  0.2062],\n",
              "                      [ 0.0873, -0.0789,  0.1591,  ..., -0.5271, -0.3782, -0.0763],\n",
              "                      [-0.3847, -0.4881, -0.2142,  ..., -0.8534, -0.3831,  0.3243],\n",
              "                      ...,\n",
              "                      [ 0.2888, -0.2209, -0.0235,  ..., -0.5988, -0.2297,  0.0507],\n",
              "                      [ 0.4043,  0.5219,  0.4200,  ..., -0.1568, -0.3401,  0.1963],\n",
              "                      [ 0.3659,  1.0861, -0.7873,  ...,  0.3589,  0.6930, -0.2177]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.7.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.0502,  0.0561,  0.5550,  ...,  0.1573, -0.3467,  0.5139],\n",
              "                      [ 0.3502, -0.3601, -0.4580,  ..., -0.0761, -0.1465,  0.0749],\n",
              "                      [-0.0418,  0.1334,  0.5023,  ...,  0.3774,  0.0759,  0.2570],\n",
              "                      ...,\n",
              "                      [ 0.1329,  0.1251, -0.0641,  ...,  0.2516,  0.2089,  0.1411],\n",
              "                      [ 0.0041,  0.2369,  0.3451,  ..., -0.1762,  0.2704,  0.4783],\n",
              "                      [-0.3129,  0.3004,  0.2112,  ..., -0.5434,  0.1929,  0.3091]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.7.layer.1.layer_norm.weight',\n",
              "              tensor([1.2021, 1.0827, 1.0941, 1.1637, 1.1423, 1.2070, 0.3129, 1.2215, 2.0648,\n",
              "                      1.1780, 1.1853, 1.1913, 1.1151, 1.2371, 1.0894, 1.1418, 1.1756, 1.1283,\n",
              "                      1.0443, 1.0983, 1.1335, 1.1887, 2.3721, 1.0554, 1.1300, 1.2288, 1.0781,\n",
              "                      1.0632, 1.2352, 1.0895, 1.1797, 1.0785, 1.1908, 1.0901, 1.1577, 1.1459,\n",
              "                      1.3702, 1.2211, 1.0976, 1.8780, 1.1123, 1.3188, 1.0744, 1.2101, 2.8884,\n",
              "                      1.1352, 1.0983, 1.1843, 1.1107, 0.5774, 1.1914, 1.1300, 1.5479, 1.0533,\n",
              "                      1.1599, 1.0827, 1.9211, 1.1109, 1.1327, 1.1819, 1.1537, 1.1176, 1.1158,\n",
              "                      1.1132, 1.1491, 1.3195, 1.1162, 1.1475, 1.2782, 1.1119, 1.1023, 1.5137,\n",
              "                      1.0694, 1.1662, 1.0936, 1.1229, 1.2963, 1.1129, 1.0905, 1.1511, 1.0448,\n",
              "                      1.1212, 1.1419, 1.2407, 1.1205, 1.2421, 1.2782, 1.1455, 1.2150, 1.1507,\n",
              "                      1.2211, 1.0925, 1.0267, 1.2013, 1.1708, 1.0623, 1.1147, 1.0999, 1.1213,\n",
              "                      1.0794, 1.2178, 1.1100, 1.0611, 1.1152, 1.1826, 1.5182, 1.1712, 1.1938,\n",
              "                      1.1378, 1.9989, 1.1961, 1.1528, 1.1052, 1.1370, 1.1138, 1.0928, 1.0912,\n",
              "                      1.0249, 1.3167, 1.1369, 1.0530, 1.0828, 1.3171, 1.0795, 0.9986, 1.1256,\n",
              "                      1.0904, 1.1078, 1.1097, 1.1995, 1.3162, 1.1481, 1.1164, 1.0766, 1.1150,\n",
              "                      1.1093, 1.3097, 1.0491, 1.1932, 1.1159, 1.0590, 1.2871, 1.1983, 1.2487,\n",
              "                      1.0497, 1.3278, 1.0904, 1.1264, 1.1565, 1.1528, 1.1367, 1.1412, 1.1086,\n",
              "                      1.2776, 1.1585, 1.0698, 1.1066, 1.1621, 1.1488, 1.0925, 1.1201, 1.1353,\n",
              "                      1.0276, 3.3732, 1.0930, 1.0473, 1.1577, 1.1746, 1.0395, 1.1002, 1.2122,\n",
              "                      1.1362, 1.1578, 1.2973, 1.1400, 1.1095, 1.1431, 0.4814, 1.1404, 0.4878,\n",
              "                      1.1084, 1.1172, 1.1353, 1.0556, 1.1632, 1.2938, 1.0565, 1.1544, 1.1946,\n",
              "                      1.1489, 1.0903, 1.1215, 1.1471, 1.1263, 1.1035, 0.4618, 1.1568, 1.2989,\n",
              "                      1.1673, 1.0754, 1.0741, 1.1370, 1.1099, 1.2192, 1.1387, 1.1768, 1.1344,\n",
              "                      1.1290, 1.1244, 1.1414, 1.2579, 1.1192, 1.1395, 1.2206, 1.1193, 1.2147,\n",
              "                      1.1052, 1.1262, 1.1698, 2.0520, 1.0676, 1.1538, 1.0993, 1.0834, 1.2292,\n",
              "                      1.1274, 1.2115, 1.1347, 1.2208, 1.1628, 1.1177, 1.1234, 0.8886, 1.0977,\n",
              "                      1.0855, 0.9227, 1.0314, 1.2105, 1.1578, 0.9792, 1.2848, 1.1957, 1.1354,\n",
              "                      1.1323, 1.0279, 1.0975, 1.1933, 1.1182, 1.0625, 1.1798, 3.0107, 1.0814,\n",
              "                      1.1425, 1.1848, 1.1005, 1.1098, 1.1312, 0.9921, 0.6451, 1.1434, 1.1280,\n",
              "                      0.4862, 1.0930, 1.1595, 1.1301, 1.0935, 1.1622, 1.1018, 1.1167, 1.1465,\n",
              "                      0.9923, 1.2604, 1.4074, 1.3399, 1.2031, 1.2831, 1.1433, 1.0922, 1.1228,\n",
              "                      1.1078, 1.2697, 1.3120, 1.2012, 1.3022, 1.1661, 1.2384, 1.1035, 1.1352,\n",
              "                      1.0795, 1.6777, 1.0572, 1.1509, 1.1016, 1.0893, 1.1530, 1.1894, 1.1223,\n",
              "                      1.1735, 1.1632, 1.2328, 1.2315, 1.1008, 1.2081, 1.0851, 1.0777, 1.1155,\n",
              "                      1.1045, 1.1458, 1.1231, 1.1641, 1.1302, 1.2269, 1.0964, 0.9592, 1.1774,\n",
              "                      1.1595, 1.1008, 1.1911, 1.3203, 1.1098, 1.0622, 1.1951, 1.1273, 1.1493,\n",
              "                      1.2059, 1.0489, 1.3421, 1.2231, 1.0833, 1.1269, 1.1798, 1.2424, 1.1761,\n",
              "                      1.0429, 1.1358, 1.1327, 1.1000, 1.0628, 1.0924, 1.2509, 1.2195, 1.1738,\n",
              "                      1.2347, 1.1605, 1.1266, 1.2155, 1.1334, 1.1932, 1.1670, 1.8936, 1.1567,\n",
              "                      1.0701, 1.2256, 1.1202, 1.1596, 1.1024, 1.0978, 1.1901, 1.1347, 1.2281,\n",
              "                      1.1195, 1.2117, 1.1955, 1.0214, 1.0979, 1.1117, 0.8390, 1.3260, 1.0683,\n",
              "                      1.2143, 1.3165, 1.1573, 0.3673, 1.0473, 1.2809, 1.1579, 1.1320, 1.1004,\n",
              "                      1.1377, 1.2542, 1.1685, 1.1643, 1.2150, 1.1348, 1.1117, 1.1076, 1.1463,\n",
              "                      0.8948, 1.0083, 1.2407, 1.1325, 2.6033, 1.1418, 1.1779, 1.1864, 1.2451,\n",
              "                      1.1871, 1.1130, 1.1504, 1.1058, 1.1031, 0.6214, 1.1192, 1.1801, 1.0625,\n",
              "                      1.1795, 1.3687, 1.0998, 1.0322, 1.0617, 1.0975, 1.0863, 1.1985, 1.1994,\n",
              "                      1.0430, 1.1110, 1.1313, 1.1018, 0.4394, 1.4542, 1.3231, 1.1713, 1.1022,\n",
              "                      0.4653, 1.1693, 1.1201, 1.1160, 1.0740, 1.1859, 1.1144, 1.1686, 1.1586,\n",
              "                      1.1214, 1.0356, 1.3303, 1.1203, 1.1795, 1.0952, 1.1688, 1.1843, 1.2346,\n",
              "                      1.0078, 1.3060, 1.1436, 1.0924, 1.1508, 1.0873, 1.1675, 1.1335, 1.1124,\n",
              "                      1.1072, 1.0840, 1.1402, 1.0854, 1.3753, 1.2341, 1.1343, 1.1507, 1.2038,\n",
              "                      1.0919, 1.0664, 1.1054, 1.0848, 1.1196, 1.1035, 1.1303, 1.0269, 1.1681,\n",
              "                      1.0325, 1.1622, 1.1051, 1.0665, 0.9459, 1.1022, 1.1752, 1.1007, 1.1256,\n",
              "                      1.1374, 1.2594, 1.0897, 1.1605, 2.0005, 1.1879, 1.1271, 1.2224, 1.1609,\n",
              "                      1.1658, 1.2862, 1.0589, 1.1587, 1.1503, 1.2703, 1.5099, 1.1607, 1.1532,\n",
              "                      1.1925, 1.1692, 1.1100, 1.0806, 1.0356, 1.0803, 1.2008, 1.2726, 2.0228,\n",
              "                      1.2311, 1.1834, 1.1524, 1.1002, 1.0457, 1.2096, 1.1448, 1.1137, 1.7871,\n",
              "                      1.0971, 1.2244, 1.1324, 1.0676, 1.1502, 1.1328, 1.1857, 1.1012, 1.1969,\n",
              "                      1.0749, 1.1512, 1.1441, 1.9099, 1.0976, 1.3685, 1.1321, 1.1482, 1.1425,\n",
              "                      1.0941, 1.1235, 1.1461, 1.1700, 1.1004, 1.1120, 1.1061, 1.2324, 1.1618,\n",
              "                      1.1995, 1.1095, 1.1403, 1.2024, 1.1313, 1.1538, 1.1503, 1.1661, 1.1704,\n",
              "                      0.4122, 1.2116, 1.2236, 1.0838, 1.3320, 1.0916, 1.1406, 1.1674, 1.1179,\n",
              "                      1.1527, 1.1135, 1.2187, 1.0067, 1.2603, 1.3419, 1.1491, 1.1141, 0.3391,\n",
              "                      1.1177, 1.1741, 1.1502, 1.1671, 0.4333, 1.0852, 1.1495, 1.0986, 1.1827,\n",
              "                      1.1414, 1.1246, 1.0546, 1.1153, 1.1407, 1.1178, 1.1483, 1.1361, 1.0595,\n",
              "                      1.0547, 1.1430, 1.0978, 1.1236, 1.0329, 1.1468, 1.1344, 1.1155, 1.1363,\n",
              "                      1.0829, 1.1259, 1.1178, 1.1577, 1.1660, 1.0927, 1.2789, 1.1146, 1.1956,\n",
              "                      0.8221, 1.1164, 1.0289, 1.0390, 1.1073, 1.2385, 1.1231, 1.1709, 1.1494,\n",
              "                      1.1730, 1.1053, 1.1535, 1.2635, 1.1383, 1.0538, 1.1160, 1.1305, 1.2814,\n",
              "                      1.1072, 1.1242, 1.1639, 1.1561, 1.1076, 1.1837, 1.2062, 1.0946, 1.0679,\n",
              "                      1.2035, 1.1627, 1.2240, 1.3196, 1.0516, 0.6909, 1.1469, 1.0972, 1.2883,\n",
              "                      1.0601, 1.1346, 1.1946, 1.0721, 1.1933, 1.2313, 1.1426, 1.0898, 1.0877,\n",
              "                      1.1313, 1.1116, 1.0616, 1.1708, 1.0697, 1.1555, 1.0699, 1.2026, 1.0818,\n",
              "                      1.0439, 1.0263, 1.1904, 0.8504, 0.4321, 1.0502, 1.3124, 1.1302, 1.2010,\n",
              "                      1.1009, 1.1106, 1.1163, 1.2011, 1.1714, 1.4767, 1.0926, 1.1378, 1.0979,\n",
              "                      1.1257, 1.0571, 1.1683, 1.1670, 1.1222, 1.1075, 1.1491, 1.1926, 1.0873,\n",
              "                      1.1082, 1.5659, 1.1307, 1.2245, 1.1284, 1.1006, 1.1135, 1.1500, 1.1784,\n",
              "                      1.1039, 1.1253, 1.1499, 1.2518, 1.0808, 1.1145, 1.1545, 1.2900, 1.0813,\n",
              "                      1.1367, 1.1117, 1.1659, 1.1089, 1.1347, 1.3424, 1.2230, 1.1336, 2.1188,\n",
              "                      1.1759, 1.1416, 1.0886, 0.5204, 1.1596, 1.2227, 1.2051, 1.1326, 1.1628,\n",
              "                      1.1221, 1.1984, 1.1992, 1.1027, 1.2169, 1.0742, 1.1003, 1.1041, 1.1921,\n",
              "                      1.2407, 1.1331, 1.1337, 1.0681, 0.9257, 1.0818, 1.0894, 1.1872, 1.1566,\n",
              "                      1.1088, 1.1943, 1.1433, 1.2696, 1.1173, 1.1217, 1.1633, 1.2393, 1.0106,\n",
              "                      1.1221, 1.1838, 1.3379, 1.2232, 1.1591, 1.3091, 1.1591, 1.1822, 1.1113,\n",
              "                      1.0593, 1.0859, 1.1032, 1.1572, 1.0298, 0.9390, 1.1764, 1.1045, 1.1096,\n",
              "                      1.1233, 1.1446, 1.1760], device='cuda:0')),\n",
              "             ('encoder.block.8.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0580,  0.0269, -0.0042,  ...,  0.0054,  0.0011,  0.0546],\n",
              "                      [-0.0065, -0.0371, -0.0197,  ..., -0.0085,  0.0306,  0.0103],\n",
              "                      [-0.0065, -0.0166, -0.0459,  ...,  0.0042, -0.0160,  0.0464],\n",
              "                      ...,\n",
              "                      [ 0.0076, -0.0295, -0.0010,  ...,  0.0492, -0.0242,  0.0119],\n",
              "                      [-0.0030,  0.0706, -0.0245,  ...,  0.0100, -0.0425, -0.0032],\n",
              "                      [-0.0513, -0.0479, -0.0195,  ...,  0.0071, -0.0343, -0.0285]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.8.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.4980,  0.1051,  0.0265,  ..., -0.1307, -0.1658,  0.1179],\n",
              "                      [-0.1690,  0.2117, -0.1176,  ..., -0.1021,  0.1065, -0.2390],\n",
              "                      [-0.0163,  0.3410, -0.1565,  ..., -0.0928, -0.1814, -0.0545],\n",
              "                      ...,\n",
              "                      [ 0.0076,  0.2503,  0.3081,  ...,  0.3799, -0.3337,  0.4256],\n",
              "                      [ 0.1459, -0.1829, -0.5371,  ...,  0.0360,  0.0054,  0.1371],\n",
              "                      [-0.1838, -0.3078, -0.1594,  ...,  0.4710,  0.2184, -0.5427]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.8.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.6751,  0.7873, -0.9682,  ..., -0.4870,  1.3631,  0.6644],\n",
              "                      [-0.4853, -0.6237,  0.0102,  ...,  0.0735,  0.4877,  0.2782],\n",
              "                      [-0.5891,  0.2422, -0.2130,  ..., -0.0240,  0.0219, -0.0580],\n",
              "                      ...,\n",
              "                      [-0.3218, -0.6006, -0.2714,  ..., -1.6185,  0.5751, -0.6930],\n",
              "                      [ 0.9837,  0.6124,  0.1724,  ...,  0.5950, -1.0652, -1.5896],\n",
              "                      [-0.4770, -0.4217, -0.5469,  ...,  1.2114, -1.2474,  0.3827]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.8.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.3584,  0.2880,  0.4044,  ..., -0.0031, -0.3719,  0.4970],\n",
              "                      [-1.1850, -0.4751, -0.9913,  ..., -0.4591,  1.0980, -0.4632],\n",
              "                      [ 1.1515, -0.5940,  0.8958,  ..., -0.4277,  1.1863,  0.8294],\n",
              "                      ...,\n",
              "                      [ 0.1214, -0.2900, -0.2146,  ..., -1.4456,  0.9038, -1.8401],\n",
              "                      [-1.4817, -0.8442, -0.0887,  ..., -0.1768, -1.4945,  0.3122],\n",
              "                      [-0.6540,  0.0576,  0.1958,  ..., -0.1854, -0.2141, -0.4901]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.8.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.1825,  0.1696,  0.1607,  0.1839,  0.1736,  0.1651,  0.0361,  0.1980,\n",
              "                       0.1060,  0.1619,  0.1869,  0.1796,  0.1353,  0.1481,  0.1462,  0.1830,\n",
              "                       0.1672,  0.1809,  0.1730,  0.1684,  0.1480,  0.1701,  0.0475,  0.1642,\n",
              "                       0.1655,  0.1738,  0.1710,  0.1525,  0.1836,  0.1483,  0.1677,  0.1665,\n",
              "                       0.1830,  0.1576,  0.1794,  0.1889,  0.1475,  0.1806,  0.1569,  0.1671,\n",
              "                       0.1624,  0.1575,  0.1568,  0.1827,  0.0879,  0.1593,  0.1314,  0.1706,\n",
              "                       0.1719,  0.0617,  0.1800,  0.1937,  0.1438,  0.1659,  0.0413,  0.1636,\n",
              "                       0.1042,  0.1754,  0.1908,  0.1661,  0.1848,  0.1493,  0.1806,  0.1745,\n",
              "                       0.1713,  0.0557,  0.1662,  0.1514,  0.1813,  0.1695,  0.1771,  0.1566,\n",
              "                       0.1550,  0.1745,  0.1715,  0.1658,  0.1553,  0.1715,  0.1708,  0.2016,\n",
              "                       0.1716,  0.1717,  0.1804,  0.1914,  0.1674,  0.1729,  0.1866,  0.1734,\n",
              "                       0.1843,  0.1569,  0.1840,  0.1492,  0.1643,  0.1579,  0.1616,  0.1546,\n",
              "                       0.1971,  0.1672,  0.1716,  0.1417,  0.1831,  0.1910,  0.1119,  0.1590,\n",
              "                       0.1827,  0.1431,  0.1685,  0.1514,  0.1694,  0.0948,  0.1788,  0.1692,\n",
              "                       0.1687,  0.1464,  0.1568,  0.1664,  0.1821,  0.1560,  0.1571,  0.1700,\n",
              "                       0.1458,  0.1864,  0.1649,  0.1671,  0.1558,  0.1741,  0.1940,  0.1773,\n",
              "                       0.1642,  0.1763,  0.1037,  0.1843,  0.1619,  0.1530,  0.1621,  0.1451,\n",
              "                       0.1941,  0.1584,  0.1769,  0.1867,  0.1691,  0.1891,  0.1566,  0.1652,\n",
              "                       0.1720,  0.1915,  0.1598,  0.1844,  0.1740,  0.1762,  0.1792,  0.1789,\n",
              "                       0.1788,  0.1893,  0.1474,  0.1746,  0.1666,  0.1595,  0.1644,  0.1732,\n",
              "                       0.1564,  0.1626,  0.1392,  0.0733,  0.1575,  0.1575,  0.1538,  0.1743,\n",
              "                       0.1879,  0.1639,  0.1924,  0.1860,  0.1877,  0.1234,  0.1857,  0.1513,\n",
              "                       0.1739,  0.0680,  0.1652,  0.0259,  0.1842,  0.1654,  0.1823,  0.1640,\n",
              "                       0.1935,  0.1872,  0.1468,  0.1769,  0.1851,  0.1785,  0.1700,  0.1733,\n",
              "                       0.1439,  0.1873,  0.1612,  0.0469,  0.1760,  0.1772,  0.1684,  0.1351,\n",
              "                       0.1455,  0.1935,  0.1717,  0.1732,  0.1669,  0.1738,  0.1557,  0.1637,\n",
              "                       0.1592,  0.1740,  0.1717,  0.1454,  0.1723,  0.1854,  0.1810,  0.1942,\n",
              "                       0.1712,  0.1572,  0.1730,  0.1464,  0.1235,  0.1882,  0.1592,  0.1891,\n",
              "                       0.1522,  0.1789,  0.1914,  0.1797,  0.1812,  0.1814,  0.1548,  0.1794,\n",
              "                       0.1219,  0.1474,  0.1474,  0.1265,  0.1307,  0.1991,  0.1806,  0.1424,\n",
              "                       0.1769,  0.2003,  0.1712,  0.1814,  0.1470,  0.1692,  0.1880,  0.1723,\n",
              "                       0.1485,  0.1689,  0.1188,  0.1452,  0.1597,  0.1434,  0.1618,  0.1578,\n",
              "                       0.1641,  0.1457,  0.0876,  0.1704,  0.1844,  0.1333,  0.1630,  0.1859,\n",
              "                       0.1712,  0.1577,  0.1708,  0.1586,  0.1835,  0.1688,  0.0807,  0.1934,\n",
              "                       0.1589,  0.0341,  0.1799,  0.1860,  0.1762,  0.1329,  0.1755,  0.1663,\n",
              "                       0.2020,  0.1956,  0.1635,  0.1769,  0.2069,  0.1366,  0.1477,  0.1862,\n",
              "                       0.1398,  0.1354,  0.1544,  0.1567,  0.1608,  0.1720,  0.1686,  0.1477,\n",
              "                       0.1680,  0.1731,  0.1542,  0.1825,  0.2027,  0.1688,  0.1910,  0.1809,\n",
              "                       0.1677,  0.1591,  0.1732,  0.1820,  0.1812,  0.1741,  0.1802,  0.1856,\n",
              "                       0.1668,  0.1368,  0.1855,  0.1645,  0.1269,  0.1927,  0.1680,  0.1673,\n",
              "                       0.1516,  0.1677,  0.1629,  0.1595,  0.1801,  0.1618,  0.1715,  0.2004,\n",
              "                       0.1728,  0.1725,  0.1825,  0.1384,  0.1719,  0.1727,  0.1711,  0.1837,\n",
              "                       0.1598,  0.1521,  0.1578,  0.1740,  0.1841,  0.1899,  0.1829,  0.1774,\n",
              "                       0.1890,  0.1679,  0.1563,  0.1840,  0.1532,  0.1245,  0.1806,  0.1939,\n",
              "                       0.1826,  0.1778,  0.1715,  0.1767,  0.1684,  0.1692,  0.1654,  0.1439,\n",
              "                       0.1670,  0.1820,  0.1663,  0.1258,  0.1679,  0.1773,  0.0788,  0.1604,\n",
              "                       0.1479,  0.1705,  0.1564,  0.1871,  0.0472,  0.1319,  0.1913,  0.1689,\n",
              "                       0.1430,  0.1643,  0.1743,  0.1307,  0.1705,  0.1735,  0.1863,  0.1765,\n",
              "                       0.1541,  0.0681,  0.1814,  0.1231,  0.1555,  0.2015,  0.1709,  0.0574,\n",
              "                       0.1687,  0.1925,  0.1868,  0.1604,  0.1804,  0.1703,  0.1749,  0.1668,\n",
              "                       0.1735, -0.0026,  0.1563,  0.1903,  0.1750,  0.1686,  0.1849,  0.1565,\n",
              "                       0.1657,  0.1572,  0.1640,  0.1634,  0.1600,  0.1699,  0.1625,  0.1521,\n",
              "                       0.1582,  0.1574,  0.0435,  0.1728,  0.1516,  0.1862,  0.1605,  0.0538,\n",
              "                       0.1699,  0.1683,  0.1822,  0.1554,  0.1862,  0.1790,  0.1920,  0.1770,\n",
              "                       0.1192,  0.1591,  0.1549,  0.1512,  0.1659,  0.1690,  0.1704,  0.1941,\n",
              "                       0.1916,  0.1376,  0.1848,  0.1779,  0.1489,  0.1745,  0.1639,  0.1889,\n",
              "                       0.1765,  0.1861,  0.1697,  0.1627,  0.1753,  0.1736,  0.2024,  0.1966,\n",
              "                       0.1825,  0.1672,  0.1668,  0.1477,  0.1491,  0.1665,  0.1674,  0.1846,\n",
              "                       0.1766,  0.1893,  0.1295,  0.1449,  0.1462,  0.1693,  0.1484,  0.1637,\n",
              "                       0.1421,  0.1543,  0.1734,  0.1824,  0.1731,  0.1702,  0.0613,  0.1829,\n",
              "                       0.1892,  0.1186,  0.1827,  0.1686,  0.1914,  0.1596,  0.1720,  0.1572,\n",
              "                       0.1649,  0.1766,  0.1728,  0.1804,  0.0849,  0.1756,  0.1569,  0.1734,\n",
              "                       0.1726,  0.1730,  0.1718,  0.1712,  0.1596,  0.1786,  0.1592,  0.0567,\n",
              "                       0.1754,  0.1875,  0.1722,  0.1768,  0.1511,  0.1880,  0.1887,  0.1625,\n",
              "                       0.0892,  0.1594,  0.1832,  0.1624,  0.1574,  0.1525,  0.1422,  0.1858,\n",
              "                       0.1472,  0.1479,  0.1460,  0.1583,  0.1791,  0.1462,  0.1919,  0.1612,\n",
              "                       0.1707,  0.1814,  0.1743,  0.1786,  0.1723,  0.1707,  0.1575,  0.1821,\n",
              "                       0.1798,  0.1639,  0.1818,  0.1597,  0.1774,  0.1618,  0.1743,  0.1876,\n",
              "                       0.1508,  0.1829,  0.1813,  0.1833,  0.1613,  0.0626,  0.1561,  0.1790,\n",
              "                       0.1477,  0.2028,  0.1767,  0.1716,  0.1621,  0.1564,  0.1758,  0.1439,\n",
              "                       0.1738,  0.1478,  0.1854,  0.1885,  0.1748,  0.1820,  0.0354,  0.1740,\n",
              "                       0.1773,  0.1760,  0.1895,  0.0832,  0.1615,  0.1652,  0.1705,  0.1739,\n",
              "                       0.1655,  0.1940,  0.1613,  0.1583,  0.1781,  0.1729,  0.1799,  0.1639,\n",
              "                       0.1512,  0.1524,  0.1752,  0.1528,  0.1693,  0.1610,  0.1795,  0.1758,\n",
              "                       0.1723,  0.1867,  0.1806,  0.1745,  0.1528,  0.1729,  0.1466,  0.1622,\n",
              "                       0.2008,  0.1724,  0.1733,  0.1080,  0.1898,  0.1556,  0.1498,  0.1748,\n",
              "                       0.1639,  0.1704,  0.1637,  0.1543,  0.1752,  0.1635,  0.1735,  0.1888,\n",
              "                       0.1686,  0.1908,  0.1840,  0.1672,  0.1851,  0.1565,  0.1635,  0.1794,\n",
              "                       0.1852,  0.1721,  0.1743,  0.1454,  0.1586,  0.1157,  0.1937,  0.1702,\n",
              "                       0.1737,  0.1965,  0.1676,  0.1256,  0.1694,  0.1673,  0.2022,  0.1708,\n",
              "                       0.1531,  0.1867,  0.1558,  0.1668,  0.1971,  0.1835,  0.1681,  0.1657,\n",
              "                       0.1684,  0.1644,  0.1503,  0.1862,  0.1795,  0.1507,  0.1563,  0.1754,\n",
              "                       0.1805,  0.1610,  0.1545,  0.1642,  0.1124,  0.0200,  0.1640,  0.1998,\n",
              "                       0.1677,  0.1813,  0.1677,  0.1744,  0.1806,  0.1660,  0.1736,  0.1355,\n",
              "                       0.1613,  0.1611,  0.1843,  0.1686,  0.1712,  0.1676,  0.1637,  0.1788,\n",
              "                       0.1794,  0.1662,  0.1822,  0.1553,  0.1688,  0.1159,  0.1570,  0.1896,\n",
              "                       0.1701,  0.1841,  0.1596,  0.1802,  0.1493,  0.1448,  0.1800,  0.1733,\n",
              "                       0.2012,  0.1504,  0.1753,  0.1796,  0.1741,  0.1448,  0.1727,  0.1563,\n",
              "                       0.1680,  0.1599,  0.1812,  0.1683,  0.1851,  0.1627,  0.0483,  0.1728,\n",
              "                       0.1751,  0.1624,  0.0521,  0.1648,  0.1749,  0.1933,  0.1734,  0.1707,\n",
              "                       0.1611,  0.1298,  0.1870,  0.1600,  0.1768,  0.1747,  0.1821,  0.1361,\n",
              "                       0.1788,  0.1703,  0.1779,  0.1665,  0.1388,  0.1373,  0.1747,  0.1644,\n",
              "                       0.1848,  0.1662,  0.1798,  0.1691,  0.1840,  0.1783,  0.1780,  0.1815,\n",
              "                       0.1659,  0.1680,  0.1736,  0.1717,  0.1878,  0.1921,  0.1602,  0.1716,\n",
              "                       0.1813,  0.1910,  0.1827,  0.1716,  0.1862,  0.1684,  0.1786,  0.1932,\n",
              "                       0.1622,  0.1518,  0.1684,  0.1521,  0.1733,  0.1861,  0.1709,  0.1888],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.8.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.7413,  0.9450, -0.0799,  ..., -0.6454, -0.5064,  0.0280],\n",
              "                      [-0.4045, -0.5306,  0.3122,  ...,  0.2531,  0.1235,  0.4127],\n",
              "                      [-0.0602, -0.2198, -0.7780,  ..., -0.4690,  0.0926,  0.3711],\n",
              "                      ...,\n",
              "                      [ 0.0658, -0.1029,  0.1741,  ..., -0.4679,  0.1497, -0.1342],\n",
              "                      [ 0.2152, -0.4618,  0.5085,  ...,  0.1257,  0.8276,  0.1849],\n",
              "                      [-0.1013, -0.7095,  0.3783,  ..., -0.4030,  0.5594, -0.6295]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.8.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.0857, -0.1783, -0.1226,  ...,  0.1879, -0.1225,  0.1113],\n",
              "                      [ 0.0133, -0.1792, -0.0768,  ...,  0.2627, -0.1049, -0.2023],\n",
              "                      [ 0.0868,  0.4038,  0.0256,  ..., -0.0568, -0.1377, -0.1946],\n",
              "                      ...,\n",
              "                      [ 0.0561,  0.1561,  0.2744,  ..., -0.2683,  0.0227, -0.1712],\n",
              "                      [-0.0485,  0.0009, -0.1762,  ..., -0.1765,  0.0087, -0.2828],\n",
              "                      [ 0.0504,  0.2892, -0.1251,  ...,  0.0528, -0.2671,  0.1020]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.8.layer.1.layer_norm.weight',\n",
              "              tensor([1.1600, 1.1164, 1.1027, 1.1303, 1.2332, 1.2624, 0.3021, 1.1986, 1.8539,\n",
              "                      1.2375, 1.1248, 1.1296, 1.1736, 1.2474, 1.1885, 1.1282, 1.1542, 1.1792,\n",
              "                      0.8995, 1.1767, 1.2245, 1.2222, 2.7757, 1.1402, 1.2066, 1.2114, 1.1810,\n",
              "                      1.1152, 1.2330, 1.1365, 1.1664, 1.1800, 1.1471, 1.1538, 1.1090, 1.1792,\n",
              "                      1.3021, 1.1707, 1.1349, 1.9015, 1.1125, 1.2216, 0.9814, 1.2120, 2.8206,\n",
              "                      1.2232, 1.0953, 1.2157, 1.1671, 0.5168, 1.1499, 1.1263, 1.4394, 1.1541,\n",
              "                      1.1699, 1.1809, 2.2602, 1.1815, 1.2122, 1.2155, 1.2056, 1.2159, 1.2304,\n",
              "                      1.1913, 1.2543, 1.2135, 1.1876, 1.2140, 1.2094, 1.1791, 1.2411, 1.1915,\n",
              "                      1.1636, 1.2423, 1.1627, 1.2352, 1.3007, 1.1658, 1.1589, 1.2486, 1.1464,\n",
              "                      1.1299, 1.1466, 1.1089, 1.1759, 1.2302, 1.1871, 1.1620, 1.1828, 1.1574,\n",
              "                      1.2183, 1.1816, 1.1161, 1.2125, 1.2650, 1.2058, 1.1894, 1.1345, 1.1447,\n",
              "                      1.1640, 1.1559, 1.1737, 0.9032, 1.1757, 1.1814, 1.4979, 1.2291, 1.2009,\n",
              "                      1.1710, 1.9567, 1.1003, 1.1785, 1.1372, 1.1896, 1.1167, 1.1928, 1.1492,\n",
              "                      1.1272, 1.1850, 1.1577, 1.1847, 1.1505, 1.2571, 1.1992, 0.9093, 1.2346,\n",
              "                      1.1855, 1.1650, 1.1438, 1.2125, 1.2697, 1.1018, 1.1894, 1.1758, 1.1074,\n",
              "                      1.0341, 1.2799, 1.1561, 1.2318, 1.0786, 1.0883, 1.1757, 1.0575, 1.2824,\n",
              "                      1.0125, 1.2632, 1.1849, 1.0598, 1.1681, 1.2030, 1.1998, 1.1416, 1.1128,\n",
              "                      1.1821, 1.2296, 1.2075, 1.1591, 1.2538, 1.1500, 1.1619, 1.1816, 1.2293,\n",
              "                      1.0304, 3.5286, 1.2081, 1.0710, 1.1499, 1.1545, 1.0372, 0.9480, 1.2275,\n",
              "                      1.1286, 1.2030, 1.1704, 1.1911, 1.0799, 1.2019, 0.4270, 1.1171, 0.4299,\n",
              "                      1.2307, 1.2052, 1.2248, 1.1740, 1.1174, 1.1969, 1.1483, 1.0741, 1.1845,\n",
              "                      1.2037, 1.1600, 1.1689, 1.2328, 1.1285, 1.1780, 0.4348, 1.2168, 1.2178,\n",
              "                      1.2086, 1.2115, 1.1906, 1.1563, 1.1335, 1.2619, 1.1287, 1.1518, 1.1843,\n",
              "                      1.1088, 1.1900, 1.1552, 1.2489, 1.1374, 1.1631, 1.2689, 1.1598, 1.1460,\n",
              "                      1.1368, 1.1855, 1.1799, 1.6098, 1.0690, 1.1904, 1.1230, 1.0959, 1.2427,\n",
              "                      1.1211, 1.1559, 0.8802, 1.1990, 1.1224, 1.1039, 1.1705, 1.0999, 1.2198,\n",
              "                      1.0912, 1.0118, 1.2182, 1.1841, 1.1396, 0.8787, 1.2269, 1.1850, 1.2102,\n",
              "                      1.1490, 1.1434, 1.1714, 1.1842, 1.1770, 1.1802, 1.2003, 2.6675, 1.1929,\n",
              "                      1.1643, 1.2862, 1.1853, 1.1819, 1.1641, 1.0291, 0.6028, 1.1338, 1.0572,\n",
              "                      0.6150, 1.1808, 1.1520, 1.2114, 1.1696, 1.2021, 1.1784, 1.1567, 1.1909,\n",
              "                      1.0731, 1.1786, 1.3995, 1.2009, 1.1719, 1.2413, 1.1744, 0.9272, 1.1937,\n",
              "                      1.0943, 1.1866, 1.2389, 1.2794, 1.2368, 1.1782, 1.0687, 1.1498, 1.2084,\n",
              "                      1.0538, 1.7168, 1.1790, 1.1676, 1.2006, 1.1912, 1.2293, 1.3136, 1.1161,\n",
              "                      1.2283, 1.1883, 1.2186, 1.2212, 1.1450, 1.0441, 1.0946, 1.1211, 1.1294,\n",
              "                      1.1238, 1.1420, 1.1424, 1.1568, 1.1607, 1.1868, 1.2042, 0.9657, 1.2311,\n",
              "                      1.1494, 1.1359, 1.1694, 1.2649, 1.1546, 1.1332, 1.1310, 1.0987, 1.2167,\n",
              "                      1.1575, 1.1845, 1.2424, 1.2005, 1.1459, 1.1352, 1.1775, 1.2226, 1.1522,\n",
              "                      1.0831, 1.2007, 1.1755, 1.1379, 1.1383, 1.1424, 1.1737, 1.1691, 1.1817,\n",
              "                      1.2139, 1.2875, 1.1694, 1.2069, 1.0422, 1.1553, 1.0367, 1.8806, 1.1627,\n",
              "                      1.1894, 1.2897, 1.1674, 1.1418, 1.1236, 1.1175, 1.1470, 1.2422, 1.1700,\n",
              "                      1.1884, 1.1840, 1.1125, 1.1369, 1.2094, 1.2111, 0.7579, 1.2997, 1.1930,\n",
              "                      1.2568, 1.3404, 1.1686, 0.4426, 1.1243, 1.2526, 1.2206, 1.0426, 1.1339,\n",
              "                      0.9731, 1.2358, 1.1931, 1.1412, 1.1975, 1.1442, 1.1765, 1.0790, 1.2717,\n",
              "                      0.7916, 1.0848, 1.2337, 1.2294, 2.5011, 1.1313, 1.1464, 1.2225, 1.2724,\n",
              "                      1.2277, 1.1954, 1.1354, 1.2138, 1.1429, 0.6859, 1.2278, 1.2027, 1.1586,\n",
              "                      1.1929, 1.3431, 1.1385, 1.1310, 1.1884, 1.1856, 1.1907, 1.2790, 1.1775,\n",
              "                      1.1856, 1.1279, 1.1902, 1.1964, 0.5141, 1.3905, 1.1621, 1.1966, 1.2109,\n",
              "                      0.4611, 1.2280, 1.1829, 1.1012, 1.2186, 1.2281, 1.0929, 1.2115, 1.2322,\n",
              "                      0.9631, 1.1810, 1.2492, 1.1833, 1.2265, 1.1239, 1.1033, 1.1387, 1.2517,\n",
              "                      1.0633, 1.2767, 0.9791, 1.1454, 1.1650, 1.1517, 1.2100, 1.1170, 1.1108,\n",
              "                      1.1868, 1.1643, 1.1591, 1.1392, 1.3437, 1.1820, 1.1277, 1.1424, 1.1945,\n",
              "                      1.1556, 1.1402, 1.1361, 1.1614, 1.1562, 1.1241, 1.1757, 1.0736, 1.1461,\n",
              "                      1.1293, 1.2212, 1.1477, 1.1757, 1.0569, 1.1759, 1.1784, 1.2040, 1.2375,\n",
              "                      1.1688, 1.1070, 1.0969, 1.1784, 1.8961, 1.2745, 1.1879, 1.1575, 1.2034,\n",
              "                      1.1853, 1.3043, 1.1727, 1.1191, 1.2134, 1.2582, 1.6335, 1.1820, 1.1569,\n",
              "                      1.1926, 1.1916, 1.1592, 1.1727, 1.1698, 1.1909, 1.1701, 1.2095, 1.9676,\n",
              "                      1.2696, 1.1859, 1.2046, 1.1030, 1.1931, 1.1813, 1.1452, 1.1905, 1.7792,\n",
              "                      1.1339, 1.2166, 1.2175, 1.1405, 1.1882, 1.0156, 1.2134, 1.1853, 1.2400,\n",
              "                      1.1392, 1.2117, 1.1794, 1.8332, 1.1153, 1.1402, 1.2075, 1.1733, 1.0629,\n",
              "                      1.1327, 1.1661, 1.1497, 1.2227, 1.1177, 1.1369, 1.1858, 1.2017, 1.1605,\n",
              "                      1.1199, 1.1094, 1.1228, 1.1144, 1.1957, 1.2133, 1.1591, 1.1669, 1.1479,\n",
              "                      0.3910, 1.1336, 1.1542, 1.1707, 1.3019, 1.2022, 1.1585, 1.1463, 1.1876,\n",
              "                      1.1500, 1.0325, 1.2364, 1.1563, 1.1965, 1.2319, 1.1997, 1.1835, 0.4337,\n",
              "                      1.1579, 1.1885, 1.2209, 1.1200, 0.5297, 1.1663, 1.1877, 1.1609, 1.1233,\n",
              "                      1.1731, 1.1034, 1.0875, 0.9954, 1.1877, 1.2353, 1.2130, 1.1424, 1.1160,\n",
              "                      1.1489, 1.1702, 1.1515, 1.2051, 1.1426, 1.2039, 1.1879, 1.1448, 1.1917,\n",
              "                      1.1140, 1.1781, 1.1162, 1.2102, 1.1027, 1.1460, 1.2052, 1.1774, 1.1318,\n",
              "                      0.8212, 1.1814, 1.1614, 1.1139, 1.1225, 1.2274, 1.2370, 1.1595, 1.1745,\n",
              "                      1.1898, 1.1530, 1.1400, 1.1955, 1.2135, 1.0198, 1.1754, 1.1677, 1.2361,\n",
              "                      1.2010, 1.2082, 1.1137, 1.1015, 1.1162, 1.1569, 1.1202, 1.0734, 1.0113,\n",
              "                      1.1625, 1.2278, 1.2191, 1.1392, 1.1955, 0.6268, 1.1852, 1.1315, 1.2146,\n",
              "                      1.1056, 1.1115, 1.1998, 1.1750, 1.2528, 1.2270, 1.0752, 1.0271, 1.1782,\n",
              "                      1.1586, 1.1921, 1.1623, 1.1685, 1.1730, 1.2003, 1.0453, 1.0353, 1.1469,\n",
              "                      1.1304, 0.9162, 1.1921, 0.7731, 0.4667, 1.1490, 1.2242, 1.1545, 1.1888,\n",
              "                      1.1582, 1.1670, 1.1301, 1.2126, 1.1968, 1.4685, 1.1753, 1.1889, 1.0660,\n",
              "                      1.2030, 1.1112, 1.1648, 1.1633, 1.2061, 1.1291, 1.1290, 1.1793, 1.1667,\n",
              "                      1.1425, 1.5220, 1.1781, 1.2095, 1.2294, 1.1257, 1.2253, 1.1493, 1.0771,\n",
              "                      1.2410, 1.1979, 1.1164, 1.1924, 1.1935, 1.1937, 1.1380, 1.3031, 1.1610,\n",
              "                      1.1030, 1.1778, 1.1937, 1.1822, 1.2019, 1.2826, 1.1201, 1.1605, 1.8868,\n",
              "                      1.2026, 1.1671, 1.1659, 0.5434, 1.1879, 1.1840, 1.1999, 1.1462, 1.0186,\n",
              "                      1.1293, 1.2486, 1.2034, 1.2336, 1.1824, 1.0927, 1.0763, 1.1732, 1.2071,\n",
              "                      1.1831, 1.1366, 1.2313, 1.1775, 0.9892, 1.1526, 1.2062, 1.2284, 1.1873,\n",
              "                      1.1679, 1.1421, 1.1875, 1.2203, 1.0898, 1.1151, 1.1379, 1.2577, 1.0518,\n",
              "                      1.2038, 1.1766, 1.2483, 1.2344, 1.2025, 1.2095, 1.1840, 1.1378, 1.1377,\n",
              "                      1.1602, 1.1409, 1.0864, 1.1046, 1.0491, 0.9951, 1.1227, 1.1656, 1.1190,\n",
              "                      1.0469, 1.2128, 1.1758], device='cuda:0')),\n",
              "             ('encoder.block.9.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0251, -0.0650,  0.0171,  ..., -0.0229, -0.0060,  0.0057],\n",
              "                      [-0.0306, -0.0029,  0.0041,  ..., -0.0208, -0.0176, -0.0102],\n",
              "                      [ 0.0589,  0.0366,  0.0692,  ...,  0.0687,  0.0362,  0.0042],\n",
              "                      ...,\n",
              "                      [ 0.0157,  0.0049, -0.0077,  ..., -0.0097,  0.0339, -0.0078],\n",
              "                      [ 0.0365,  0.0038, -0.0095,  ...,  0.0010,  0.0235,  0.0101],\n",
              "                      [ 0.0032, -0.0038,  0.0374,  ..., -0.0207,  0.0259, -0.0149]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.9.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.3458, -0.4756,  0.4239,  ..., -0.1424, -0.1621, -0.4171],\n",
              "                      [-0.1394,  0.1073, -0.1834,  ..., -0.0212,  0.0750, -0.0151],\n",
              "                      [-0.0140, -0.3244,  0.4789,  ..., -0.2242,  0.1361, -0.0697],\n",
              "                      ...,\n",
              "                      [ 0.2468, -0.3484, -0.0901,  ...,  0.2229,  0.0756, -0.1619],\n",
              "                      [ 0.1571, -0.0218, -0.1378,  ..., -0.2165, -0.0646, -0.2498],\n",
              "                      [ 0.0867, -0.3454,  0.0848,  ..., -0.0133, -0.0527,  0.1385]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.9.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.8709, -0.5474,  0.1715,  ..., -0.2787, -0.3227, -0.8814],\n",
              "                      [-0.1346, -0.0523, -0.5737,  ..., -0.8827, -0.1664, -0.3107],\n",
              "                      [-1.3268,  0.3205,  0.0082,  ..., -0.0181,  0.3001, -0.5499],\n",
              "                      ...,\n",
              "                      [-0.5874, -0.3823,  1.2724,  ...,  0.0758, -0.2569, -0.3377],\n",
              "                      [ 0.1577, -0.1358,  0.5749,  ...,  0.4335, -0.1498, -0.5177],\n",
              "                      [-0.0053, -0.2943,  0.1498,  ...,  2.5429, -1.6288,  0.2463]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.9.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-1.1408,  0.8066,  0.3876,  ...,  2.2480, -0.1344, -0.1338],\n",
              "                      [ 1.2059, -0.0442,  0.4258,  ..., -1.6657,  0.6466,  1.3533],\n",
              "                      [-0.2830, -0.4394, -0.3045,  ..., -1.8379,  0.1004,  0.9764],\n",
              "                      ...,\n",
              "                      [ 0.7150,  1.6872, -0.1573,  ..., -0.9730, -0.6415, -0.4833],\n",
              "                      [ 0.5443, -0.2325, -0.3624,  ...,  0.7361,  0.5150,  1.0807],\n",
              "                      [ 1.4916, -0.2901,  1.0127,  ...,  0.9507, -1.5250,  0.5749]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.9.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.1782,  0.1885,  0.1774,  0.2049,  0.1843,  0.1858,  0.0352,  0.1962,\n",
              "                       0.1285,  0.2119,  0.2015,  0.1999,  0.1457,  0.1673,  0.1789,  0.2007,\n",
              "                       0.1671,  0.1755,  0.1692,  0.1851,  0.1793,  0.2049,  0.0561,  0.1743,\n",
              "                       0.2049,  0.1895,  0.1832,  0.1751,  0.1699,  0.1824,  0.1709,  0.1921,\n",
              "                       0.1968,  0.1896,  0.1823,  0.1946,  0.1709,  0.1893,  0.1852,  0.1847,\n",
              "                       0.1834,  0.1737,  0.1786,  0.1879,  0.1044,  0.1932,  0.1550,  0.1843,\n",
              "                       0.1948,  0.0499,  0.2114,  0.1922,  0.1653,  0.1852, -0.0031,  0.1725,\n",
              "                       0.1488,  0.1958,  0.2159,  0.1883,  0.1861,  0.1762,  0.2011,  0.1889,\n",
              "                       0.1961,  0.0584,  0.1947,  0.1870,  0.1999,  0.2086,  0.1990,  0.1606,\n",
              "                       0.1880,  0.2024,  0.1928,  0.1877,  0.1569,  0.1931,  0.1692,  0.2178,\n",
              "                       0.1719,  0.2014,  0.2035,  0.2061,  0.1962,  0.1895,  0.1794,  0.1969,\n",
              "                       0.2065,  0.1976,  0.1942,  0.1811,  0.1848,  0.1766,  0.1911,  0.1861,\n",
              "                       0.1850,  0.1957,  0.1956,  0.1668,  0.1790,  0.2076,  0.1272,  0.1803,\n",
              "                       0.1864,  0.1467,  0.1946,  0.1777,  0.1838,  0.1069,  0.1966,  0.2061,\n",
              "                       0.1946,  0.1769,  0.1846,  0.1950,  0.1850,  0.1746,  0.1680,  0.1874,\n",
              "                       0.1924,  0.2075,  0.1933,  0.1974,  0.1443,  0.1848,  0.2170,  0.1767,\n",
              "                       0.1758,  0.1949,  0.1352,  0.2028,  0.1962,  0.1591,  0.1885,  0.1604,\n",
              "                       0.1950,  0.1927,  0.1978,  0.1846,  0.1818,  0.1987,  0.1612,  0.1800,\n",
              "                       0.1914,  0.2040,  0.1895,  0.1889,  0.1784,  0.1842,  0.2005,  0.1922,\n",
              "                       0.1957,  0.1837,  0.2035,  0.2111,  0.1704,  0.1981,  0.1717,  0.1843,\n",
              "                       0.1795,  0.1927,  0.1520, -0.0881,  0.1808,  0.1782,  0.1864,  0.1799,\n",
              "                       0.1892,  0.1640,  0.1923,  0.2092,  0.2170,  0.1357,  0.2010,  0.1949,\n",
              "                       0.1870,  0.0791,  0.1698,  0.0356,  0.1948,  0.1932,  0.1931,  0.1979,\n",
              "                       0.1855,  0.2091,  0.1837,  0.1697,  0.1943,  0.1892,  0.1893,  0.2160,\n",
              "                       0.1608,  0.2010,  0.1788,  0.0578,  0.1963,  0.1949,  0.1857,  0.1629,\n",
              "                       0.1797,  0.1923,  0.1885,  0.1936,  0.1933,  0.1896,  0.1875,  0.1795,\n",
              "                       0.1776,  0.1902,  0.1844,  0.1790,  0.1874,  0.1769,  0.1821,  0.1984,\n",
              "                       0.1794,  0.1853,  0.1633,  0.1516,  0.1330,  0.1943,  0.1786,  0.1980,\n",
              "                       0.1574,  0.1872,  0.1884,  0.1992,  0.1927,  0.2020,  0.1603,  0.1753,\n",
              "                       0.1536,  0.2021,  0.1886,  0.1382,  0.1570,  0.1838,  0.1874,  0.1561,\n",
              "                       0.1854,  0.2002,  0.1933,  0.2051,  0.1708,  0.1884,  0.1966,  0.2031,\n",
              "                       0.1668,  0.2048,  0.1500,  0.1733,  0.1794,  0.1960,  0.1907,  0.1834,\n",
              "                       0.1828,  0.1506,  0.1058,  0.1876,  0.1886,  0.1593,  0.1827,  0.2013,\n",
              "                       0.2037,  0.1936,  0.1928,  0.1890,  0.1778,  0.1896,  0.1131,  0.2071,\n",
              "                       0.1585,  0.0317,  0.1823,  0.2081,  0.2014,  0.1449,  0.2029,  0.1848,\n",
              "                       0.1996,  0.1881,  0.1789,  0.1946,  0.2131,  0.1377,  0.1914,  0.1779,\n",
              "                       0.1668,  0.1514,  0.1870,  0.1902,  0.1804,  0.1909,  0.2049,  0.1816,\n",
              "                       0.1677,  0.1964,  0.1778,  0.1940,  0.2032,  0.1892,  0.2014,  0.1874,\n",
              "                       0.1876,  0.1768,  0.1985,  0.1975,  0.2052,  0.1738,  0.1924,  0.1980,\n",
              "                       0.1899,  0.1409,  0.1752,  0.1877,  0.1557,  0.1872,  0.1911,  0.1818,\n",
              "                       0.1827,  0.1813,  0.1682,  0.1920,  0.1826,  0.1990,  0.1856,  0.1987,\n",
              "                       0.1982,  0.1991,  0.1894,  0.1484,  0.1764,  0.1730,  0.1950,  0.1846,\n",
              "                       0.1760,  0.1903,  0.1912,  0.2061,  0.1811,  0.2155,  0.1932,  0.1757,\n",
              "                       0.1935,  0.1885,  0.1669,  0.1886,  0.1672,  0.1413,  0.1948,  0.1960,\n",
              "                       0.1954,  0.2006,  0.1763,  0.2029,  0.1854,  0.1704,  0.2116,  0.1543,\n",
              "                       0.1922,  0.1655,  0.1893,  0.1467,  0.1962,  0.1856,  0.0949,  0.1795,\n",
              "                       0.1755,  0.1853,  0.1786,  0.2063,  0.0704,  0.1661,  0.1991,  0.1858,\n",
              "                       0.1495,  0.1769,  0.1727,  0.1471,  0.1948,  0.1957,  0.2180,  0.1824,\n",
              "                       0.1797,  0.0899,  0.1822,  0.1158,  0.1729,  0.1797,  0.1863,  0.0661,\n",
              "                       0.1809,  0.1942,  0.1835,  0.1869,  0.1994,  0.1940,  0.1908,  0.1854,\n",
              "                       0.1872,  0.0474,  0.1953,  0.2135,  0.1811,  0.1903,  0.1869,  0.1821,\n",
              "                       0.1854,  0.1803,  0.1905,  0.1902,  0.1851,  0.1804,  0.1827,  0.1768,\n",
              "                       0.1712,  0.1735,  0.0669,  0.1986,  0.1583,  0.1805,  0.1737,  0.0722,\n",
              "                       0.1869,  0.2000,  0.1857,  0.1828,  0.1926,  0.1911,  0.1878,  0.1994,\n",
              "                       0.1321,  0.1695,  0.1607,  0.1789,  0.1757,  0.1834,  0.1767,  0.1862,\n",
              "                       0.1927,  0.1614,  0.1978,  0.1978,  0.1737,  0.1879,  0.1819,  0.2049,\n",
              "                       0.1748,  0.2012,  0.1904,  0.1935,  0.1920,  0.2019,  0.2164,  0.1809,\n",
              "                       0.1806,  0.1820,  0.1694,  0.1852,  0.1945,  0.1852,  0.1983,  0.1987,\n",
              "                       0.1897,  0.1856,  0.1559,  0.1914,  0.1642,  0.1968,  0.1685,  0.1850,\n",
              "                       0.1634,  0.1926,  0.2109,  0.2040,  0.2012,  0.1766,  0.0674,  0.1877,\n",
              "                       0.1865,  0.1220,  0.1819,  0.1857,  0.2058,  0.1938,  0.1711,  0.1677,\n",
              "                       0.1854,  0.2036,  0.2058,  0.1830,  0.1086,  0.2270,  0.1744,  0.1860,\n",
              "                       0.1769,  0.1993,  0.1800,  0.1749,  0.1848,  0.1916,  0.1683,  0.0557,\n",
              "                       0.1898,  0.1888,  0.2079,  0.1940,  0.1920,  0.2061,  0.2067,  0.2088,\n",
              "                       0.1298,  0.2000,  0.1812,  0.2021,  0.1746,  0.1617,  0.1631,  0.1913,\n",
              "                       0.1889,  0.1717,  0.1720,  0.1737,  0.2042,  0.1586,  0.2047,  0.1606,\n",
              "                       0.1761,  0.1829,  0.1841,  0.2019,  0.1896,  0.1986,  0.1731,  0.1847,\n",
              "                       0.1823,  0.1821,  0.1787,  0.1953,  0.1878,  0.1790,  0.1914,  0.1924,\n",
              "                       0.1938,  0.1953,  0.2015,  0.1915,  0.1882,  0.0685,  0.1668,  0.1889,\n",
              "                       0.1783,  0.2215,  0.1867,  0.2033,  0.1709,  0.1854,  0.1833,  0.1253,\n",
              "                       0.1720,  0.1816,  0.1954,  0.1738,  0.1955,  0.1998,  0.0401,  0.1727,\n",
              "                       0.1882,  0.1865,  0.1930,  0.1006,  0.1927,  0.1742,  0.1917,  0.1827,\n",
              "                       0.1884,  0.1906,  0.1936,  0.1680,  0.1890,  0.1920,  0.2220,  0.1795,\n",
              "                       0.1921,  0.1814,  0.1901,  0.1878,  0.1758,  0.1866,  0.2010,  0.1796,\n",
              "                       0.1917,  0.1963,  0.1914,  0.2060,  0.1872,  0.1823,  0.1913,  0.1852,\n",
              "                       0.1936,  0.2021,  0.1962,  0.1254,  0.2175,  0.1823,  0.1699,  0.1728,\n",
              "                       0.1629,  0.1853,  0.1984,  0.1795,  0.1790,  0.1869,  0.1780,  0.1904,\n",
              "                       0.1791,  0.2044,  0.1855,  0.1774,  0.1877,  0.1751,  0.1859,  0.1941,\n",
              "                       0.1928,  0.1788,  0.1813,  0.1616,  0.1917,  0.1266,  0.1866,  0.1825,\n",
              "                       0.1786,  0.1995,  0.2031,  0.1268,  0.1950,  0.1679,  0.2116,  0.1873,\n",
              "                       0.1646,  0.2000,  0.1710,  0.1808,  0.1917,  0.1957,  0.1694,  0.2034,\n",
              "                       0.1910,  0.1811,  0.1694,  0.1853,  0.1987,  0.1784,  0.1581,  0.1695,\n",
              "                       0.1960,  0.1574,  0.1862,  0.1725,  0.1263,  0.0279,  0.1807,  0.1948,\n",
              "                       0.1680,  0.1651,  0.1779,  0.2002,  0.2104,  0.1896,  0.1907,  0.1547,\n",
              "                       0.1879,  0.1883,  0.1996,  0.1739,  0.1844,  0.1764,  0.1697,  0.2056,\n",
              "                       0.1933,  0.1886,  0.1868,  0.1809,  0.2026,  0.1331,  0.1667,  0.2042,\n",
              "                       0.1941,  0.1985,  0.1951,  0.1870,  0.1403,  0.1881,  0.1973,  0.1842,\n",
              "                       0.2076,  0.1861,  0.1920,  0.2019,  0.1764,  0.1522,  0.1892,  0.1783,\n",
              "                       0.1966,  0.1815,  0.1869,  0.1748,  0.2095,  0.1950,  0.0830,  0.2025,\n",
              "                       0.1843,  0.1895,  0.0816,  0.1892,  0.1613,  0.1868,  0.1861,  0.1713,\n",
              "                       0.1951,  0.1476,  0.1777,  0.1838,  0.1745,  0.1808,  0.1924,  0.1591,\n",
              "                       0.1939,  0.1869,  0.1902,  0.1838,  0.1848,  0.1619,  0.1910,  0.1899,\n",
              "                       0.1880,  0.1927,  0.1991,  0.2008,  0.1899,  0.1835,  0.1923,  0.1981,\n",
              "                       0.2053,  0.1899,  0.2013,  0.1832,  0.2093,  0.2018,  0.1715,  0.1862,\n",
              "                       0.1936,  0.1765,  0.1857,  0.1993,  0.2053,  0.1898,  0.2023,  0.2309,\n",
              "                       0.1749,  0.1900,  0.1877,  0.1761,  0.1929,  0.1817,  0.1785,  0.2063],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.9.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.3228, -0.2138,  0.3389,  ...,  0.0835, -0.4850, -0.3795],\n",
              "                      [ 1.1348, -0.1946, -0.8707,  ...,  0.8381, -0.0879,  1.8041],\n",
              "                      [ 0.8630, -0.1978, -0.0076,  ...,  0.4488,  0.2854, -0.0365],\n",
              "                      ...,\n",
              "                      [ 1.4605, -0.1160,  0.3672,  ...,  0.5562, -0.3444,  0.7192],\n",
              "                      [-0.0064, -0.8303, -0.3645,  ..., -0.6652, -0.2285, -0.1048],\n",
              "                      [-0.4647, -0.3131, -0.1428,  ..., -0.6384,  0.0359, -0.3247]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.9.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.2031,  0.3678, -0.4048,  ...,  0.4830, -0.5665,  0.0904],\n",
              "                      [-0.3870, -0.3096, -0.1317,  ...,  0.1435, -0.4293, -0.2867],\n",
              "                      [ 0.1095,  0.1344, -0.3248,  ...,  0.0730, -0.3794,  0.1684],\n",
              "                      ...,\n",
              "                      [ 0.3672,  0.2861, -0.7127,  ..., -0.0494, -0.0873,  0.2372],\n",
              "                      [ 0.0460, -0.2002, -0.0236,  ..., -0.1246,  0.3050,  0.1711],\n",
              "                      [-0.1102,  0.0785,  0.2166,  ..., -0.1059, -0.2783,  0.0930]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.9.layer.1.layer_norm.weight',\n",
              "              tensor([1.3052, 1.1846, 1.1546, 1.2523, 1.3735, 1.3277, 0.3353, 1.3370, 1.5298,\n",
              "                      1.3929, 1.1784, 1.1635, 1.2559, 1.2881, 1.3466, 1.3328, 1.2554, 1.2898,\n",
              "                      0.8765, 1.3325, 1.3799, 1.3555, 3.5829, 1.2613, 1.4033, 1.2851, 1.3565,\n",
              "                      1.2151, 1.3741, 1.3152, 1.3381, 1.2844, 1.3555, 1.3162, 1.2128, 1.3448,\n",
              "                      1.3780, 1.2689, 1.3277, 1.7601, 1.2183, 1.3174, 0.9058, 1.3325, 3.1922,\n",
              "                      1.3875, 1.1240, 1.3085, 1.3053, 0.5023, 1.2455, 1.3094, 1.4848, 1.3267,\n",
              "                      1.3068, 1.2405, 2.9010, 1.3207, 1.4244, 1.4213, 1.3117, 1.4029, 1.3577,\n",
              "                      1.3128, 1.3898, 1.2251, 1.3491, 1.3245, 1.3268, 1.3008, 1.3438, 0.9912,\n",
              "                      1.3150, 1.3716, 1.3397, 1.3974, 1.3150, 1.2578, 1.3157, 1.3626, 1.2890,\n",
              "                      1.2639, 1.3384, 1.2691, 1.3350, 1.3365, 1.2323, 1.3300, 1.3226, 1.3176,\n",
              "                      1.3913, 1.3309, 1.2890, 1.3496, 1.4737, 1.3538, 1.3573, 1.3185, 1.3413,\n",
              "                      1.3755, 1.2495, 1.2707, 0.7913, 1.3127, 1.2937, 1.5878, 1.3833, 1.4137,\n",
              "                      1.3351, 2.2413, 1.3053, 1.3875, 1.2490, 1.3470, 1.3123, 1.3900, 1.2939,\n",
              "                      1.2961, 1.1318, 1.3604, 1.4506, 1.2849, 1.3537, 1.3533, 0.9039, 1.3108,\n",
              "                      1.3923, 1.2457, 1.2857, 1.3467, 1.3132, 1.2743, 1.3725, 1.3969, 1.3095,\n",
              "                      1.0320, 1.4784, 1.3435, 1.2887, 1.1807, 1.2296, 1.2226, 1.1129, 1.3989,\n",
              "                      1.2202, 1.3530, 1.3467, 1.2745, 1.3208, 1.3106, 1.3468, 1.2374, 1.2285,\n",
              "                      1.3051, 1.3555, 1.4168, 1.2798, 1.4164, 1.2291, 1.2410, 1.4061, 1.3327,\n",
              "                      1.2041, 4.2865, 1.4084, 1.1901, 1.3173, 1.2152, 1.1558, 0.9951, 1.2091,\n",
              "                      1.3086, 1.3606, 1.1680, 1.3716, 1.2838, 1.3296, 0.4275, 1.1537, 0.4721,\n",
              "                      1.4098, 1.3923, 1.3061, 1.3899, 1.2867, 1.3076, 1.2978, 1.1606, 1.3034,\n",
              "                      1.2954, 1.3463, 1.4367, 1.4665, 1.2886, 1.3419, 0.5196, 1.2991, 1.3118,\n",
              "                      1.3071, 1.3665, 1.3918, 1.2894, 1.3482, 1.3299, 1.2965, 1.2568, 1.3420,\n",
              "                      1.2376, 1.3841, 1.3414, 1.3322, 1.2475, 1.2294, 1.3984, 1.3465, 1.3095,\n",
              "                      1.2438, 1.2870, 1.2353, 1.4755, 1.1396, 1.3106, 1.3168, 1.2303, 1.3171,\n",
              "                      1.3305, 1.2962, 0.9582, 1.3264, 1.3102, 1.2702, 1.3008, 1.2851, 1.4316,\n",
              "                      1.2788, 1.2228, 1.3450, 1.3338, 1.1317, 0.8707, 1.3034, 1.3298, 1.3931,\n",
              "                      1.3360, 1.2764, 1.2638, 1.3093, 1.3440, 1.4099, 1.3255, 2.7599, 1.3150,\n",
              "                      1.3897, 1.4482, 1.3841, 1.3770, 1.3957, 1.2012, 0.6104, 1.2908, 1.1631,\n",
              "                      0.9081, 1.3062, 1.3969, 1.3854, 1.3554, 1.3341, 1.2720, 1.3350, 1.3150,\n",
              "                      1.3559, 1.2966, 1.3839, 1.1267, 1.2070, 1.3475, 1.3304, 0.9214, 1.3486,\n",
              "                      1.2413, 1.2955, 1.3052, 1.3579, 1.3316, 1.3092, 1.0719, 1.4171, 1.4095,\n",
              "                      1.1545, 1.7775, 1.4589, 1.3264, 1.3556, 1.3627, 1.4005, 1.5076, 1.1874,\n",
              "                      1.3922, 1.3636, 1.3029, 1.3118, 1.2993, 1.0931, 1.2189, 1.2413, 1.3729,\n",
              "                      1.2666, 1.2932, 1.2674, 1.2950, 1.3648, 1.3220, 1.3548, 1.2069, 1.3673,\n",
              "                      1.2940, 1.2757, 1.3025, 1.4268, 1.2816, 1.3647, 1.2290, 1.2771, 1.4728,\n",
              "                      1.2472, 1.3947, 1.0757, 1.2454, 1.1934, 1.3839, 1.3698, 1.1175, 1.2468,\n",
              "                      1.2449, 1.3523, 1.3345, 1.3308, 1.2788, 1.2816, 1.3200, 1.3019, 1.3468,\n",
              "                      1.3885, 1.4538, 1.2956, 1.3208, 1.0516, 1.2627, 1.0554, 2.0893, 1.1901,\n",
              "                      1.3318, 1.4085, 1.3284, 1.1723, 1.3378, 1.2638, 1.2237, 1.4021, 1.1406,\n",
              "                      1.2982, 1.1860, 1.1679, 1.3303, 1.3992, 1.2751, 0.7161, 1.3913, 1.3687,\n",
              "                      1.3607, 1.4970, 1.2598, 0.5219, 1.2691, 1.2734, 1.3844, 1.1013, 1.3024,\n",
              "                      0.9921, 1.2413, 1.3198, 1.2445, 1.2481, 1.3270, 1.3156, 1.0767, 1.3418,\n",
              "                      0.7421, 1.3532, 1.3061, 1.3505, 2.9140, 1.2785, 1.2421, 1.2648, 1.3611,\n",
              "                      1.3042, 1.3742, 1.2567, 1.3525, 1.2968, 0.9489, 1.3517, 1.3400, 1.3320,\n",
              "                      1.3678, 1.3680, 1.3774, 1.3603, 1.3526, 1.3050, 1.3583, 1.3649, 1.3207,\n",
              "                      1.3772, 1.2561, 1.4013, 1.3363, 0.6035, 1.4813, 1.1505, 1.3837, 1.3868,\n",
              "                      0.4950, 1.3581, 1.3986, 1.2342, 1.4227, 1.3513, 1.2127, 1.3834, 1.4428,\n",
              "                      0.8086, 1.3461, 1.2323, 1.3411, 1.3327, 1.3449, 1.0118, 1.2386, 1.3272,\n",
              "                      1.1373, 1.3228, 1.0710, 1.3048, 1.2493, 1.3486, 1.2958, 1.1500, 1.2926,\n",
              "                      1.2646, 1.3383, 1.3144, 1.3420, 1.4261, 1.2446, 1.3004, 1.2846, 1.2674,\n",
              "                      1.3795, 1.3753, 1.3328, 1.3515, 1.2586, 1.2625, 1.3499, 1.2436, 1.3071,\n",
              "                      1.2950, 1.3623, 1.3729, 1.3592, 1.2393, 1.3297, 1.3266, 1.3891, 1.3885,\n",
              "                      1.3661, 0.9454, 1.2343, 1.2210, 1.9561, 1.4258, 1.4079, 1.2559, 1.3685,\n",
              "                      1.3682, 1.4007, 1.3044, 1.3277, 1.2986, 1.3760, 1.7788, 1.3905, 1.3161,\n",
              "                      1.2792, 1.2763, 1.2663, 1.2707, 1.3895, 1.3384, 1.2774, 1.3461, 2.1157,\n",
              "                      1.4523, 1.2723, 1.3356, 1.1338, 1.4149, 1.2992, 1.2655, 1.3672, 2.0646,\n",
              "                      1.4156, 1.2894, 1.3266, 1.2760, 1.2953, 0.9429, 1.3694, 1.3795, 1.3494,\n",
              "                      1.3994, 1.2892, 1.2845, 2.0177, 1.2205, 1.0517, 1.3186, 1.2810, 1.1613,\n",
              "                      1.3157, 1.3049, 1.2670, 1.2735, 1.2127, 1.2059, 1.3074, 1.2097, 1.2438,\n",
              "                      1.2680, 1.2431, 1.2331, 1.2360, 1.3962, 1.3777, 1.2770, 1.3251, 1.3641,\n",
              "                      0.4425, 1.1594, 1.2591, 1.4160, 1.4402, 1.3482, 1.3208, 1.2241, 1.3387,\n",
              "                      1.2569, 0.9920, 1.3660, 1.3624, 1.2561, 1.2681, 1.3350, 1.3034, 0.5301,\n",
              "                      1.2743, 1.2811, 1.4042, 1.2676, 0.5748, 1.3676, 1.3289, 1.3203, 1.2377,\n",
              "                      1.3170, 1.2401, 1.3153, 0.9894, 1.3665, 1.4938, 1.3780, 1.3436, 1.3712,\n",
              "                      1.3733, 1.3531, 1.3192, 1.3680, 1.3494, 1.3619, 1.2340, 1.3241, 1.3691,\n",
              "                      1.2626, 1.3160, 1.2663, 1.3720, 1.1668, 1.2890, 1.3351, 1.2906, 1.3021,\n",
              "                      0.9649, 1.2895, 1.3515, 1.3203, 1.2259, 1.2630, 1.3454, 1.2712, 1.3824,\n",
              "                      1.2997, 1.3702, 1.3114, 1.2762, 1.3914, 1.1941, 1.3568, 1.3111, 1.3160,\n",
              "                      1.3409, 1.3535, 1.1768, 1.2923, 1.3010, 1.2621, 1.1847, 1.3017, 1.0674,\n",
              "                      1.2957, 1.3484, 1.3323, 1.2878, 1.3542, 0.5999, 1.3638, 1.2840, 1.2612,\n",
              "                      1.2464, 1.1780, 1.3437, 1.3072, 1.4290, 1.3098, 1.1803, 1.1362, 1.3380,\n",
              "                      1.3317, 1.3675, 1.2838, 1.3462, 1.2905, 1.3137, 1.1505, 0.9643, 1.2899,\n",
              "                      1.1596, 0.9380, 1.2453, 0.7641, 0.5584, 1.2736, 1.2967, 1.2849, 1.2737,\n",
              "                      1.3251, 1.3732, 1.2361, 1.3748, 1.3744, 1.5105, 1.3375, 1.3363, 1.2846,\n",
              "                      1.4004, 1.3156, 1.3082, 1.3506, 1.3664, 1.3214, 1.3186, 1.2745, 1.2684,\n",
              "                      1.2667, 1.6213, 1.2867, 1.3153, 1.4093, 1.2433, 1.4285, 1.2843, 0.9710,\n",
              "                      1.3229, 1.3669, 1.3295, 1.2792, 1.3439, 1.3031, 1.2208, 1.3387, 1.3671,\n",
              "                      1.3398, 1.3497, 1.3650, 1.4300, 1.3013, 1.3119, 1.1953, 1.2890, 1.9098,\n",
              "                      1.3659, 1.2798, 1.3805, 0.5405, 1.2574, 1.3237, 1.2381, 1.2673, 0.9099,\n",
              "                      1.3549, 1.2944, 1.2721, 1.3872, 1.2791, 1.2143, 1.2239, 1.3510, 1.4452,\n",
              "                      1.2368, 1.1766, 1.4028, 1.3248, 1.2190, 1.3552, 1.3687, 1.3846, 1.3129,\n",
              "                      1.2807, 1.3596, 1.3181, 1.2715, 1.1904, 1.2180, 1.2989, 1.2429, 1.1826,\n",
              "                      1.4218, 1.2682, 1.2624, 1.3124, 1.3618, 1.3286, 1.2531, 1.2445, 1.3634,\n",
              "                      1.2244, 1.3478, 1.2742, 1.2958, 1.2450, 1.2463, 1.2998, 1.4209, 1.1631,\n",
              "                      1.2180, 1.3666, 1.3276], device='cuda:0')),\n",
              "             ('encoder.block.10.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0432, -0.0160,  0.0178,  ...,  0.0963,  0.0551,  0.0127],\n",
              "                      [-0.0306, -0.0045, -0.0369,  ...,  0.0382,  0.0354,  0.0085],\n",
              "                      [ 0.0488,  0.0016, -0.0187,  ...,  0.0342,  0.0643,  0.0125],\n",
              "                      ...,\n",
              "                      [-0.0161, -0.0465,  0.0447,  ...,  0.0291, -0.0025,  0.0063],\n",
              "                      [-0.0317,  0.0747,  0.0049,  ...,  0.0488, -0.0352, -0.0185],\n",
              "                      [ 0.0080,  0.0069,  0.0611,  ...,  0.0062, -0.0202, -0.0292]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.10.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.0482,  0.0328,  0.1193,  ..., -0.1144, -0.3570, -0.0273],\n",
              "                      [ 0.1065, -0.3180, -0.0438,  ...,  0.2269, -0.4486,  0.1510],\n",
              "                      [ 0.0996,  0.4512,  0.4642,  ..., -0.2909, -0.2398, -0.1054],\n",
              "                      ...,\n",
              "                      [ 0.0608, -0.3596,  0.2962,  ..., -0.0158, -0.1661,  0.1146],\n",
              "                      [-0.1737, -0.0971, -0.2956,  ...,  0.2162, -0.0117, -0.2446],\n",
              "                      [ 0.1512, -0.4068,  0.2370,  ..., -0.0712,  0.1539, -0.0459]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.10.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.5846, -0.1572, -0.2299,  ..., -0.2609,  0.3869,  0.2693],\n",
              "                      [-0.4934,  0.2464, -0.4822,  ..., -0.4875,  1.4994,  0.4703],\n",
              "                      [-0.3403,  0.1945,  0.0302,  ...,  0.2877, -0.4311, -0.1228],\n",
              "                      ...,\n",
              "                      [ 0.7396,  0.9862,  0.3215,  ...,  0.8271, -0.4035, -0.1825],\n",
              "                      [-0.4588, -0.4218,  0.5380,  ..., -0.2352,  0.4002,  1.1174],\n",
              "                      [-0.6532,  0.1909,  0.2061,  ...,  0.2932, -1.5069,  0.3934]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.10.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.3146,  0.3829,  0.6198,  ..., -0.2094,  1.9722,  0.2639],\n",
              "                      [ 0.5339,  1.1361,  0.7076,  ..., -0.8329,  0.2854, -0.0469],\n",
              "                      [ 0.9169,  0.6010, -0.9060,  ..., -1.0176, -0.5870, -1.7089],\n",
              "                      ...,\n",
              "                      [ 0.0091,  1.7143, -0.0788,  ...,  0.1885, -0.2324, -0.7122],\n",
              "                      [ 0.6204, -0.5609,  0.6247,  ...,  0.3250,  0.6845,  1.4462],\n",
              "                      [-0.4154, -1.5974,  0.1854,  ..., -0.2040, -0.8288, -1.3036]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.10.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2055,  0.1895,  0.1861,  0.2077,  0.2039,  0.1864,  0.0396,  0.2005,\n",
              "                       0.0913,  0.2002,  0.1899,  0.2052,  0.1615,  0.1753,  0.1621,  0.2047,\n",
              "                       0.1877,  0.1929,  0.1498,  0.1954,  0.1909,  0.2037,  0.0530,  0.1941,\n",
              "                       0.1924,  0.2108,  0.1962,  0.1859,  0.1919,  0.2017,  0.1916,  0.1987,\n",
              "                       0.2114,  0.1847,  0.1670,  0.1874,  0.1498,  0.1930,  0.1700,  0.1495,\n",
              "                       0.1951,  0.1611,  0.1541,  0.2015,  0.1042,  0.1947,  0.1584,  0.2033,\n",
              "                       0.2035,  0.0537,  0.1866,  0.1889,  0.1643,  0.1883, -0.0013,  0.1858,\n",
              "                       0.1400,  0.2031,  0.2375,  0.1970,  0.2055,  0.1774,  0.1965,  0.1940,\n",
              "                       0.1860,  0.0433,  0.1910,  0.1903,  0.1959,  0.1869,  0.1977,  0.1287,\n",
              "                       0.1940,  0.1990,  0.1962,  0.1877,  0.1343,  0.2112,  0.1844,  0.2167,\n",
              "                       0.2036,  0.1957,  0.2144,  0.2220,  0.1942,  0.2055,  0.1964,  0.2007,\n",
              "                       0.2093,  0.1916,  0.2095,  0.1927,  0.1868,  0.1781,  0.1952,  0.1980,\n",
              "                       0.1984,  0.1940,  0.2099,  0.1576,  0.1834,  0.2067,  0.1295,  0.1901,\n",
              "                       0.1921,  0.1502,  0.1938,  0.1868,  0.1976,  0.0960,  0.1877,  0.2103,\n",
              "                       0.1931,  0.1608,  0.2147,  0.2040,  0.2024,  0.1908,  0.1348,  0.1809,\n",
              "                       0.1857,  0.2133,  0.1775,  0.1831,  0.1430,  0.1997,  0.2245,  0.2016,\n",
              "                       0.1917,  0.1935,  0.1104,  0.2137,  0.1929,  0.1715,  0.1939,  0.1541,\n",
              "                       0.2057,  0.1864,  0.1824,  0.1973,  0.1977,  0.2007,  0.1690,  0.1877,\n",
              "                       0.1910,  0.2024,  0.1961,  0.1873,  0.1888,  0.2175,  0.1995,  0.1898,\n",
              "                       0.2039,  0.1985,  0.1872,  0.1971,  0.1733,  0.1823,  0.1663,  0.1794,\n",
              "                       0.1915,  0.1892,  0.1532,  0.0797,  0.1706,  0.1673,  0.2056,  0.1655,\n",
              "                       0.1911,  0.1287,  0.1848,  0.2299,  0.2172,  0.1351,  0.2096,  0.1801,\n",
              "                       0.2009,  0.0634,  0.1883,  0.0266,  0.1885,  0.2004,  0.1930,  0.2114,\n",
              "                       0.1972,  0.2053,  0.1867,  0.1833,  0.1895,  0.2090,  0.2006,  0.2093,\n",
              "                       0.1663,  0.2167,  0.1870,  0.0610,  0.1910,  0.1952,  0.1860,  0.1686,\n",
              "                       0.1914,  0.1943,  0.1949,  0.1929,  0.1933,  0.1787,  0.1869,  0.1885,\n",
              "                       0.1873,  0.2076,  0.1946,  0.1690,  0.2008,  0.1941,  0.2137,  0.2041,\n",
              "                       0.2012,  0.1999,  0.1887,  0.1058,  0.1391,  0.2076,  0.1938,  0.2078,\n",
              "                       0.1525,  0.2083,  0.1983,  0.1518,  0.2012,  0.2120,  0.1773,  0.1958,\n",
              "                       0.1591,  0.1721,  0.1984,  0.1499,  0.1718,  0.1949,  0.1808,  0.1180,\n",
              "                       0.1707,  0.2229,  0.2182,  0.1925,  0.1774,  0.1862,  0.1997,  0.2149,\n",
              "                       0.1935,  0.1826,  0.1262,  0.1909,  0.1821,  0.1945,  0.1922,  0.1871,\n",
              "                       0.1946,  0.1762,  0.0923,  0.1981,  0.1942,  0.1609,  0.1802,  0.1983,\n",
              "                       0.2053,  0.1896,  0.1990,  0.1773,  0.1859,  0.1787,  0.1050,  0.2050,\n",
              "                       0.1445,  0.0207,  0.1911,  0.2055,  0.2100,  0.1313,  0.2128,  0.1847,\n",
              "                       0.2018,  0.1893,  0.2031,  0.1866,  0.2083,  0.1302,  0.1953,  0.1992,\n",
              "                       0.1725,  0.1249,  0.1817,  0.1818,  0.1894,  0.2003,  0.1957,  0.1926,\n",
              "                       0.1853,  0.2144,  0.1841,  0.2015,  0.2115,  0.2087,  0.1930,  0.1716,\n",
              "                       0.1999,  0.1859,  0.2117,  0.2290,  0.2183,  0.1790,  0.2147,  0.2175,\n",
              "                       0.1996,  0.1525,  0.2038,  0.2024,  0.1744,  0.1864,  0.1841,  0.1993,\n",
              "                       0.1805,  0.1843,  0.1747,  0.1819,  0.1894,  0.2030,  0.1768,  0.1937,\n",
              "                       0.2073,  0.2107,  0.2010,  0.1244,  0.1756,  0.1788,  0.2100,  0.1999,\n",
              "                       0.1720,  0.1911,  0.2134,  0.1910,  0.2170,  0.2271,  0.2087,  0.1845,\n",
              "                       0.1952,  0.1946,  0.1713,  0.1963,  0.1460,  0.1265,  0.2054,  0.1995,\n",
              "                       0.2171,  0.1915,  0.1782,  0.1984,  0.1984,  0.1918,  0.2039,  0.1424,\n",
              "                       0.1940,  0.1818,  0.1699,  0.1718,  0.2002,  0.1870,  0.0825,  0.1907,\n",
              "                       0.1853,  0.1891,  0.1787,  0.1987,  0.0631,  0.1908,  0.2029,  0.1816,\n",
              "                       0.1393,  0.1976,  0.1500,  0.1567,  0.2036,  0.1922,  0.1855,  0.1871,\n",
              "                       0.2017,  0.0828,  0.2004,  0.1056,  0.1951,  0.1773,  0.1917,  0.0515,\n",
              "                       0.1920,  0.1953,  0.2003,  0.1950,  0.2035,  0.1978,  0.2002,  0.1833,\n",
              "                       0.2024,  0.0483,  0.1958,  0.2168,  0.2038,  0.2062,  0.1928,  0.2044,\n",
              "                       0.1970,  0.1743,  0.1982,  0.1883,  0.1722,  0.1887,  0.2044,  0.1989,\n",
              "                       0.1762,  0.1680,  0.0633,  0.1912,  0.1591,  0.2059,  0.1983,  0.0659,\n",
              "                       0.1798,  0.2191,  0.1883,  0.1967,  0.1996,  0.2028,  0.1834,  0.2079,\n",
              "                       0.1099,  0.2009,  0.1601,  0.1658,  0.1950,  0.1948,  0.1776,  0.2021,\n",
              "                       0.2057,  0.1741,  0.1911,  0.1539,  0.2006,  0.2046,  0.1865,  0.2076,\n",
              "                       0.1850,  0.1960,  0.1792,  0.2087,  0.2154,  0.1907,  0.1961,  0.2023,\n",
              "                       0.1901,  0.1967,  0.1885,  0.1824,  0.2002,  0.1847,  0.1962,  0.2091,\n",
              "                       0.2066,  0.1888,  0.1519,  0.1903,  0.1757,  0.2097,  0.1843,  0.1900,\n",
              "                       0.1837,  0.1862,  0.1960,  0.2191,  0.2099,  0.1902,  0.0486,  0.1975,\n",
              "                       0.2009,  0.0991,  0.2094,  0.2114,  0.1989,  0.1920,  0.1817,  0.1518,\n",
              "                       0.1917,  0.2005,  0.2077,  0.1991,  0.0914,  0.2128,  0.1721,  0.1998,\n",
              "                       0.2006,  0.1979,  0.1977,  0.1720,  0.1708,  0.1999,  0.1725,  0.0408,\n",
              "                       0.1913,  0.1998,  0.2141,  0.1999,  0.1865,  0.2028,  0.2156,  0.1932,\n",
              "                       0.1157,  0.2126,  0.2069,  0.1994,  0.1938,  0.1782,  0.1466,  0.1995,\n",
              "                       0.1817,  0.1796,  0.1885,  0.1849,  0.2090,  0.1277,  0.1895,  0.1440,\n",
              "                       0.1887,  0.2029,  0.1787,  0.1956,  0.2067,  0.1828,  0.1784,  0.1915,\n",
              "                       0.1919,  0.1838,  0.1757,  0.1985,  0.1916,  0.1935,  0.1862,  0.1755,\n",
              "                       0.1910,  0.2074,  0.2087,  0.1953,  0.1825,  0.0663,  0.1632,  0.1901,\n",
              "                       0.1781,  0.2098,  0.2044,  0.2133,  0.1853,  0.1910,  0.2069,  0.1305,\n",
              "                       0.1929,  0.1691,  0.1769,  0.1770,  0.2122,  0.2024,  0.0271,  0.1751,\n",
              "                       0.1873,  0.1976,  0.1910,  0.1052,  0.1880,  0.2033,  0.1989,  0.1996,\n",
              "                       0.2001,  0.2031,  0.1901,  0.1554,  0.2044,  0.2068,  0.2022,  0.1882,\n",
              "                       0.1840,  0.1795,  0.1747,  0.1920,  0.2003,  0.1820,  0.2065,  0.1908,\n",
              "                       0.1975,  0.2110,  0.1967,  0.2177,  0.1737,  0.1808,  0.1441,  0.1973,\n",
              "                       0.2214,  0.2109,  0.2077,  0.1219,  0.2189,  0.1827,  0.1795,  0.1957,\n",
              "                       0.1692,  0.2088,  0.1996,  0.2069,  0.1954,  0.2107,  0.1940,  0.1885,\n",
              "                       0.1749,  0.1928,  0.2105,  0.1822,  0.2142,  0.1829,  0.1955,  0.2007,\n",
              "                       0.2139,  0.1859,  0.1822,  0.1625,  0.1857,  0.1211,  0.2027,  0.1888,\n",
              "                       0.1792,  0.2073,  0.1865,  0.1096,  0.1997,  0.1955,  0.2011,  0.2022,\n",
              "                       0.1694,  0.2115,  0.1747,  0.1839,  0.1986,  0.2069,  0.1895,  0.2013,\n",
              "                       0.1869,  0.1864,  0.1784,  0.2001,  0.1961,  0.1771,  0.1836,  0.1702,\n",
              "                       0.2035,  0.1833,  0.1729,  0.1776,  0.1175,  0.0209,  0.1761,  0.2066,\n",
              "                       0.1897,  0.1803,  0.1859,  0.1905,  0.2169,  0.1925,  0.2158,  0.1478,\n",
              "                       0.1798,  0.1791,  0.2141,  0.2039,  0.1963,  0.1861,  0.1819,  0.2011,\n",
              "                       0.1920,  0.1928,  0.1860,  0.1779,  0.2010,  0.1273,  0.1791,  0.2023,\n",
              "                       0.2118,  0.2105,  0.1921,  0.1841,  0.1294,  0.1770,  0.1934,  0.1956,\n",
              "                       0.2061,  0.1902,  0.2139,  0.1954,  0.1777,  0.1850,  0.1837,  0.1973,\n",
              "                       0.1921,  0.2010,  0.1957,  0.1647,  0.1955,  0.2018,  0.0369,  0.1812,\n",
              "                       0.2116,  0.2026,  0.0790,  0.1928,  0.1788,  0.1986,  0.1976,  0.1509,\n",
              "                       0.2018,  0.1496,  0.1807,  0.1921,  0.2028,  0.2035,  0.1989,  0.1623,\n",
              "                       0.2206,  0.1739,  0.1914,  0.1880,  0.1872,  0.1798,  0.1959,  0.1998,\n",
              "                       0.1941,  0.1924,  0.2065,  0.1963,  0.2052,  0.1712,  0.2090,  0.2051,\n",
              "                       0.1889,  0.1876,  0.1930,  0.1730,  0.1898,  0.1539,  0.1808,  0.1944,\n",
              "                       0.1951,  0.1901,  0.1937,  0.1931,  0.2020,  0.2103,  0.2065,  0.2232,\n",
              "                       0.1830,  0.2026,  0.2011,  0.1737,  0.2006,  0.1661,  0.2013,  0.2177],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.10.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.4220,  0.0903, -0.0767,  ..., -0.5199, -0.6065,  0.1546],\n",
              "                      [-0.3321, -1.9750,  0.2274,  ...,  0.1194, -1.1600, -1.2004],\n",
              "                      [-0.1449,  0.8275, -0.2990,  ...,  0.9601,  0.2497, -0.1361],\n",
              "                      ...,\n",
              "                      [ 0.1239,  0.6654, -1.6513,  ..., -0.1135,  1.0649,  1.3294],\n",
              "                      [-1.6219,  0.2278, -0.4075,  ..., -0.3294,  0.1157,  0.5605],\n",
              "                      [ 0.5580, -0.2890, -0.1482,  ..., -1.5404, -0.3890, -0.2348]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.10.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.4324, -0.0016,  0.0394,  ...,  0.1162, -0.4371,  0.0149],\n",
              "                      [ 0.1693, -0.5703,  0.2292,  ...,  1.3300,  0.2435,  0.4503],\n",
              "                      [ 0.1755,  0.9536,  0.5537,  ..., -0.5190, -0.0928,  0.4952],\n",
              "                      ...,\n",
              "                      [ 0.2245,  0.3037,  0.7137,  ..., -0.1984,  0.3208, -0.3182],\n",
              "                      [ 0.3009, -0.6241,  0.2481,  ..., -0.0378, -0.0487, -0.7587],\n",
              "                      [ 0.1088,  0.7200, -0.6612,  ..., -0.2390, -0.0174,  0.2985]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.10.layer.1.layer_norm.weight',\n",
              "              tensor([1.2434, 1.2458, 1.1850, 1.2410, 1.4847, 1.3479, 0.3648, 1.2981, 0.9026,\n",
              "                      1.5132, 1.1095, 1.1741, 1.3342, 1.3435, 1.4442, 1.4603, 1.2790, 1.2787,\n",
              "                      0.8053, 1.4137, 1.4195, 1.4044, 4.2515, 1.3827, 1.4677, 1.3414, 1.4742,\n",
              "                      1.2313, 1.3620, 1.4523, 1.3841, 1.4022, 1.3579, 1.4594, 1.1819, 1.4453,\n",
              "                      1.3283, 1.1766, 1.4881, 1.4228, 1.2239, 1.2573, 0.8777, 1.3682, 2.9735,\n",
              "                      1.4856, 1.0998, 1.3918, 1.3238, 0.5651, 1.1922, 1.3802, 1.3704, 1.4559,\n",
              "                      1.3311, 1.3717, 2.9606, 1.3605, 1.5178, 1.4982, 1.3809, 1.4829, 1.4293,\n",
              "                      1.4544, 1.5226, 1.0856, 1.4540, 1.4368, 1.2252, 1.3614, 1.3956, 0.7628,\n",
              "                      1.4545, 1.4695, 1.4422, 1.4544, 1.3339, 1.3037, 1.4360, 1.3609, 1.4663,\n",
              "                      1.2970, 1.4016, 1.2466, 1.3222, 1.3547, 1.2652, 1.3828, 1.3337, 1.4941,\n",
              "                      1.3709, 1.5077, 1.4313, 1.3416, 1.5938, 1.4697, 1.4084, 1.4208, 1.4558,\n",
              "                      1.4835, 1.2969, 1.2971, 0.7174, 1.4350, 1.3577, 1.6030, 1.4012, 1.5424,\n",
              "                      1.4564, 2.1112, 1.2861, 1.4334, 1.3434, 1.4403, 1.3993, 1.5197, 1.3907,\n",
              "                      1.3833, 0.9429, 1.4297, 1.4885, 1.3966, 1.3222, 1.4416, 0.8490, 1.3707,\n",
              "                      1.4317, 1.3596, 1.3317, 1.3789, 1.1885, 1.3362, 1.4492, 1.4959, 1.3202,\n",
              "                      0.9363, 1.4248, 1.4265, 1.3523, 1.2080, 1.3499, 1.1785, 1.0675, 1.4400,\n",
              "                      1.2729, 1.3579, 1.4085, 1.2281, 1.4147, 1.3495, 1.4359, 1.3033, 1.3024,\n",
              "                      1.3552, 1.5185, 1.4766, 1.3195, 1.4840, 1.1865, 1.3216, 1.5495, 1.3941,\n",
              "                      1.2632, 4.3713, 1.4774, 1.3264, 1.4113, 1.2646, 1.2017, 0.8409, 1.1947,\n",
              "                      1.3466, 1.4402, 1.0665, 1.4470, 1.2931, 1.3720, 0.4484, 1.1588, 0.4923,\n",
              "                      1.4241, 1.5301, 1.3441, 1.4934, 1.2600, 1.3328, 1.3518, 1.0660, 1.3318,\n",
              "                      1.3463, 1.3375, 1.4360, 1.6980, 1.4047, 1.4797, 0.5479, 1.3856, 1.2991,\n",
              "                      1.3733, 1.5113, 1.5225, 1.3505, 1.4308, 1.4299, 1.4244, 1.2066, 1.3938,\n",
              "                      1.2942, 1.4469, 1.4644, 1.3574, 1.3954, 1.2808, 1.4196, 1.4344, 1.2931,\n",
              "                      1.3403, 1.3983, 1.2844, 0.9236, 1.1628, 1.3192, 1.4674, 1.2877, 1.2989,\n",
              "                      1.4560, 1.2404, 0.8666, 1.3882, 1.3456, 1.3358, 1.3327, 1.5341, 1.5675,\n",
              "                      1.4491, 1.4419, 1.8805, 1.3630, 1.2063, 0.8403, 1.2402, 1.3713, 1.4766,\n",
              "                      1.3955, 1.4133, 1.4052, 1.4105, 1.3530, 1.5294, 1.3036, 2.1648, 1.5028,\n",
              "                      1.4458, 1.5373, 1.4579, 1.4509, 1.4672, 1.2621, 0.6074, 1.3756, 1.1584,\n",
              "                      1.0047, 1.4509, 1.3958, 1.4241, 1.4106, 1.3941, 1.4012, 1.4689, 1.4231,\n",
              "                      1.5216, 1.2135, 1.2099, 0.8618, 1.2024, 1.3652, 1.3794, 0.8351, 1.4176,\n",
              "                      1.2900, 1.3173, 1.2462, 1.4625, 1.3855, 1.4123, 0.9642, 1.4962, 1.5533,\n",
              "                      1.1095, 1.6063, 1.5069, 1.3831, 1.4918, 1.4676, 1.5794, 1.6712, 1.2323,\n",
              "                      1.5110, 1.4334, 1.3632, 1.3194, 1.3818, 1.1066, 1.2549, 1.4156, 1.5050,\n",
              "                      1.2644, 1.4500, 1.3121, 1.2817, 1.4004, 1.2823, 1.4311, 1.2369, 1.3668,\n",
              "                      1.3599, 1.3484, 1.2486, 1.4325, 1.4098, 1.4576, 1.1413, 1.3224, 1.5509,\n",
              "                      1.2173, 1.4760, 1.0051, 1.2391, 1.3332, 1.3911, 1.5238, 0.9432, 1.2735,\n",
              "                      1.3208, 1.4791, 1.4316, 1.5532, 1.4394, 1.3550, 1.3489, 1.2942, 1.3236,\n",
              "                      1.4455, 1.5049, 1.3395, 1.4118, 0.9747, 1.3937, 1.0297, 1.9170, 1.2311,\n",
              "                      1.3787, 1.4972, 1.4121, 1.2645, 1.3216, 1.2912, 1.3094, 1.5147, 0.9618,\n",
              "                      1.3899, 1.1967, 1.0140, 1.4992, 1.5280, 1.4278, 0.6139, 1.4729, 1.4324,\n",
              "                      1.3788, 1.5041, 1.2443, 0.6489, 1.3909, 1.2737, 1.5306, 1.1845, 1.3723,\n",
              "                      0.8128, 1.2298, 1.4198, 1.2814, 1.2073, 1.3455, 1.4196, 0.9291, 1.4334,\n",
              "                      0.6962, 1.5664, 1.3425, 1.4172, 2.8552, 1.3043, 1.2388, 1.2805, 1.4492,\n",
              "                      1.2962, 1.4919, 1.3357, 1.4579, 1.3952, 1.0356, 1.5378, 1.4363, 1.4148,\n",
              "                      1.4474, 1.3747, 1.4628, 1.4594, 1.3629, 1.4331, 1.4871, 1.4011, 1.4279,\n",
              "                      1.4377, 1.3310, 1.4891, 1.4629, 0.6775, 1.4991, 1.0357, 1.3116, 1.5640,\n",
              "                      0.5302, 1.4036, 1.5279, 1.3046, 1.4899, 1.3884, 1.2398, 1.2971, 1.4979,\n",
              "                      0.6688, 1.4815, 1.1196, 1.4386, 1.4208, 1.4061, 0.9422, 1.2849, 1.3979,\n",
              "                      1.1754, 1.2896, 0.8054, 1.4341, 1.2884, 1.4607, 1.3200, 1.1715, 1.3704,\n",
              "                      1.3167, 1.5088, 1.3442, 1.4340, 1.3926, 1.2807, 1.3112, 1.3596, 1.3272,\n",
              "                      1.4537, 1.4558, 1.4065, 1.4581, 1.3609, 1.3144, 1.3231, 1.3605, 1.3637,\n",
              "                      1.4031, 1.4511, 1.4574, 1.5807, 1.2754, 1.4710, 1.3776, 1.4936, 1.5308,\n",
              "                      1.4487, 0.8067, 1.2947, 1.2231, 1.8557, 1.3984, 1.4724, 1.2065, 1.4564,\n",
              "                      1.4880, 1.3171, 1.4531, 1.3348, 1.4011, 1.3997, 1.7492, 1.5226, 1.3342,\n",
              "                      1.3285, 1.3674, 1.4042, 1.4259, 1.4408, 1.3812, 1.2785, 1.3387, 2.1172,\n",
              "                      1.5033, 1.3167, 1.3775, 1.2032, 1.5836, 1.3510, 1.3300, 1.4886, 2.0172,\n",
              "                      1.4527, 1.2794, 1.4712, 1.3072, 1.3977, 0.8326, 1.4122, 1.5840, 1.3567,\n",
              "                      1.4788, 1.4530, 1.3926, 1.8064, 1.2770, 0.8862, 1.4207, 1.2342, 1.1263,\n",
              "                      1.3604, 1.3945, 1.2875, 1.3880, 1.2178, 1.3158, 1.3797, 1.1181, 1.3116,\n",
              "                      1.2827, 1.3191, 1.2388, 1.1643, 1.4689, 1.4647, 1.2727, 1.3393, 1.4941,\n",
              "                      0.4362, 1.0936, 1.2999, 1.5156, 1.3984, 1.4230, 1.4273, 1.2573, 1.4618,\n",
              "                      1.3231, 0.9897, 1.3974, 1.5391, 1.2199, 1.2804, 1.4086, 1.4148, 0.5755,\n",
              "                      1.3780, 1.3597, 1.4515, 1.2693, 0.8300, 1.4493, 1.4215, 1.3341, 1.3238,\n",
              "                      1.4629, 1.1641, 1.4057, 0.9285, 1.3831, 1.5694, 1.4737, 1.4566, 1.5249,\n",
              "                      1.5129, 1.5379, 1.4870, 1.4830, 1.3970, 1.3929, 1.3093, 1.4399, 1.4333,\n",
              "                      1.2733, 1.4615, 1.2505, 1.4364, 1.1127, 1.3257, 1.3366, 1.4037, 1.3268,\n",
              "                      1.1129, 1.3527, 1.4712, 1.3580, 1.2352, 1.2005, 1.4550, 1.3331, 1.4839,\n",
              "                      1.3021, 1.4590, 1.3982, 1.2468, 1.3976, 1.1336, 1.3461, 1.2938, 1.2988,\n",
              "                      1.4604, 1.4290, 1.1438, 1.3076, 1.3772, 1.3507, 1.1136, 1.3277, 0.9761,\n",
              "                      1.3855, 1.5505, 1.3140, 1.1650, 1.5246, 0.5826, 1.4247, 1.2784, 1.0315,\n",
              "                      1.3994, 1.2956, 1.3902, 1.4299, 1.4758, 1.3338, 1.1775, 1.1379, 1.4772,\n",
              "                      1.3992, 1.4785, 1.3739, 1.4780, 1.3410, 1.3747, 1.1098, 0.8691, 1.3733,\n",
              "                      1.1411, 0.8905, 1.2410, 0.6973, 0.7045, 1.3074, 1.3059, 1.3804, 1.3009,\n",
              "                      1.4727, 1.4455, 1.3763, 1.4813, 1.4960, 1.5033, 1.3886, 1.4122, 1.3284,\n",
              "                      1.5024, 1.3760, 1.4103, 1.4007, 1.4393, 1.3447, 1.4059, 1.4281, 1.4363,\n",
              "                      1.2996, 1.5367, 1.3710, 1.3913, 1.4720, 1.3497, 1.5330, 1.2965, 0.8532,\n",
              "                      1.4084, 1.4116, 1.3956, 1.2157, 1.4729, 1.3895, 1.3033, 1.3871, 1.4891,\n",
              "                      1.2994, 1.3605, 1.4057, 1.5552, 1.4140, 1.2751, 1.1813, 1.5031, 1.8487,\n",
              "                      1.3695, 1.4042, 1.4952, 0.6519, 1.3601, 1.3837, 1.2344, 1.3584, 0.7925,\n",
              "                      1.4538, 1.3330, 1.2778, 1.4693, 1.3122, 1.2335, 1.2869, 1.4081, 1.4664,\n",
              "                      1.1960, 1.2567, 1.4930, 1.4278, 1.3228, 1.3665, 1.4198, 1.3964, 1.3441,\n",
              "                      1.3908, 1.3726, 1.3681, 1.2363, 1.1260, 1.2206, 1.3956, 1.3067, 1.2210,\n",
              "                      1.5613, 1.3288, 0.9339, 1.3504, 1.4343, 1.2603, 1.4250, 1.2886, 1.4427,\n",
              "                      1.3487, 1.3878, 1.2818, 1.2929, 1.2014, 1.3499, 1.3187, 1.4617, 1.2732,\n",
              "                      1.2077, 1.4398, 1.2818], device='cuda:0')),\n",
              "             ('encoder.block.11.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0371, -0.0048,  0.0317,  ..., -0.0136, -0.0455,  0.0305],\n",
              "                      [-0.0176, -0.0753, -0.0127,  ..., -0.0399, -0.0399, -0.0195],\n",
              "                      [ 0.0130, -0.0071,  0.0022,  ..., -0.0163,  0.0593, -0.0398],\n",
              "                      ...,\n",
              "                      [ 0.0492, -0.0155, -0.0065,  ..., -0.0156, -0.0512, -0.0277],\n",
              "                      [-0.0051, -0.0221, -0.0011,  ...,  0.0426, -0.0095, -0.0057],\n",
              "                      [ 0.0710,  0.0128,  0.0109,  ...,  0.0156,  0.0006,  0.0293]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.11.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.1478, -0.1347,  0.0295,  ..., -0.1041,  0.0784, -0.2840],\n",
              "                      [-0.1404, -0.0995, -0.1039,  ..., -0.1098, -0.1282, -0.0425],\n",
              "                      [ 0.0930,  0.1379,  0.2177,  ...,  0.1597, -0.1296, -0.4136],\n",
              "                      ...,\n",
              "                      [ 0.2888, -0.2998, -0.1739,  ...,  0.3068, -0.2118, -0.1726],\n",
              "                      [ 0.2089, -0.1681, -0.1631,  ...,  0.1439, -0.3289,  0.2425],\n",
              "                      [ 0.0234,  0.2231,  0.2195,  ...,  0.1543,  0.1790, -0.2121]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.11.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.1921,  0.7464,  0.9078,  ...,  0.9328,  0.6197, -0.8030],\n",
              "                      [ 0.6923, -1.1582,  0.5167,  ...,  0.9306, -1.3809, -0.5117],\n",
              "                      [ 1.4289, -0.0226, -1.8590,  ..., -0.3385, -0.7187,  0.2668],\n",
              "                      ...,\n",
              "                      [-0.1926, -0.6014, -0.6806,  ...,  1.2847, -0.6988, -0.2341],\n",
              "                      [-0.2074,  1.3549,  1.4385,  ...,  0.4384, -2.0721,  0.7866],\n",
              "                      [ 0.3548, -0.3369,  1.0311,  ...,  0.5065, -0.2794,  1.7628]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.11.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-1.8094,  1.6572, -1.2940,  ...,  1.7433, -1.4455, -0.0956],\n",
              "                      [ 1.5851,  4.1274,  0.6576,  ...,  1.4765, -0.5707,  0.5950],\n",
              "                      [-2.3801, -1.4036,  1.1088,  ...,  1.7200, -2.3518, -0.9798],\n",
              "                      ...,\n",
              "                      [-2.4098, -0.4932,  1.2476,  ...,  1.1085,  0.0862,  0.6932],\n",
              "                      [-0.5151,  1.7035,  0.1993,  ...,  0.9768,  1.2954,  0.9255],\n",
              "                      [ 1.0564,  0.9194,  1.0769,  ..., -0.3823,  0.7407, -2.6634]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.11.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.1787,  0.1781,  0.1536,  0.1746,  0.1810,  0.1625,  0.0370,  0.1840,\n",
              "                       0.0633,  0.1839,  0.1686,  0.1913,  0.1359,  0.1386,  0.1672,  0.1776,\n",
              "                       0.1678,  0.1779,  0.1309,  0.1705,  0.1572,  0.1865,  0.0598,  0.1830,\n",
              "                       0.1921,  0.1647,  0.1791,  0.1697,  0.1788,  0.1675,  0.1706,  0.1779,\n",
              "                       0.1801,  0.1751,  0.1527,  0.1842,  0.1276,  0.1393,  0.1902,  0.1150,\n",
              "                       0.1476,  0.1373,  0.1428,  0.2027, -0.0663,  0.1777,  0.1314,  0.1809,\n",
              "                       0.1798,  0.0480,  0.1519,  0.1772,  0.1365,  0.1974, -0.0017,  0.1704,\n",
              "                       0.1164,  0.1828,  0.2151,  0.1917,  0.1867,  0.1727,  0.1858,  0.1869,\n",
              "                       0.1849,  0.0352,  0.1807,  0.1804,  0.1658,  0.1761,  0.1802,  0.1098,\n",
              "                       0.1676,  0.1891,  0.1813,  0.1822,  0.1367,  0.1871,  0.1946,  0.2028,\n",
              "                       0.1790,  0.1672,  0.1985,  0.1849,  0.1663,  0.1796,  0.1637,  0.1902,\n",
              "                       0.1880,  0.1871,  0.1957,  0.1543,  0.1808,  0.1692,  0.1835,  0.1865,\n",
              "                       0.1825,  0.1846,  0.1908,  0.1611,  0.1633,  0.1812,  0.1126,  0.1859,\n",
              "                       0.1798,  0.1346,  0.1861,  0.1807,  0.1789,  0.0906,  0.1706,  0.1918,\n",
              "                       0.1626,  0.1605,  0.1765,  0.1965,  0.1727,  0.1870,  0.1113,  0.1743,\n",
              "                       0.1801,  0.1917,  0.1573,  0.1799,  0.1199,  0.1729,  0.2010,  0.1713,\n",
              "                       0.1733,  0.1825,  0.0917,  0.1723,  0.1846,  0.1591,  0.1846,  0.1291,\n",
              "                       0.1712,  0.1840,  0.1751,  0.1715,  0.1711,  0.1554,  0.1372,  0.1627,\n",
              "                       0.1670,  0.1683,  0.1762,  0.1619,  0.1723,  0.1822,  0.1869,  0.1810,\n",
              "                       0.1829,  0.1599,  0.1754,  0.1898,  0.1652,  0.2102,  0.1515,  0.1823,\n",
              "                       0.1826,  0.1770,  0.1464, -0.0669,  0.1713,  0.1650,  0.1646,  0.1514,\n",
              "                       0.1694,  0.0769,  0.1609,  0.2086,  0.1869,  0.1229,  0.1937,  0.1660,\n",
              "                       0.1859,  0.0526,  0.1373, -0.0235,  0.1904,  0.1841,  0.1665,  0.1967,\n",
              "                       0.1871,  0.1920,  0.1810,  0.1547,  0.1656,  0.1698,  0.1763,  0.1955,\n",
              "                       0.1911,  0.2030,  0.1850,  0.0513,  0.1743,  0.1893,  0.1850,  0.1685,\n",
              "                       0.1855,  0.1710,  0.1620,  0.1949,  0.1884,  0.1531,  0.1637,  0.1731,\n",
              "                       0.1717,  0.1830,  0.1664,  0.1657,  0.1749,  0.1657,  0.1695,  0.1732,\n",
              "                       0.1768,  0.1758,  0.1579,  0.0779,  0.1087,  0.1677,  0.1883,  0.1792,\n",
              "                       0.1518,  0.1891,  0.1687,  0.0990,  0.1718,  0.1864,  0.1689,  0.1734,\n",
              "                       0.1621,  0.1937,  0.1832,  0.1779,  0.1663,  0.1670,  0.1518,  0.1111,\n",
              "                       0.1484,  0.1898,  0.1949,  0.1879,  0.1814,  0.1913,  0.1763,  0.1775,\n",
              "                       0.1859,  0.1654,  0.1069,  0.1663,  0.1684,  0.1811,  0.1859,  0.1822,\n",
              "                       0.1845,  0.1748,  0.0645,  0.1796,  0.1588,  0.1381,  0.1697,  0.1886,\n",
              "                       0.1787,  0.1812,  0.1809,  0.1644,  0.1794,  0.1752,  0.0915,  0.1665,\n",
              "                       0.1260,  0.0218,  0.1672,  0.1937,  0.1981,  0.1214,  0.1909,  0.1649,\n",
              "                       0.1545,  0.1541,  0.1903,  0.1634,  0.1927,  0.1218,  0.1790,  0.1846,\n",
              "                       0.1536,  0.1036,  0.1807,  0.1644,  0.1849,  0.1927,  0.1746,  0.1895,\n",
              "                       0.1640,  0.1961,  0.1690,  0.1795,  0.1916,  0.1739,  0.1716,  0.1639,\n",
              "                       0.1752,  0.1672,  0.1771,  0.1822,  0.1752,  0.1656,  0.1833,  0.1879,\n",
              "                       0.1878,  0.1469,  0.1852,  0.1792,  0.1471,  0.1624,  0.1769,  0.1841,\n",
              "                       0.1796,  0.1496,  0.1788,  0.1852,  0.1544,  0.1993,  0.1654,  0.1740,\n",
              "                       0.1785,  0.1777,  0.1990,  0.1160,  0.1640,  0.1490,  0.1938,  0.1751,\n",
              "                       0.1814,  0.1841,  0.1813,  0.1687,  0.1828,  0.1952,  0.1807,  0.1776,\n",
              "                       0.1754,  0.1757,  0.1469,  0.1788,  0.1333,  0.1018,  0.1776,  0.1839,\n",
              "                       0.1735,  0.2017,  0.1542,  0.1734,  0.1710,  0.1603,  0.2044,  0.1411,\n",
              "                       0.1776,  0.1348,  0.1388,  0.1745,  0.1851,  0.1757,  0.0652,  0.1660,\n",
              "                       0.1877,  0.1669,  0.1653,  0.1735,  0.0642,  0.1787,  0.1895,  0.1845,\n",
              "                       0.1280,  0.1788,  0.0995,  0.1528,  0.1869,  0.1718,  0.1599,  0.1669,\n",
              "                       0.1877,  0.0777,  0.1903,  0.0916,  0.2038,  0.1535,  0.1835,  0.0363,\n",
              "                       0.1757,  0.1704,  0.1912,  0.1745,  0.1803,  0.1818,  0.1674,  0.1952,\n",
              "                       0.1798,  0.0393,  0.1874,  0.2113,  0.1699,  0.1928,  0.1865,  0.1741,\n",
              "                       0.1837,  0.1850,  0.1671,  0.1762,  0.1695,  0.1717,  0.1865,  0.1730,\n",
              "                       0.1820,  0.1685,  0.0619,  0.1559,  0.1359,  0.1740,  0.1972,  0.0589,\n",
              "                       0.1735,  0.1948,  0.1817,  0.1838,  0.1758,  0.1719,  0.1595,  0.1897,\n",
              "                       0.0961,  0.1705,  0.1473,  0.1735,  0.1768,  0.1825,  0.1495,  0.1677,\n",
              "                       0.1924,  0.1477,  0.1756,  0.1089,  0.1606,  0.1667,  0.1746,  0.1951,\n",
              "                       0.1564,  0.1945,  0.1648,  0.1886,  0.1790,  0.1806,  0.1959,  0.1896,\n",
              "                       0.1580,  0.1926,  0.1630,  0.1634,  0.1831,  0.1730,  0.1891,  0.1881,\n",
              "                       0.1655,  0.1681,  0.1685,  0.1660,  0.1608,  0.1806,  0.1811,  0.1838,\n",
              "                       0.1591,  0.1757,  0.1851,  0.1942,  0.1934,  0.1896,  0.0448,  0.1752,\n",
              "                       0.1555,  0.0861,  0.1716,  0.1890,  0.1700,  0.1822,  0.1861,  0.1189,\n",
              "                       0.1934,  0.1709,  0.2056,  0.1595,  0.0732,  0.2003,  0.1742,  0.1707,\n",
              "                       0.1734,  0.1727,  0.1763,  0.1814,  0.1726,  0.1756,  0.1636,  0.0311,\n",
              "                       0.1751,  0.1801,  0.1868,  0.1546,  0.1835,  0.1624,  0.1871,  0.2055,\n",
              "                       0.1003,  0.1922,  0.1703,  0.1800,  0.1773,  0.1608,  0.1357,  0.1804,\n",
              "                       0.1749,  0.1670,  0.1766,  0.1739,  0.1741,  0.0895,  0.1801,  0.1179,\n",
              "                       0.1889,  0.1820,  0.1621,  0.1771,  0.1784,  0.1688,  0.1589,  0.1657,\n",
              "                       0.1886,  0.1784,  0.1408,  0.1742,  0.1616,  0.1782,  0.1642,  0.1600,\n",
              "                       0.1807,  0.1733,  0.1708,  0.1826,  0.1825,  0.0680,  0.1356,  0.1695,\n",
              "                       0.1796,  0.1960,  0.1803,  0.1889,  0.1599,  0.1701,  0.1698,  0.1357,\n",
              "                       0.1575,  0.1674,  0.1572,  0.1454,  0.1839,  0.1710,  0.0227,  0.1717,\n",
              "                       0.1738,  0.1925,  0.1622,  0.1166,  0.1832,  0.1838,  0.1710,  0.1632,\n",
              "                       0.1918,  0.1676,  0.1649,  0.1468,  0.1797,  0.1934,  0.1879,  0.1717,\n",
              "                       0.1733,  0.1846,  0.1713,  0.1912,  0.1897,  0.1777,  0.1899,  0.1675,\n",
              "                       0.1828,  0.1846,  0.1656,  0.1915,  0.1608,  0.1623,  0.1311,  0.1647,\n",
              "                       0.1737,  0.1914,  0.1831,  0.1137,  0.1854,  0.1697,  0.1815,  0.1691,\n",
              "                       0.1447,  0.1940,  0.1739,  0.1853,  0.1723,  0.1884,  0.1750,  0.1651,\n",
              "                       0.1696,  0.1719,  0.1821,  0.1651,  0.1852,  0.1644,  0.1760,  0.1644,\n",
              "                       0.1684,  0.1808,  0.1755,  0.1371,  0.1670,  0.1149,  0.1785,  0.1798,\n",
              "                       0.1641,  0.1629,  0.1815,  0.0849,  0.1768,  0.1733,  0.1010,  0.1752,\n",
              "                       0.1492,  0.1922,  0.1652,  0.1671,  0.1858,  0.1720,  0.1607,  0.1824,\n",
              "                       0.1744,  0.1675,  0.1720,  0.1836,  0.1763,  0.1821,  0.1539,  0.1461,\n",
              "                       0.1858,  0.1599,  0.1591,  0.1615,  0.1021,  0.0152,  0.1719,  0.1791,\n",
              "                       0.1735,  0.1554,  0.1713,  0.1861,  0.1972,  0.1878,  0.1791,  0.1496,\n",
              "                       0.1716,  0.1595,  0.2038,  0.1955,  0.1832,  0.1731,  0.1712,  0.1943,\n",
              "                       0.1831,  0.1754,  0.1671,  0.1621,  0.1869,  0.0938,  0.1692,  0.1728,\n",
              "                       0.1902,  0.1702,  0.1807,  0.1681,  0.1356,  0.1816,  0.1822,  0.1641,\n",
              "                       0.1893,  0.1644,  0.1817,  0.1642,  0.1505,  0.1663,  0.1806,  0.1802,\n",
              "                       0.1610,  0.1913,  0.1811,  0.1617,  0.1711,  0.1746,  0.0223,  0.1733,\n",
              "                       0.1848,  0.1953,  0.0717,  0.1734,  0.1512,  0.1637,  0.1765,  0.1257,\n",
              "                       0.2001,  0.1311,  0.1556,  0.1755,  0.1877,  0.1873,  0.1747,  0.1574,\n",
              "                       0.1915,  0.1566,  0.1611,  0.1853,  0.1799,  0.1820,  0.1870,  0.1889,\n",
              "                       0.1791,  0.1655,  0.1904,  0.1809,  0.1828,  0.1607,  0.1701,  0.1746,\n",
              "                       0.1895,  0.1643,  0.1598,  0.1854,  0.1687,  0.1009,  0.1739,  0.1925,\n",
              "                       0.1630,  0.1735,  0.1616,  0.1685,  0.1821,  0.1845,  0.1894,  0.1944,\n",
              "                       0.1529,  0.1963,  0.1732,  0.1677,  0.1689,  0.1572,  0.1805,  0.1906],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.11.layer.1.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.5562,  0.5512, -0.1649,  ..., -0.3765, -0.3255, -0.2930],\n",
              "                      [-1.7874, -0.5661,  0.6666,  ...,  0.0056, -0.0580, -0.3972],\n",
              "                      [ 0.5101,  0.5380,  0.5846,  ...,  0.2107, -1.6483,  0.4251],\n",
              "                      ...,\n",
              "                      [ 0.1091,  0.6728, -0.3065,  ..., -0.0659, -0.2240,  0.0300],\n",
              "                      [ 1.2398,  0.2544, -0.1849,  ..., -0.9648,  0.3215, -0.8926],\n",
              "                      [ 0.4023, -0.5827,  0.1427,  ...,  0.7941, -0.3386, -0.7677]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.11.layer.1.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.0300,  0.2186, -0.9018,  ...,  0.0533,  0.5373,  0.7366],\n",
              "                      [-0.4532,  0.0497, -0.4587,  ..., -0.6185, -0.0457, -0.4369],\n",
              "                      [ 0.4435,  0.3826,  0.4694,  ...,  0.0687,  0.1096,  0.4641],\n",
              "                      ...,\n",
              "                      [ 0.2896,  0.2102, -0.9460,  ...,  0.0369,  0.1210,  0.4659],\n",
              "                      [ 0.2166, -0.1533, -0.9492,  ..., -0.0653, -0.1564,  0.6471],\n",
              "                      [-0.2130,  0.4637,  0.2574,  ...,  0.2996, -0.0176, -0.3250]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.block.11.layer.1.layer_norm.weight',\n",
              "              tensor([0.8977, 0.8754, 0.8059, 0.8141, 1.0865, 0.9386, 0.3008, 0.9377, 0.6243,\n",
              "                      1.0199, 0.8396, 0.8973, 0.9415, 0.8893, 1.0789, 0.9919, 0.9080, 0.8574,\n",
              "                      0.4997, 1.0286, 0.9913, 0.9750, 3.0065, 0.9897, 1.0617, 0.8799, 1.0768,\n",
              "                      0.8963, 0.9492, 1.0137, 0.9976, 0.9940, 0.9770, 1.0459, 0.8654, 1.0484,\n",
              "                      0.9002, 0.7858, 1.1528, 0.7097, 0.8800, 0.8280, 0.6590, 0.9719, 0.9870,\n",
              "                      1.0771, 0.7351, 1.0375, 0.9283, 0.3657, 0.8235, 0.9931, 0.9280, 1.0209,\n",
              "                      0.8490, 0.9486, 1.7568, 0.9949, 1.0555, 1.0230, 1.0056, 1.1001, 1.0409,\n",
              "                      0.9894, 1.1082, 0.5103, 1.0528, 0.9858, 0.8991, 1.0007, 0.9846, 0.5490,\n",
              "                      1.0510, 1.0359, 0.9953, 1.0321, 0.8945, 0.9570, 0.9974, 0.9875, 1.0596,\n",
              "                      0.9419, 1.0455, 0.8872, 0.9696, 1.0038, 0.8420, 1.0114, 0.9695, 1.0532,\n",
              "                      1.0086, 1.0843, 1.0140, 0.9566, 1.1309, 1.0415, 1.0009, 1.0414, 1.0684,\n",
              "                      1.0126, 0.9200, 0.9316, 0.5656, 1.0192, 0.9559, 1.0087, 1.0351, 1.0587,\n",
              "                      1.0877, 1.3498, 0.9440, 1.0221, 0.9531, 1.0223, 0.9920, 1.0585, 0.9441,\n",
              "                      0.9812, 0.5890, 1.0495, 1.1280, 1.0027, 0.9082, 1.0160, 0.5816, 0.9895,\n",
              "                      1.0005, 0.9087, 0.9712, 0.9606, 0.7235, 0.9092, 1.0468, 1.0910, 0.9731,\n",
              "                      0.6429, 0.9826, 1.0331, 0.9194, 0.8302, 0.9359, 0.7512, 0.7255, 0.9430,\n",
              "                      0.9133, 0.9110, 0.9889, 0.8870, 0.9721, 0.9534, 1.0423, 0.8984, 0.9322,\n",
              "                      0.9034, 1.0719, 1.0689, 0.8924, 1.1038, 0.8275, 0.9337, 1.1403, 1.0066,\n",
              "                      0.9009, 2.4248, 1.0536, 1.0057, 0.9658, 0.8684, 0.8852, 0.5802, 0.8422,\n",
              "                      1.0112, 0.9913, 0.7347, 1.0489, 0.9238, 0.9359, 0.3088, 0.7868, 0.3649,\n",
              "                      1.0077, 1.0837, 0.9663, 1.1149, 0.8999, 0.9346, 1.0128, 0.7761, 0.9807,\n",
              "                      0.9281, 1.0344, 1.1092, 1.1828, 1.0006, 1.1046, 0.4105, 0.9872, 0.8894,\n",
              "                      0.9962, 1.1073, 1.1486, 0.9280, 0.9711, 1.0634, 1.0402, 0.8604, 1.0043,\n",
              "                      0.9731, 1.0302, 0.9880, 0.9796, 0.9604, 0.8742, 1.0000, 1.0118, 0.8991,\n",
              "                      0.9546, 0.9490, 0.9171, 0.7248, 0.8186, 0.9367, 1.0563, 0.9052, 0.8764,\n",
              "                      1.0189, 0.8198, 0.8018, 1.0313, 0.9969, 0.9393, 0.9685, 1.2384, 1.1503,\n",
              "                      1.0763, 1.1439, 1.6556, 0.9272, 0.8384, 0.5953, 0.8481, 0.9685, 1.0703,\n",
              "                      1.0232, 1.0531, 1.0268, 1.0122, 0.9823, 1.1099, 0.9225, 1.2043, 1.0362,\n",
              "                      1.0455, 1.1404, 1.0630, 1.0260, 1.0368, 0.9069, 0.3982, 0.9609, 0.7670,\n",
              "                      0.8753, 1.0160, 1.0092, 1.0190, 1.0062, 1.0112, 0.9541, 1.0612, 1.0096,\n",
              "                      0.9383, 0.8200, 0.8409, 0.3993, 0.7846, 0.9139, 1.0182, 0.5196, 1.0492,\n",
              "                      0.9717, 0.9199, 0.8822, 1.0428, 0.9369, 1.0413, 0.6798, 1.0743, 1.0508,\n",
              "                      0.8211, 1.0886, 1.0969, 0.9153, 1.0596, 1.0804, 1.0528, 1.1669, 0.8500,\n",
              "                      1.0611, 1.0422, 0.9146, 0.9411, 0.9993, 0.8737, 0.9126, 0.9825, 1.0088,\n",
              "                      0.9509, 1.0048, 1.0020, 0.8898, 0.9861, 0.8752, 1.0210, 0.9078, 0.9860,\n",
              "                      0.9244, 1.0308, 0.8404, 1.1050, 1.0046, 1.0677, 0.7153, 0.9066, 1.1434,\n",
              "                      0.8441, 1.0794, 0.7326, 0.8338, 0.9163, 0.9703, 1.0715, 0.5875, 0.8970,\n",
              "                      0.9633, 1.0427, 0.9681, 1.1326, 1.0012, 0.9572, 0.9323, 0.9545, 0.9930,\n",
              "                      0.9637, 1.0582, 0.9290, 0.9739, 0.7095, 0.9391, 0.6948, 1.1168, 0.8236,\n",
              "                      1.0253, 1.0504, 0.9982, 0.8376, 0.9732, 0.8681, 0.8811, 1.0728, 0.6262,\n",
              "                      1.0110, 0.7705, 0.6694, 1.1507, 1.0811, 0.9985, 0.4001, 1.0130, 1.0623,\n",
              "                      0.9405, 1.1227, 0.8746, 0.4507, 1.0252, 0.9147, 1.1047, 0.8677, 1.0276,\n",
              "                      0.6831, 0.8496, 1.0047, 0.9031, 0.8450, 1.0041, 1.0429, 0.5828, 1.0517,\n",
              "                      0.4318, 1.1573, 0.8880, 1.0074, 1.6339, 0.8975, 0.9150, 0.9103, 1.0714,\n",
              "                      0.8684, 1.0737, 0.9199, 1.0429, 0.9746, 0.7138, 1.1025, 1.0504, 1.0234,\n",
              "                      1.0239, 0.9574, 1.0324, 1.0684, 1.0194, 1.0272, 1.0267, 0.9964, 0.9896,\n",
              "                      1.1128, 0.9586, 1.1075, 1.0883, 0.5212, 0.9596, 0.6885, 0.9298, 1.1007,\n",
              "                      0.3777, 1.0410, 1.0456, 0.9378, 1.0519, 0.9731, 0.8826, 0.9002, 1.1047,\n",
              "                      0.4771, 1.0946, 0.6971, 1.0670, 0.9866, 1.0300, 0.6816, 0.9396, 0.9731,\n",
              "                      0.8156, 0.8524, 0.6003, 1.0315, 0.9096, 1.0455, 0.9512, 0.8062, 0.9773,\n",
              "                      0.9511, 1.0664, 0.9380, 1.0177, 0.9098, 0.9057, 0.8943, 0.9750, 0.9087,\n",
              "                      1.0862, 1.0792, 1.0245, 1.0616, 0.9348, 0.8900, 1.0074, 0.9925, 0.9780,\n",
              "                      1.0447, 1.0643, 1.0817, 1.1017, 0.9049, 1.0705, 0.9908, 1.0828, 1.1265,\n",
              "                      1.0437, 0.4335, 0.8918, 0.8630, 1.1879, 1.0230, 1.0678, 0.8538, 1.1086,\n",
              "                      1.0509, 0.8906, 1.0964, 0.9500, 1.0131, 0.9816, 1.0967, 1.0596, 0.9273,\n",
              "                      0.9225, 0.9434, 0.9829, 1.0354, 1.0805, 1.0217, 0.8662, 0.8991, 1.0211,\n",
              "                      1.0294, 0.9512, 0.9555, 0.8217, 1.1224, 0.9440, 0.8465, 1.1116, 1.1593,\n",
              "                      1.1240, 0.9216, 1.0923, 0.9159, 0.9850, 0.5884, 0.9553, 1.1164, 0.9495,\n",
              "                      1.0484, 1.0365, 1.0032, 0.9615, 0.8662, 0.6002, 1.0438, 0.8677, 0.7650,\n",
              "                      0.9805, 0.9538, 0.9049, 0.9207, 0.9115, 0.9473, 1.0056, 0.8429, 0.9396,\n",
              "                      0.9015, 0.9761, 0.8635, 0.7422, 1.0607, 1.0546, 0.8921, 0.9587, 1.0819,\n",
              "                      0.3211, 0.7656, 0.9125, 1.1526, 0.9686, 1.0236, 0.9859, 0.8988, 1.0607,\n",
              "                      0.9193, 0.6972, 0.9142, 1.0630, 0.8357, 0.8155, 0.9915, 0.9730, 0.3912,\n",
              "                      0.9586, 0.9769, 1.0088, 0.8807, 0.6177, 1.1398, 1.0229, 0.9417, 0.9461,\n",
              "                      1.0712, 0.8100, 1.0281, 0.5979, 0.9873, 1.1522, 1.0378, 1.0519, 1.0951,\n",
              "                      1.0786, 1.1169, 1.1069, 1.1540, 1.0622, 1.0447, 0.8968, 1.0448, 0.9981,\n",
              "                      0.9012, 1.0111, 0.9059, 1.0398, 0.7056, 0.9445, 0.8875, 1.0253, 0.8889,\n",
              "                      0.8381, 0.9509, 1.0880, 1.0188, 0.8486, 0.8569, 1.0123, 0.9083, 1.0729,\n",
              "                      0.9506, 1.0201, 0.9671, 0.8920, 1.0369, 0.8125, 1.0042, 0.9436, 0.9025,\n",
              "                      1.0548, 1.0693, 0.7476, 0.8936, 0.9861, 1.0033, 0.7958, 0.9314, 0.6441,\n",
              "                      1.0610, 1.1141, 0.9189, 0.7793, 1.0771, 0.4049, 1.0018, 0.9535, 0.5905,\n",
              "                      1.0462, 0.8325, 1.0021, 1.0508, 1.0499, 0.9522, 0.8618, 0.7800, 1.1101,\n",
              "                      1.0421, 1.0302, 1.0096, 1.0136, 0.9535, 0.9597, 0.8119, 0.5993, 1.0207,\n",
              "                      0.8308, 0.6552, 0.9170, 0.4835, 0.5053, 0.9447, 0.9124, 0.9725, 0.8862,\n",
              "                      1.0452, 1.0487, 0.9728, 1.1089, 1.0182, 0.9748, 1.0056, 0.9980, 0.9494,\n",
              "                      1.0304, 0.9965, 1.0415, 0.9898, 1.0838, 0.9661, 0.9588, 0.9959, 1.0644,\n",
              "                      0.9194, 1.0274, 1.0042, 0.9382, 1.0803, 0.8977, 1.0992, 0.9102, 0.5746,\n",
              "                      1.0393, 1.0404, 0.9561, 0.8144, 1.0200, 0.9896, 0.8899, 0.9295, 1.1390,\n",
              "                      0.9600, 0.9816, 1.0189, 1.1065, 1.0093, 0.8722, 0.8043, 1.0466, 1.3066,\n",
              "                      0.9545, 0.9924, 1.0690, 0.4681, 0.9653, 0.9594, 0.8758, 0.9680, 0.5230,\n",
              "                      1.0752, 0.9415, 0.8837, 1.1164, 0.9068, 0.8450, 0.9218, 1.0216, 1.0097,\n",
              "                      0.8057, 0.8656, 1.0680, 1.0328, 0.9704, 0.9739, 1.0370, 1.0148, 0.9386,\n",
              "                      0.9989, 0.9752, 1.0151, 0.8607, 0.8084, 0.8455, 1.0546, 0.8898, 0.8446,\n",
              "                      1.0470, 0.9048, 0.6593, 0.9435, 1.0246, 0.8631, 1.0121, 0.8957, 1.0468,\n",
              "                      0.9165, 0.9768, 0.9251, 0.8928, 0.8652, 1.0110, 0.9394, 1.0810, 0.8865,\n",
              "                      0.8658, 1.0537, 0.8828], device='cuda:0')),\n",
              "             ('encoder.final_layer_norm.weight',\n",
              "              tensor([0.3520, 0.3213, 0.3103, 0.3257, 0.5135, 0.3839, 0.0526, 0.3628, 0.1787,\n",
              "                      0.4293, 0.3333, 0.2998, 0.3339, 0.3077, 0.4902, 0.4276, 0.3641, 0.3621,\n",
              "                      0.1907, 0.4613, 0.4334, 0.4239, 0.1342, 0.4628, 0.4702, 0.3766, 0.4933,\n",
              "                      0.3711, 0.3828, 0.4883, 0.4152, 0.3836, 0.3983, 0.4852, 0.3246, 0.4162,\n",
              "                      0.2439, 0.2936, 0.4995, 0.1624, 0.3602, 0.2841, 0.2289, 0.3933, 0.1767,\n",
              "                      0.4076, 0.2464, 0.4158, 0.3692, 0.1028, 0.3119, 0.3892, 0.3117, 0.4753,\n",
              "                      0.0612, 0.3831, 0.1108, 0.3998, 0.4802, 0.4497, 0.4035, 0.5141, 0.4266,\n",
              "                      0.4709, 0.4687, 0.0305, 0.4361, 0.4319, 0.3186, 0.4679, 0.4348, 0.1951,\n",
              "                      0.4682, 0.4034, 0.4513, 0.4610, 0.2785, 0.4081, 0.4791, 0.4221, 0.4714,\n",
              "                      0.3746, 0.4507, 0.3535, 0.4106, 0.4046, 0.3243, 0.3904, 0.4129, 0.4976,\n",
              "                      0.3930, 0.4696, 0.4408, 0.3753, 0.4885, 0.4844, 0.4599, 0.4683, 0.4899,\n",
              "                      0.4372, 0.3145, 0.4237, 0.2120, 0.4968, 0.4160, 0.2306, 0.4379, 0.4605,\n",
              "                      0.4745, 0.2076, 0.3835, 0.4463, 0.3967, 0.4157, 0.4180, 0.4875, 0.3790,\n",
              "                      0.4434, 0.2185, 0.4513, 0.5210, 0.4431, 0.3013, 0.4364, 0.1801, 0.4121,\n",
              "                      0.4174, 0.3761, 0.3883, 0.3241, 0.1361, 0.3603, 0.4871, 0.4633, 0.3900,\n",
              "                      0.2528, 0.3754, 0.4386, 0.3654, 0.3332, 0.4021, 0.2556, 0.2483, 0.3138,\n",
              "                      0.3852, 0.3282, 0.4550, 0.3338, 0.4397, 0.3944, 0.4381, 0.3970, 0.3771,\n",
              "                      0.3255, 0.4909, 0.4713, 0.3531, 0.5027, 0.3217, 0.3986, 0.4988, 0.4094,\n",
              "                      0.3687, 0.1584, 0.4494, 0.4020, 0.4247, 0.3390, 0.3515, 0.1505, 0.3344,\n",
              "                      0.4342, 0.4691, 0.2390, 0.4276, 0.3481, 0.3873, 0.0874, 0.3350, 0.0284,\n",
              "                      0.4843, 0.4704, 0.3900, 0.4937, 0.3785, 0.3570, 0.4677, 0.3007, 0.3984,\n",
              "                      0.3806, 0.4242, 0.4797, 0.4479, 0.4243, 0.4535, 0.0640, 0.4284, 0.3092,\n",
              "                      0.4145, 0.4679, 0.5119, 0.3776, 0.4262, 0.4288, 0.4604, 0.3331, 0.4071,\n",
              "                      0.4156, 0.4476, 0.4185, 0.3721, 0.4098, 0.3483, 0.3501, 0.4345, 0.3585,\n",
              "                      0.4253, 0.4478, 0.3633, 0.1912, 0.2393, 0.3778, 0.4734, 0.3775, 0.3589,\n",
              "                      0.4276, 0.3118, 0.1955, 0.4060, 0.3730, 0.3684, 0.3927, 0.2522, 0.5319,\n",
              "                      0.4915, 0.4109, 0.3080, 0.3467, 0.3260, 0.1817, 0.3023, 0.3607, 0.4623,\n",
              "                      0.4232, 0.4486, 0.4226, 0.4312, 0.3785, 0.5044, 0.3948, 0.2172, 0.4515,\n",
              "                      0.4545, 0.4909, 0.4976, 0.4273, 0.4548, 0.3574, 0.1251, 0.4215, 0.3019,\n",
              "                      0.1906, 0.4820, 0.4513, 0.4320, 0.4383, 0.4362, 0.4189, 0.4361, 0.4418,\n",
              "                      0.1731, 0.3208, 0.2544, 0.0438, 0.2978, 0.3807, 0.4591, 0.2259, 0.4411,\n",
              "                      0.4016, 0.3341, 0.3148, 0.4574, 0.3569, 0.3894, 0.2701, 0.5262, 0.4651,\n",
              "                      0.2869, 0.2243, 0.4855, 0.4087, 0.4676, 0.4840, 0.4596, 0.5148, 0.3529,\n",
              "                      0.4587, 0.4687, 0.3538, 0.3698, 0.4627, 0.3154, 0.3631, 0.4037, 0.4891,\n",
              "                      0.4146, 0.4632, 0.4175, 0.3718, 0.4125, 0.3455, 0.4628, 0.3232, 0.3643,\n",
              "                      0.3713, 0.3258, 0.3172, 0.3784, 0.4562, 0.4850, 0.2716, 0.3822, 0.4971,\n",
              "                      0.3070, 0.4407, 0.2492, 0.3151, 0.4177, 0.4225, 0.4751, 0.1869, 0.3323,\n",
              "                      0.4202, 0.4648, 0.4434, 0.4969, 0.4707, 0.3944, 0.2971, 0.3971, 0.3791,\n",
              "                      0.3918, 0.4363, 0.4012, 0.4119, 0.2639, 0.3920, 0.2374, 0.1830, 0.3028,\n",
              "                      0.4523, 0.4083, 0.4626, 0.3386, 0.3879, 0.3716, 0.3415, 0.5017, 0.2072,\n",
              "                      0.4393, 0.2844, 0.2067, 0.5018, 0.4848, 0.4497, 0.0985, 0.4109, 0.4616,\n",
              "                      0.3973, 0.3732, 0.3627, 0.0901, 0.4344, 0.3028, 0.4959, 0.2186, 0.4559,\n",
              "                      0.1909, 0.2890, 0.4264, 0.3929, 0.2532, 0.4453, 0.4437, 0.1839, 0.4602,\n",
              "                      0.1521, 0.5034, 0.3290, 0.4443, 0.0589, 0.3720, 0.3355, 0.3443, 0.4252,\n",
              "                      0.3377, 0.4989, 0.3778, 0.4824, 0.4397, 0.0621, 0.5338, 0.4621, 0.4576,\n",
              "                      0.4243, 0.3696, 0.4579, 0.4712, 0.4473, 0.4596, 0.4852, 0.4037, 0.3987,\n",
              "                      0.4908, 0.4020, 0.4598, 0.4729, 0.0838, 0.3274, 0.2024, 0.4028, 0.5162,\n",
              "                      0.0775, 0.4145, 0.4585, 0.3572, 0.4900, 0.3800, 0.3439, 0.3403, 0.4722,\n",
              "                      0.1602, 0.4700, 0.2197, 0.4645, 0.4403, 0.4426, 0.2409, 0.3529, 0.3861,\n",
              "                      0.2855, 0.3431, 0.1970, 0.4684, 0.3928, 0.4736, 0.3935, 0.3214, 0.4090,\n",
              "                      0.4177, 0.4792, 0.4125, 0.4824, 0.3776, 0.3531, 0.3489, 0.3881, 0.3534,\n",
              "                      0.4682, 0.4806, 0.4609, 0.4580, 0.4085, 0.4014, 0.4122, 0.4075, 0.4011,\n",
              "                      0.4776, 0.4769, 0.4726, 0.5044, 0.3616, 0.4968, 0.4140, 0.4721, 0.4836,\n",
              "                      0.4411, 0.0511, 0.3558, 0.3489, 0.1806, 0.4384, 0.4633, 0.3224, 0.4433,\n",
              "                      0.4475, 0.2464, 0.4998, 0.4055, 0.4301, 0.3679, 0.1748, 0.4913, 0.3978,\n",
              "                      0.3513, 0.3832, 0.4342, 0.4533, 0.4871, 0.4481, 0.3478, 0.3228, 0.0647,\n",
              "                      0.4338, 0.3798, 0.4166, 0.3177, 0.5269, 0.3852, 0.3796, 0.5114, 0.1977,\n",
              "                      0.4797, 0.3771, 0.5007, 0.3835, 0.3748, 0.2246, 0.3533, 0.5410, 0.4003,\n",
              "                      0.4963, 0.4341, 0.4101, 0.1808, 0.3452, 0.1915, 0.4389, 0.3578, 0.2754,\n",
              "                      0.4321, 0.4047, 0.3925, 0.3773, 0.3494, 0.4197, 0.4263, 0.2947, 0.4007,\n",
              "                      0.3796, 0.4570, 0.3439, 0.2745, 0.4302, 0.4849, 0.3675, 0.4160, 0.4555,\n",
              "                      0.0743, 0.2412, 0.3460, 0.4918, 0.3149, 0.4811, 0.4470, 0.3650, 0.4725,\n",
              "                      0.3910, 0.2268, 0.3555, 0.4405, 0.3185, 0.3171, 0.3934, 0.3931, 0.0232,\n",
              "                      0.4009, 0.3835, 0.4479, 0.3624, 0.1812, 0.5095, 0.4458, 0.3985, 0.3911,\n",
              "                      0.4582, 0.3166, 0.4597, 0.1941, 0.4107, 0.5105, 0.4793, 0.4320, 0.5085,\n",
              "                      0.5131, 0.4698, 0.4612, 0.4955, 0.4731, 0.4406, 0.3255, 0.4782, 0.4211,\n",
              "                      0.3808, 0.4293, 0.3503, 0.4258, 0.2285, 0.4334, 0.3469, 0.4605, 0.3865,\n",
              "                      0.2180, 0.3717, 0.5043, 0.4636, 0.3298, 0.2678, 0.4197, 0.3796, 0.4625,\n",
              "                      0.3541, 0.4713, 0.3984, 0.3333, 0.4194, 0.3139, 0.4526, 0.3926, 0.3857,\n",
              "                      0.4451, 0.4515, 0.2863, 0.3831, 0.4237, 0.3830, 0.2683, 0.4004, 0.1766,\n",
              "                      0.3638, 0.4177, 0.3659, 0.2886, 0.4721, 0.1428, 0.4011, 0.3788, 0.1539,\n",
              "                      0.4365, 0.3349, 0.3911, 0.4533, 0.4290, 0.3529, 0.3389, 0.2997, 0.4950,\n",
              "                      0.4452, 0.4852, 0.4179, 0.4562, 0.4013, 0.4073, 0.2728, 0.2375, 0.4429,\n",
              "                      0.3172, 0.2570, 0.3523, 0.1496, 0.0481, 0.3918, 0.3344, 0.4101, 0.3453,\n",
              "                      0.4237, 0.4838, 0.3918, 0.4769, 0.4300, 0.3508, 0.4230, 0.4221, 0.3903,\n",
              "                      0.4921, 0.4302, 0.4498, 0.4238, 0.4373, 0.4148, 0.4506, 0.3842, 0.4707,\n",
              "                      0.3962, 0.2188, 0.3976, 0.3632, 0.4660, 0.3913, 0.4787, 0.3711, 0.2100,\n",
              "                      0.4662, 0.4559, 0.4118, 0.3015, 0.4576, 0.4094, 0.3922, 0.3726, 0.4742,\n",
              "                      0.3930, 0.3859, 0.3961, 0.5079, 0.4629, 0.3186, 0.2922, 0.4721, 0.1927,\n",
              "                      0.4005, 0.4073, 0.4630, 0.0984, 0.3782, 0.3485, 0.3420, 0.4183, 0.1995,\n",
              "                      0.4718, 0.3169, 0.3246, 0.4613, 0.3893, 0.3564, 0.3714, 0.4316, 0.4637,\n",
              "                      0.3390, 0.3463, 0.4487, 0.4451, 0.3884, 0.4325, 0.4370, 0.4024, 0.3905,\n",
              "                      0.4173, 0.3866, 0.3921, 0.3115, 0.3262, 0.3574, 0.4553, 0.3456, 0.3491,\n",
              "                      0.4904, 0.3556, 0.1955, 0.4052, 0.4241, 0.3019, 0.4210, 0.3453, 0.4363,\n",
              "                      0.4014, 0.4389, 0.3426, 0.3614, 0.3662, 0.3575, 0.3834, 0.4869, 0.3425,\n",
              "                      0.3424, 0.4452, 0.3370], device='cuda:0')),\n",
              "             ('decoder.embed_tokens.weight',\n",
              "              tensor([[ -0.7576,   0.6001,  -2.4332,  ...,   1.2522,  -0.7822,   3.5235],\n",
              "                      [ 11.3739,  -4.8733,   9.0615,  ...,   4.8424,  14.3902,  -5.7711],\n",
              "                      [-16.6135,  11.0992, -20.8572,  ...,  10.6604,  22.2536,  24.9938],\n",
              "                      ...,\n",
              "                      [  2.2344,   6.7500, -11.0625,  ..., -11.3125,  13.5625,  16.6250],\n",
              "                      [  4.2500,   5.1250, -12.2500,  ..., -11.9375,  13.5000,  17.0000],\n",
              "                      [  4.0625,   6.9688, -12.2500,  ..., -11.3750,  11.9375,  16.6250]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0567,  0.0207,  0.0941,  ..., -0.0454, -0.0713, -0.0221],\n",
              "                      [-0.0814,  0.0348,  0.0168,  ..., -0.0153, -0.0112,  0.0254],\n",
              "                      [-0.0122, -0.0428, -0.0034,  ...,  0.0695, -0.0126, -0.0205],\n",
              "                      ...,\n",
              "                      [ 0.1042,  0.0197,  0.0848,  ...,  0.0175, -0.0018,  0.0333],\n",
              "                      [-0.0607,  0.0856,  0.0232,  ...,  0.1006, -0.0640, -0.0786],\n",
              "                      [-0.0467,  0.1211,  0.0585,  ...,  0.0093, -0.0337, -0.1073]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.1810,  0.2216, -0.1454,  ..., -0.1404, -0.4983,  0.3283],\n",
              "                      [ 0.2615, -0.1021, -0.0410,  ..., -0.1951,  0.3161, -0.0346],\n",
              "                      [-0.0713,  0.0819,  0.2933,  ...,  0.2626, -0.7638,  0.0550],\n",
              "                      ...,\n",
              "                      [ 0.4862,  0.2117,  0.0063,  ...,  0.7060, -0.2387, -0.1330],\n",
              "                      [-0.0981, -0.2853,  0.1125,  ..., -0.6080, -0.3508, -0.2263],\n",
              "                      [-0.4726, -0.1495,  0.1879,  ..., -0.1816, -0.3182, -0.6885]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.0013, -0.1743, -0.0529,  ..., -0.3097, -0.2426, -0.0604],\n",
              "                      [ 0.4907,  0.3595, -0.1682,  ...,  0.0134, -0.1694,  0.2884],\n",
              "                      [-0.2990, -0.0146, -0.0270,  ..., -0.2273,  0.0065, -0.3731],\n",
              "                      ...,\n",
              "                      [ 0.0959, -0.3725,  0.3890,  ...,  0.3669,  0.3171,  0.0656],\n",
              "                      [-0.0016, -0.4221,  0.1333,  ..., -0.0317,  0.2136,  0.3205],\n",
              "                      [-0.0374,  0.2223, -0.2080,  ..., -0.0051, -0.2145,  0.3862]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.0322, -0.0804, -0.0167,  ..., -0.0774, -0.1688,  0.1817],\n",
              "                      [ 0.0057, -0.6390,  0.5193,  ..., -0.9483, -0.4032, -0.8912],\n",
              "                      [ 0.8850,  1.3334, -0.2480,  ..., -0.1948, -0.8176, -0.4373],\n",
              "                      ...,\n",
              "                      [ 0.2530,  0.1082,  0.1189,  ...,  0.0716, -0.0555,  0.4223],\n",
              "                      [-0.0893, -0.2183, -0.0262,  ..., -0.0726,  0.0731, -0.2982],\n",
              "                      [ 0.0024,  0.2089, -0.0194,  ..., -0.5277, -0.0679, -0.0130]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight',\n",
              "              tensor([[ 2.3195e+00,  3.9357e+00,  2.0138e+00, -2.2007e+01,  1.6664e+00,\n",
              "                        1.6733e+00,  2.4638e+00,  6.6594e-01,  4.1155e+00,  2.4353e+00,\n",
              "                        3.3183e+00,  3.7289e+00],\n",
              "                      [ 3.2912e+00,  3.3970e+00,  4.3501e+00,  6.3501e-01,  1.0630e+00,\n",
              "                        2.6171e+00,  5.3915e+00,  2.3782e+00,  4.0397e+00,  2.7863e+00,\n",
              "                        2.9717e+00,  3.6482e+00],\n",
              "                      [ 2.8001e+00,  2.0127e+00,  3.0579e+00,  1.0517e+00,  9.1370e-01,\n",
              "                        1.9243e+00,  2.1510e+00,  2.2335e+00,  1.7053e+00,  2.0924e+00,\n",
              "                        2.0818e+00,  1.6969e+00],\n",
              "                      [ 2.3531e+00,  1.1537e+00,  2.0373e+00,  1.1760e+00,  7.3951e-01,\n",
              "                        1.4912e+00,  2.8901e-01,  2.0340e+00,  5.9366e-01,  1.5056e+00,\n",
              "                        1.4368e+00,  3.7078e-01],\n",
              "                      [ 1.9607e+00,  5.5017e-01,  1.2206e+00,  1.2556e+00,  5.9195e-01,\n",
              "                        1.1994e+00, -7.4431e-01,  1.8308e+00, -2.3748e-02,  1.0510e+00,\n",
              "                        9.8679e-01, -7.5018e-01],\n",
              "                      [ 1.6285e+00,  4.5468e-02,  5.7924e-01,  1.2910e+00,  5.0564e-01,\n",
              "                        8.7201e-01, -1.3050e+00,  1.6557e+00, -3.1304e-01,  6.5117e-01,\n",
              "                        5.6998e-01, -1.6398e+00],\n",
              "                      [ 1.3403e+00, -2.0346e-01, -4.8097e-02,  1.3126e+00,  3.9217e-01,\n",
              "                        6.8576e-01, -1.6475e+00,  1.4900e+00, -6.4561e-01,  2.8362e-01,\n",
              "                        2.5498e-01, -2.3573e+00],\n",
              "                      [ 1.1009e+00, -5.5697e-01, -6.2337e-01,  1.3174e+00,  3.1469e-01,\n",
              "                        5.3490e-01, -1.8290e+00,  1.2986e+00, -8.8293e-01, -1.0151e-01,\n",
              "                        3.8830e-02, -2.9885e+00],\n",
              "                      [ 8.2245e-01, -7.9873e-01, -9.8570e-01,  1.3229e+00,  2.3811e-01,\n",
              "                        4.1968e-01, -2.0105e+00,  1.1992e+00, -1.0689e+00, -4.7566e-01,\n",
              "                       -2.1163e-01, -3.3411e+00],\n",
              "                      [ 5.5648e-01, -1.0201e+00, -1.3969e+00,  1.2868e+00,  1.3546e-01,\n",
              "                        3.0381e-01, -2.1925e+00,  1.1026e+00, -1.1721e+00, -7.8825e-01,\n",
              "                       -4.0766e-01, -3.7124e+00],\n",
              "                      [ 3.3734e-01, -1.1103e+00, -1.7741e+00,  1.2840e+00,  1.0078e-01,\n",
              "                        1.8537e-01, -2.2513e+00,  9.7143e-01, -1.4044e+00, -1.1104e+00,\n",
              "                       -5.3924e-01, -4.0539e+00],\n",
              "                      [-7.7979e-01, -1.2794e+00, -2.0449e+00,  1.3180e+00, -5.7851e-02,\n",
              "                        8.6913e-02, -2.3258e+00,  8.6922e-01, -1.4198e+00, -3.2681e-01,\n",
              "                       -6.5933e-01, -4.1427e+00],\n",
              "                      [-1.5905e-01, -1.3718e+00, -2.1845e+00,  1.2748e+00, -2.2275e-02,\n",
              "                        7.8636e-03, -2.4272e+00,  7.6521e-01, -1.5152e+00, -1.2382e+00,\n",
              "                       -8.1913e-01, -4.2373e+00],\n",
              "                      [-4.2969e-01, -1.4653e+00, -2.3553e+00,  1.2990e+00, -4.7107e-02,\n",
              "                       -1.0006e-01, -2.3904e+00,  6.7137e-01, -1.5618e+00, -1.4227e+00,\n",
              "                       -8.2108e-01, -4.3969e+00],\n",
              "                      [-6.5149e-01, -1.5762e+00, -2.5730e+00,  1.2717e+00, -8.7167e-02,\n",
              "                       -1.5927e-01, -2.4691e+00,  5.9893e-01, -1.6141e+00, -1.6597e+00,\n",
              "                       -9.6601e-01, -4.5493e+00],\n",
              "                      [-7.6369e-01, -1.7454e+00, -2.7567e+00,  1.2650e+00, -1.8716e-01,\n",
              "                       -2.2994e-01, -2.6053e+00,  5.3765e-01, -1.6573e+00, -1.7265e+00,\n",
              "                       -1.1071e+00, -4.6207e+00],\n",
              "                      [-1.0848e+00, -1.7189e+00, -2.9192e+00,  1.1792e+00, -2.2353e-01,\n",
              "                       -3.1129e-01, -2.5739e+00,  3.7294e-01, -1.7311e+00, -2.0533e+00,\n",
              "                       -1.2072e+00, -4.7278e+00],\n",
              "                      [-1.4906e+00, -1.8968e+00, -3.1444e+00,  1.1466e+00, -3.5704e-01,\n",
              "                       -3.7258e-01, -2.5903e+00,  1.9268e-01, -1.7945e+00, -2.3320e+00,\n",
              "                       -1.3028e+00, -4.8338e+00],\n",
              "                      [-1.7311e+00, -1.9302e+00, -3.2862e+00,  1.0930e+00, -3.6600e-01,\n",
              "                       -4.6752e-01, -2.6591e+00,  9.1689e-02, -1.8756e+00, -2.4959e+00,\n",
              "                       -1.4286e+00, -4.9807e+00],\n",
              "                      [-1.9625e+00, -2.0121e+00, -3.3948e+00,  1.0093e+00, -4.2919e-01,\n",
              "                       -5.3119e-01, -2.6269e+00, -1.3629e-02, -1.8979e+00, -2.6964e+00,\n",
              "                       -1.5291e+00, -5.0393e+00],\n",
              "                      [-2.1481e+00, -2.1207e+00, -3.4351e+00,  9.6276e-01, -5.2628e-01,\n",
              "                       -6.9087e-01, -2.6443e+00, -1.8235e-01, -1.9033e+00, -2.8576e+00,\n",
              "                       -1.6016e+00, -5.0153e+00],\n",
              "                      [-2.3419e+00, -2.1695e+00, -3.5630e+00,  8.5643e-01, -5.8422e-01,\n",
              "                       -7.0306e-01, -2.6114e+00, -2.7833e-01, -2.0071e+00, -2.9781e+00,\n",
              "                       -1.6315e+00, -5.1402e+00],\n",
              "                      [-2.4881e+00, -2.1602e+00, -3.5928e+00,  7.3931e-01, -6.1595e-01,\n",
              "                       -7.6651e-01, -2.5856e+00, -4.2652e-01, -1.9575e+00, -3.0652e+00,\n",
              "                       -1.7659e+00, -5.0794e+00],\n",
              "                      [-2.6944e+00, -2.2505e+00, -3.6433e+00,  5.8163e-01, -6.5211e-01,\n",
              "                       -8.2101e-01, -2.5369e+00, -5.7065e-01, -1.8983e+00, -3.1271e+00,\n",
              "                       -1.6875e+00, -4.9792e+00],\n",
              "                      [-2.6802e+00, -2.1466e+00, -3.5945e+00,  3.9257e-01, -6.9517e-01,\n",
              "                       -8.3462e-01, -2.5320e+00, -5.8328e-01, -1.9221e+00, -3.1045e+00,\n",
              "                       -1.6815e+00, -4.9331e+00],\n",
              "                      [-2.7178e+00, -2.1233e+00, -3.5544e+00,  2.1392e-01, -6.9824e-01,\n",
              "                       -8.2469e-01, -2.4806e+00, -7.0437e-01, -1.8579e+00, -2.7906e+00,\n",
              "                       -1.6564e+00, -4.8142e+00],\n",
              "                      [-2.7035e+00, -2.0639e+00, -3.3500e+00, -3.1165e-02, -7.3472e-01,\n",
              "                       -7.9953e-01, -2.4683e+00, -7.9702e-01, -1.8046e+00, -2.3620e+00,\n",
              "                       -1.5795e+00, -4.6205e+00],\n",
              "                      [-2.6002e+00, -1.9561e+00, -3.2033e+00, -3.1044e-01, -7.2800e-01,\n",
              "                       -7.4023e-01, -2.3759e+00, -8.4286e-01, -1.7237e+00, -1.6496e+00,\n",
              "                       -1.4569e+00, -4.3507e+00],\n",
              "                      [-2.4738e+00, -1.8395e+00, -3.0057e+00, -6.5076e-01, -7.0646e-01,\n",
              "                       -6.5223e-01, -2.3147e+00, -8.8582e-01, -1.6272e+00, -6.2514e-01,\n",
              "                       -1.3187e+00, -4.1414e+00],\n",
              "                      [-2.2203e+00, -1.6269e+00, -2.6906e+00, -9.7339e-01, -7.2755e-01,\n",
              "                       -4.8598e-01, -2.1871e+00, -8.6022e-01, -1.5963e+00,  9.2740e-01,\n",
              "                       -1.0862e+00, -3.7165e+00],\n",
              "                      [-1.6788e+00, -1.3123e+00, -2.0655e+00, -1.4437e+00, -6.5944e-01,\n",
              "                       -2.4867e-01, -1.9406e+00, -8.4206e-01, -1.2634e+00,  4.4729e+00,\n",
              "                       -6.7626e-01, -2.9702e+00],\n",
              "                      [ 7.3686e+00,  3.2750e+01,  2.8751e+01, -3.6250e+01,  3.2749e+01,\n",
              "                       -2.7625e+01, -3.6750e+01, -3.0875e+01, -4.0750e+01, -2.6375e+01,\n",
              "                       -2.5000e+01,  3.1375e+01]], device='cuda:0')),\n",
              "             ('decoder.block.0.layer.0.layer_norm.weight',\n",
              "              tensor([0.1030, 0.0952, 0.0973, 0.0803, 0.0933, 0.0956, 0.0969, 0.1164, 0.0918,\n",
              "                      0.1009, 0.1022, 0.1021, 0.1347, 0.1246, 0.0892, 0.0967, 0.1021, 0.1025,\n",
              "                      0.1261, 0.0937, 0.0799, 0.0915, 0.1482, 0.0801, 0.0804, 0.1284, 0.0850,\n",
              "                      0.1194, 0.1012, 0.0928, 0.1025, 0.0396, 0.1034, 0.0979, 0.1153, 0.0915,\n",
              "                      0.1028, 0.1008, 0.0746, 0.1317, 0.1166, 0.1083, 0.0979, 0.1136, 0.0954,\n",
              "                      0.0790, 0.1293, 0.1051, 0.0864, 0.1032, 0.1310, 0.0985, 0.1087, 0.0836,\n",
              "                      0.1702, 0.1035, 0.1132, 0.1011, 0.0969, 0.0887, 0.1134, 0.0724, 0.1045,\n",
              "                      0.0862, 0.0932, 0.0756, 0.0888, 0.0946, 0.2092, 0.0683, 0.0976, 0.1174,\n",
              "                      0.0951, 0.0991, 0.0964, 0.0947, 0.1152, 0.0988, 0.0738, 0.1096, 0.0999,\n",
              "                      0.1101, 0.1027, 0.1339, 0.0999, 0.0952, 0.1007, 0.0996, 0.1017, 0.0770,\n",
              "                      0.0878, 0.0976, 0.0814, 0.1103, 0.0933, 0.0954, 0.0893, 0.1028, 0.0770,\n",
              "                      0.0820, 0.1112, 0.0872, 0.1082, 0.0829, 0.0938, 0.1718, 0.0932, 0.0993,\n",
              "                      0.0888, 0.1256, 0.0993, 0.1071, 0.0981, 0.0947, 0.0855, 0.0842, 0.1040,\n",
              "                      0.0877, 0.2108, 0.0981, 0.0720, 0.0752, 0.1467, 0.0937, 0.0946, 0.0942,\n",
              "                      0.1024, 0.0856, 0.0908, 0.1091, 0.0729, 0.1120, 0.0885, 0.0847, 0.0474,\n",
              "                      0.1121, 0.0834, 0.1056, 0.1161, 0.0989, 0.1046, 0.1002, 0.1185, 0.1777,\n",
              "                      0.1074, 0.1021, 0.0792, 0.1152, 0.0882, 0.1003, 0.0868, 0.0938, 0.1019,\n",
              "                      0.1081, 0.0886, 0.0942, 0.1244, 0.0781, 0.0475, 0.0854, 0.0798, 0.1085,\n",
              "                      0.1082, 0.1372, 0.0680, 0.0680, 0.0919, 0.1193, 0.1024, 0.1019, 0.1888,\n",
              "                      0.0863, 0.1030, 0.1386, 0.0883, 0.1140, 0.0973, 0.1232, 0.1355, 0.0904,\n",
              "                      0.0945, 0.0851, 0.0931, 0.1004, 0.1374, 0.1540, 0.0891, 0.0975, 0.0933,\n",
              "                      0.1037, 0.0868, 0.0803, 0.0780, 0.0997, 0.0839, 0.0903, 0.0933, 0.1070,\n",
              "                      0.1030, 0.0858, 0.0926, 0.0825, 0.0993, 0.0774, 0.0946, 0.1242, 0.0973,\n",
              "                      0.1034, 0.0991, 0.1011, 0.1062, 0.0901, 0.1150, 0.0982, 0.0855, 0.1133,\n",
              "                      0.0766, 0.0862, 0.1050, 0.0742, 0.0960, 0.1020, 0.0820, 0.0864, 0.1018,\n",
              "                      0.0901, 0.1194, 0.1255, 0.0951, 0.1190, 0.0970, 0.1007, 0.0984, 0.0784,\n",
              "                      0.0794, 0.0710, 0.1281, 0.0965, 0.0832, 0.1149, 0.1363, 0.1058, 0.0892,\n",
              "                      0.0997, 0.0928, 0.0895, 0.1039, 0.0983, 0.0640, 0.1087, 0.1103, 0.0935,\n",
              "                      0.0982, 0.0928, 0.0912, 0.0951, 0.0868, 0.0842, 0.0980, 0.0965, 0.1087,\n",
              "                      0.1395, 0.0891, 0.0958, 0.0935, 0.0870, 0.0682, 0.0873, 0.0866, 0.1081,\n",
              "                      0.0805, 0.1299, 0.1154, 0.0806, 0.2279, 0.1108, 0.0894, 0.1091, 0.0865,\n",
              "                      0.0873, 0.1033, 0.1696, 0.0962, 0.0975, 0.1044, 0.1229, 0.0799, 0.0837,\n",
              "                      0.0842, 0.1159, 0.0878, 0.0866, 0.0848, 0.0920, 0.1018, 0.0988, 0.1227,\n",
              "                      0.0930, 0.0793, 0.1232, 0.1226, 0.0877, 0.0646, 0.1022, 0.1081, 0.0851,\n",
              "                      0.1013, 0.0887, 0.1079, 0.0937, 0.1048, 0.1032, 0.0818, 0.1083, 0.1410,\n",
              "                      0.0880, 0.1094, 0.1230, 0.0848, 0.0829, 0.0641, 0.1133, 0.0899, 0.0736,\n",
              "                      0.1035, 0.0898, 0.1013, 0.1396, 0.0949, 0.1012, 0.1000, 0.1041, 0.0914,\n",
              "                      0.0869, 0.0920, 0.0877, 0.0877, 0.0846, 0.0980, 0.1924, 0.1087, 0.1199,\n",
              "                      0.1075, 0.0828, 0.1008, 0.1025, 0.1012, 0.0907, 0.1013, 0.0848, 0.1103,\n",
              "                      0.0735, 0.0944, 0.1002, 0.1128, 0.1099, 0.1036, 0.3933, 0.1006, 0.1086,\n",
              "                      0.1017, 0.1195, 0.0596, 0.0761, 0.0935, 0.1038, 0.1440, 0.0966, 0.0834,\n",
              "                      0.0836, 0.1062, 0.1159, 0.1114, 0.0991, 0.1207, 0.0888, 0.1093, 0.0827,\n",
              "                      0.1359, 0.1405, 0.0936, 0.0935, 0.1481, 0.1031, 0.0845, 0.1108, 0.0848,\n",
              "                      0.1078, 0.0717, 0.1077, 0.1014, 0.0975, 0.0876, 0.1749, 0.1252, 0.0976,\n",
              "                      0.1003, 0.0958, 0.0947, 0.0677, 0.0793, 0.0991, 0.0816, 0.0937, 0.0954,\n",
              "                      0.0877, 0.1030, 0.0905, 0.0863, 0.0898, 0.0892, 0.0765, 0.1224, 0.1046,\n",
              "                      0.0903, 0.1059, 0.0952, 0.0978, 0.0682, 0.1112, 0.1195, 0.0922, 0.0844,\n",
              "                      0.1827, 0.0888, 0.0948, 0.1150, 0.0850, 0.0910, 0.1013, 0.1208, 0.0872,\n",
              "                      0.1108, 0.0839, 0.1284, 0.0916, 0.0954, 0.0923, 0.1101, 0.1345, 0.1110,\n",
              "                      0.1343, 0.0888, 0.1141, 0.0950, 0.1136, 0.0875, 0.1030, 0.3774, 0.0918,\n",
              "                      0.0968, 0.0967, 0.0834, 0.0890, 0.0981, 0.1233, 0.1786, 0.0817, 0.1052,\n",
              "                      0.0717, 0.0858, 0.0878, 0.1131, 0.1040, 0.0983, 0.0979, 0.0955, 0.1117,\n",
              "                      0.0804, 0.0775, 0.0774, 0.0817, 0.0834, 0.0709, 0.0882, 0.0889, 0.1001,\n",
              "                      0.0920, 0.0990, 0.1010, 0.0832, 0.1107, 0.1051, 0.0905, 0.1398, 0.0925,\n",
              "                      0.0801, 0.0989, 0.0729, 0.0922, 0.1098, 0.1103, 0.1139, 0.0974, 0.1046,\n",
              "                      0.0758, 0.0977, 0.1009, 0.0807, 0.0989, 0.0881, 0.1246, 0.1066, 0.0954,\n",
              "                      0.1062, 0.1151, 0.0956, 0.0883, 0.0780, 0.0902, 0.0939, 0.0717, 0.0893,\n",
              "                      0.0942, 0.1014, 0.0827, 0.0874, 0.0948, 0.1783, 0.1062, 0.0844, 0.0888,\n",
              "                      0.0893, 0.1151, 0.0981, 0.0992, 0.1160, 0.1114, 0.0974, 0.1108, 0.0911,\n",
              "                      0.1114, 0.0991, 0.1015, 0.0882, 0.0893, 0.1010, 0.0971, 0.0987, 0.0993,\n",
              "                      0.1066, 0.0958, 0.1026, 0.1343, 0.0866, 0.0840, 0.1202, 0.0947, 0.0935,\n",
              "                      0.1084, 0.1359, 0.1998, 0.0713, 0.2125, 0.0844, 0.1030, 0.1227, 0.0722,\n",
              "                      0.1125, 0.1044, 0.1087, 0.1016, 0.1136, 0.1547, 0.1009, 0.1464, 0.0998,\n",
              "                      0.1046, 0.1273, 0.0918, 0.1013, 0.1103, 0.0783, 0.1043, 0.0999, 0.1300,\n",
              "                      0.0910, 0.1067, 0.0863, 0.1537, 0.0982, 0.0825, 0.0915, 0.0933, 0.0756,\n",
              "                      0.0926, 0.0769, 0.0930, 0.0852, 0.0921, 0.0915, 0.0947, 0.0945, 0.0905,\n",
              "                      0.0945, 0.1007, 0.0903, 0.0886, 0.2359, 0.0956, 0.0928, 0.0958, 0.1003,\n",
              "                      0.0836, 0.1103, 0.0791, 0.0882, 0.0583, 0.1214, 0.1121, 0.0811, 0.0982,\n",
              "                      0.0987, 0.0695, 0.0921, 0.1188, 0.0981, 0.0747, 0.0825, 0.0932, 0.1017,\n",
              "                      0.0741, 0.0769, 0.1298, 0.1046, 0.0807, 0.0833, 0.1016, 0.0839, 0.1277,\n",
              "                      0.0947, 0.0803, 0.1109, 0.1447, 0.1043, 0.1030, 0.0970, 0.0948, 0.1229,\n",
              "                      0.0850, 0.0843, 0.1088, 0.0770, 0.0940, 0.1074, 0.0997, 0.0859, 0.0926,\n",
              "                      0.0692, 0.0987, 0.0313, 0.1005, 0.0985, 0.1227, 0.0970, 0.1270, 0.1007,\n",
              "                      0.0645, 0.0993, 0.1280, 0.1242, 0.1035, 0.0915, 0.2046, 0.0791, 0.1009,\n",
              "                      0.0952, 0.0837, 0.0840, 0.0865, 0.0938, 0.1031, 0.0983, 0.0773, 0.0849,\n",
              "                      0.0966, 0.0866, 0.0906, 0.0939, 0.1004, 0.0898, 0.0929, 0.1068, 0.0678,\n",
              "                      0.0881, 0.0862, 0.0921, 0.1002, 0.0916, 0.1077, 0.0947, 0.0992, 0.1484,\n",
              "                      0.0791, 0.0888, 0.0968, 0.1131, 0.0873, 0.0967, 0.1144, 0.0941, 0.0774,\n",
              "                      0.0933, 0.0411, 0.0968, 0.0709, 0.0856, 0.1578, 0.1307, 0.0870, 0.1056,\n",
              "                      0.0870, 0.0383, 0.0772, 0.1555, 0.0909, 0.1025, 0.1191, 0.0838, 0.1134,\n",
              "                      0.0917, 0.0955, 0.1637, 0.0784, 0.1153, 0.0890, 0.0972, 0.0848, 0.0991,\n",
              "                      0.1154, 0.0933, 0.1004, 0.0957, 0.0829, 0.1007, 0.0896, 0.0932, 0.0822,\n",
              "                      0.1024, 0.1159, 0.0962, 0.1126, 0.1074, 0.1521, 0.0992, 0.1218, 0.0993,\n",
              "                      0.0699, 0.1365, 0.1040, 0.0842, 0.0935, 0.1301, 0.0971, 0.1083, 0.0876,\n",
              "                      0.1103, 0.0795, 0.1243, 0.1100, 0.1009, 0.0726, 0.0917, 0.0798, 0.0945,\n",
              "                      0.0946, 0.0860, 0.1257], device='cuda:0')),\n",
              "             ('decoder.block.0.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[ 0.0499,  0.0040,  0.0538,  ..., -0.0071, -0.0161, -0.0548],\n",
              "                      [-0.0147,  0.0109, -0.0469,  ...,  0.0064, -0.0005,  0.0057],\n",
              "                      [-0.0914,  0.0205, -0.0071,  ...,  0.0136,  0.0267,  0.0510],\n",
              "                      ...,\n",
              "                      [ 0.0238,  0.0067, -0.0771,  ..., -0.0318,  0.0154,  0.0059],\n",
              "                      [ 0.0524,  0.0353, -0.0114,  ...,  0.0425,  0.0455, -0.0028],\n",
              "                      [-0.0597,  0.0092,  0.0010,  ...,  0.0120, -0.0874,  0.0116]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[ 0.2956,  0.0932, -0.0468,  ...,  0.1599,  0.1430, -0.1751],\n",
              "                      [ 0.1090, -0.0743,  0.2979,  ..., -0.4440,  0.3777, -0.7024],\n",
              "                      [ 0.2982, -0.2391, -0.1584,  ..., -0.1872, -0.0691, -0.1678],\n",
              "                      ...,\n",
              "                      [-0.0813, -0.1883, -0.0461,  ...,  0.1521,  0.3525,  0.0357],\n",
              "                      [ 0.0650, -0.0838,  0.2096,  ...,  0.1624, -0.1112, -0.0111],\n",
              "                      [-0.2363,  0.3531,  0.3340,  ...,  0.2609,  0.0929, -0.1646]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[-0.1120, -0.0136, -0.1595,  ..., -0.2544,  0.2927,  0.5096],\n",
              "                      [ 0.5188, -0.0350,  0.2803,  ..., -0.2602,  0.0301,  0.2545],\n",
              "                      [ 0.2197,  0.3995, -0.1186,  ..., -0.1150,  0.3247, -0.2041],\n",
              "                      ...,\n",
              "                      [ 0.0833, -0.0019,  0.2737,  ...,  0.3155, -0.0936,  0.0901],\n",
              "                      [-0.1358,  0.0852,  0.2907,  ...,  0.1367,  0.0994, -0.0593],\n",
              "                      [-0.0934,  0.3124, -0.1561,  ..., -0.2522, -0.0996, -0.2278]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[ 0.1139, -0.2195, -0.2180,  ...,  0.0790,  0.2250,  0.3021],\n",
              "                      [-0.9352,  1.1930,  0.1456,  ...,  1.7914, -0.4874, -0.7594],\n",
              "                      [-1.3115,  0.2572, -0.1445,  ...,  1.7960,  0.6426,  1.8173],\n",
              "                      ...,\n",
              "                      [ 0.4957, -0.1610,  0.2508,  ...,  0.1059,  0.4486,  0.0710],\n",
              "                      [-0.6608, -0.2175, -0.0581,  ..., -0.3441, -0.4345,  0.0965],\n",
              "                      [ 0.0924,  0.0457,  0.2873,  ...,  0.5073,  0.3530,  0.2455]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.1.EncDecAttention.relative_attention_bias.weight',\n",
              "              tensor([[ 1.1492e-01,  1.6548e-02,  1.2875e-02, -1.1532e-02,  1.5108e-02,\n",
              "                        6.6258e-02,  1.1841e-02, -4.1232e-02, -4.3252e-02,  3.1554e-02,\n",
              "                       -2.7081e-02,  2.6070e-02],\n",
              "                      [-3.3526e-02, -8.7097e-02, -1.2138e-02, -3.6928e-02,  3.9904e-02,\n",
              "                        9.0536e-02,  3.7910e-02,  5.2872e-02,  4.0217e-02, -2.8770e-02,\n",
              "                        2.8966e-02, -1.9851e-02],\n",
              "                      [ 4.0831e-03,  6.7791e-02, -4.2759e-02,  5.4095e-03,  8.9569e-04,\n",
              "                       -4.4593e-03, -6.5244e-03,  4.4756e-03,  4.9494e-02, -4.9957e-02,\n",
              "                        7.4977e-02, -1.3036e-02],\n",
              "                      [-1.2477e-02, -1.2275e-02, -5.0813e-02, -1.5115e-03,  3.9211e-02,\n",
              "                       -1.3755e-02,  4.0532e-02,  1.3705e-04,  6.9848e-02,  4.7084e-02,\n",
              "                       -4.1997e-03, -1.9635e-02],\n",
              "                      [ 4.2106e-03,  7.2437e-02, -4.6862e-02, -5.2097e-03, -1.6386e-02,\n",
              "                        3.6760e-02,  2.9415e-03, -6.4039e-03, -2.3718e-02, -2.2817e-02,\n",
              "                       -3.1663e-02,  1.3429e-02],\n",
              "                      [ 2.3275e-02,  2.9178e-02,  3.3420e-02,  2.3986e-02,  4.7861e-02,\n",
              "                       -8.9027e-03, -1.7207e-02,  6.4024e-03, -3.1208e-03, -1.4360e-02,\n",
              "                        3.9012e-02, -2.9094e-02],\n",
              "                      [ 2.1326e-02,  3.8657e-02,  3.6932e-02,  1.0259e-03, -2.0926e-02,\n",
              "                       -8.6022e-02, -6.8467e-03,  2.7370e-02,  6.5457e-02, -7.6415e-03,\n",
              "                       -9.7554e-03,  4.0679e-02],\n",
              "                      [-7.9793e-02,  1.2179e-03, -3.3854e-03, -3.5971e-02,  4.1962e-03,\n",
              "                        2.1877e-02, -3.4671e-03, -4.7714e-02,  6.3386e-03,  1.5941e-02,\n",
              "                        8.1437e-02, -2.8997e-02],\n",
              "                      [-4.6171e-02, -2.7976e-02,  1.0756e-02, -1.7393e-02,  1.5252e-02,\n",
              "                       -2.8494e-02, -3.2464e-02,  1.5674e-02, -1.9382e-02,  2.3034e-02,\n",
              "                       -1.0696e-02,  1.8621e-02],\n",
              "                      [-5.7004e-02,  1.4830e-02,  1.9000e-03, -5.9063e-02,  3.2523e-02,\n",
              "                       -2.6196e-02,  5.8778e-02,  5.6525e-02, -5.0663e-02, -1.8516e-02,\n",
              "                       -4.5951e-02, -2.9819e-02],\n",
              "                      [-3.1459e-03,  3.8560e-02, -4.1952e-03, -2.5680e-02,  4.2123e-02,\n",
              "                       -7.4795e-02,  3.4773e-02,  2.0915e-03, -3.5102e-02,  2.1578e-02,\n",
              "                        5.6145e-02, -1.1702e-02],\n",
              "                      [ 5.1249e-02, -9.9026e-03, -4.4994e-03,  3.2157e-02, -1.0489e-02,\n",
              "                        7.7082e-03, -3.5117e-02, -2.3834e-02,  2.0392e-02, -1.1825e-01,\n",
              "                        2.1637e-02, -5.6435e-02],\n",
              "                      [-5.5469e-02, -2.4030e-02, -2.7603e-02, -1.4456e-02, -1.1288e-02,\n",
              "                        6.3927e-03,  1.9756e-02,  5.3824e-02,  8.6647e-03, -3.4056e-03,\n",
              "                       -2.6393e-02, -2.9316e-02],\n",
              "                      [ 2.3446e-02, -5.4303e-02,  8.1300e-03, -3.5055e-02, -4.9646e-02,\n",
              "                       -2.3872e-02,  3.5662e-02, -1.2580e-02,  1.6349e-02, -7.3377e-02,\n",
              "                       -6.0383e-02, -2.7057e-03],\n",
              "                      [-1.0864e-04,  4.6273e-02,  1.6895e-02,  5.6706e-02,  5.4138e-02,\n",
              "                        2.0077e-03,  6.3043e-02, -1.5519e-02,  1.5824e-02, -5.2042e-03,\n",
              "                       -5.6505e-02, -3.7496e-02],\n",
              "                      [-3.1824e-03,  5.9412e-02,  9.6550e-03, -7.0863e-03,  3.3466e-02,\n",
              "                       -1.3533e-03,  1.9622e-02, -1.3585e-02,  1.8817e-02,  3.5015e-02,\n",
              "                       -3.0569e-02,  1.2924e-02],\n",
              "                      [-1.1588e-02, -1.6435e-02, -7.7915e-02, -1.8825e-02,  2.5251e-02,\n",
              "                       -2.0880e-02,  3.9057e-03, -8.8445e-03, -1.4082e-02,  3.4305e-02,\n",
              "                       -2.5423e-02, -6.6071e-02],\n",
              "                      [-4.0756e-03,  2.7981e-02, -2.0787e-02, -5.2080e-02, -2.4327e-03,\n",
              "                       -3.4489e-02, -3.1445e-02, -3.0888e-02,  2.4298e-02, -1.2521e-03,\n",
              "                        9.2038e-03, -2.5712e-02],\n",
              "                      [ 5.5966e-02,  1.5370e-02, -5.9148e-02,  1.5499e-02,  1.4231e-03,\n",
              "                        7.1391e-02, -3.4367e-02,  1.5561e-02,  2.4526e-02,  3.9322e-02,\n",
              "                        2.3795e-02, -2.5373e-04],\n",
              "                      [-3.2901e-02, -2.2862e-02,  3.6028e-02, -6.0652e-02,  7.7039e-03,\n",
              "                       -1.9225e-02, -3.5606e-02,  4.1832e-02, -7.6069e-03, -1.2087e-03,\n",
              "                        1.2772e-02, -6.8629e-02],\n",
              "                      [ 6.9827e-02, -1.4721e-02,  1.4598e-02,  3.2771e-02, -1.9447e-02,\n",
              "                       -1.0991e-02, -1.1882e-02, -7.8571e-03,  1.6974e-02, -4.6518e-02,\n",
              "                       -3.5326e-02, -1.3471e-03],\n",
              "                      [ 2.9860e-02,  6.7019e-03, -6.4126e-02, -5.3619e-02,  5.7929e-02,\n",
              "                        1.2419e-02,  4.5782e-02, -4.3594e-02, -4.9259e-02,  5.8095e-03,\n",
              "                       -2.1373e-02,  3.8630e-02],\n",
              "                      [ 5.0406e-02,  1.3030e-03,  6.6408e-02,  1.3506e-02,  1.3349e-02,\n",
              "                        3.0728e-02, -7.2427e-02,  2.5765e-02,  9.6639e-03, -3.5122e-02,\n",
              "                        1.7313e-02,  4.0193e-02],\n",
              "                      [-2.0599e-02,  1.4197e-02, -6.4505e-04,  1.5621e-02,  1.7873e-02,\n",
              "                        5.9690e-03, -2.5839e-02, -2.1552e-02, -3.0766e-03, -2.1123e-03,\n",
              "                       -3.1622e-02, -3.5953e-02],\n",
              "                      [-6.1277e-02,  3.6242e-02, -6.4231e-03, -6.3638e-02, -1.6165e-02,\n",
              "                       -1.4214e-02, -1.7514e-02,  3.8364e-02, -5.5607e-02, -2.9266e-02,\n",
              "                       -5.1656e-02,  4.1204e-02],\n",
              "                      [-1.8712e-02,  2.3495e-02, -2.9992e-02, -5.4773e-02,  4.0520e-02,\n",
              "                        5.4403e-02, -8.2392e-02, -1.2935e-02,  1.0862e-02, -3.3924e-02,\n",
              "                        3.3747e-02, -1.0680e-01],\n",
              "                      [ 5.7843e-03, -2.6707e-02, -3.1689e-02, -1.4743e-02, -2.2080e-02,\n",
              "                        7.4780e-03, -8.2701e-03, -5.7712e-02, -1.7752e-02, -5.4355e-02,\n",
              "                        4.3286e-03, -7.7499e-02],\n",
              "                      [ 2.3011e-02,  7.0738e-03,  9.3775e-02, -8.2630e-03, -3.1464e-02,\n",
              "                       -2.9818e-02,  2.6105e-02, -1.6021e-02, -2.6886e-02, -5.6980e-02,\n",
              "                       -2.2939e-02, -5.5467e-02],\n",
              "                      [-2.8422e-03,  3.9264e-02,  5.1737e-02,  5.4326e-03, -7.3349e-02,\n",
              "                        5.7807e-03, -7.2476e-02, -5.7666e-02, -1.6944e-03,  5.3489e-02,\n",
              "                       -1.0586e-01, -2.5335e-02],\n",
              "                      [ 4.9242e-02,  2.7054e-02,  2.3352e-02, -2.2565e-02, -1.8900e-02,\n",
              "                        4.2785e-03,  2.3249e-02, -3.2311e-02, -4.6348e-02,  3.2714e-04,\n",
              "                        8.4246e-03,  2.1043e-02],\n",
              "                      [-1.8235e-02,  2.5313e-02,  1.4383e-02,  1.1943e-02,  9.1023e-03,\n",
              "                        5.4067e-02, -1.1145e-02, -4.4906e-02,  5.6400e-03, -4.1120e-02,\n",
              "                       -1.6835e-02, -4.4875e-02],\n",
              "                      [-2.6363e-02, -1.7720e-02,  2.6122e-02,  3.2802e-02,  1.7987e-02,\n",
              "                       -1.5619e-02, -3.2252e-02, -5.4815e-04, -4.5376e-03,  7.6785e-02,\n",
              "                       -8.6013e-03,  1.3960e-02]], device='cuda:0')),\n",
              "             ('decoder.block.0.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.0679,  0.0496,  0.0526,  0.1439,  0.0596,  0.0762,  0.0738,  0.0825,\n",
              "                       0.0688,  0.0754,  0.0831,  0.0742,  0.0769,  0.0800,  0.0702,  0.0654,\n",
              "                       0.0694,  0.0687,  0.0829,  0.0729,  0.0689,  0.0693,  0.0917,  0.0699,\n",
              "                       0.0617,  0.0717,  0.0590,  0.0658,  0.0732,  0.0734,  0.0587,  0.0376,\n",
              "                       0.0688,  0.0583,  0.0751,  0.0687,  0.0663,  0.0646,  0.0675,  0.0808,\n",
              "                       0.1051,  0.0780,  0.0726,  0.0709,  0.0451,  0.0736,  0.0848,  0.0732,\n",
              "                       0.0741,  0.0752,  0.1071,  0.0668,  0.0713,  0.0756,  0.4859,  0.0686,\n",
              "                       0.1096,  0.0613,  0.0595,  0.0758,  0.0717,  0.0658,  0.0657,  0.0688,\n",
              "                       0.0608,  0.0350,  0.0716,  0.0643,  0.0438,  0.0531,  0.0690,  0.0821,\n",
              "                       0.0525,  0.0698,  0.0628,  0.0712,  0.0880,  0.0764,  0.0645,  0.0636,\n",
              "                       0.0814,  0.0639,  0.0794,  0.0957,  0.0648,  0.0652,  0.1701,  0.0694,\n",
              "                       0.0645,  0.0551,  0.0652,  0.0631,  0.0761,  0.0819,  0.0716,  0.0627,\n",
              "                       0.0586,  0.0788,  0.0596,  0.0680,  0.0800,  0.0648,  0.0397,  0.0646,\n",
              "                       0.0807,  0.1041,  0.0713,  0.0660,  0.0565,  0.0779,  0.0674,  0.0727,\n",
              "                       0.0844,  0.0621,  0.0653,  0.0583,  0.0664,  0.0700,  0.0173,  0.0677,\n",
              "                       0.0670,  0.0640,  0.0786,  0.0598,  0.0808,  0.0708,  0.0769,  0.0677,\n",
              "                       0.0772,  0.0769,  0.0868,  0.0770,  0.0551,  0.0630,  0.0544,  0.0997,\n",
              "                       0.0734,  0.0663,  0.0752,  0.0805,  0.0608,  0.0828,  0.0859,  0.1065,\n",
              "                       0.0701,  0.0762,  0.0685,  0.0691,  0.0613,  0.0770,  0.0713,  0.0721,\n",
              "                       0.0700,  0.1160,  0.0586,  0.0594,  0.0734,  0.0569,  0.0789,  0.0752,\n",
              "                       0.0599,  0.0740,  0.0682,  0.0771,  0.0623,  0.0445,  0.0708,  0.0872,\n",
              "                       0.0246,  0.0926,  0.0640,  0.0798,  0.0698,  0.0766,  0.0580,  0.0683,\n",
              "                       0.0743,  0.0887,  0.0547,  0.0584,  0.0698,  0.0626,  0.0661,  0.0616,\n",
              "                       0.0742,  0.0825,  0.0599,  0.0705,  0.0699,  0.0723,  0.0780,  0.0706,\n",
              "                       0.0503,  0.0782,  0.0704,  0.0704,  0.0658,  0.0701,  0.0692,  0.0606,\n",
              "                       0.0568,  0.0753,  0.0687,  0.0557,  0.0572,  0.0842,  0.0822,  0.0661,\n",
              "                       0.0709,  0.0670,  0.0799,  0.0709,  0.0754,  0.0730,  0.0583,  0.0681,\n",
              "                       0.0669,  0.0707,  0.0699,  0.0157,  0.0671,  0.0685,  0.0568,  0.0600,\n",
              "                       0.0729,  0.0684,  0.0339,  0.0724,  0.0735,  0.0885,  0.0643,  0.0664,\n",
              "                       0.0818,  0.0559,  0.0567,  0.0658,  0.0788,  0.0845,  0.0970,  0.0732,\n",
              "                       0.1619,  0.0857,  0.0658,  0.0698,  0.0715,  0.0703,  0.0637,  0.0778,\n",
              "                       0.0618,  0.0840,  0.0785,  0.0790,  0.0659,  0.0634,  0.0708,  0.0657,\n",
              "                       0.0809,  0.0908,  0.0771,  0.0603,  0.1237,  0.0863,  0.0738,  0.0747,\n",
              "                       0.0679,  0.0566,  0.0676,  0.0733,  0.0690,  0.0693,  0.0830,  0.0245,\n",
              "                       0.0795,  0.0643,  0.0549,  0.0747,  0.0772,  0.0848,  0.0605,  0.0741,\n",
              "                       0.0558,  0.0741,  0.0537,  0.0736,  0.0774,  0.0962,  0.0610,  0.0589,\n",
              "                       0.0590,  0.0864,  0.0632,  0.0647,  0.0619,  0.0599,  0.0684,  0.0605,\n",
              "                       0.0334,  0.0662,  0.0753,  0.0857,  0.0728,  0.0560,  0.0443,  0.0746,\n",
              "                       0.0684,  0.0634,  0.0660,  0.0649,  0.0854,  0.0698,  0.0633,  0.0835,\n",
              "                       0.0736,  0.0792,  0.0677,  0.0730,  0.0756,  0.1552,  0.0659,  0.0657,\n",
              "                       0.0536,  0.0804,  0.0760,  0.0634,  0.0751,  0.0700,  0.0934,  0.0855,\n",
              "                       0.0782,  0.0782,  0.0621,  0.1039,  0.0727,  0.0731,  0.0645,  0.0616,\n",
              "                       0.0524,  0.0673,  0.0744,  0.1119,  0.0614,  0.0721,  0.0741,  0.0751,\n",
              "                       0.0804,  0.0742,  0.0713,  0.0827,  0.0918,  0.0783,  0.0908,  0.0607,\n",
              "                       0.0561,  0.0550,  0.0892,  0.0599,  0.0739,  0.0164,  0.0593,  0.0770,\n",
              "                       0.0731,  0.0932,  0.0695,  0.0710,  0.0669,  0.0552,  0.0909,  0.0680,\n",
              "                       0.0735,  0.0750,  0.0724,  0.0743,  0.0766,  0.0774,  0.0883,  0.0667,\n",
              "                       0.0863,  0.0656,  0.0794,  0.0928,  0.0691,  0.0745,  0.0872,  0.0718,\n",
              "                       0.0602,  0.0919,  0.0676,  0.0807,  0.0593,  0.0694,  0.0646,  0.0688,\n",
              "                       0.0721,  0.1341,  0.0810,  0.0701,  0.0698,  0.0483,  0.0689,  0.0691,\n",
              "                       0.0617,  0.0709,  0.0563,  0.0643,  0.0671,  0.0752,  0.0772,  0.0603,\n",
              "                       0.0679,  0.0636,  0.0758,  0.0675,  0.0787,  0.0747,  0.0653,  0.0758,\n",
              "                       0.0640,  0.0591,  0.0372,  0.0731,  0.0347,  0.0656,  0.0630,  0.0443,\n",
              "                       0.0820,  0.0686,  0.0948,  0.0618,  0.0741,  0.0837,  0.0712,  0.0723,\n",
              "                       0.0794,  0.0612,  0.0919,  0.0723,  0.0684,  0.0689,  0.0750,  0.0772,\n",
              "                       0.0745,  0.0970,  0.0726,  0.0713,  0.0560,  0.0800,  0.0712,  0.0679,\n",
              "                       0.0204,  0.0662,  0.0748,  0.0664,  0.0656,  0.0555,  0.0749,  0.0854,\n",
              "                       0.0889,  0.0544,  0.0842,  0.0728,  0.0536,  0.0673,  0.0626,  0.0742,\n",
              "                       0.0803,  0.0734,  0.0685,  0.0688,  0.0550,  0.0665,  0.0584,  0.0735,\n",
              "                       0.0361,  0.0478,  0.0729,  0.0610,  0.0736,  0.0700,  0.0734,  0.0670,\n",
              "                       0.0794,  0.0870,  0.0642,  0.0507,  0.0279,  0.0629,  0.0653,  0.0726,\n",
              "                       0.0658,  0.0667,  0.0568,  0.0853,  0.0682,  0.0631,  0.0764,  0.0111,\n",
              "                       0.0759,  0.0668,  0.0728,  0.0671,  0.0652,  0.0571,  0.0702,  0.0673,\n",
              "                       0.0614,  0.0846,  0.0842,  0.0805,  0.0678,  0.0840,  0.0797,  0.0610,\n",
              "                       0.0755,  0.0585,  0.0770,  0.0519,  0.0674,  0.0683,  0.0995,  0.0712,\n",
              "                       0.0692,  0.0729,  0.0732,  0.0690,  0.0731,  0.0738,  0.0810,  0.0533,\n",
              "                       0.0637,  0.0685,  0.0787,  0.0669,  0.0786,  0.0641,  0.0737,  0.0659,\n",
              "                       0.0713,  0.0613,  0.0711,  0.0837,  0.0734,  0.0538,  0.0797,  0.0876,\n",
              "                       0.0776,  0.0710,  0.0763,  0.0714,  0.0807,  0.0692,  0.0950,  0.0825,\n",
              "                       0.0611,  0.0813,  0.0621,  0.0659,  0.0877,  0.0701,  0.0622,  0.0760,\n",
              "                       0.0882,  0.0764,  0.1851,  0.3298,  0.0663,  0.0866,  0.0621,  0.0742,\n",
              "                       0.0773,  0.0611,  0.0782,  0.0733,  0.0617,  0.0751,  0.0697,  0.0722,\n",
              "                       0.0700,  0.0688,  0.0714,  0.0151, -0.0621,  0.0614,  0.0630,  0.0747,\n",
              "                       0.0650,  0.0656,  0.0706,  0.0690,  0.0598,  0.0612,  0.0782,  0.0780,\n",
              "                       0.0726,  0.0650,  0.0692,  0.0600,  0.0552,  0.0660,  0.1472,  0.0644,\n",
              "                       0.1038,  0.0630,  0.0700,  0.0753,  0.0792,  0.0649,  0.0562,  0.0326,\n",
              "                       0.0809,  0.0766,  0.0738,  0.0764,  0.0901,  0.0622,  0.0684,  0.0680,\n",
              "                       0.0722,  0.0531,  0.0736,  0.0830,  0.0699,  0.0699,  0.0631,  0.0866,\n",
              "                       0.0766,  0.0709,  0.0804,  0.0772,  0.0768,  0.0722,  0.0797,  0.0639,\n",
              "                       0.0610,  0.1354,  0.0678,  0.0803,  0.0722,  0.0657,  0.0677,  0.0678,\n",
              "                       0.0789,  0.0732,  0.0664,  0.0684,  0.0837,  0.0677,  0.0728,  0.0629,\n",
              "                       0.0629,  0.0686,  0.0525,  0.0717,  0.0721,  0.0845,  0.0673,  0.0421,\n",
              "                       0.0679,  0.0669,  0.0654,  0.0902,  0.0691,  0.0698,  0.0756,  0.1251,\n",
              "                       0.0708,  0.0788,  0.0654,  0.0549,  0.0701,  0.0619,  0.0685,  0.0691,\n",
              "                       0.0730,  0.0581,  0.0701,  0.0600,  0.0746,  0.0685,  0.0724,  0.0702,\n",
              "                       0.0732,  0.0748,  0.0764,  0.0646,  0.0841,  0.0664,  0.0569,  0.0758,\n",
              "                       0.0661,  0.0703,  0.0633,  0.0801,  0.0895,  0.0705,  0.0701,  0.0667,\n",
              "                       0.0775,  0.0651,  0.0759,  0.0621,  0.0753,  0.0619,  0.0696,  0.0770,\n",
              "                       0.0710,  0.0581,  0.0629,  0.0833,  0.0366,  0.0649,  0.0744,  0.0679,\n",
              "                       0.0667,  0.0629,  0.0821,  0.0665,  0.0649,  0.0780,  0.0716,  0.0815,\n",
              "                       0.0759,  0.0733,  0.0853,  0.0555,  0.0729,  0.0452,  0.0804,  0.0712,\n",
              "                       0.0639,  0.0875,  0.0784,  0.0531,  0.0623,  0.0806,  0.0760,  0.0601,\n",
              "                       0.0647,  0.0712,  0.0763,  0.0712,  0.0601,  0.0600,  0.0780,  0.0852,\n",
              "                       0.0681,  0.0953,  0.0692,  0.0641,  0.0794,  0.0894,  0.0645,  0.0740,\n",
              "                       0.0903,  0.0716,  0.0756,  0.0616,  0.0805,  0.0588,  0.0883,  0.0701,\n",
              "                       0.0854,  0.0587,  0.0682,  0.0643,  0.0771,  0.0770,  0.0609,  0.0841],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.3207,  0.1741,  0.0495,  ..., -0.6092, -0.4785, -0.3279],\n",
              "                      [ 0.1652,  0.0512,  0.1196,  ...,  0.0023,  0.3334,  0.1259],\n",
              "                      [-0.2465,  0.1311,  0.5553,  ...,  0.4811, -0.3800,  0.2178],\n",
              "                      ...,\n",
              "                      [ 0.0936, -0.2781,  0.1688,  ...,  0.0888,  0.8107,  0.3648],\n",
              "                      [ 1.0066, -0.1365,  0.5348,  ...,  0.0304, -0.3393, -0.1811],\n",
              "                      [ 0.3117, -0.1939,  0.2139,  ..., -0.2560, -0.1700, -0.0681]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.1478, -0.1472, -0.0301,  ...,  0.1632, -0.1625,  0.1039],\n",
              "                      [-0.5416, -0.1251,  0.3015,  ..., -0.0261,  0.2851,  0.4084],\n",
              "                      [ 0.0731, -0.2025,  0.0537,  ...,  0.1443, -0.2305,  0.1174],\n",
              "                      ...,\n",
              "                      [-0.1845, -0.0186, -0.0649,  ..., -0.1114,  0.0912,  0.1555],\n",
              "                      [ 0.2822, -0.0149, -0.0336,  ...,  0.0955, -0.1580,  0.1426],\n",
              "                      [-0.1166, -0.0475, -0.0987,  ..., -0.2727, -0.5504,  0.0759]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.0.layer.2.layer_norm.weight',\n",
              "              tensor([0.6425, 0.3207, 0.3053, 1.1076, 0.5075, 0.6302, 0.5258, 0.6400, 0.5652,\n",
              "                      0.5934, 0.9082, 0.6095, 0.6004, 0.7325, 0.5125, 0.5680, 0.6737, 0.4965,\n",
              "                      0.7550, 0.5604, 0.5735, 0.6230, 0.8747, 0.5838, 0.5482, 0.5460, 0.5056,\n",
              "                      0.6044, 0.5586, 0.5589, 0.5566, 0.2675, 0.6317, 0.5069, 0.6471, 0.5120,\n",
              "                      0.6351, 0.3424, 0.5280, 0.7113, 0.7997, 0.6989, 0.6286, 0.6212, 0.2612,\n",
              "                      0.5951, 0.7120, 0.5496, 0.5805, 0.6587, 0.7028, 0.5953, 0.6216, 0.5367,\n",
              "                      4.8981, 0.6044, 1.1670, 0.5602, 0.5658, 0.5872, 0.5903, 0.4754, 0.6058,\n",
              "                      0.5412, 0.5239, 0.3146, 0.5533, 0.5883, 0.3246, 0.5472, 0.5419, 0.6581,\n",
              "                      0.5197, 0.5589, 0.5335, 0.5307, 0.7371, 0.5849, 0.4954, 0.5451, 0.5621,\n",
              "                      0.6713, 0.5820, 0.6657, 0.5196, 0.5606, 1.0973, 0.6196, 0.6034, 0.5183,\n",
              "                      0.5600, 0.5499, 0.5810, 0.6753, 0.5170, 0.5932, 0.5269, 0.5950, 0.4824,\n",
              "                      0.5486, 0.6944, 0.5614, 0.3541, 0.4912, 0.5472, 0.8781, 0.5983, 0.5284,\n",
              "                      0.4831, 0.6418, 0.6158, 0.6007, 0.6197, 0.5470, 0.5436, 0.5177, 0.6226,\n",
              "                      0.5790, 0.0931, 0.4931, 0.4881, 0.5142, 0.6461, 0.5354, 0.6088, 0.5917,\n",
              "                      0.6151, 0.6331, 0.6098, 0.6629, 0.7491, 0.5841, 0.5352, 0.5047, 0.4451,\n",
              "                      0.7650, 0.6460, 0.5227, 0.6789, 0.8617, 0.5354, 0.6249, 0.6998, 0.7475,\n",
              "                      0.5973, 0.7221, 0.4923, 0.5940, 0.5207, 0.6627, 0.5593, 0.5742, 0.4821,\n",
              "                      0.7821, 0.4674, 0.5342, 0.6571, 0.5085, 0.5208, 0.7697, 0.5081, 0.6272,\n",
              "                      0.5989, 0.5820, 0.4733, 0.3694, 0.5859, 0.5036, 0.2935, 0.6632, 0.6334,\n",
              "                      0.5691, 0.5825, 0.6403, 0.5549, 0.6238, 0.5703, 0.6587, 0.5280, 0.4970,\n",
              "                      0.5391, 0.5241, 0.6243, 0.5257, 0.7410, 0.6333, 0.5672, 0.4847, 0.5817,\n",
              "                      0.5960, 0.5580, 0.5691, 0.4448, 0.5938, 0.5602, 0.5492, 0.5592, 0.6348,\n",
              "                      0.5840, 0.5618, 0.5368, 0.7349, 0.6019, 0.5194, 0.5236, 0.7307, 0.6535,\n",
              "                      0.6356, 0.5325, 0.6159, 0.5194, 0.6389, 0.6416, 0.6055, 0.6258, 0.6488,\n",
              "                      0.5693, 0.5202, 0.6600, 0.1185, 0.5776, 0.5499, 0.4514, 0.5761, 0.5950,\n",
              "                      0.5939, 0.2465, 0.6426, 0.5791, 0.6390, 0.5180, 0.6368, 0.6197, 0.5132,\n",
              "                      0.5210, 0.5411, 0.6977, 0.6799, 0.9243, 0.6314, 0.9466, 0.6072, 0.5394,\n",
              "                      0.5331, 0.5422, 0.5819, 0.5353, 0.6266, 0.4934, 0.6134, 0.6704, 0.5402,\n",
              "                      0.5613, 0.5176, 0.4860, 0.5575, 0.5013, 0.9070, 0.6384, 0.5963, 0.7790,\n",
              "                      0.9190, 0.5405, 0.6259, 0.5409, 0.5698, 0.5193, 0.5525, 0.5453, 0.5949,\n",
              "                      0.7699, 0.1395, 0.6605, 0.5741, 0.5695, 0.6028, 0.5432, 0.6838, 0.5697,\n",
              "                      0.6736, 0.0979, 0.5322, 0.5691, 0.6466, 0.6275, 0.7159, 0.5180, 0.5340,\n",
              "                      0.5699, 0.7321, 0.5018, 0.5630, 0.5222, 0.5789, 0.5752, 0.5416, 0.2378,\n",
              "                      0.5512, 0.4887, 0.6354, 0.6287, 0.5132, 0.1537, 0.6421, 0.6008, 0.4832,\n",
              "                      0.6370, 0.5671, 0.7031, 0.6476, 0.5347, 0.6065, 0.5355, 0.6634, 0.3266,\n",
              "                      0.6347, 0.5822, 0.9546, 0.6232, 0.5133, 0.5205, 0.5937, 0.6036, 0.5049,\n",
              "                      0.5613, 0.5642, 0.6951, 0.6913, 0.6420, 0.5983, 0.5566, 0.6330, 0.6246,\n",
              "                      0.5411, 0.5647, 0.5837, 0.4988, 0.5323, 0.5580, 0.9695, 0.6499, 0.6224,\n",
              "                      0.5886, 0.5645, 0.5922, 0.5398, 0.6173, 0.6439, 0.5567, 0.6366, 0.7026,\n",
              "                      0.5193, 0.6569, 0.5317, 0.7184, 0.5672, 0.6005, 0.1432, 0.5569, 0.6817,\n",
              "                      0.5663, 0.6589, 0.4639, 0.5203, 0.5126, 0.5532, 0.6920, 0.5719, 0.5174,\n",
              "                      0.6045, 0.6059, 0.6416, 0.5968, 0.5605, 0.6879, 0.5086, 0.6468, 0.5142,\n",
              "                      0.6633, 0.6657, 0.5784, 0.5879, 0.8433, 0.5857, 0.5391, 0.7355, 0.5493,\n",
              "                      0.6733, 0.5204, 0.6284, 0.5136, 0.6413, 0.6209, 1.0641, 0.6880, 0.6080,\n",
              "                      0.5806, 0.5414, 0.5395, 0.5706, 0.5509, 0.5943, 0.5233, 0.5159, 0.5684,\n",
              "                      0.5455, 0.5759, 0.5588, 0.4911, 0.5354, 0.4991, 0.5043, 0.6188, 0.6156,\n",
              "                      0.5349, 0.5832, 0.5106, 0.5569, 0.2097, 0.6694, 0.2007, 0.5502, 0.4959,\n",
              "                      0.5167, 0.5743, 0.5333, 0.7401, 0.5116, 0.6027, 0.8733, 0.6669, 0.5200,\n",
              "                      0.6792, 0.4993, 0.6549, 0.5539, 0.6101, 0.4602, 0.6077, 0.6241, 0.5412,\n",
              "                      0.6118, 0.4901, 0.6540, 0.5620, 0.5355, 0.5370, 0.6145, 0.0637, 0.5956,\n",
              "                      0.6342, 0.4955, 0.5711, 0.4988, 0.5753, 0.7344, 0.6065, 0.4340, 0.6744,\n",
              "                      0.5213, 0.5297, 0.5543, 0.5549, 0.6114, 0.5932, 0.5886, 0.6777, 0.5780,\n",
              "                      0.4574, 0.5396, 0.5289, 0.5376, 0.5291, 0.5103, 0.5537, 0.5329, 0.5915,\n",
              "                      0.5416, 0.5601, 0.6010, 0.7068, 0.6547, 0.5763, 0.5676, 0.0974, 0.5565,\n",
              "                      0.5447, 0.4581, 0.4467, 0.6424, 0.5531, 0.5973, 0.6232, 0.5453, 0.5982,\n",
              "                      0.1213, 0.5756, 0.5962, 0.5458, 0.5526, 0.5144, 0.2773, 0.5922, 0.5968,\n",
              "                      0.5675, 0.6463, 0.6162, 0.6691, 0.4765, 0.5946, 0.5849, 0.5732, 0.6297,\n",
              "                      0.5608, 0.6075, 0.5487, 0.6235, 0.5724, 0.7895, 0.6415, 0.5573, 0.6269,\n",
              "                      0.4842, 0.5611, 0.6323, 0.5882, 0.6741, 0.3791, 0.5822, 0.6173, 0.6118,\n",
              "                      0.5897, 0.5890, 0.6160, 0.5845, 0.5808, 0.6321, 0.5788, 0.6325, 0.6196,\n",
              "                      0.6288, 0.5563, 0.6849, 0.6952, 0.5961, 0.5527, 0.6352, 0.5805, 0.5324,\n",
              "                      0.6829, 0.7093, 0.6567, 0.5272, 0.6445, 0.6562, 0.5524, 0.6505, 0.5363,\n",
              "                      0.5485, 0.6703, 0.6563, 0.5526, 1.2596, 3.4733, 0.5877, 0.5989, 0.6192,\n",
              "                      0.6500, 0.7003, 0.5568, 0.6481, 0.5952, 0.5332, 0.6497, 0.7216, 0.6610,\n",
              "                      0.5068, 0.5921, 0.4924, 0.0919, 0.4783, 0.4937, 0.5402, 0.5985, 0.4985,\n",
              "                      0.5256, 0.5334, 0.5715, 0.5510, 0.5328, 0.5818, 0.6109, 0.5016, 0.6020,\n",
              "                      0.6115, 0.5654, 0.4115, 0.6119, 0.9631, 0.5539, 0.7672, 0.5502, 0.6540,\n",
              "                      0.5582, 0.6448, 0.5018, 0.4822, 0.2164, 0.7066, 0.6021, 0.6492, 0.5250,\n",
              "                      0.5850, 0.5465, 0.5505, 0.6592, 0.5894, 0.3100, 0.5042, 0.5807, 0.6195,\n",
              "                      0.5597, 0.5267, 0.7087, 0.6838, 0.5392, 0.8428, 0.6358, 0.5790, 0.6390,\n",
              "                      0.6064, 0.5416, 0.5270, 0.7358, 0.5499, 0.5773, 0.6716, 0.6137, 0.6654,\n",
              "                      0.5439, 0.6138, 0.5934, 0.5547, 0.5163, 0.9126, 0.6453, 0.5953, 0.5324,\n",
              "                      0.7493, 0.5384, 0.5693, 0.5561, 0.5899, 0.6712, 0.6104, 0.4981, 0.5950,\n",
              "                      0.5942, 0.6546, 0.6760, 0.6217, 0.6347, 0.5985, 0.7815, 0.5647, 0.6390,\n",
              "                      0.5323, 0.5044, 0.6300, 0.5194, 0.5867, 0.5821, 0.5595, 0.5676, 0.5818,\n",
              "                      0.5423, 0.5554, 0.5285, 0.6338, 0.5719, 0.5862, 0.5787, 0.6314, 0.5251,\n",
              "                      0.6540, 0.6277, 0.5829, 0.6448, 0.5110, 0.6262, 0.5632, 0.6389, 0.7336,\n",
              "                      0.5097, 0.5724, 0.6007, 0.6077, 0.4899, 0.5441, 0.6138, 0.6200, 0.5629,\n",
              "                      0.6214, 0.8184, 0.4923, 0.4988, 0.5591, 0.7654, 0.1796, 0.5464, 0.6777,\n",
              "                      0.5558, 0.5904, 0.5424, 0.5326, 0.3899, 0.6318, 0.5376, 0.6059, 0.7985,\n",
              "                      0.5791, 0.5862, 0.6456, 0.5197, 0.6515, 0.3400, 0.6436, 0.5785, 0.5390,\n",
              "                      0.7514, 0.6217, 0.5620, 0.5160, 0.5742, 0.4782, 0.5743, 0.5638, 0.5606,\n",
              "                      0.5708, 0.6096, 0.5771, 0.6494, 0.6155, 0.7051, 0.6091, 0.7867, 0.5716,\n",
              "                      0.4630, 0.6232, 0.6925, 0.6528, 0.5896, 0.8364, 0.5841, 0.6724, 0.5366,\n",
              "                      0.6673, 0.5628, 0.7175, 0.6414, 0.5769, 0.5187, 0.6205, 0.5726, 0.5996,\n",
              "                      0.6408, 0.6021, 0.6851], device='cuda:0')),\n",
              "             ('decoder.block.1.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0290,  0.0502,  0.0495,  ...,  0.0419,  0.0670,  0.0690],\n",
              "                      [ 0.0690,  0.0270, -0.0702,  ...,  0.0016, -0.0098,  0.0182],\n",
              "                      [-0.0192,  0.0299, -0.0418,  ...,  0.0269,  0.0205,  0.0194],\n",
              "                      ...,\n",
              "                      [ 0.0653, -0.0422,  0.0471,  ...,  0.0137,  0.0825,  0.0111],\n",
              "                      [ 0.0682, -0.0201,  0.0391,  ..., -0.0182,  0.0529,  0.0915],\n",
              "                      [ 0.0336, -0.0142, -0.0544,  ...,  0.0368,  0.0387, -0.0014]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.0601,  0.1301, -0.0466,  ..., -0.0305, -0.2883, -0.2691],\n",
              "                      [ 0.3752, -0.3928,  0.0706,  ..., -0.1261, -0.2809,  0.0032],\n",
              "                      [-0.2035,  0.0012,  0.1557,  ..., -0.0369, -0.1486, -0.2633],\n",
              "                      ...,\n",
              "                      [ 0.2047,  0.2642,  0.4984,  ..., -0.3855,  0.2331,  0.3419],\n",
              "                      [-0.0964,  0.0868,  0.1090,  ..., -0.2287,  0.1226, -0.2222],\n",
              "                      [ 0.2428, -0.0492,  0.0756,  ..., -0.3894, -0.0160, -0.3808]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-0.1717,  0.6729,  0.6044,  ...,  0.2247, -0.2297,  0.3020],\n",
              "                      [-0.4413,  0.5819,  0.5502,  ..., -0.2484,  0.3022, -0.2473],\n",
              "                      [-0.3704, -0.6277,  0.3817,  ...,  0.3808, -0.0596, -0.0236],\n",
              "                      ...,\n",
              "                      [ 0.1066, -0.0993, -0.0229,  ...,  0.0458, -0.2186,  0.1549],\n",
              "                      [ 0.2440, -0.0598,  0.1049,  ...,  0.6721, -0.5473, -0.4525],\n",
              "                      [-0.3916,  0.0864, -0.0355,  ...,  0.2748, -0.4164, -0.2165]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.0827, -0.0734, -0.1652,  ..., -0.0605, -0.4761, -0.1355],\n",
              "                      [-1.2536, -0.9897,  1.0944,  ...,  1.0371,  0.2216, -0.9817],\n",
              "                      [-0.0581, -0.0917, -0.3207,  ..., -0.0149, -0.0310, -0.5445],\n",
              "                      ...,\n",
              "                      [-0.2259,  0.3610, -0.2151,  ..., -0.0702, -0.3311,  0.4634],\n",
              "                      [ 0.1642, -0.0721,  0.1686,  ..., -0.1924, -0.0138,  0.1821],\n",
              "                      [-0.0578, -0.3239,  0.0718,  ..., -0.1804, -0.2224,  0.0406]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.0.layer_norm.weight',\n",
              "              tensor([0.1544, 0.0562, 0.0744, 0.1807, 0.1223, 0.1509, 0.1423, 0.1687, 0.1453,\n",
              "                      0.1550, 0.1169, 0.1639, 0.0999, 0.1331, 0.1377, 0.1488, 0.1258, 0.1137,\n",
              "                      0.1379, 0.1500, 0.1482, 0.1594, 0.1784, 0.1566, 0.1245, 0.1071, 0.1246,\n",
              "                      0.1185, 0.1501, 0.1334, 0.1457, 0.0678, 0.1505, 0.1429, 0.1673, 0.1149,\n",
              "                      0.1619, 0.1370, 0.1271, 0.1736, 0.1689, 0.1411, 0.1584, 0.1593, 0.0719,\n",
              "                      0.1321, 0.1834, 0.1367, 0.1456, 0.1642, 0.1358, 0.1558, 0.1347, 0.1393,\n",
              "                      0.4376, 0.1430, 0.1763, 0.1513, 0.1747, 0.1235, 0.1443, 0.1464, 0.1501,\n",
              "                      0.1314, 0.1325, 0.0733, 0.1425, 0.1315, 0.0881, 0.1242, 0.1347, 0.1554,\n",
              "                      0.1328, 0.1380, 0.1315, 0.1214, 0.1364, 0.1459, 0.1279, 0.1196, 0.1611,\n",
              "                      0.1479, 0.1520, 0.1365, 0.1265, 0.1392, 0.2383, 0.1544, 0.1362, 0.1431,\n",
              "                      0.1338, 0.1320, 0.1340, 0.1451, 0.1466, 0.1413, 0.1321, 0.1392, 0.1344,\n",
              "                      0.1491, 0.1457, 0.1238, 0.0958, 0.1369, 0.1324, 0.1860, 0.1555, 0.1315,\n",
              "                      0.1238, 0.1563, 0.1480, 0.1540, 0.1500, 0.1375, 0.1364, 0.1144, 0.1671,\n",
              "                      0.1367, 0.0355, 0.1305, 0.1343, 0.1317, 0.0990, 0.1304, 0.1534, 0.1246,\n",
              "                      0.1476, 0.1655, 0.1548, 0.1152, 0.1174, 0.1408, 0.1249, 0.1349, 0.0692,\n",
              "                      0.1651, 0.1511, 0.1057, 0.1497, 0.0958, 0.1195, 0.1720, 0.1509, 0.1835,\n",
              "                      0.1234, 0.1697, 0.1199, 0.1254, 0.1264, 0.1609, 0.1431, 0.1360, 0.1327,\n",
              "                      0.1488, 0.1361, 0.1374, 0.1582, 0.1329, 0.0607, 0.0938, 0.1080, 0.1319,\n",
              "                      0.1464, 0.1379, 0.1113, 0.0657, 0.1449, 0.1448, 0.0603, 0.1496, 0.0813,\n",
              "                      0.1386, 0.1384, 0.1691, 0.1508, 0.1440, 0.1685, 0.1718, 0.0918, 0.1226,\n",
              "                      0.1585, 0.1523, 0.1510, 0.1466, 0.1421, 0.1275, 0.1509, 0.0423, 0.1596,\n",
              "                      0.1235, 0.1430, 0.1478, 0.1068, 0.1470, 0.1505, 0.1304, 0.1545, 0.1590,\n",
              "                      0.1590, 0.1286, 0.1362, 0.1756, 0.1564, 0.1168, 0.1258, 0.1635, 0.1563,\n",
              "                      0.1368, 0.1395, 0.1555, 0.1386, 0.1453, 0.1290, 0.1374, 0.1450, 0.1504,\n",
              "                      0.1294, 0.1367, 0.1713, 0.0347, 0.0972, 0.1546, 0.0946, 0.1464, 0.1267,\n",
              "                      0.1586, 0.1384, 0.1624, 0.1381, 0.1399, 0.1472, 0.1543, 0.1302, 0.1483,\n",
              "                      0.1226, 0.1368, 0.1531, 0.1432, 0.0954, 0.1564, 0.1485, 0.1389, 0.1253,\n",
              "                      0.1381, 0.1424, 0.1352, 0.1437, 0.1486, 0.1231, 0.1499, 0.1648, 0.1243,\n",
              "                      0.1300, 0.1473, 0.1312, 0.1079, 0.1352, 0.1042, 0.1558, 0.1368, 0.1724,\n",
              "                      0.1149, 0.1546, 0.1503, 0.1295, 0.1431, 0.1237, 0.1372, 0.1408, 0.1612,\n",
              "                      0.1589, 0.1089, 0.1597, 0.1359, 0.0966, 0.1513, 0.1318, 0.1675, 0.1234,\n",
              "                      0.1370, 0.0452, 0.1016, 0.1474, 0.1426, 0.1604, 0.1587, 0.1510, 0.1550,\n",
              "                      0.1024, 0.1265, 0.1336, 0.1270, 0.1227, 0.1478, 0.1378, 0.1327, 0.0777,\n",
              "                      0.1478, 0.1250, 0.1760, 0.1632, 0.1344, 0.0416, 0.1518, 0.1647, 0.1418,\n",
              "                      0.1414, 0.1563, 0.1394, 0.1419, 0.1474, 0.1519, 0.1265, 0.1831, 0.1359,\n",
              "                      0.1434, 0.1411, 0.2275, 0.1458, 0.1389, 0.1451, 0.1593, 0.1358, 0.1172,\n",
              "                      0.1272, 0.1554, 0.1552, 0.1614, 0.1573, 0.1471, 0.1596, 0.1367, 0.1724,\n",
              "                      0.1243, 0.1293, 0.1341, 0.1243, 0.1462, 0.1296, 0.1670, 0.1493, 0.1490,\n",
              "                      0.1579, 0.1355, 0.1688, 0.1457, 0.1661, 0.1438, 0.0713, 0.1323, 0.1461,\n",
              "                      0.1305, 0.1161, 0.1210, 0.1567, 0.1575, 0.1563, 0.0291, 0.1629, 0.1531,\n",
              "                      0.1314, 0.1196, 0.1035, 0.1235, 0.1345, 0.1318, 0.1703, 0.1235, 0.1242,\n",
              "                      0.1324, 0.1361, 0.1660, 0.1439, 0.1316, 0.1595, 0.1317, 0.1302, 0.1529,\n",
              "                      0.1633, 0.1248, 0.1361, 0.1405, 0.1442, 0.1522, 0.1291, 0.1536, 0.1447,\n",
              "                      0.1509, 0.1222, 0.1609, 0.1079, 0.1623, 0.1306, 0.2265, 0.1776, 0.1475,\n",
              "                      0.1519, 0.1332, 0.1569, 0.1412, 0.1219, 0.1497, 0.1481, 0.1517, 0.1350,\n",
              "                      0.1430, 0.1203, 0.1461, 0.1246, 0.1413, 0.1382, 0.1347, 0.1607, 0.1558,\n",
              "                      0.1424, 0.1553, 0.1248, 0.1530, 0.1379, 0.1463, 0.0379, 0.1555, 0.1588,\n",
              "                      0.0691, 0.1481, 0.1353, 0.1436, 0.1324, 0.1375, 0.1053, 0.1444, 0.1309,\n",
              "                      0.1695, 0.1264, 0.1489, 0.1374, 0.1615, 0.1311, 0.1375, 0.1764, 0.1514,\n",
              "                      0.1480, 0.1354, 0.1426, 0.1252, 0.1318, 0.1288, 0.1570, 0.0249, 0.1328,\n",
              "                      0.1612, 0.1248, 0.1614, 0.1356, 0.1481, 0.1701, 0.1833, 0.1022, 0.1557,\n",
              "                      0.1379, 0.1457, 0.1479, 0.1476, 0.1661, 0.1636, 0.1533, 0.1520, 0.1415,\n",
              "                      0.1187, 0.1319, 0.1293, 0.1386, 0.0389, 0.1327, 0.1381, 0.1309, 0.1393,\n",
              "                      0.1326, 0.1445, 0.1391, 0.1539, 0.1721, 0.1452, 0.1311, 0.0997, 0.1372,\n",
              "                      0.1313, 0.0231, 0.1236, 0.1526, 0.1375, 0.1399, 0.1689, 0.1453, 0.1692,\n",
              "                      0.0670, 0.1330, 0.1386, 0.1370, 0.1421, 0.1505, 0.1165, 0.1434, 0.1577,\n",
              "                      0.1332, 0.1277, 0.1626, 0.1618, 0.1264, 0.1590, 0.1355, 0.1379, 0.1519,\n",
              "                      0.1373, 0.1261, 0.1518, 0.1523, 0.1052, 0.1586, 0.1567, 0.1437, 0.1526,\n",
              "                      0.1509, 0.1441, 0.1379, 0.1438, 0.1630, 0.0800, 0.1569, 0.1570, 0.1233,\n",
              "                      0.1191, 0.1665, 0.1400, 0.1379, 0.1439, 0.1481, 0.1451, 0.1708, 0.1337,\n",
              "                      0.1493, 0.1328, 0.1628, 0.1385, 0.1421, 0.1474, 0.1514, 0.1311, 0.1374,\n",
              "                      0.1388, 0.1364, 0.1180, 0.1405, 0.1115, 0.1595, 0.1472, 0.1466, 0.1415,\n",
              "                      0.1056, 0.1574, 0.1465, 0.1464, 0.1462, 0.3997, 0.1536, 0.1464, 0.1477,\n",
              "                      0.1517, 0.1413, 0.1499, 0.1457, 0.1791, 0.1368, 0.1539, 0.0944, 0.1509,\n",
              "                      0.1143, 0.1638, 0.1271, 0.0301, 0.1161, 0.1329, 0.1303, 0.1316, 0.1123,\n",
              "                      0.1439, 0.1343, 0.1483, 0.1183, 0.1330, 0.1540, 0.1466, 0.1280, 0.1467,\n",
              "                      0.1533, 0.1442, 0.0813, 0.1571, 0.3134, 0.1446, 0.1314, 0.1424, 0.1478,\n",
              "                      0.1206, 0.1662, 0.1267, 0.1477, 0.0525, 0.1768, 0.1541, 0.1471, 0.1341,\n",
              "                      0.1520, 0.1284, 0.1428, 0.1680, 0.1440, 0.1241, 0.1415, 0.1616, 0.1568,\n",
              "                      0.1414, 0.1339, 0.1298, 0.1601, 0.1260, 0.1342, 0.1593, 0.1257, 0.1524,\n",
              "                      0.1209, 0.1267, 0.1252, 0.1581, 0.1238, 0.1466, 0.1162, 0.1407, 0.1463,\n",
              "                      0.1236, 0.1132, 0.1279, 0.1389, 0.1259, 0.1519, 0.1514, 0.0961, 0.1352,\n",
              "                      0.1285, 0.1492, 0.0832, 0.1442, 0.1278, 0.1651, 0.1363, 0.0771, 0.1271,\n",
              "                      0.1249, 0.1487, 0.1538, 0.1485, 0.1815, 0.1475, 0.2006, 0.1275, 0.1567,\n",
              "                      0.1515, 0.1360, 0.1233, 0.1378, 0.1380, 0.1447, 0.1516, 0.1177, 0.1460,\n",
              "                      0.1441, 0.1376, 0.1393, 0.1596, 0.1581, 0.1569, 0.1377, 0.1357, 0.1184,\n",
              "                      0.1536, 0.1646, 0.1428, 0.1221, 0.1414, 0.1499, 0.1610, 0.1506, 0.1469,\n",
              "                      0.1346, 0.1394, 0.1303, 0.1838, 0.1185, 0.1421, 0.1463, 0.1312, 0.1508,\n",
              "                      0.1328, 0.0784, 0.1415, 0.1228, 0.1472, 0.1497, 0.1002, 0.1178, 0.1495,\n",
              "                      0.1236, 0.1101, 0.1211, 0.1515, 0.1400, 0.1364, 0.1663, 0.1363, 0.1452,\n",
              "                      0.1394, 0.1346, 0.1317, 0.1291, 0.1485, 0.1004, 0.1386, 0.1505, 0.1542,\n",
              "                      0.1579, 0.1608, 0.1437, 0.1477, 0.0399, 0.1462, 0.1349, 0.1561, 0.1452,\n",
              "                      0.1395, 0.1323, 0.1325, 0.0820, 0.1492, 0.1694, 0.1706, 0.1276, 0.0990,\n",
              "                      0.1126, 0.1577, 0.1319, 0.1407, 0.1252, 0.1681, 0.1355, 0.1362, 0.1460,\n",
              "                      0.1547, 0.1330, 0.0960, 0.1315, 0.1365, 0.1253, 0.1413, 0.1411, 0.1317,\n",
              "                      0.1455, 0.1542, 0.1442], device='cuda:0')),\n",
              "             ('decoder.block.1.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[ 0.0010, -0.0469, -0.0142,  ...,  0.0992, -0.1124,  0.0437],\n",
              "                      [ 0.0247,  0.0131, -0.0106,  ..., -0.0113,  0.0479, -0.0392],\n",
              "                      [-0.0604, -0.0137, -0.0292,  ...,  0.0055,  0.0577,  0.0091],\n",
              "                      ...,\n",
              "                      [-0.0008, -0.0103, -0.0378,  ...,  0.0129,  0.0139,  0.0437],\n",
              "                      [-0.0126,  0.0284, -0.0012,  ...,  0.0024,  0.0987,  0.0059],\n",
              "                      [-0.0371,  0.0082,  0.0102,  ..., -0.0507,  0.0587, -0.0452]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[ 0.5405, -0.0656,  0.0129,  ...,  0.0513, -0.5139, -0.4890],\n",
              "                      [ 0.3870, -0.2951, -0.1656,  ...,  0.0911,  0.2217,  0.0389],\n",
              "                      [-0.3274, -0.1051,  0.1595,  ..., -0.3030, -0.1665, -0.1343],\n",
              "                      ...,\n",
              "                      [ 0.0690, -0.1617, -0.2338,  ..., -0.0317,  0.0785, -0.1882],\n",
              "                      [ 0.1896,  0.1682,  0.2598,  ...,  0.1240, -0.1236, -0.3716],\n",
              "                      [-0.0403, -0.0490, -0.1281,  ...,  0.2432, -0.0155,  0.2782]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.0237, -0.1846, -0.1049,  ..., -0.3173, -0.0187, -0.0341],\n",
              "                      [-0.6754, -0.1763,  0.4673,  ...,  0.0670,  0.0558,  0.2123],\n",
              "                      [ 0.1500, -0.3896,  0.4379,  ..., -0.0145,  0.4177, -0.4229],\n",
              "                      ...,\n",
              "                      [-0.1366,  0.0796,  0.0995,  ...,  0.1630,  0.2103,  0.0567],\n",
              "                      [-0.0197,  0.0594, -0.2257,  ..., -0.2141,  0.4032, -0.4429],\n",
              "                      [ 0.1708,  0.2007, -0.1949,  ...,  0.3307,  0.1400,  0.2884]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[-0.2633, -0.2478,  0.4209,  ...,  0.2289,  0.1240,  0.2924],\n",
              "                      [-0.4418,  0.1964,  0.0834,  ...,  1.0933, -0.2932, -0.3149],\n",
              "                      [ 0.1230,  1.0148, -0.3365,  ...,  0.8875,  0.2270, -0.7167],\n",
              "                      ...,\n",
              "                      [-0.1333, -0.2152, -0.4826,  ...,  0.3432, -0.3971,  0.1925],\n",
              "                      [-0.1960,  0.3181,  0.1346,  ..., -0.2968, -0.6720,  0.0293],\n",
              "                      [ 0.5139, -0.2028, -0.4998,  ..., -0.1759, -0.2107,  0.4369]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.0708,  0.0256,  0.0292,  0.1027,  0.0835,  0.0707,  0.0696,  0.0866,\n",
              "                       0.0570,  0.0722,  0.0779,  0.0919,  0.0775,  0.0544,  0.0799,  0.0689,\n",
              "                       0.0537,  0.0494,  0.0812,  0.0787,  0.0740,  0.0702,  0.0746,  0.0785,\n",
              "                       0.0775,  0.0637,  0.0928,  0.0583,  0.0844,  0.0838,  0.0824,  0.0300,\n",
              "                       0.0792,  0.0707,  0.0862,  0.0527,  0.0910,  0.0669,  0.0636,  0.0862,\n",
              "                       0.0854,  0.0812,  0.0819,  0.0739,  0.0380,  0.0775,  0.1033,  0.0738,\n",
              "                       0.0785,  0.0776,  0.0791,  0.0666,  0.0771,  0.0798,  0.1717,  0.0649,\n",
              "                       0.0781,  0.0783,  0.0750,  0.0787,  0.0714,  0.0787,  0.0771,  0.0774,\n",
              "                       0.0715,  0.0377,  0.0732,  0.0722,  0.0318,  0.0777,  0.0680,  0.0839,\n",
              "                       0.0766,  0.0787,  0.0801,  0.0838,  0.0517,  0.0666,  0.0731,  0.0764,\n",
              "                       0.0716,  0.0755,  0.0736,  0.0600,  0.0586,  0.0744,  0.1072,  0.0729,\n",
              "                       0.0732,  0.0787,  0.0673,  0.0746,  0.0686,  0.0786,  0.0709,  0.0743,\n",
              "                       0.0844,  0.0790,  0.0779,  0.0697,  0.0755,  0.0674,  0.0384,  0.0755,\n",
              "                       0.0670,  0.0980,  0.0806,  0.0708,  0.0712,  0.0773,  0.0729,  0.0734,\n",
              "                       0.0588,  0.0706,  0.0701,  0.0683,  0.0779,  0.0699,  0.0063,  0.0720,\n",
              "                       0.0702,  0.0703,  0.0561,  0.0652,  0.0844,  0.0634,  0.0859,  0.0694,\n",
              "                       0.0641,  0.0478,  0.0576,  0.0572,  0.0670,  0.0657,  0.0698,  0.0841,\n",
              "                       0.0819,  0.0628,  0.0866,  0.0522,  0.0678,  0.0737,  0.0694,  0.0806,\n",
              "                       0.0745,  0.0687,  0.0700,  0.0564,  0.0759,  0.0751,  0.0707,  0.0816,\n",
              "                       0.0641,  0.0657,  0.0835,  0.0815,  0.0857,  0.0828,  0.1087,  0.0503,\n",
              "                       0.0698,  0.0615,  0.0662,  0.0635, -0.0544,  0.0207,  0.0923,  0.0543,\n",
              "                       0.0195,  0.0627,  0.0459,  0.0666,  0.0805,  0.0680,  0.0742,  0.0822,\n",
              "                       0.0755,  0.0943,  0.0317,  0.0580,  0.0719,  0.0712,  0.0757,  0.0735,\n",
              "                       0.0638,  0.0666,  0.0788,  0.0589,  0.0759,  0.0569,  0.0743,  0.0722,\n",
              "                       0.0595,  0.0963,  0.0804,  0.0680,  0.0803,  0.0725,  0.0735,  0.0667,\n",
              "                       0.0853,  0.0817,  0.0686,  0.0584,  0.0701,  0.0690,  0.0909,  0.0869,\n",
              "                       0.0763,  0.0980,  0.0617,  0.0684,  0.0715,  0.0714, -0.0733,  0.0680,\n",
              "                       0.0810,  0.0548,  0.0906,  0.0154,  0.0466,  0.0720,  0.0632,  0.0715,\n",
              "                       0.0681,  0.0857,  0.0325,  0.0975,  0.0826,  0.0822,  0.0642,  0.0838,\n",
              "                       0.0683,  0.0862,  0.0705,  0.0524,  0.0735,  0.0789,  0.0508,  0.0762,\n",
              "                       0.0639,  0.0882,  0.0795,  0.0946,  0.0787,  0.0748,  0.0694,  0.0719,\n",
              "                       0.0624,  0.0823,  0.0786,  0.0630,  0.0756,  0.0819,  0.0691,  0.0700,\n",
              "                       0.0797,  0.0572,  0.0807,  0.0765,  0.0829,  0.0595,  0.0857,  0.0818,\n",
              "                       0.0733,  0.0748,  0.0815,  0.0556,  0.0658,  0.0798,  0.0764,  0.0298,\n",
              "                       0.0723,  0.0647,  0.0396,  0.0688,  0.0776,  0.0823,  0.0773,  0.0688,\n",
              "                       0.0099,  0.0296,  0.0840,  0.0641,  0.0834,  0.0774,  0.0809,  0.0856,\n",
              "                       0.0517,  0.0677,  0.0685,  0.0845,  0.0624,  0.0743,  0.0753,  0.0771,\n",
              "                       0.0427,  0.0786,  0.0763,  0.0847,  0.0763,  0.0790,  0.0094,  0.0827,\n",
              "                       0.0903,  0.0694,  0.0958,  0.0940,  0.0755,  0.0754,  0.0710,  0.0718,\n",
              "                       0.0686,  0.0764,  0.0729,  0.0651,  0.0839,  0.1009,  0.0877,  0.0713,\n",
              "                       0.0719,  0.0696,  0.0633,  0.0773,  0.0738,  0.0692,  0.0730,  0.0867,\n",
              "                       0.0805,  0.0789,  0.0762,  0.0677,  0.0813,  0.0695,  0.0607,  0.0775,\n",
              "                       0.0653,  0.0783,  0.0646,  0.0845,  0.0685,  0.0787,  0.0886,  0.0749,\n",
              "                       0.0649,  0.0616,  0.0715,  0.0636,  0.0451,  0.0589,  0.0820,  0.0627,\n",
              "                       0.0647,  0.0681,  0.0834,  0.0682,  0.0820,  0.0025,  0.0772,  0.0818,\n",
              "                       0.0827,  0.0509,  0.0395,  0.0646,  0.0732,  0.0707,  0.0778,  0.0622,\n",
              "                       0.0786,  0.0780,  0.0866,  0.0754,  0.0736,  0.0671,  0.0799,  0.0769,\n",
              "                       0.0711,  0.0791,  0.0910,  0.0461,  0.0694,  0.0709,  0.0651,  0.0705,\n",
              "                       0.0779,  0.0857,  0.0744,  0.0735,  0.0610,  0.0797,  0.0695,  0.0703,\n",
              "                       0.0606,  0.1004,  0.0722,  0.0870,  0.0838,  0.0765,  0.0670,  0.0767,\n",
              "                       0.0654,  0.0771,  0.0886,  0.0889,  0.0573,  0.0640,  0.0691,  0.0670,\n",
              "                       0.0652,  0.0748,  0.0794,  0.0692,  0.0625,  0.0813,  0.0867,  0.0744,\n",
              "                       0.0691,  0.0638,  0.0583,  0.0720,  0.0210,  0.0593,  0.0771,  0.0330,\n",
              "                       0.0745,  0.0810,  0.1014,  0.0830,  0.0669,  0.0633,  0.0962,  0.0762,\n",
              "                       0.0812,  0.0639,  0.0546,  0.0525,  0.0830,  0.0742,  0.0714,  0.0666,\n",
              "                       0.0647,  0.0731,  0.0485,  0.0752,  0.0716,  0.0696,  0.0818,  0.0757,\n",
              "                       0.0117,  0.0730,  0.0907,  0.0803,  0.0667,  0.0748,  0.0737,  0.0597,\n",
              "                       0.1059,  0.0487,  0.0694,  0.0757,  0.0797,  0.0839,  0.0877,  0.0798,\n",
              "                       0.0839,  0.0661,  0.0576,  0.0742,  0.0604,  0.0759,  0.0735,  0.0817,\n",
              "                       0.0260,  0.0740,  0.0642,  0.0563,  0.0782,  0.0791,  0.0720,  0.0748,\n",
              "                       0.0654,  0.0839,  0.0801,  0.0675,  0.0162,  0.0791,  0.0775,  0.0825,\n",
              "                       0.0825,  0.0805,  0.0780,  0.0721,  0.0729,  0.0838,  0.0783,  0.0243,\n",
              "                       0.0664,  0.0804,  0.0756,  0.0775,  0.0812,  0.0661,  0.0880,  0.0775,\n",
              "                       0.0750,  0.0671,  0.0743,  0.0700,  0.0761,  0.0823,  0.0621,  0.0865,\n",
              "                       0.0739,  0.0673,  0.0568,  0.0899,  0.0743,  0.0669,  0.0824,  0.0894,\n",
              "                       0.0728,  0.0771,  0.0732,  0.0600,  0.0753,  0.0698,  0.0738,  0.0345,\n",
              "                       0.0715,  0.0691,  0.0546,  0.0610,  0.0702,  0.0701,  0.0713,  0.0748,\n",
              "                       0.0838,  0.0878,  0.0815,  0.0781,  0.0782,  0.0721,  0.0634,  0.0574,\n",
              "                       0.0653,  0.0682,  0.0736,  0.0777,  0.0826,  0.0804,  0.0672,  0.0567,\n",
              "                       0.0708,  0.0558,  0.0718,  0.0792,  0.0733,  0.0781,  0.0610,  0.0758,\n",
              "                       0.0741,  0.0693,  0.0438,  0.1738,  0.0730,  0.0755,  0.0701,  0.0731,\n",
              "                       0.0744,  0.0735,  0.0732,  0.0794,  0.0716,  0.0760,  0.0565,  0.0723,\n",
              "                       0.0886,  0.0686,  0.0710,  0.0022,  0.0573,  0.0793,  0.0780,  0.0682,\n",
              "                       0.0709,  0.0804,  0.0755,  0.0829,  0.0748,  0.0704,  0.0783,  0.0769,\n",
              "                       0.0652,  0.0759,  0.0647,  0.0755,  0.0409,  0.0760,  0.1163,  0.0645,\n",
              "                       0.0634,  0.0688,  0.0798,  0.0743,  0.0841,  0.0580,  0.0741,  0.0144,\n",
              "                       0.0905,  0.0805,  0.0759,  0.0867,  0.0771,  0.0751,  0.0721,  0.0890,\n",
              "                       0.0806,  0.0534,  0.0724,  0.0728,  0.0755,  0.0683,  0.0705,  0.0689,\n",
              "                       0.0731,  0.0659,  0.0715,  0.0664,  0.0666,  0.0699,  0.0633,  0.0716,\n",
              "                       0.0480,  0.0578,  0.0731,  0.0735,  0.0745,  0.0799,  0.0758,  0.0740,\n",
              "                       0.0544,  0.0771,  0.0819,  0.0800,  0.0795,  0.0807,  0.0436,  0.0793,\n",
              "                       0.0592,  0.0776,  0.0523,  0.0813,  0.0678,  0.0766,  0.0847, -0.0349,\n",
              "                       0.0668,  0.0678,  0.0872,  0.0828,  0.0784,  0.0791,  0.0744,  0.1123,\n",
              "                       0.0810,  0.0762,  0.0719,  0.0740,  0.0721,  0.0776,  0.0644,  0.0672,\n",
              "                       0.0782,  0.0584,  0.0901,  0.0861,  0.0562,  0.0757,  0.0795,  0.0743,\n",
              "                       0.0938,  0.0729,  0.0602,  0.0684,  0.0659,  0.0721,  0.0613,  0.0718,\n",
              "                       0.0798,  0.0600,  0.0702,  0.0759,  0.0694,  0.0638,  0.0916,  0.0714,\n",
              "                       0.0889,  0.0649,  0.0806,  0.0821,  0.0732,  0.0754,  0.0678,  0.0387,\n",
              "                       0.0626,  0.0757,  0.0843,  0.0804,  0.0334,  0.0797,  0.0501,  0.0739,\n",
              "                       0.0617,  0.0689,  0.0391,  0.0814,  0.0772,  0.0799,  0.0725,  0.0898,\n",
              "                       0.0836,  0.0776,  0.0577,  0.0751,  0.0727,  0.0431,  0.0631,  0.0717,\n",
              "                       0.0682,  0.0783,  0.0766,  0.0716,  0.0728,  0.0619,  0.0676,  0.0699,\n",
              "                       0.0719,  0.0660,  0.0760,  0.0672,  0.0714,  0.0454,  0.0760,  0.0689,\n",
              "                       0.0813,  0.0673,  0.0529,  0.0701,  0.0739,  0.0591,  0.0831,  0.0680,\n",
              "                       0.0918,  0.0667,  0.0899,  0.0726,  0.0677,  0.0741,  0.0521,  0.0766,\n",
              "                       0.0565,  0.0687,  0.0689,  0.0750,  0.0736,  0.0709,  0.0754,  0.0768],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.6610,  0.2377,  0.4962,  ..., -0.2093,  0.1284,  0.0103],\n",
              "                      [-0.2274,  0.7018,  0.5289,  ..., -0.0790,  0.1116, -0.1261],\n",
              "                      [ 0.0542,  0.0212,  0.0488,  ..., -0.3699,  0.3174, -0.6832],\n",
              "                      ...,\n",
              "                      [ 0.2183,  0.2774,  0.6256,  ...,  0.0281,  0.2324,  0.4321],\n",
              "                      [-0.3111,  0.2065,  0.3415,  ..., -0.3904,  0.1560,  0.3496],\n",
              "                      [ 0.5065,  0.8414,  0.3072,  ..., -0.1865,  0.2606, -0.2469]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.1213, -0.2517,  0.1519,  ...,  0.0165,  0.0851, -0.1806],\n",
              "                      [-0.0654,  0.0507,  0.5445,  ...,  0.2303, -0.2056,  0.9274],\n",
              "                      [-0.1435, -0.7045, -0.2645,  ..., -0.0240, -0.9987,  1.0481],\n",
              "                      ...,\n",
              "                      [-0.1930,  0.1228, -0.1085,  ..., -0.4717,  0.0033,  0.1853],\n",
              "                      [ 0.0335,  0.3036, -0.2929,  ...,  0.1171, -0.2332,  0.1637],\n",
              "                      [ 0.2708, -0.0302, -0.3387,  ..., -0.2274,  0.0783, -0.0905]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.1.layer.2.layer_norm.weight',\n",
              "              tensor([1.1572, 0.4168, 0.4281, 1.3707, 0.9743, 1.1310, 0.8297, 1.2638, 0.7559,\n",
              "                      0.9521, 1.5778, 1.0634, 0.7814, 0.9905, 1.0266, 1.0472, 0.9795, 0.6962,\n",
              "                      1.0399, 1.0312, 1.0143, 1.0660, 1.1016, 1.0026, 0.9897, 0.7316, 0.9610,\n",
              "                      0.9169, 0.9906, 0.9561, 0.9717, 0.4719, 1.0545, 0.9510, 1.0845, 0.7905,\n",
              "                      0.9614, 0.4937, 0.9400, 1.2030, 1.0237, 1.0394, 0.9255, 1.0621, 0.5025,\n",
              "                      0.9600, 1.0680, 0.9905, 0.9871, 1.1685, 0.9578, 0.9914, 0.9955, 0.9810,\n",
              "                      2.0378, 1.1053, 1.1796, 1.0350, 1.0733, 1.1089, 0.9648, 1.0017, 1.0416,\n",
              "                      0.9900, 0.9737, 0.3564, 0.9884, 1.0242, 0.5636, 0.9770, 0.9199, 0.9852,\n",
              "                      0.8898, 0.9325, 1.0071, 0.9541, 0.9996, 1.0528, 0.9071, 0.8733, 0.9278,\n",
              "                      0.9843, 1.0407, 0.7667, 0.8247, 0.9362, 1.1485, 0.9544, 0.9434, 1.0059,\n",
              "                      0.9289, 0.9411, 0.9246, 1.1130, 0.9527, 1.0494, 0.9896, 1.0128, 0.9598,\n",
              "                      0.9202, 1.1518, 0.8698, 1.1082, 0.9669, 0.9225, 1.1261, 1.0351, 0.9390,\n",
              "                      0.8255, 1.0287, 1.0194, 1.0019, 1.0797, 0.9783, 0.8862, 0.7980, 1.0928,\n",
              "                      0.9815, 0.1757, 0.8973, 0.9421, 0.8915, 0.7184, 0.8742, 0.9507, 0.9166,\n",
              "                      1.0169, 1.1303, 1.0129, 0.9898, 1.0055, 0.9040, 1.0089, 0.9627, 0.7293,\n",
              "                      1.0412, 0.9611, 0.7572, 1.2327, 1.4369, 0.8164, 0.9234, 1.1075, 1.0881,\n",
              "                      0.9615, 1.0371, 0.7854, 0.8107, 0.8388, 1.1543, 0.9023, 0.9356, 0.8308,\n",
              "                      0.9987, 0.9433, 0.9323, 1.0923, 1.0069, 0.8202, 1.0682, 0.8800, 0.9535,\n",
              "                      0.8892, 0.9326, 0.7292, 0.5200, 1.0291, 0.6917, 0.4358, 1.0001, 1.0519,\n",
              "                      0.9481, 0.9728, 0.9714, 1.0260, 1.0224, 0.9492, 1.0240, 1.1718, 0.6943,\n",
              "                      0.9850, 0.9948, 1.0930, 1.0583, 0.9842, 0.8996, 1.0174, 0.7257, 0.9637,\n",
              "                      1.0320, 1.0014, 0.9932, 0.7718, 1.1018, 0.9686, 0.8208, 1.0404, 1.0006,\n",
              "                      1.0485, 0.8537, 0.9784, 1.2703, 0.9831, 0.8416, 0.9593, 1.1373, 1.0303,\n",
              "                      1.0425, 0.8676, 1.0707, 0.7447, 1.1597, 0.9839, 0.9343, 1.0939, 1.1282,\n",
              "                      0.9579, 0.8556, 1.0494, 0.5001, 0.9484, 0.8556, 0.7579, 0.9568, 0.9008,\n",
              "                      1.0281, 0.1999, 0.9446, 0.9753, 0.9871, 0.8339, 1.0911, 0.9329, 0.9392,\n",
              "                      0.8986, 0.9127, 1.1462, 1.1066, 1.2232, 1.1559, 1.2993, 0.9798, 0.8726,\n",
              "                      0.8300, 0.9673, 0.9935, 0.8840, 1.1620, 0.8620, 0.9779, 1.0529, 0.9060,\n",
              "                      0.9830, 0.9671, 0.8863, 0.8269, 0.9623, 1.3354, 0.9803, 0.9829, 1.0153,\n",
              "                      1.3504, 1.0007, 1.2122, 0.9632, 0.9067, 0.8579, 0.8118, 0.9045, 1.0632,\n",
              "                      1.0160, 0.4729, 1.0853, 0.8805, 1.1902, 1.0571, 0.9665, 1.1577, 0.9102,\n",
              "                      1.0095, 0.1667, 0.5701, 1.0023, 0.9344, 0.9768, 1.0442, 1.0077, 1.0495,\n",
              "                      0.8377, 1.0294, 0.8840, 0.9327, 0.9604, 1.1135, 1.0014, 0.9622, 0.4144,\n",
              "                      0.9679, 0.9653, 1.1764, 1.0712, 0.9853, 0.2614, 1.0728, 1.0297, 0.9034,\n",
              "                      1.0742, 1.0928, 1.0790, 0.8540, 0.8380, 1.0270, 1.0084, 0.9540, 0.4357,\n",
              "                      1.1049, 0.9227, 1.0317, 1.0114, 0.8696, 0.9712, 0.9661, 1.0315, 0.9210,\n",
              "                      0.7644, 1.0001, 1.0984, 0.9193, 1.1449, 1.0052, 0.9906, 0.9067, 1.0200,\n",
              "                      0.8573, 0.9140, 1.0518, 0.8160, 0.9088, 0.8251, 1.2419, 0.9579, 1.0013,\n",
              "                      0.9265, 1.0168, 0.9775, 0.8542, 1.0545, 1.1523, 0.5464, 1.0440, 0.8658,\n",
              "                      0.7850, 0.8175, 0.8566, 1.1000, 0.9754, 1.0575, 0.2645, 1.0895, 1.0962,\n",
              "                      1.0369, 0.7840, 0.7388, 0.8542, 0.8799, 0.8667, 1.0830, 0.8912, 0.9350,\n",
              "                      1.0334, 0.9946, 0.9947, 0.8575, 0.9458, 1.0624, 1.0195, 0.9807, 0.7740,\n",
              "                      0.9735, 0.7762, 0.9495, 0.9489, 1.0049, 1.0129, 0.9191, 1.0938, 0.9145,\n",
              "                      1.1385, 0.8093, 1.0106, 0.8283, 0.9672, 1.0106, 1.3421, 1.0024, 1.0452,\n",
              "                      0.9941, 0.9368, 0.9783, 1.1159, 0.8991, 0.9958, 0.9997, 1.0249, 0.9670,\n",
              "                      0.9168, 0.8383, 0.9334, 0.8284, 0.9364, 0.9109, 0.8584, 0.9764, 0.9823,\n",
              "                      1.0169, 0.9427, 0.8954, 1.0663, 0.3251, 0.9529, 0.6069, 0.9097, 0.9770,\n",
              "                      1.3018, 0.9497, 0.8823, 1.1247, 0.9588, 0.9356, 1.6862, 0.9488, 0.9198,\n",
              "                      1.0936, 0.8678, 0.9414, 0.8567, 0.9764, 0.8027, 0.9569, 0.9270, 0.9562,\n",
              "                      0.9515, 0.6360, 1.0537, 0.9262, 0.8297, 0.9621, 1.0135, 0.2552, 0.9304,\n",
              "                      1.0195, 0.9344, 1.0369, 0.9332, 0.8505, 1.0898, 0.7357, 0.4623, 1.0823,\n",
              "                      0.8739, 0.9731, 1.0469, 1.0492, 0.9949, 1.1252, 0.9982, 1.0469, 1.0128,\n",
              "                      0.7730, 0.9290, 0.9802, 0.9083, 0.6451, 0.9902, 0.9331, 0.9136, 1.0467,\n",
              "                      0.9395, 0.9549, 1.0820, 1.2638, 1.1217, 0.9970, 0.8759, 0.2695, 1.0259,\n",
              "                      0.9561, 0.7174, 0.9127, 1.0335, 1.0271, 0.8874, 1.1006, 0.9454, 1.0647,\n",
              "                      0.8248, 0.9046, 0.9842, 1.0105, 1.1237, 0.9187, 0.4891, 0.9303, 1.0222,\n",
              "                      0.9883, 0.9069, 0.9499, 1.0275, 0.8557, 0.9594, 0.8478, 1.0341, 1.0412,\n",
              "                      0.9710, 0.7148, 1.0534, 0.9963, 0.8029, 1.1824, 1.1162, 1.0109, 1.0352,\n",
              "                      0.8869, 0.8441, 1.0664, 0.8726, 1.1940, 0.6274, 0.9449, 0.8630, 0.7723,\n",
              "                      0.9992, 0.9702, 0.9474, 0.8165, 0.9747, 1.0425, 1.0245, 0.9843, 0.9542,\n",
              "                      0.9570, 0.9431, 1.0411, 0.9506, 0.9768, 0.9911, 0.9437, 0.9936, 0.9477,\n",
              "                      0.9960, 0.8181, 0.8204, 0.8861, 0.8160, 1.0208, 0.9572, 1.0069, 1.0730,\n",
              "                      0.7523, 1.0277, 0.9490, 0.8273, 0.4930, 2.1350, 1.0356, 0.8306, 0.9564,\n",
              "                      1.0271, 1.0809, 0.9571, 0.8480, 1.0650, 0.9796, 1.1965, 1.1809, 0.8416,\n",
              "                      0.9884, 0.9869, 0.8401, 0.1470, 0.6875, 1.0003, 1.0553, 0.9522, 1.0087,\n",
              "                      0.9669, 0.9615, 1.1143, 0.9652, 0.9941, 1.0216, 1.0242, 0.8877, 0.9044,\n",
              "                      0.9740, 1.0906, 0.5388, 1.0477, 1.5201, 0.9407, 0.9012, 0.9984, 1.0210,\n",
              "                      0.9673, 0.9975, 0.9545, 0.8982, 0.3225, 1.1162, 1.0725, 1.0775, 0.9669,\n",
              "                      0.9795, 0.9521, 0.9326, 1.1765, 0.9702, 0.3028, 0.8193, 1.0067, 1.0178,\n",
              "                      0.9059, 0.9215, 1.1511, 1.2324, 0.9554, 1.2790, 1.0018, 0.8518, 0.9933,\n",
              "                      0.8029, 0.8828, 0.7230, 0.7302, 0.9152, 0.9134, 1.2731, 1.0399, 0.9907,\n",
              "                      0.9453, 0.8764, 0.8052, 0.9578, 0.9343, 1.0043, 1.1265, 0.7016, 0.9701,\n",
              "                      1.1559, 0.9861, 0.6427, 1.0178, 0.8981, 1.0286, 1.0252, 0.8830, 0.9404,\n",
              "                      1.1199, 1.0972, 1.1019, 0.9089, 1.0812, 0.9337, 1.0276, 0.9235, 0.9953,\n",
              "                      0.8805, 0.9309, 0.9906, 1.0418, 0.8602, 1.0116, 0.9759, 0.8544, 0.9754,\n",
              "                      0.9623, 0.9446, 0.8775, 1.0725, 0.9790, 0.9656, 0.9941, 1.0661, 0.8496,\n",
              "                      0.9519, 1.0274, 0.9162, 0.9148, 0.9723, 0.9565, 1.0099, 1.0994, 0.8803,\n",
              "                      0.8467, 0.9487, 0.9416, 1.0238, 0.8540, 0.9998, 1.0053, 0.9864, 0.9116,\n",
              "                      0.9578, 1.1588, 0.7074, 0.9982, 0.9984, 1.2053, 0.4096, 0.9960, 0.9119,\n",
              "                      0.9087, 0.8659, 0.8813, 0.8592, 0.5729, 1.0064, 0.8462, 0.9138, 1.0942,\n",
              "                      1.0031, 0.9618, 0.8005, 0.8826, 1.0455, 0.4996, 0.8450, 0.9247, 0.9735,\n",
              "                      1.1982, 0.9782, 1.0978, 0.9809, 0.8105, 0.7364, 0.9655, 0.9464, 0.9362,\n",
              "                      0.9605, 0.9158, 0.8564, 0.9635, 1.0061, 1.1248, 1.1639, 0.8295, 0.9301,\n",
              "                      0.8457, 1.0465, 1.1423, 1.1704, 0.8372, 1.0743, 0.8732, 1.0043, 0.9403,\n",
              "                      0.9325, 0.9154, 0.7255, 1.0033, 0.8284, 0.8931, 1.0586, 1.2278, 0.8673,\n",
              "                      0.9570, 1.0830, 1.1069], device='cuda:0')),\n",
              "             ('decoder.block.2.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0458,  0.0328,  0.0154,  ...,  0.0523, -0.0376, -0.0155],\n",
              "                      [ 0.0162, -0.0768,  0.0439,  ..., -0.0669,  0.0543, -0.0346],\n",
              "                      [ 0.0080, -0.0630,  0.0208,  ..., -0.0217,  0.0026,  0.0095],\n",
              "                      ...,\n",
              "                      [-0.0005, -0.0877, -0.0056,  ...,  0.0317, -0.0090,  0.0303],\n",
              "                      [ 0.0244,  0.0243, -0.0180,  ...,  0.0155,  0.0059, -0.0073],\n",
              "                      [-0.0414,  0.0265, -0.0346,  ..., -0.0200, -0.0057, -0.0495]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.4266, -0.5638, -0.1069,  ..., -0.2715, -0.0087, -0.4187],\n",
              "                      [-0.3323,  0.4098,  0.1618,  ...,  0.1355, -0.2144,  0.1623],\n",
              "                      [ 0.4288, -0.2181,  0.3446,  ..., -0.1797,  0.3323, -0.1959],\n",
              "                      ...,\n",
              "                      [ 0.0536, -0.2093,  0.4074,  ...,  0.3413, -0.2537, -0.2464],\n",
              "                      [-0.0932, -0.3733, -0.1275,  ...,  0.3857, -0.0736,  0.0079],\n",
              "                      [-0.7638,  0.3792, -0.3835,  ...,  0.3537, -0.0250, -0.8180]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.3081,  0.8379, -0.1213,  ..., -0.7451,  0.3936, -1.0651],\n",
              "                      [ 0.8407, -0.2340,  0.7081,  ..., -0.5467,  0.0088, -0.3783],\n",
              "                      [ 0.2704, -0.6799,  0.7058,  ..., -0.6121,  0.3691, -0.6874],\n",
              "                      ...,\n",
              "                      [ 0.1559,  0.3097,  0.5973,  ...,  0.3527,  0.6306,  0.4247],\n",
              "                      [ 0.7070, -0.0013, -0.0810,  ..., -0.2431,  1.0923, -0.6286],\n",
              "                      [-0.0431,  0.1298,  0.0028,  ..., -0.6125, -0.6137,  0.6318]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 1.2150e-01, -1.7948e-01, -3.6947e-01,  ..., -3.9092e-01,\n",
              "                        2.1841e-01,  1.2806e-01],\n",
              "                      [-1.0145e+00, -1.9778e+00, -1.0370e+00,  ..., -5.1729e-01,\n",
              "                        2.3546e-01, -1.4379e-01],\n",
              "                      [ 3.2556e-01, -1.6602e-01, -2.7506e-01,  ..., -3.6071e-01,\n",
              "                        6.0341e-01, -1.5626e-01],\n",
              "                      ...,\n",
              "                      [-1.7868e-01,  6.2763e-01,  2.5614e-03,  ..., -4.0676e-02,\n",
              "                        2.8117e-01,  9.6325e-01],\n",
              "                      [-8.3674e-02, -4.0087e-02,  4.8565e-01,  ...,  2.9574e-01,\n",
              "                       -5.1235e-01,  6.0373e-02],\n",
              "                      [ 1.4769e-01, -6.3458e-01, -3.1375e-01,  ..., -6.3016e-01,\n",
              "                        7.2374e-01, -1.9590e-03]], device='cuda:0')),\n",
              "             ('decoder.block.2.layer.0.layer_norm.weight',\n",
              "              tensor([0.1803, 0.0684, 0.0745, 0.2411, 0.1768, 0.1427, 0.1724, 0.1989, 0.1590,\n",
              "                      0.1964, 0.1243, 0.2123, 0.0871, 0.1328, 0.1806, 0.1858, 0.1653, 0.1293,\n",
              "                      0.1870, 0.1960, 0.1792, 0.1992, 0.2023, 0.1836, 0.1968, 0.1317, 0.1861,\n",
              "                      0.1419, 0.1709, 0.1780, 0.1936, 0.0809, 0.1976, 0.1809, 0.1938, 0.1323,\n",
              "                      0.1918, 0.1502, 0.1882, 0.2063, 0.2005, 0.1829, 0.1824, 0.1979, 0.1000,\n",
              "                      0.1688, 0.2043, 0.1897, 0.1921, 0.2022, 0.1743, 0.1801, 0.1665, 0.1859,\n",
              "                      0.3323, 0.1543, 0.1686, 0.1966, 0.2239, 0.1726, 0.1755, 0.1909, 0.2006,\n",
              "                      0.1824, 0.1785, 0.0915, 0.1876, 0.1989, 0.0918, 0.1804, 0.2012, 0.2052,\n",
              "                      0.1800, 0.1865, 0.1797, 0.1727, 0.1398, 0.1687, 0.1618, 0.1692, 0.1889,\n",
              "                      0.1727, 0.1861, 0.1429, 0.1634, 0.1734, 0.1902, 0.2065, 0.1800, 0.1928,\n",
              "                      0.1726, 0.1727, 0.1598, 0.1765, 0.1736, 0.1921, 0.1846, 0.1917, 0.1917,\n",
              "                      0.1906, 0.1560, 0.1560, 0.0877, 0.1787, 0.1822, 0.2031, 0.1805, 0.1600,\n",
              "                      0.1686, 0.1969, 0.2004, 0.2228, 0.1716, 0.1877, 0.1606, 0.1731, 0.1786,\n",
              "                      0.1615, 0.0376, 0.1722, 0.1721, 0.1754, 0.1330, 0.1739, 0.2234, 0.1664,\n",
              "                      0.2060, 0.1573, 0.1759, 0.1228, 0.1352, 0.1580, 0.1704, 0.1832, 0.1061,\n",
              "                      0.1962, 0.1735, 0.1509, 0.1708, 0.1084, 0.1371, 0.1805, 0.1897, 0.2066,\n",
              "                      0.1579, 0.1658, 0.1609, 0.1463, 0.1584, 0.1803, 0.1927, 0.1755, 0.1785,\n",
              "                      0.1624, 0.1832, 0.1985, 0.1994, 0.1985, 0.0412, 0.1041, 0.1439, 0.1490,\n",
              "                      0.1536, 0.1655, 0.1489, 0.0819, 0.1993, 0.1369, 0.0820, 0.1856, 0.0925,\n",
              "                      0.1743, 0.2328, 0.1853, 0.1895, 0.2034, 0.1663, 0.2092, 0.0777, 0.1423,\n",
              "                      0.1862, 0.1911, 0.2025, 0.1945, 0.1521, 0.1682, 0.1968, 0.0224, 0.1929,\n",
              "                      0.1358, 0.1713, 0.1912, 0.1514, 0.1957, 0.1719, 0.1478, 0.2041, 0.2039,\n",
              "                      0.2064, 0.1672, 0.2023, 0.1916, 0.1855, 0.1586, 0.1777, 0.1803, 0.1818,\n",
              "                      0.1713, 0.1554, 0.2261, 0.1533, 0.1546, 0.1921, 0.1587, 0.1903, 0.2101,\n",
              "                      0.1811, 0.1561, 0.2036, 0.0298, 0.1270, 0.1624, 0.1292, 0.1817, 0.1526,\n",
              "                      0.1920, 0.1970, 0.1983, 0.1944, 0.2044, 0.1680, 0.2020, 0.1644, 0.2009,\n",
              "                      0.1712, 0.1693, 0.1778, 0.1843, 0.1114, 0.2112, 0.1590, 0.1951, 0.1601,\n",
              "                      0.1733, 0.2050, 0.1787, 0.1778, 0.1749, 0.1702, 0.1987, 0.1904, 0.1628,\n",
              "                      0.1703, 0.1820, 0.1849, 0.1554, 0.2005, 0.1134, 0.1960, 0.1671, 0.2354,\n",
              "                      0.1150, 0.1950, 0.2003, 0.1754, 0.1718, 0.1770, 0.1755, 0.1932, 0.1902,\n",
              "                      0.1867, 0.0961, 0.2072, 0.1697, 0.0880, 0.2062, 0.1804, 0.1909, 0.1649,\n",
              "                      0.1568, 0.0378, 0.0970, 0.1862, 0.1745, 0.1971, 0.1954, 0.1816, 0.2055,\n",
              "                      0.1416, 0.1558, 0.1793, 0.1497, 0.1664, 0.1976, 0.1797, 0.1693, 0.0924,\n",
              "                      0.1959, 0.1737, 0.2260, 0.2081, 0.1868, 0.0324, 0.1910, 0.2048, 0.1814,\n",
              "                      0.2065, 0.1926, 0.1941, 0.1580, 0.1774, 0.1827, 0.1869, 0.1846, 0.1537,\n",
              "                      0.1791, 0.1880, 0.2276, 0.2054, 0.1712, 0.1987, 0.1849, 0.1494, 0.1806,\n",
              "                      0.1602, 0.1752, 0.1877, 0.2046, 0.2051, 0.1983, 0.1886, 0.1503, 0.2091,\n",
              "                      0.1583, 0.1717, 0.1866, 0.1734, 0.1891, 0.1638, 0.1749, 0.1828, 0.1741,\n",
              "                      0.1987, 0.1895, 0.1947, 0.1729, 0.2008, 0.1615, 0.0806, 0.1826, 0.1708,\n",
              "                      0.1682, 0.1442, 0.1807, 0.1822, 0.1824, 0.2031, 0.0368, 0.2043, 0.2018,\n",
              "                      0.1932, 0.1444, 0.1168, 0.1582, 0.1689, 0.1586, 0.1914, 0.1705, 0.1671,\n",
              "                      0.1791, 0.1961, 0.2109, 0.1701, 0.1716, 0.2021, 0.1790, 0.1845, 0.2060,\n",
              "                      0.1932, 0.1455, 0.1730, 0.1788, 0.1394, 0.1739, 0.1753, 0.2063, 0.1829,\n",
              "                      0.2066, 0.1605, 0.2050, 0.1605, 0.1781, 0.1599, 0.2313, 0.1849, 0.1975,\n",
              "                      0.1999, 0.1577, 0.1723, 0.1827, 0.1716, 0.1885, 0.1833, 0.1899, 0.1663,\n",
              "                      0.1891, 0.1403, 0.1831, 0.1628, 0.1921, 0.1790, 0.1771, 0.2096, 0.1732,\n",
              "                      0.1783, 0.1845, 0.1651, 0.1967, 0.1483, 0.1856, 0.0262, 0.1557, 0.1886,\n",
              "                      0.0583, 0.1870, 0.1935, 0.1703, 0.1810, 0.1797, 0.1190, 0.1784, 0.1870,\n",
              "                      0.1912, 0.1538, 0.1700, 0.1648, 0.1873, 0.1759, 0.1804, 0.1866, 0.1964,\n",
              "                      0.1733, 0.1609, 0.2146, 0.1990, 0.1831, 0.1703, 0.1856, 0.0327, 0.1571,\n",
              "                      0.1854, 0.1883, 0.1906, 0.1948, 0.1661, 0.1823, 0.1905, 0.1786, 0.1983,\n",
              "                      0.1779, 0.2000, 0.1936, 0.2074, 0.1777, 0.1861, 0.1819, 0.1591, 0.1908,\n",
              "                      0.1518, 0.1805, 0.1869, 0.1772, 0.0598, 0.1846, 0.1850, 0.1694, 0.1969,\n",
              "                      0.1755, 0.1764, 0.1975, 0.1478, 0.2074, 0.2014, 0.1652, 0.0640, 0.1863,\n",
              "                      0.1805, 0.0416, 0.1803, 0.1931, 0.1896, 0.1788, 0.1996, 0.2035, 0.1964,\n",
              "                      0.0555, 0.1617, 0.1723, 0.2003, 0.2026, 0.1638, 0.1364, 0.1783, 0.1731,\n",
              "                      0.1858, 0.1825, 0.1923, 0.1547, 0.1871, 0.1723, 0.1605, 0.1768, 0.1821,\n",
              "                      0.1715, 0.1542, 0.2025, 0.1688, 0.1622, 0.1616, 0.2104, 0.1857, 0.1881,\n",
              "                      0.1796, 0.1857, 0.1793, 0.1720, 0.1867, 0.1089, 0.1703, 0.1863, 0.1348,\n",
              "                      0.1730, 0.1895, 0.1754, 0.1757, 0.1920, 0.2125, 0.1827, 0.1945, 0.1718,\n",
              "                      0.2015, 0.1885, 0.1954, 0.1782, 0.1724, 0.1809, 0.1988, 0.1993, 0.1677,\n",
              "                      0.1706, 0.1480, 0.1435, 0.1803, 0.1214, 0.2081, 0.1945, 0.1671, 0.1987,\n",
              "                      0.1388, 0.1754, 0.1876, 0.1780, 0.1585, 0.3301, 0.2202, 0.1638, 0.1862,\n",
              "                      0.2002, 0.1880, 0.1911, 0.1740, 0.2132, 0.1740, 0.1584, 0.1190, 0.1839,\n",
              "                      0.1819, 0.1969, 0.1610, 0.0310, 0.1226, 0.1777, 0.1774, 0.1754, 0.1915,\n",
              "                      0.1849, 0.1744, 0.2080, 0.1960, 0.1807, 0.1927, 0.2084, 0.1693, 0.1702,\n",
              "                      0.1791, 0.2069, 0.1041, 0.1975, 0.2384, 0.1797, 0.1668, 0.1867, 0.1907,\n",
              "                      0.1666, 0.1871, 0.1775, 0.1790, 0.0707, 0.2013, 0.1895, 0.2042, 0.1707,\n",
              "                      0.1878, 0.1899, 0.1916, 0.2323, 0.1642, 0.1321, 0.1747, 0.2025, 0.1850,\n",
              "                      0.1678, 0.1863, 0.1293, 0.1884, 0.1865, 0.1788, 0.1895, 0.1553, 0.1907,\n",
              "                      0.1527, 0.1712, 0.1561, 0.1641, 0.1687, 0.1873, 0.1507, 0.1745, 0.1897,\n",
              "                      0.1578, 0.1398, 0.1779, 0.1888, 0.1802, 0.1274, 0.1838, 0.1130, 0.1720,\n",
              "                      0.1798, 0.2045, 0.1054, 0.1907, 0.1562, 0.1763, 0.2056, 0.0893, 0.1912,\n",
              "                      0.1374, 0.1986, 0.1946, 0.2027, 0.1744, 0.1882, 0.2225, 0.1899, 0.1895,\n",
              "                      0.1621, 0.2076, 0.1483, 0.1969, 0.1597, 0.1872, 0.1858, 0.1285, 0.1859,\n",
              "                      0.1791, 0.1487, 0.1706, 0.1852, 0.1855, 0.1777, 0.1866, 0.1718, 0.1411,\n",
              "                      0.1717, 0.1953, 0.1962, 0.1719, 0.2053, 0.1828, 0.2026, 0.1974, 0.1715,\n",
              "                      0.1720, 0.1923, 0.1826, 0.2230, 0.1758, 0.1814, 0.1759, 0.1695, 0.1849,\n",
              "                      0.1687, 0.0810, 0.1509, 0.1869, 0.1949, 0.1353, 0.1043, 0.1743, 0.1750,\n",
              "                      0.1635, 0.1285, 0.1680, 0.1124, 0.1715, 0.1687, 0.1830, 0.1747, 0.1737,\n",
              "                      0.1835, 0.1832, 0.1432, 0.1798, 0.1981, 0.0957, 0.1636, 0.1704, 0.1878,\n",
              "                      0.1909, 0.2130, 0.1872, 0.1771, 0.0558, 0.1664, 0.1597, 0.1942, 0.1761,\n",
              "                      0.1951, 0.1555, 0.1783, 0.0896, 0.2101, 0.1769, 0.2158, 0.1690, 0.1246,\n",
              "                      0.1556, 0.2031, 0.1472, 0.1765, 0.1582, 0.1972, 0.1787, 0.1720, 0.1931,\n",
              "                      0.1889, 0.1772, 0.1095, 0.1707, 0.1365, 0.1430, 0.1813, 0.1790, 0.1667,\n",
              "                      0.1829, 0.1958, 0.1832], device='cuda:0')),\n",
              "             ('decoder.block.2.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0318,  0.0075, -0.0660,  ...,  0.0131,  0.0071, -0.0458],\n",
              "                      [-0.0366,  0.0062, -0.0629,  ..., -0.0340, -0.0364, -0.0145],\n",
              "                      [-0.0003, -0.0295,  0.0135,  ...,  0.0596,  0.0209,  0.0158],\n",
              "                      ...,\n",
              "                      [ 0.0152, -0.0071, -0.0452,  ..., -0.0273, -0.0079,  0.0079],\n",
              "                      [ 0.0349,  0.0557, -0.0180,  ...,  0.0167, -0.0166,  0.0666],\n",
              "                      [-0.0081,  0.0258,  0.0508,  ...,  0.0830, -0.0461,  0.0686]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[ 0.2953, -0.3548,  0.1761,  ..., -0.5097,  0.0428, -0.1626],\n",
              "                      [-0.1275, -0.1508, -0.0686,  ..., -0.5714, -0.1234,  0.1270],\n",
              "                      [-0.0955,  0.0315,  0.3621,  ..., -0.2946,  0.2788,  0.0469],\n",
              "                      ...,\n",
              "                      [ 0.3318,  0.2114,  0.1105,  ...,  0.0138,  0.1105, -0.0626],\n",
              "                      [ 0.2345,  0.0426, -0.3798,  ...,  0.2965, -0.6272, -0.2538],\n",
              "                      [-0.2228, -0.2934,  0.1809,  ...,  0.1387, -0.1851, -0.0650]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[-0.1124, -0.6246,  0.4296,  ..., -0.0186, -0.0871,  0.9747],\n",
              "                      [-0.0101, -0.4235,  0.2272,  ...,  0.7972,  0.1609, -0.2229],\n",
              "                      [-0.0045, -0.6248, -0.0166,  ..., -0.2842,  0.0954, -0.1308],\n",
              "                      ...,\n",
              "                      [ 0.3142,  0.0402,  0.0198,  ...,  0.2789, -0.0267,  0.0976],\n",
              "                      [ 0.4469, -0.0154, -0.1786,  ...,  0.5544,  0.2105,  0.0778],\n",
              "                      [ 0.1508,  0.2709, -0.1186,  ...,  0.4136,  0.0117,  0.2276]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[ 0.1169,  0.6098, -0.4495,  ..., -0.2348,  0.1250,  0.1349],\n",
              "                      [ 0.5840, -0.1105,  0.0147,  ...,  0.1229, -0.0796, -0.3031],\n",
              "                      [-1.4411,  0.0225, -1.0668,  ...,  0.3153,  0.1858,  0.3071],\n",
              "                      ...,\n",
              "                      [-0.3524, -0.0283, -0.6077,  ..., -0.3444,  0.1457, -0.2402],\n",
              "                      [ 0.0337, -0.4528, -0.4659,  ..., -0.3234,  0.0770,  0.1046],\n",
              "                      [-0.1005,  0.2900,  0.6628,  ...,  0.1916,  0.0538,  0.0321]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.1.layer_norm.weight',\n",
              "              tensor([ 8.1063e-02,  3.1245e-02,  3.5638e-02,  1.1742e-01,  7.8612e-02,\n",
              "                       5.8844e-02,  8.5839e-02,  9.9579e-02,  6.4686e-02,  7.3813e-02,\n",
              "                       6.1891e-02,  9.0480e-02,  6.3475e-02,  5.3569e-02,  7.2668e-02,\n",
              "                       8.8516e-02,  5.8938e-02,  6.0828e-02,  7.8790e-02,  9.6313e-02,\n",
              "                       7.1613e-02,  8.2559e-02,  9.4260e-02,  7.4660e-02,  9.6158e-02,\n",
              "                       6.3005e-02,  8.9844e-02,  6.0978e-02,  8.3367e-02,  9.2710e-02,\n",
              "                       7.5189e-02,  4.0000e-02,  8.4475e-02,  7.9832e-02,  8.2554e-02,\n",
              "                       6.1342e-02,  9.4507e-02,  6.5314e-02,  7.7751e-02,  8.7909e-02,\n",
              "                       1.0128e-01,  7.8357e-02,  6.4647e-02,  8.1344e-02,  3.5428e-02,\n",
              "                       8.5430e-02,  1.0778e-01,  9.4371e-02,  9.9783e-02,  7.7748e-02,\n",
              "                       7.3606e-02,  7.9443e-02,  6.8438e-02,  8.0089e-02,  1.4783e-01,\n",
              "                       6.7130e-02,  7.3554e-02,  8.6535e-02,  7.5907e-02,  9.0515e-02,\n",
              "                       7.6186e-02,  8.5506e-02,  6.8740e-02,  9.0936e-02,  8.9627e-02,\n",
              "                       5.7703e-02,  8.0638e-02,  8.4065e-02,  2.9254e-02,  7.9496e-02,\n",
              "                       8.9971e-02,  9.7359e-02,  5.7564e-02,  7.5049e-02,  6.6388e-02,\n",
              "                       7.4853e-02,  5.1077e-02,  7.1200e-02,  8.1119e-02,  6.9978e-02,\n",
              "                       8.3967e-02,  7.0213e-02,  6.8691e-02,  6.4080e-02,  6.4258e-02,\n",
              "                       7.9327e-02,  9.0039e-02,  8.3068e-02,  8.8254e-02,  8.0060e-02,\n",
              "                       7.4092e-02,  6.9994e-02,  7.4709e-02,  6.5449e-02,  7.5955e-02,\n",
              "                       8.3069e-02,  7.5618e-02,  9.0358e-02,  7.8264e-02,  7.9673e-02,\n",
              "                       7.8227e-02,  7.5515e-02,  3.2861e-02,  6.9931e-02,  6.5401e-02,\n",
              "                       8.2372e-02,  9.2416e-02,  6.5535e-02,  8.6634e-02,  8.6113e-02,\n",
              "                       9.1382e-02,  8.6453e-02,  6.7321e-02,  7.4144e-02,  7.5897e-02,\n",
              "                       7.9336e-02,  6.9797e-02,  7.8058e-02, -5.5694e-04,  7.9049e-02,\n",
              "                       8.7345e-02,  8.1301e-02,  6.4353e-02,  7.1384e-02,  7.6304e-02,\n",
              "                       6.9696e-02,  8.4506e-02,  6.2553e-02,  7.7295e-02,  5.0174e-02,\n",
              "                       5.4303e-02,  6.6862e-02,  6.9199e-02,  8.4322e-02,  4.2746e-02,\n",
              "                       9.0907e-02,  7.9981e-02,  6.4807e-02,  7.0792e-02,  6.0406e-02,\n",
              "                       5.9775e-02,  8.0587e-02,  6.6639e-02,  7.9859e-02,  5.9203e-02,\n",
              "                       6.5760e-02,  7.7140e-02,  5.1782e-02,  6.3823e-02,  7.3870e-02,\n",
              "                       7.6855e-02,  6.5524e-02,  7.6551e-02,  6.0939e-02,  9.0226e-02,\n",
              "                       7.9677e-02,  8.7680e-02,  7.7928e-02,  1.2897e-01,  6.0381e-02,\n",
              "                       7.3459e-02,  6.4754e-02,  6.0940e-02,  7.2640e-02,  5.9889e-02,\n",
              "                       1.9679e-02,  8.6055e-02,  5.2881e-02,  2.5171e-02,  1.0000e-01,\n",
              "                       3.6120e-02,  7.7296e-02,  9.4087e-02,  6.7337e-02,  8.4745e-02,\n",
              "                       8.5406e-02,  7.3949e-02,  9.3793e-02, -2.9721e-02,  4.4237e-02,\n",
              "                       9.6196e-02,  7.1879e-02,  8.2039e-02,  9.0543e-02,  6.7238e-02,\n",
              "                       7.7730e-02,  7.7822e-02,  7.5419e-02,  7.8862e-02,  5.8109e-02,\n",
              "                       8.3386e-02,  8.2360e-02,  7.0423e-02,  8.4176e-02,  8.3575e-02,\n",
              "                       7.3542e-02,  7.8559e-02,  8.7125e-02,  8.7670e-02,  7.1271e-02,\n",
              "                       7.8840e-02,  7.1064e-02,  8.4532e-02,  6.1946e-02,  7.0099e-02,\n",
              "                       5.8304e-02,  8.6484e-02,  8.4772e-02,  8.5668e-02,  8.4621e-02,\n",
              "                       6.6832e-02,  6.9503e-02,  6.7684e-02,  7.4462e-02,  8.0129e-02,\n",
              "                       7.5786e-02,  7.6229e-02,  5.1332e-02,  9.9767e-02,  1.3906e-02,\n",
              "                       4.9183e-02,  8.6507e-02,  6.5881e-02,  6.9865e-02,  6.4914e-02,\n",
              "                       1.0082e-01,  6.3356e-02,  1.0382e-01,  6.8313e-02,  8.5341e-02,\n",
              "                       7.8913e-02,  6.8190e-02,  6.2350e-02,  9.0087e-02,  5.9717e-02,\n",
              "                       7.1320e-02,  7.3662e-02,  7.5881e-02,  5.5853e-02,  7.9736e-02,\n",
              "                       6.3149e-02,  9.2556e-02,  7.2412e-02,  8.0266e-02,  7.9855e-02,\n",
              "                       8.3096e-02,  7.3875e-02,  7.1099e-02,  8.3365e-02,  6.9066e-02,\n",
              "                       7.9389e-02,  6.9407e-02,  7.6494e-02,  7.7140e-02,  7.5022e-02,\n",
              "                       6.3720e-02,  9.4919e-02,  4.9070e-02,  9.2463e-02,  5.7612e-02,\n",
              "                       1.0315e-01,  6.1259e-02,  9.4341e-02,  7.4844e-02,  7.0597e-02,\n",
              "                       7.5455e-02,  8.1218e-02,  6.2402e-02,  8.5600e-02,  8.6834e-02,\n",
              "                       7.9672e-02,  4.0166e-02,  8.6089e-02,  8.0520e-02, -2.8952e-02,\n",
              "                       7.8607e-02,  8.7242e-02,  8.6782e-02,  7.5021e-02,  7.0871e-02,\n",
              "                      -1.0533e-03,  4.0199e-02,  7.9226e-02,  7.6076e-02,  8.9473e-02,\n",
              "                       7.9247e-02,  8.4050e-02,  9.8065e-02,  6.3559e-02,  5.1965e-02,\n",
              "                       7.5303e-02,  7.4440e-02,  7.3850e-02,  8.7043e-02,  8.1343e-02,\n",
              "                       6.4105e-02,  3.9169e-02,  8.8262e-02,  7.5840e-02,  1.0751e-01,\n",
              "                       8.9012e-02,  7.8204e-02, -3.9537e-05,  8.1543e-02,  1.0059e-01,\n",
              "                       7.1367e-02,  7.8894e-02,  9.4660e-02,  7.5637e-02,  7.5161e-02,\n",
              "                       7.4343e-02,  8.2348e-02,  7.7567e-02,  8.3909e-02,  9.1221e-02,\n",
              "                       7.3706e-02,  9.6944e-02,  1.0144e-01,  9.9368e-02,  7.9974e-02,\n",
              "                       8.6627e-02,  8.1295e-02,  5.7190e-02,  6.7109e-02,  6.4231e-02,\n",
              "                       7.8256e-02,  6.3661e-02,  8.7590e-02,  9.7068e-02,  8.5038e-02,\n",
              "                       8.9034e-02,  6.4650e-02,  8.6617e-02,  7.1612e-02,  8.0624e-02,\n",
              "                       8.8824e-02,  7.4126e-02,  8.5497e-02,  6.0411e-02,  7.5845e-02,\n",
              "                       6.6410e-02,  7.7757e-02,  7.9616e-02,  9.0052e-02,  7.9912e-02,\n",
              "                       7.3753e-02,  6.7990e-02,  5.8419e-02,  3.6334e-02,  7.6623e-02,\n",
              "                       8.4361e-02,  8.2030e-02,  6.4055e-02,  8.2921e-02,  7.8863e-02,\n",
              "                       7.4057e-02,  9.6017e-02,  9.4770e-03,  9.2752e-02,  8.9948e-02,\n",
              "                       9.0476e-02,  5.8271e-02,  5.0805e-02,  6.6894e-02,  8.3059e-02,\n",
              "                       7.5207e-02,  8.8860e-02,  7.7177e-02,  7.8764e-02,  8.4437e-02,\n",
              "                       7.8406e-02,  7.9008e-02,  7.6286e-02,  6.5688e-02,  8.3197e-02,\n",
              "                       7.4984e-02,  8.2642e-02,  8.4725e-02,  8.3636e-02,  5.7625e-02,\n",
              "                       7.0152e-02,  7.6773e-02,  6.6781e-02,  7.4522e-02,  7.6971e-02,\n",
              "                       7.0574e-02,  7.3405e-02,  7.4998e-02,  6.5609e-02,  8.1980e-02,\n",
              "                       6.1974e-02,  7.5247e-02,  6.5022e-02,  9.6497e-02,  7.4954e-02,\n",
              "                       7.7406e-02,  8.2376e-02,  6.5626e-02,  7.7097e-02,  7.7294e-02,\n",
              "                       6.6639e-02,  8.1699e-02,  8.4538e-02,  8.9271e-02,  6.4129e-02,\n",
              "                       6.6455e-02,  6.8565e-02,  6.5893e-02,  6.9346e-02,  7.4106e-02,\n",
              "                       8.3198e-02,  8.3320e-02,  8.2921e-02,  7.5551e-02,  7.7003e-02,\n",
              "                       9.1532e-02,  7.0253e-02,  8.2093e-02,  6.9846e-02,  7.9479e-02,\n",
              "                       2.3766e-02,  7.1398e-02,  9.1069e-02, -2.0183e-02,  1.0515e-01,\n",
              "                       8.7388e-02,  7.4249e-02,  7.3149e-02,  8.0613e-02,  5.7496e-02,\n",
              "                       9.2693e-02,  7.9518e-02,  8.1054e-02,  6.5877e-02,  7.7054e-02,\n",
              "                       6.8012e-02,  8.7079e-02,  8.2730e-02,  8.7124e-02,  7.4181e-02,\n",
              "                       7.6853e-02,  7.9737e-02,  5.2641e-02,  8.4445e-02,  7.8288e-02,\n",
              "                       7.2279e-02,  7.1343e-02,  8.4818e-02,  1.7301e-02,  8.1696e-02,\n",
              "                       7.2392e-02,  9.1337e-02,  6.8323e-02,  7.9168e-02,  8.0874e-02,\n",
              "                       6.9478e-02,  1.1964e-01,  6.3362e-02,  9.0307e-02,  7.1946e-02,\n",
              "                       8.2700e-02,  7.7382e-02,  7.7630e-02,  6.4380e-02,  8.1732e-02,\n",
              "                       8.2133e-02,  6.3390e-02,  6.3914e-02,  6.7906e-02,  6.9937e-02,\n",
              "                       8.1022e-02,  6.9961e-02,  3.1035e-02,  8.5023e-02,  8.1949e-02,\n",
              "                       8.1239e-02,  8.3235e-02,  8.0021e-02,  7.2631e-02,  7.8134e-02,\n",
              "                       6.7990e-02,  7.5458e-02,  9.1724e-02,  7.3641e-02,  2.0376e-02,\n",
              "                       8.9955e-02,  6.9259e-02,  1.0863e-01,  7.7787e-02,  8.1675e-02,\n",
              "                       9.6073e-02,  8.5399e-02,  8.7159e-02,  8.1658e-02,  8.6712e-02,\n",
              "                       1.2131e-03,  6.9324e-02,  8.0673e-02,  7.5394e-02,  8.0306e-02,\n",
              "                       7.8228e-02,  7.8685e-02,  7.2436e-02,  8.2396e-02,  7.2544e-02,\n",
              "                       6.8190e-02,  9.0959e-02,  7.7654e-02,  7.3506e-02,  8.2210e-02,\n",
              "                       7.5298e-02,  8.5236e-02,  6.7029e-02,  7.6021e-02,  5.9007e-02,\n",
              "                       1.0013e-01,  6.0628e-02,  5.6994e-02,  6.5902e-02,  7.4522e-02,\n",
              "                       8.5622e-02,  8.3259e-02,  8.1937e-02,  6.6031e-02,  7.4784e-02,\n",
              "                       7.0096e-02,  7.0459e-02,  4.1438e-02,  7.1465e-02,  7.0896e-02,\n",
              "                       5.1904e-02,  7.3704e-02,  7.4603e-02,  8.9958e-02,  6.8744e-02,\n",
              "                       7.6527e-02,  8.6735e-02,  8.7032e-02,  8.4200e-02,  7.2485e-02,\n",
              "                       7.3148e-02,  7.7125e-02,  7.5702e-02,  7.7509e-02,  7.7447e-02,\n",
              "                       7.6042e-02,  7.3201e-02,  7.9789e-02,  8.1352e-02,  7.7377e-02,\n",
              "                       7.4984e-02,  5.9427e-02,  7.0994e-02,  5.4878e-02,  9.3122e-02,\n",
              "                       8.6392e-02,  7.0263e-02,  8.7217e-02,  5.1617e-02,  7.6911e-02,\n",
              "                       8.4819e-02,  8.1373e-02,  4.9387e-02,  1.7070e-01,  8.8830e-02,\n",
              "                       6.7014e-02,  8.6239e-02,  7.6072e-02,  7.6840e-02,  8.7103e-02,\n",
              "                       8.8905e-02,  8.3462e-02,  6.3038e-02,  7.6917e-02,  4.2981e-02,\n",
              "                       6.7178e-02,  8.4527e-02,  9.0474e-02,  6.6124e-02,  6.9924e-05,\n",
              "                       4.5645e-02,  7.9991e-02,  7.9118e-02,  6.9557e-02,  8.7182e-02,\n",
              "                       8.1307e-02,  7.0387e-02,  8.0850e-02,  6.5628e-02,  7.1163e-02,\n",
              "                       8.3422e-02,  8.6319e-02,  7.3039e-02,  8.1653e-02,  6.6039e-02,\n",
              "                       9.3724e-02,  3.1572e-02,  7.4330e-02,  1.0868e-01,  7.1538e-02,\n",
              "                       6.0044e-02,  8.1910e-02, -7.6944e-02,  7.7767e-02,  9.2373e-02,\n",
              "                       5.9039e-02,  8.1709e-02,  3.0509e-02,  8.0051e-02,  8.9474e-02,\n",
              "                       8.4755e-02,  8.9667e-02,  7.4828e-02,  9.2063e-02,  6.8326e-02,\n",
              "                       7.2847e-02,  7.4648e-02,  6.5994e-02,  9.2558e-02,  6.8508e-02,\n",
              "                       8.0872e-02,  7.2730e-02,  9.0183e-02,  6.0085e-02,  7.9113e-02,\n",
              "                       7.5309e-02,  8.2089e-02,  7.3274e-02,  7.6411e-02,  7.6723e-02,\n",
              "                       5.4428e-02,  8.4251e-02,  5.7436e-02,  5.9425e-02,  8.0824e-02,\n",
              "                       7.1153e-02,  7.0100e-02,  7.5043e-02,  8.4182e-02,  7.6510e-02,\n",
              "                       5.2471e-02,  7.1651e-02,  9.6730e-02,  6.6478e-02,  6.8310e-02,\n",
              "                       7.8218e-02,  4.4785e-02,  8.3761e-02,  5.7009e-02,  9.4675e-02,\n",
              "                       5.6795e-02,  8.7404e-02,  8.0360e-02,  9.4085e-02,  9.3604e-02,\n",
              "                       3.8675e-02,  7.3871e-02,  7.3961e-02,  7.9922e-02,  8.8893e-02,\n",
              "                       7.1104e-02,  6.9102e-02,  6.6071e-02,  1.2672e-01,  8.0579e-02,\n",
              "                       7.5572e-02,  6.8795e-02,  7.9125e-02,  8.2276e-02,  8.1734e-02,\n",
              "                       6.0706e-02,  7.9023e-02,  7.0247e-02,  5.9426e-02,  8.2341e-02,\n",
              "                       8.3317e-02,  5.8973e-02,  6.5898e-02,  7.0773e-02,  7.6454e-02,\n",
              "                       7.8051e-02,  8.5291e-02,  7.4828e-02,  7.1438e-02,  7.1031e-02,\n",
              "                       6.9894e-02,  8.2671e-02,  6.7950e-02,  9.0366e-02,  6.1630e-02,\n",
              "                       7.8594e-02,  7.7313e-02,  5.7179e-02,  7.1969e-02,  8.4429e-02,\n",
              "                       7.0651e-02,  7.6202e-02,  7.9722e-02,  8.9503e-02,  8.4951e-02,\n",
              "                       8.4079e-02,  8.4371e-02,  6.8912e-02,  3.3020e-02,  6.8052e-02,\n",
              "                       8.6881e-02,  7.5139e-02,  6.8268e-02,  4.2468e-02,  6.9073e-02,\n",
              "                       6.5668e-02,  7.9218e-02,  6.9106e-02,  6.9589e-02,  3.1641e-02,\n",
              "                       9.5544e-02,  6.8698e-02,  9.2072e-02,  7.3658e-02,  8.0186e-02,\n",
              "                       9.1944e-02,  7.2388e-02,  6.4776e-02,  8.0837e-02,  9.1401e-02,\n",
              "                       4.3710e-02,  7.1861e-02,  6.3469e-02,  7.3606e-02,  9.4484e-02,\n",
              "                       8.1198e-02,  8.3858e-02,  8.3463e-02,  5.9869e-02,  7.1262e-02,\n",
              "                       6.8121e-02,  7.9587e-02,  6.2012e-02,  7.3730e-02,  6.1929e-02,\n",
              "                       6.4331e-02,  6.7970e-02,  7.0468e-02,  5.6554e-02,  8.6354e-02,\n",
              "                       6.2638e-02,  5.2392e-02,  7.8817e-02,  8.4113e-02,  5.0066e-02,\n",
              "                       6.5210e-02,  6.5891e-02,  8.2467e-02,  8.4810e-02,  9.0994e-02,\n",
              "                       9.3206e-02,  7.3673e-02,  7.1204e-02,  5.2126e-02,  8.3575e-02,\n",
              "                       5.9608e-02,  6.9128e-02,  7.5665e-02,  8.0720e-02,  6.1523e-02,\n",
              "                       8.6269e-02,  9.7021e-02,  6.5810e-02], device='cuda:0')),\n",
              "             ('decoder.block.2.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.0842,  0.5158,  0.8125,  ..., -1.0737,  0.2334,  0.4820],\n",
              "                      [ 1.5418, -0.4334,  0.3932,  ..., -0.2551, -0.3707,  0.2076],\n",
              "                      [ 0.3177, -0.0430,  0.5493,  ..., -0.3108, -0.0052, -0.4220],\n",
              "                      ...,\n",
              "                      [-0.3034,  3.7088, -0.8620,  ...,  1.9657,  0.0958,  1.2659],\n",
              "                      [ 0.2826, -0.2819,  0.0083,  ...,  0.5370,  0.4929,  0.6478],\n",
              "                      [ 0.2004,  0.1826,  0.2684,  ..., -0.1919, -0.3008, -0.0704]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.1437,  0.1479, -0.0207,  ..., -0.0421,  0.0337, -0.3634],\n",
              "                      [-0.0026, -0.0038,  0.2735,  ...,  0.0676,  0.3039, -0.0433],\n",
              "                      [ 0.0381, -0.6392, -0.2561,  ...,  0.0231, -0.0229, -0.0200],\n",
              "                      ...,\n",
              "                      [-0.3415, -0.0690,  0.0016,  ..., -0.0106,  0.1890, -0.1196],\n",
              "                      [ 0.0315, -0.1510,  0.0458,  ..., -0.0175, -0.1306,  0.3391],\n",
              "                      [ 0.1228,  0.0477,  0.1868,  ..., -0.0095,  0.0069,  0.3747]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.2.layer.2.layer_norm.weight',\n",
              "              tensor([1.6691, 0.7274, 0.7372, 1.7542, 1.4536, 1.7053, 1.1452, 1.7792, 1.0883,\n",
              "                      1.3912, 2.4086, 1.4481, 1.1276, 1.5982, 1.4972, 1.5254, 1.3620, 1.0739,\n",
              "                      1.4613, 1.4827, 1.4695, 1.5433, 1.4662, 1.4428, 1.5029, 1.0759, 1.4636,\n",
              "                      1.3580, 1.4776, 1.3998, 1.4471, 0.7280, 1.5568, 1.4046, 1.6406, 1.1712,\n",
              "                      1.4397, 0.7720, 1.3287, 1.6162, 1.3857, 1.4896, 1.2860, 1.5508, 0.7282,\n",
              "                      1.3848, 1.4440, 1.5192, 1.5012, 1.6333, 1.3037, 1.3939, 1.5043, 1.5698,\n",
              "                      1.9959, 1.6224, 1.3956, 1.4055, 1.5625, 1.5235, 1.4206, 1.4544, 1.4655,\n",
              "                      1.4002, 1.5305, 0.4453, 1.4735, 1.4469, 0.9796, 1.4526, 1.2933, 1.3597,\n",
              "                      1.3825, 1.3053, 1.4180, 1.4571, 1.5974, 1.5188, 1.4039, 1.3056, 1.3447,\n",
              "                      1.5270, 1.5786, 1.0904, 1.1894, 1.3497, 1.6320, 1.4329, 1.4060, 1.4888,\n",
              "                      1.3143, 1.3828, 1.3838, 1.6505, 1.5397, 1.4890, 1.4759, 1.4960, 1.4337,\n",
              "                      1.3346, 1.6053, 1.2001, 1.7308, 1.4502, 1.3729, 1.3584, 1.5097, 1.3527,\n",
              "                      1.2545, 1.4740, 1.5001, 1.4860, 1.5190, 1.3601, 1.3451, 1.2295, 1.4065,\n",
              "                      1.5020, 0.2224, 1.4123, 1.3831, 1.3083, 1.0594, 1.2952, 1.3689, 1.2562,\n",
              "                      1.5311, 1.5650, 1.4471, 1.5485, 1.4692, 1.2327, 1.5028, 1.4627, 0.9746,\n",
              "                      1.4972, 1.3641, 1.1349, 1.8861, 2.1010, 1.2659, 1.3043, 1.7178, 1.4862,\n",
              "                      1.3684, 1.4724, 1.1823, 1.1256, 1.3049, 1.6341, 1.2892, 1.3557, 1.2040,\n",
              "                      1.2875, 1.4884, 1.4598, 1.5581, 1.5528, 1.1224, 1.5276, 1.3026, 1.3181,\n",
              "                      1.3104, 1.2384, 1.0607, 0.8646, 1.5355, 1.0474, 0.7565, 1.4127, 1.6271,\n",
              "                      1.3627, 1.4617, 1.4006, 1.4617, 1.3810, 1.4328, 1.3193, 1.6212, 1.0265,\n",
              "                      1.4507, 1.4831, 1.5672, 1.6203, 1.4419, 1.2363, 1.5432, 1.0159, 1.3947,\n",
              "                      1.5831, 1.3970, 1.4103, 1.1538, 1.5925, 1.3567, 1.2559, 1.4721, 1.3643,\n",
              "                      1.5194, 1.2365, 1.4892, 1.7233, 1.4475, 1.1682, 1.4325, 1.4943, 1.4392,\n",
              "                      1.5179, 1.3230, 1.5649, 1.1335, 1.8969, 1.3058, 1.3299, 1.5560, 1.5618,\n",
              "                      1.4580, 1.2150, 1.5625, 0.6285, 1.4867, 1.2516, 1.0978, 1.4477, 1.2993,\n",
              "                      1.5748, 0.1903, 1.3299, 1.4684, 1.3970, 1.2003, 1.5801, 1.2986, 1.5002,\n",
              "                      1.3564, 1.3872, 1.4938, 1.5879, 1.7555, 1.6119, 2.1917, 1.3882, 1.2950,\n",
              "                      1.1830, 1.3696, 1.3907, 1.2338, 1.6561, 1.3078, 1.3957, 1.4806, 1.4024,\n",
              "                      1.4826, 1.3916, 1.3371, 1.1237, 1.5208, 1.8405, 1.5462, 1.4096, 1.4059,\n",
              "                      1.8859, 1.4318, 1.6367, 1.4430, 1.4556, 1.3304, 1.2607, 1.4712, 1.5813,\n",
              "                      1.4661, 0.8103, 1.4969, 1.2648, 1.8054, 1.4964, 1.4143, 1.6912, 1.4103,\n",
              "                      1.4922, 0.2319, 0.9473, 1.4396, 1.3528, 1.4422, 1.4872, 1.5320, 1.5769,\n",
              "                      1.2294, 1.6757, 1.2273, 1.3630, 1.4101, 1.5625, 1.3865, 1.4112, 0.6572,\n",
              "                      1.4654, 1.4309, 1.7237, 1.5480, 1.3927, 0.4076, 1.5453, 1.4398, 1.2728,\n",
              "                      1.5475, 1.4774, 1.5364, 1.2509, 1.1903, 1.5042, 1.4386, 1.3072, 0.7441,\n",
              "                      1.5796, 1.2598, 1.4342, 1.5142, 1.2849, 1.3705, 1.3703, 1.5364, 1.3532,\n",
              "                      1.1279, 1.3458, 1.4610, 1.3507, 1.5613, 1.4987, 1.4718, 1.2627, 1.3689,\n",
              "                      1.2470, 1.3447, 1.5168, 1.2778, 1.3386, 1.2643, 1.9382, 1.4861, 1.3906,\n",
              "                      1.3698, 1.4060, 1.3738, 1.2376, 1.5179, 1.8246, 0.8337, 1.4604, 1.2932,\n",
              "                      1.2704, 1.2134, 1.2561, 1.5769, 1.3644, 1.5359, 0.4250, 1.6564, 1.5522,\n",
              "                      1.5354, 1.0768, 1.3942, 1.2536, 1.3118, 1.3885, 1.5275, 1.3190, 1.3795,\n",
              "                      1.4929, 1.4721, 1.3332, 1.1787, 1.4100, 1.4485, 1.5423, 1.3878, 1.1657,\n",
              "                      1.3976, 1.1127, 1.3665, 1.2983, 1.4500, 1.4332, 1.4126, 1.4305, 1.4354,\n",
              "                      1.6514, 1.2288, 1.4496, 1.2625, 1.2513, 1.4752, 1.7434, 1.4303, 1.5543,\n",
              "                      1.4513, 1.3742, 1.3410, 1.6952, 1.2548, 1.3843, 1.5295, 1.5442, 1.3573,\n",
              "                      1.3850, 1.1972, 1.3772, 1.2583, 1.4120, 1.3662, 1.3198, 1.4365, 1.4184,\n",
              "                      1.4704, 1.3673, 1.2805, 1.5923, 0.4414, 1.3480, 0.7526, 1.2942, 1.4888,\n",
              "                      1.5335, 1.4346, 1.3343, 1.5483, 1.5198, 1.3067, 2.5325, 1.3487, 1.3862,\n",
              "                      1.4327, 1.3196, 1.2954, 1.1858, 1.4330, 1.2065, 1.3878, 1.3108, 1.3989,\n",
              "                      1.3353, 0.9759, 1.4782, 1.3520, 1.2513, 1.4314, 1.4686, 0.5667, 1.3305,\n",
              "                      1.5614, 1.4514, 1.4572, 1.4734, 1.3371, 1.4850, 1.0340, 0.6406, 1.4973,\n",
              "                      1.3250, 1.4881, 1.5009, 1.5148, 1.3861, 1.5161, 1.4472, 1.5117, 1.4633,\n",
              "                      1.1886, 1.4287, 1.4660, 1.3661, 0.9021, 1.4499, 1.3826, 1.3360, 1.4771,\n",
              "                      1.3703, 1.4199, 1.5515, 2.0135, 1.5651, 1.5045, 1.2779, 0.4395, 1.5570,\n",
              "                      1.3198, 0.9352, 1.3535, 1.4899, 1.5545, 1.3063, 1.6337, 1.4405, 1.5322,\n",
              "                      1.3869, 1.3414, 1.3539, 1.5595, 1.5512, 1.3602, 0.7640, 1.3356, 1.4856,\n",
              "                      1.4622, 1.2903, 1.3470, 1.4870, 1.3469, 1.3970, 1.2508, 1.5902, 1.5324,\n",
              "                      1.3889, 0.9991, 1.5375, 1.4068, 1.2322, 1.7454, 1.6436, 1.5048, 1.4946,\n",
              "                      1.3398, 1.2623, 1.4826, 1.2141, 1.6815, 0.9060, 1.3783, 1.2838, 1.1030,\n",
              "                      1.4013, 1.3851, 1.3661, 1.1915, 1.4548, 1.4943, 1.4337, 1.3605, 1.3870,\n",
              "                      1.3379, 1.4255, 1.4786, 1.4017, 1.4079, 1.4390, 1.3208, 1.4036, 1.3387,\n",
              "                      1.3811, 1.1474, 1.1747, 1.3026, 1.1338, 1.4395, 1.3709, 1.3326, 1.5676,\n",
              "                      1.1335, 1.5862, 1.3121, 1.2115, 0.6891, 2.0930, 1.5630, 1.1633, 1.4646,\n",
              "                      1.4767, 1.6561, 1.3867, 1.3134, 1.4694, 1.4157, 1.7809, 1.7715, 1.1848,\n",
              "                      1.4559, 1.3855, 1.2335, 0.2713, 0.9917, 1.4413, 1.6248, 1.3854, 1.4489,\n",
              "                      1.4890, 1.4324, 1.6142, 1.4649, 1.3700, 1.4564, 1.5070, 1.3249, 1.3637,\n",
              "                      1.4306, 1.5866, 0.8918, 1.4521, 1.9123, 1.4149, 1.1854, 1.4891, 1.4605,\n",
              "                      1.3109, 1.4141, 1.3822, 1.3263, 0.6020, 1.5636, 1.5057, 1.5391, 1.5430,\n",
              "                      1.4203, 1.4572, 1.3078, 1.5972, 1.4672, 0.4318, 1.2151, 1.4408, 1.4686,\n",
              "                      1.3290, 1.3909, 1.7273, 1.7614, 1.4708, 1.7004, 1.4152, 1.2693, 1.3804,\n",
              "                      1.0869, 1.3958, 1.0381, 1.0517, 1.3897, 1.3071, 1.8752, 1.4820, 1.4366,\n",
              "                      1.3556, 1.3007, 1.1967, 1.4227, 1.3735, 1.2853, 1.5484, 0.9940, 1.4300,\n",
              "                      1.5842, 1.4095, 0.9000, 1.4328, 1.3117, 1.4646, 1.4651, 1.5295, 1.2554,\n",
              "                      1.6815, 1.5711, 1.5917, 1.3000, 1.5116, 1.2583, 1.4989, 1.3962, 1.4028,\n",
              "                      1.2992, 1.5221, 1.5661, 1.5111, 1.2340, 1.4762, 1.4031, 1.2080, 1.4444,\n",
              "                      1.4721, 1.3386, 1.3219, 1.4299, 1.4865, 1.3132, 1.5002, 1.5314, 1.2237,\n",
              "                      1.3321, 1.5058, 1.3085, 1.3100, 1.4711, 1.3108, 1.5177, 1.4979, 1.2407,\n",
              "                      1.2831, 1.3512, 1.2912, 1.4657, 1.2373, 1.4619, 1.4337, 1.3700, 1.3707,\n",
              "                      1.3521, 1.4633, 1.1081, 1.4589, 1.4295, 1.8480, 0.8764, 1.3902, 1.3651,\n",
              "                      1.3341, 1.2816, 1.2622, 1.3971, 0.8537, 1.4209, 1.1536, 1.3370, 1.4930,\n",
              "                      1.4524, 1.3426, 1.2574, 1.2938, 1.4688, 0.8477, 1.2561, 1.2514, 1.4035,\n",
              "                      1.4662, 1.3690, 1.6575, 1.4733, 1.0427, 1.1288, 1.4122, 1.4100, 1.2849,\n",
              "                      1.3817, 1.2935, 1.2744, 1.4885, 1.4034, 1.5136, 1.6324, 1.1802, 1.3002,\n",
              "                      1.2252, 1.4997, 1.8317, 1.7054, 1.2078, 1.4303, 1.2767, 1.4262, 1.4210,\n",
              "                      1.4129, 1.2856, 1.0696, 1.4927, 1.1924, 1.3063, 1.4683, 1.6742, 1.2381,\n",
              "                      1.4093, 1.6924, 1.6094], device='cuda:0')),\n",
              "             ('decoder.block.3.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0083,  0.0011,  0.0172,  ...,  0.0048, -0.0218,  0.0195],\n",
              "                      [ 0.0150,  0.0137, -0.0340,  ...,  0.0096,  0.0085, -0.0013],\n",
              "                      [-0.0451,  0.0374, -0.0212,  ..., -0.0356,  0.0068, -0.0256],\n",
              "                      ...,\n",
              "                      [-0.0472,  0.0575,  0.0154,  ...,  0.0068,  0.0124, -0.0388],\n",
              "                      [-0.0183,  0.0015,  0.0048,  ..., -0.0196,  0.0028, -0.0021],\n",
              "                      [ 0.0016, -0.0506,  0.0132,  ..., -0.0124, -0.0238, -0.0129]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.0631,  0.0148,  0.2610,  ...,  0.1375,  0.0506,  0.0830],\n",
              "                      [-0.0993, -0.5117, -0.1567,  ..., -0.0161, -0.1534,  0.0479],\n",
              "                      [ 0.0348,  0.5434,  0.2402,  ...,  0.1020, -0.1974,  0.0724],\n",
              "                      ...,\n",
              "                      [ 0.1560, -0.1338,  0.2827,  ..., -0.1290,  0.1024,  0.1489],\n",
              "                      [ 0.3139, -0.4490, -0.4796,  ...,  0.2362, -0.1209, -0.3224],\n",
              "                      [-0.3597,  0.2648,  0.2400,  ...,  0.2818,  0.2157,  0.0196]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.6874,  0.4732, -0.8078,  ...,  1.4176, -0.6940,  0.3351],\n",
              "                      [-1.2728,  0.5022,  0.0976,  ...,  0.0476, -0.3930, -0.2066],\n",
              "                      [-1.0236,  0.3019,  0.1262,  ...,  0.8175,  0.1895,  0.4322],\n",
              "                      ...,\n",
              "                      [-0.6052,  0.8781,  0.1909,  ..., -0.2729,  0.3181,  0.4161],\n",
              "                      [-0.2943, -0.2586, -0.4006,  ..., -0.0333,  0.2664,  0.0586],\n",
              "                      [ 0.5985,  0.4767,  0.1488,  ..., -0.5106,  0.1863,  0.8118]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 0.2144, -0.3421,  0.7670,  ..., -0.2255,  0.0360,  0.5047],\n",
              "                      [-1.0802,  0.6242,  1.0739,  ...,  0.5213, -0.7132,  0.1997],\n",
              "                      [-0.9208, -0.1189, -1.4921,  ..., -0.2611,  0.4427, -0.2697],\n",
              "                      ...,\n",
              "                      [ 0.2971, -0.0472, -0.7240,  ..., -0.9094,  0.2060,  0.0169],\n",
              "                      [-0.7308, -1.3933,  0.0950,  ...,  0.1570,  1.1735, -0.2519],\n",
              "                      [ 0.0207,  0.3095,  0.0941,  ..., -0.0060,  0.3156,  0.4091]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2018,  0.1028,  0.1102,  0.2424,  0.2074,  0.1601,  0.1773,  0.2473,\n",
              "                       0.1790,  0.2125,  0.1245,  0.2296,  0.1084,  0.1444,  0.2242,  0.2187,\n",
              "                       0.2006,  0.1563,  0.1973,  0.2238,  0.1916,  0.2369,  0.2205,  0.2210,\n",
              "                       0.2090,  0.1505,  0.2122,  0.1588,  0.2158,  0.2290,  0.2222,  0.1314,\n",
              "                       0.2268,  0.1830,  0.2323,  0.1645,  0.2210,  0.1590,  0.2010,  0.2342,\n",
              "                       0.2275,  0.2049,  0.2082,  0.2073,  0.1314,  0.2084,  0.2161,  0.2015,\n",
              "                       0.2378,  0.2305,  0.1837,  0.1978,  0.1969,  0.2159,  0.3138,  0.1593,\n",
              "                       0.1940,  0.2153,  0.2344,  0.2020,  0.1890,  0.2335,  0.2195,  0.2076,\n",
              "                       0.2145,  0.1058,  0.2194,  0.2040,  0.1188,  0.2134,  0.2144,  0.2247,\n",
              "                       0.2069,  0.2023,  0.1979,  0.2078,  0.1405,  0.1914,  0.2067,  0.1981,\n",
              "                       0.2147,  0.1913,  0.2195,  0.1638,  0.1887,  0.2177,  0.1738,  0.2088,\n",
              "                       0.2072,  0.2183,  0.1868,  0.2022,  0.1968,  0.1718,  0.2274,  0.2216,\n",
              "                       0.2080,  0.2181,  0.2282,  0.2087,  0.1823,  0.1700,  0.1152,  0.2215,\n",
              "                       0.1961,  0.2165,  0.2044,  0.1727,  0.1901,  0.2138,  0.2111,  0.2349,\n",
              "                       0.1916,  0.2097,  0.1983,  0.1804,  0.2085,  0.2043,  0.0390,  0.2062,\n",
              "                       0.2224,  0.1928,  0.1600,  0.1972,  0.2205,  0.1747,  0.2163,  0.1708,\n",
              "                       0.2003,  0.1375,  0.1419,  0.1863,  0.2113,  0.2253,  0.1027,  0.2129,\n",
              "                       0.1980,  0.1652,  0.1851,  0.1218,  0.1504,  0.1974,  0.2050,  0.2167,\n",
              "                       0.1787,  0.1731,  0.1831,  0.1692,  0.1984,  0.1985,  0.2204,  0.1813,\n",
              "                       0.2058,  0.1879,  0.2251,  0.2156,  0.2169,  0.2289,  0.0562,  0.1146,\n",
              "                       0.1803,  0.1773,  0.1783,  0.1784,  0.1623,  0.1075,  0.2174,  0.1497,\n",
              "                       0.0997,  0.2264,  0.0890,  0.2065,  0.2247,  0.2256,  0.2044,  0.2252,\n",
              "                       0.1843,  0.2086,  0.0807,  0.1653,  0.2019,  0.2033,  0.2330,  0.2453,\n",
              "                       0.1794,  0.1673,  0.2174,  0.0316,  0.2202,  0.1408,  0.2123,  0.2180,\n",
              "                       0.1925,  0.2272,  0.1992,  0.1685,  0.2159,  0.2113,  0.2144,  0.1751,\n",
              "                       0.2394,  0.1886,  0.2120,  0.1911,  0.1992,  0.1783,  0.2191,  0.1974,\n",
              "                       0.1905,  0.2446,  0.1658,  0.1654,  0.1846,  0.1868,  0.2182,  0.2250,\n",
              "                       0.2052,  0.1836,  0.2327,  0.0310,  0.1526,  0.1911,  0.1638,  0.2034,\n",
              "                       0.1729,  0.1936,  0.2046,  0.2288,  0.2182,  0.2276,  0.1925,  0.2246,\n",
              "                       0.1859,  0.2368,  0.1908,  0.1955,  0.1705,  0.2070,  0.1098,  0.2287,\n",
              "                       0.1791,  0.2219,  0.1746,  0.1855,  0.2323,  0.2052,  0.2120,  0.2138,\n",
              "                       0.1788,  0.2165,  0.1939,  0.1947,  0.2287,  0.2166,  0.1949,  0.1799,\n",
              "                       0.2019,  0.1206,  0.2107,  0.1728,  0.2521,  0.1134,  0.2308,  0.2286,\n",
              "                       0.2063,  0.2172,  0.2042,  0.1974,  0.2143,  0.2118,  0.1987,  0.0901,\n",
              "                       0.2031,  0.2108,  0.0910,  0.2242,  0.2033,  0.2313,  0.1827,  0.1738,\n",
              "                       0.0353,  0.1065,  0.2090,  0.1845,  0.2173,  0.2102,  0.2126,  0.2477,\n",
              "                       0.1621,  0.1574,  0.1855,  0.2036,  0.1931,  0.2416,  0.1906,  0.2002,\n",
              "                       0.1124,  0.2271,  0.2059,  0.2259,  0.2184,  0.1919,  0.0432,  0.2074,\n",
              "                       0.2058,  0.1981,  0.2164,  0.2220,  0.1953,  0.1920,  0.1885,  0.2137,\n",
              "                       0.1881,  0.2137,  0.1735,  0.1978,  0.2067,  0.2121,  0.2257,  0.2053,\n",
              "                       0.2222,  0.2077,  0.1633,  0.1969,  0.1699,  0.2007,  0.1912,  0.2018,\n",
              "                       0.2278,  0.1895,  0.2105,  0.1820,  0.2304,  0.1810,  0.1963,  0.2078,\n",
              "                       0.2040,  0.2037,  0.1879,  0.1812,  0.1976,  0.2108,  0.1978,  0.1904,\n",
              "                       0.2198,  0.1714,  0.2301,  0.1634,  0.0950,  0.2036,  0.1947,  0.1769,\n",
              "                       0.1731,  0.2006,  0.1955,  0.2098,  0.2215,  0.0367,  0.2351,  0.2344,\n",
              "                       0.2179,  0.1561,  0.1320,  0.1735,  0.2001,  0.1946,  0.2190,  0.1844,\n",
              "                       0.2002,  0.2008,  0.2406,  0.2262,  0.2018,  0.1938,  0.2222,  0.2003,\n",
              "                       0.2067,  0.2153,  0.2087,  0.1452,  0.1762,  0.1937,  0.1384,  0.2012,\n",
              "                       0.2143,  0.2246,  0.2024,  0.2243,  0.1801,  0.2277,  0.2103,  0.2010,\n",
              "                       0.1919,  0.2212,  0.2130,  0.2090,  0.2028,  0.1730,  0.2020,  0.2094,\n",
              "                       0.2016,  0.2071,  0.2145,  0.2170,  0.1797,  0.1952,  0.1646,  0.2120,\n",
              "                       0.1716,  0.2242,  0.1874,  0.1929,  0.2153,  0.2050,  0.2213,  0.2064,\n",
              "                       0.2004,  0.2077,  0.1690,  0.2041,  0.0260,  0.1875,  0.2269,  0.0558,\n",
              "                       0.2048,  0.2068,  0.1978,  0.1964,  0.2012,  0.1341,  0.1971,  0.2153,\n",
              "                       0.2231,  0.1723,  0.1815,  0.1780,  0.2139,  0.1853,  0.2039,  0.2007,\n",
              "                       0.2117,  0.1888,  0.1605,  0.2372,  0.1996,  0.1902,  0.1918,  0.2080,\n",
              "                       0.0351,  0.1838,  0.1962,  0.2046,  0.2110,  0.2312,  0.1901,  0.2032,\n",
              "                       0.2133,  0.2005,  0.2125,  0.1941,  0.2146,  0.2116,  0.2022,  0.2023,\n",
              "                       0.2233,  0.2252,  0.1659,  0.1918,  0.1881,  0.2040,  0.2273,  0.1921,\n",
              "                       0.1081,  0.2060,  0.2032,  0.1981,  0.2215,  0.2113,  0.2047,  0.2148,\n",
              "                       0.1448,  0.2271,  0.2147,  0.1717,  0.0597,  0.2211,  0.1894,  0.0406,\n",
              "                       0.2013,  0.2173,  0.2284,  0.1964,  0.2110,  0.2124,  0.2239, -0.0521,\n",
              "                       0.1866,  0.2030,  0.2151,  0.2010,  0.1851,  0.1485,  0.2194,  0.1888,\n",
              "                       0.2126,  0.2071,  0.1995,  0.1843,  0.2006,  0.2095,  0.1793,  0.2202,\n",
              "                       0.2120,  0.1810,  0.1753,  0.2101,  0.1914,  0.1957,  0.1693,  0.2328,\n",
              "                       0.2130,  0.2005,  0.1988,  0.1943,  0.1888,  0.1892,  0.2123,  0.1293,\n",
              "                       0.1982,  0.1707,  0.1537,  0.2091,  0.1939,  0.2074,  0.1862,  0.2150,\n",
              "                       0.2394,  0.2007,  0.2050,  0.1872,  0.2052,  0.2112,  0.2013,  0.1926,\n",
              "                       0.2046,  0.2009,  0.2130,  0.2208,  0.1966,  0.1933,  0.1678,  0.1583,\n",
              "                       0.1918,  0.1599,  0.2203,  0.1839,  0.1841,  0.2251,  0.1533,  0.2376,\n",
              "                       0.2119,  0.1763,  0.1656,  0.3008,  0.2311,  0.1840,  0.2140,  0.2170,\n",
              "                       0.2275,  0.1991,  0.2106,  0.2179,  0.2031,  0.1772,  0.1281,  0.1747,\n",
              "                       0.2331,  0.2169,  0.1863,  0.0258,  0.1539,  0.2084,  0.2187,  0.1850,\n",
              "                       0.1930,  0.2149,  0.2120,  0.2014,  0.2247,  0.1802,  0.2332,  0.2335,\n",
              "                       0.2235,  0.1860,  0.1861,  0.2358,  0.1256,  0.2224,  0.2322,  0.1875,\n",
              "                       0.1662,  0.2023,  0.2049,  0.1787,  0.2058,  0.1962,  0.2040,  0.0997,\n",
              "                       0.2426,  0.2232,  0.2159,  0.2086,  0.2028,  0.2097,  0.1946,  0.2381,\n",
              "                       0.1936,  0.1453,  0.1941,  0.2200,  0.2093,  0.1812,  0.2114,  0.1460,\n",
              "                       0.1952,  0.2174,  0.1852,  0.2086,  0.1872,  0.2139,  0.1637,  0.2087,\n",
              "                       0.1742,  0.1824,  0.1948,  0.2052,  0.1561,  0.1994,  0.2115,  0.1941,\n",
              "                       0.1579,  0.1835,  0.2137,  0.2020,  0.1545,  0.2105,  0.1217,  0.1932,\n",
              "                       0.1869,  0.2171,  0.1136,  0.2314,  0.1969,  0.2103,  0.2125,  0.0981,\n",
              "                       0.1931,  0.1534,  0.2266,  0.2024,  0.2116,  0.2004,  0.1797,  0.2373,\n",
              "                       0.2033,  0.2004,  0.1997,  0.2184,  0.1902,  0.2132,  0.1732,  0.2123,\n",
              "                       0.2024,  0.1641,  0.2281,  0.2213,  0.1883,  0.1976,  0.2183,  0.2156,\n",
              "                       0.2170,  0.2226,  0.1783,  0.1787,  0.1903,  0.2030,  0.2043,  0.1989,\n",
              "                       0.2273,  0.2086,  0.2260,  0.2208,  0.1781,  0.1779,  0.2025,  0.2090,\n",
              "                       0.2266,  0.2035,  0.2146,  0.2124,  0.1995,  0.1865,  0.1985,  0.0956,\n",
              "                       0.1707,  0.2192,  0.2174,  0.1651,  0.1122,  0.2098,  0.2014,  0.1831,\n",
              "                       0.1720,  0.2010,  0.0988,  0.1913,  0.1936,  0.1815,  0.1960,  0.2012,\n",
              "                       0.2123,  0.1903,  0.1525,  0.2107,  0.2094,  0.0807,  0.1937,  0.1982,\n",
              "                       0.1965,  0.2002,  0.2091,  0.2019,  0.2136,  0.0650,  0.1870,  0.1852,\n",
              "                       0.2100,  0.1847,  0.2027,  0.1752,  0.2008,  0.1021,  0.2281,  0.1956,\n",
              "                       0.2307,  0.1838,  0.1561,  0.1932,  0.2261,  0.1509,  0.1929,  0.1862,\n",
              "                       0.2012,  0.1792,  0.2175,  0.2084,  0.2077,  0.2004,  0.1092,  0.2023,\n",
              "                       0.1872,  0.1534,  0.2008,  0.1976,  0.2001,  0.2135,  0.2263,  0.2029],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0389, -0.0495, -0.0377,  ...,  0.1240,  0.0369, -0.0384],\n",
              "                      [ 0.0124,  0.0480,  0.0789,  ...,  0.0278, -0.0200, -0.0318],\n",
              "                      [ 0.0303,  0.0723, -0.0095,  ..., -0.0157, -0.0271,  0.0027],\n",
              "                      ...,\n",
              "                      [-0.0176,  0.0901, -0.0494,  ..., -0.0057, -0.0615,  0.0460],\n",
              "                      [ 0.0624,  0.0552,  0.0041,  ..., -0.0171, -0.0017,  0.0231],\n",
              "                      [ 0.0465, -0.0445,  0.0110,  ..., -0.0857, -0.0319, -0.0878]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[-0.2750,  0.2720,  0.7022,  ...,  0.7789, -0.3353,  0.1708],\n",
              "                      [-0.0944,  0.0126, -0.0241,  ..., -0.0850, -0.3542,  0.0544],\n",
              "                      [ 0.0829, -0.7566, -0.3142,  ..., -0.6232, -0.1062,  0.2223],\n",
              "                      ...,\n",
              "                      [ 0.0698,  0.2021, -0.7192,  ..., -0.4528,  0.0106,  0.1198],\n",
              "                      [ 0.1040, -0.0496, -1.0553,  ..., -0.0352, -0.0032,  0.5017],\n",
              "                      [ 0.0404, -0.5044,  0.1476,  ...,  0.0744,  0.1832, -0.6172]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.0404,  0.2887, -0.3654,  ...,  0.5000,  0.2357,  0.1048],\n",
              "                      [-0.4698,  0.3156,  0.6378,  ...,  0.7520, -0.1711,  0.0316],\n",
              "                      [-0.5344, -0.8516, -0.2589,  ...,  0.0308,  0.3119,  0.5490],\n",
              "                      ...,\n",
              "                      [ 0.0172, -0.2805, -0.5778,  ..., -0.0714,  0.1349,  0.3503],\n",
              "                      [ 0.1411,  0.5216,  0.4476,  ..., -0.1272,  0.2347,  0.6875],\n",
              "                      [-0.6977, -0.0356,  0.3489,  ...,  0.2316,  0.0789, -0.4131]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[ 0.2181,  0.1175,  0.2210,  ...,  0.3447,  0.0567, -0.0499],\n",
              "                      [-0.5137,  0.3440,  0.1128,  ...,  0.6877, -0.5706, -0.5650],\n",
              "                      [-0.0701, -0.0705,  0.0830,  ...,  0.0068, -0.4141, -0.1624],\n",
              "                      ...,\n",
              "                      [ 0.1252, -0.3117,  0.3296,  ..., -0.2483, -0.0330, -0.0022],\n",
              "                      [ 0.2788,  0.2294, -0.2471,  ...,  0.1724, -0.1531, -0.2757],\n",
              "                      [ 0.1687, -0.2208, -0.3040,  ...,  0.1095, -0.3889, -0.0372]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.0793,  0.0415,  0.0421,  0.1090,  0.0801,  0.0629,  0.0881,  0.0900,\n",
              "                       0.0660,  0.0789,  0.0559,  0.0854,  0.0518,  0.0543,  0.0632,  0.0775,\n",
              "                       0.0625,  0.0529,  0.0740,  0.0941,  0.0719,  0.0844,  0.0813,  0.0831,\n",
              "                       0.0822,  0.0583,  0.0747,  0.0519,  0.0787,  0.0895,  0.0876,  0.0605,\n",
              "                       0.0743,  0.0688,  0.0863,  0.0587,  0.1016,  0.0869,  0.0730,  0.0815,\n",
              "                       0.0751,  0.0764,  0.0708,  0.0779,  0.0475,  0.0667,  0.1020,  0.0916,\n",
              "                       0.0926,  0.0796,  0.0806,  0.0622,  0.0674,  0.0792,  0.1204,  0.0641,\n",
              "                       0.0671,  0.0730,  0.0797,  0.0791,  0.0700,  0.0743,  0.1042,  0.0738,\n",
              "                       0.0858,  0.0943,  0.0881,  0.0778,  0.0446,  0.0699,  0.0882,  0.0789,\n",
              "                       0.0506,  0.0792,  0.0681,  0.0718,  0.0470,  0.0688,  0.0824,  0.0665,\n",
              "                       0.0795,  0.0700,  0.0840,  0.0670,  0.0765,  0.0738,  0.0617,  0.0849,\n",
              "                       0.0779,  0.0807,  0.0582,  0.0719,  0.0699,  0.0596,  0.0815,  0.0880,\n",
              "                       0.0824,  0.0878,  0.0806,  0.0657,  0.0838,  0.0780,  0.0444,  0.0628,\n",
              "                       0.0739,  0.0825,  0.0809,  0.0556,  0.0672,  0.0863,  0.0818,  0.1042,\n",
              "                       0.0758,  0.0733,  0.0706,  0.0822,  0.0753,  0.0669,  0.0054,  0.0715,\n",
              "                       0.0668,  0.0872,  0.0554,  0.0755,  0.0765,  0.0595,  0.0724,  0.0705,\n",
              "                       0.0658,  0.0573,  0.0599,  0.0618,  0.0733,  0.0798,  0.0382,  0.0875,\n",
              "                       0.0771,  0.0686,  0.0671,  0.0644,  0.0692,  0.0697,  0.0639,  0.0843,\n",
              "                       0.0761,  0.0624,  0.0778,  0.0663,  0.0773,  0.0710,  0.0800,  0.0780,\n",
              "                       0.0903,  0.0551,  0.0836,  0.0848,  0.0783,  0.0804,  0.1258,  0.0597,\n",
              "                       0.0737,  0.0628,  0.0595,  0.0725,  0.0644,  0.0353,  0.0834,  0.0554,\n",
              "                       0.0309,  0.0702,  0.0371,  0.0751,  0.0999,  0.0721,  0.0773,  0.0789,\n",
              "                       0.0674,  0.0884,  0.0326,  0.0696,  0.0832,  0.0672,  0.0765,  0.0833,\n",
              "                       0.0798,  0.0740,  0.0820,  0.0733,  0.0822,  0.0586,  0.0686,  0.0798,\n",
              "                       0.0741,  0.0754,  0.0757,  0.0588,  0.0753,  0.0743,  0.0897,  0.0722,\n",
              "                       0.0862,  0.0893,  0.0810,  0.0714,  0.0784,  0.0658,  0.0805,  0.0911,\n",
              "                       0.0653,  0.0975,  0.0684,  0.0650,  0.0742,  0.0844,  0.0884,  0.0717,\n",
              "                       0.0668,  0.0710,  0.0840,  0.0006,  0.0618,  0.0712,  0.0720,  0.0870,\n",
              "                       0.0604,  0.0876,  0.0929,  0.0973,  0.0909,  0.0848,  0.0690,  0.0810,\n",
              "                       0.0658,  0.0909,  0.0739,  0.0660,  0.0767,  0.0829, -0.0537,  0.0805,\n",
              "                       0.0732,  0.0869,  0.0647,  0.0741,  0.0738,  0.0719,  0.0729,  0.0860,\n",
              "                       0.0841,  0.0728,  0.0770,  0.0872,  0.0764,  0.0675,  0.0697,  0.0762,\n",
              "                       0.0706,  0.0592,  0.0735,  0.0707,  0.1084,  0.0682,  0.0976,  0.0914,\n",
              "                       0.0853,  0.0757,  0.0890,  0.0796,  0.0755,  0.0702,  0.0810,  0.0728,\n",
              "                       0.0846,  0.0714,  0.0414,  0.0716,  0.0665,  0.0772,  0.0719,  0.0557,\n",
              "                      -0.0010,  0.0519,  0.0834,  0.0723,  0.0887,  0.0791,  0.0750,  0.0775,\n",
              "                       0.0662,  0.0633,  0.0681,  0.0891,  0.0709,  0.0854,  0.0732,  0.0721,\n",
              "                       0.0460,  0.0724,  0.0837,  0.0884,  0.0903,  0.0823,  0.0125,  0.0775,\n",
              "                       0.0770,  0.0769,  0.0893,  0.0870,  0.0626,  0.0975,  0.0760,  0.0700,\n",
              "                       0.0747,  0.0748,  0.0969,  0.0788,  0.0939,  0.0928,  0.0892,  0.0874,\n",
              "                       0.0793,  0.0817,  0.0563,  0.0732,  0.0820,  0.0703,  0.0716,  0.0845,\n",
              "                       0.0906,  0.0750,  0.0791,  0.0643,  0.0884,  0.0671,  0.0652,  0.0829,\n",
              "                       0.0853,  0.0834,  0.0742,  0.0697,  0.0540,  0.0698,  0.0874,  0.0696,\n",
              "                       0.0865,  0.0607,  0.0864,  0.0612,  0.0436,  0.0743,  0.0786,  0.0700,\n",
              "                       0.0674,  0.0748,  0.0882,  0.0713,  0.0958,  0.0006,  0.0757,  0.0946,\n",
              "                       0.0779,  0.0523,  0.0559,  0.0640,  0.0740,  0.0902,  0.0721,  0.0742,\n",
              "                       0.0752,  0.0760,  0.0785,  0.0929,  0.0594,  0.0796,  0.0879,  0.0820,\n",
              "                       0.0772,  0.0833,  0.0769,  0.0519,  0.0581,  0.0505,  0.0682,  0.0679,\n",
              "                       0.0772,  0.0590,  0.0745,  0.0881,  0.0701,  0.0810,  0.0832,  0.0755,\n",
              "                       0.0728,  0.0885,  0.0762,  0.0760,  0.0899,  0.0809,  0.0756,  0.0770,\n",
              "                       0.0645,  0.0707,  0.0746,  0.0888,  0.0585,  0.0630,  0.0717,  0.0749,\n",
              "                       0.0753,  0.0848,  0.0762,  0.0824,  0.0772,  0.0862,  0.0767,  0.0889,\n",
              "                       0.0592,  0.0811,  0.1041,  0.0602,  0.0200,  0.0802,  0.0777,  0.0241,\n",
              "                       0.0843,  0.0733,  0.0619,  0.0804,  0.0765,  0.0722,  0.0776,  0.0692,\n",
              "                       0.0859,  0.0546,  0.0615,  0.0661,  0.0862,  0.0700,  0.0729,  0.0819,\n",
              "                       0.0635,  0.0783,  0.0566,  0.0853,  0.0871,  0.0744,  0.0769,  0.0827,\n",
              "                       0.0204,  0.0752,  0.0918,  0.0862,  0.0824,  0.0852,  0.0683,  0.0763,\n",
              "                       0.1120,  0.1060,  0.0741,  0.0644,  0.0734,  0.0791,  0.0888,  0.0796,\n",
              "                       0.0819,  0.0817,  0.0566,  0.0705,  0.0628,  0.0744,  0.0823,  0.0738,\n",
              "                       0.0256,  0.0802,  0.0808,  0.0736,  0.0815,  0.0761,  0.0733,  0.0796,\n",
              "                       0.0604,  0.0630,  0.0948,  0.0730,  0.0263,  0.0946,  0.0865,  0.1126,\n",
              "                       0.0603,  0.0742,  0.0802,  0.0913,  0.0739,  0.0840,  0.0907,  0.0437,\n",
              "                       0.0763,  0.0843,  0.0752,  0.0855,  0.0688,  0.0876,  0.0689,  0.0791,\n",
              "                       0.0784,  0.0671,  0.0804,  0.0568,  0.0691,  0.0820,  0.0740,  0.0931,\n",
              "                       0.0665,  0.0676,  0.0590,  0.0710,  0.0642,  0.0508,  0.0560,  0.0939,\n",
              "                       0.0756,  0.1026,  0.0761,  0.0692,  0.0775,  0.0805,  0.0782,  0.0523,\n",
              "                       0.0669,  0.0560,  0.0621,  0.0793,  0.0777,  0.0755,  0.0702,  0.0648,\n",
              "                       0.0733,  0.0726,  0.0887,  0.1044,  0.0681,  0.0808,  0.0674,  0.0836,\n",
              "                       0.0693,  0.0823,  0.0725,  0.0725,  0.0726,  0.0753,  0.0645,  0.0627,\n",
              "                       0.0734,  0.0487,  0.0802,  0.0915,  0.0782,  0.0851,  0.0523,  0.0754,\n",
              "                       0.0811,  0.0750,  0.0504,  0.1484,  0.0822,  0.0804,  0.0868,  0.0782,\n",
              "                       0.0546,  0.0726,  0.0762,  0.0847,  0.0655,  0.0692,  0.0641,  0.0654,\n",
              "                       0.0694,  0.0779,  0.0670, -0.0013,  0.0624,  0.0850,  0.0587,  0.0727,\n",
              "                       0.0811,  0.0872,  0.0678,  0.0725,  0.0816,  0.0702,  0.0770,  0.0926,\n",
              "                       0.0691,  0.0778,  0.0708,  0.0835,  0.0542,  0.0731,  0.0759,  0.0712,\n",
              "                       0.0639,  0.0812,  0.0893,  0.0613,  0.0707,  0.0789,  0.0768,  0.0373,\n",
              "                       0.0915,  0.0813,  0.0792,  0.0707,  0.0736,  0.0891,  0.0751,  0.0884,\n",
              "                       0.0775,  0.0870,  0.0826,  0.0953,  0.0770,  0.0687,  0.0863,  0.0579,\n",
              "                       0.0882,  0.0762,  0.0810,  0.0793,  0.0719,  0.0676,  0.0739,  0.0804,\n",
              "                       0.0708,  0.0655,  0.0826,  0.0690,  0.0698,  0.0793,  0.0826,  0.0717,\n",
              "                       0.0580,  0.0769,  0.0815,  0.0758,  0.0520,  0.0655,  0.0454,  0.0612,\n",
              "                       0.0745,  0.0768,  0.0607,  0.0759,  0.0758,  0.0919,  0.0756,  0.0448,\n",
              "                       0.0661,  0.0744,  0.0891,  0.0760,  0.0681,  0.0687,  0.0644,  0.0951,\n",
              "                       0.0773,  0.0758,  0.0817,  0.0913,  0.0719,  0.0851,  0.0677,  0.0725,\n",
              "                       0.0743,  0.0584,  0.0906,  0.0820,  0.0676,  0.0734,  0.0635,  0.0806,\n",
              "                       0.0799,  0.0875,  0.0545,  0.0607,  0.0760,  0.0728,  0.0837,  0.0743,\n",
              "                       0.0883,  0.0752,  0.0876,  0.0742,  0.0573,  0.0689,  0.0713,  0.0750,\n",
              "                       0.0743,  0.0760,  0.0931,  0.0748,  0.0750,  0.0755,  0.0693, -0.0262,\n",
              "                       0.0660,  0.0806,  0.0765,  0.0730,  0.0526,  0.0758,  0.0687,  0.0774,\n",
              "                       0.0837,  0.0754,  0.0339,  0.0935,  0.0816,  0.0725,  0.0834,  0.0659,\n",
              "                       0.0834,  0.0816,  0.0593,  0.0774,  0.0746,  0.0519,  0.0720,  0.0729,\n",
              "                       0.0747,  0.0846,  0.0871,  0.0936,  0.0882,  0.0707,  0.0828,  0.0812,\n",
              "                       0.0829,  0.0892,  0.0798,  0.0529,  0.0688,  0.0535,  0.0765,  0.0647,\n",
              "                       0.0901,  0.0653,  0.0726,  0.0707,  0.0775,  0.0559,  0.0742,  0.0705,\n",
              "                       0.0688,  0.0675,  0.0752,  0.0796,  0.0924,  0.0711,  0.0529,  0.0794,\n",
              "                       0.0641,  0.0627,  0.0725,  0.0734,  0.0666,  0.0691,  0.0868,  0.0834],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.8955,  0.2279,  0.0194,  ...,  0.1848,  0.8473,  0.3478],\n",
              "                      [ 0.5240,  0.2005, -0.2932,  ..., -0.7751,  0.1490, -0.7048],\n",
              "                      [-0.3215, -0.4685, -0.6924,  ..., -0.4921,  0.5978,  0.3296],\n",
              "                      ...,\n",
              "                      [-0.3372,  0.2012, -0.1402,  ..., -0.3713, -0.4901,  0.5905],\n",
              "                      [-0.7411, -0.1996, -0.6421,  ..., -0.2682, -1.2070,  0.2269],\n",
              "                      [ 0.1954,  0.5043, -0.4188,  ...,  0.4404,  0.6587, -0.3480]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.1246, -0.0768, -0.2434,  ...,  0.1678, -0.5094,  0.1109],\n",
              "                      [-0.1334,  0.0932, -0.0637,  ...,  0.0958, -0.1945, -0.4047],\n",
              "                      [-0.0927, -0.0538, -0.2978,  ..., -0.1536,  0.2592, -0.0287],\n",
              "                      ...,\n",
              "                      [ 0.3950, -0.5053,  0.4076,  ..., -0.0768, -0.0907,  0.1444],\n",
              "                      [ 0.7129, -0.0749, -0.2494,  ..., -0.0610, -0.1012,  0.0833],\n",
              "                      [ 0.0927, -0.0142, -0.1364,  ...,  0.3328, -0.1076,  0.0149]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.3.layer.2.layer_norm.weight',\n",
              "              tensor([ 2.0847,  1.1900,  1.2148,  2.2004,  2.0847,  2.3744,  1.5978,  2.3412,\n",
              "                       1.5556,  1.8641,  3.4303,  2.0158,  1.5921,  2.5388,  2.0164,  2.0987,\n",
              "                       1.9910,  1.4456,  2.0261,  2.0091,  2.0518,  2.0568,  1.8787,  2.0781,\n",
              "                       2.0738,  1.5972,  2.0459,  2.0183,  2.0569,  1.8875,  2.0546,  1.1072,\n",
              "                       2.1321,  1.9457,  2.1672,  1.5566,  1.9974,  1.1576,  1.8055,  2.1257,\n",
              "                       1.7915,  2.0036,  1.9093,  2.1538,  1.1864,  1.9363,  1.9381,  2.1037,\n",
              "                       1.9896,  2.2936,  1.7746,  1.9055,  2.0664,  2.0994,  2.4508,  2.1485,\n",
              "                       1.8919,  1.9045,  2.0332,  2.1590,  1.8685,  2.1687,  2.0201,  1.9121,\n",
              "                       2.1584,  0.8347,  1.8956,  1.9873,  1.4556,  2.0277,  1.8372,  1.9232,\n",
              "                       1.8841,  1.8723,  2.0252,  1.9026,  2.2332,  2.0841,  1.9094,  1.8115,\n",
              "                       1.8606,  1.9232,  2.1239,  1.5819,  1.7731,  1.9459,  2.4063,  2.1058,\n",
              "                       1.9760,  1.9837,  1.7624,  1.8485,  1.9059,  2.2127,  2.1135,  2.0200,\n",
              "                       2.0259,  1.9511,  2.0540,  1.9111,  2.4881,  1.6725,  2.4135,  2.1247,\n",
              "                       1.8792,  1.7654,  2.0917,  1.8146,  1.7402,  2.0062,  1.9474,  1.9835,\n",
              "                       1.9787,  1.9083,  1.8753,  1.7308,  2.0415,  2.2229, -0.3475,  1.9467,\n",
              "                       1.9999,  1.7549,  1.5442,  1.8325,  1.9572,  1.8195,  2.0319,  2.0845,\n",
              "                       1.9726,  2.3724,  2.1060,  1.7578,  2.0548,  1.9935,  1.3799,  1.9771,\n",
              "                       1.9183,  1.6467,  2.5766,  2.6055,  1.7480,  1.8569,  2.3802,  2.0684,\n",
              "                       1.8731,  2.1015,  1.7331,  1.5682,  1.8396,  2.2229,  1.7573,  1.7919,\n",
              "                       1.6645,  1.6614,  2.0170,  2.0366,  2.1035,  2.1038,  1.7255,  2.2695,\n",
              "                       1.9279,  1.7993,  1.7054,  1.7957,  1.5594,  1.2977,  2.0787,  1.4346,\n",
              "                       1.2324,  1.8769,  2.2814,  1.7009,  1.9027,  1.8468,  2.0515,  1.9585,\n",
              "                       1.8353,  1.7006,  2.1802,  1.4979,  2.0841,  2.0214,  2.2098,  2.1647,\n",
              "                       1.9911,  1.7272,  2.0357,  1.4739,  1.9299,  2.2489,  1.9513,  2.0137,\n",
              "                       1.7213,  2.2925,  1.8857,  1.7701,  1.9895,  1.9647,  1.9911,  1.8135,\n",
              "                       2.0148,  2.2945,  2.0030,  1.6603,  1.9431,  2.0786,  1.9707,  2.0153,\n",
              "                       1.7299,  2.1944,  1.6299,  2.8040,  1.8485,  1.8728,  2.0699,  2.1322,\n",
              "                       2.0396,  1.7182,  2.1661,  0.8172,  2.1909,  1.8138,  1.6212,  1.8731,\n",
              "                       1.7723,  2.0475,  0.7448,  1.8795,  2.0693,  1.9839,  1.6222,  2.0893,\n",
              "                       1.7496,  2.1376,  1.9052,  1.7952,  2.1412,  2.0119,  2.5926,  2.2962,\n",
              "                       3.4422,  1.9378,  1.7062,  1.6921,  1.8680,  1.9199,  1.8025,  2.2757,\n",
              "                       1.8332,  1.8480,  1.8930,  2.0677,  2.1250,  1.9786,  1.8179,  1.5657,\n",
              "                       2.0034,  2.5528,  2.0516,  1.9016,  1.9616,  2.5203,  2.0026,  2.1654,\n",
              "                       1.9308,  1.9597,  1.8507,  1.7121,  2.0006,  2.1500,  2.0375,  1.3299,\n",
              "                       1.9409,  1.9153,  2.6472,  2.1418,  2.0490,  2.2584,  1.9207,  2.0238,\n",
              "                       0.4502,  1.4676,  1.9602,  1.8479,  1.9396,  1.9954,  2.1064,  2.0678,\n",
              "                       1.7306,  2.5127,  1.8689,  1.8755,  1.8907,  2.1474,  1.8594,  2.0018,\n",
              "                       1.1464,  1.9932,  1.9332,  2.3637,  1.9986,  1.9164,  0.5300,  2.0456,\n",
              "                       2.0359,  1.8971,  2.0765,  2.0474,  2.1142,  1.7498,  1.6112,  1.9709,\n",
              "                       1.9328,  1.7448,  1.1484,  2.2776,  1.7880,  1.9988,  1.9710,  1.7992,\n",
              "                       1.8271,  1.9534,  2.2190,  1.8909,  1.6177,  1.7226,  1.9777,  1.8559,\n",
              "                       2.0428,  1.9773,  2.0547,  1.7047,  1.8640,  1.7765,  1.8940,  2.1135,\n",
              "                       1.8036,  1.9086,  1.7710,  2.9480,  1.9707,  1.9499,  1.8525,  1.9864,\n",
              "                       2.0386,  1.7232,  2.0056,  2.6547,  1.1746,  2.1119,  1.7572,  1.6810,\n",
              "                       1.6403,  1.8169,  2.0915,  1.9325,  2.0859,  0.4977,  2.2170,  2.2187,\n",
              "                       2.0519,  1.4595,  2.1754,  1.7422,  1.8333,  1.8098,  2.0187,  1.8777,\n",
              "                       1.9149,  2.1093,  1.9603,  1.8300,  1.6413,  1.9155,  2.0000,  2.1219,\n",
              "                       1.9135,  1.6176,  1.9620,  1.6025,  1.8455,  1.7398,  2.2782,  1.9848,\n",
              "                       2.0274,  2.0601,  1.9863,  2.1845,  1.8253,  1.9638,  1.8457,  1.8038,\n",
              "                       1.9011,  2.2142,  1.9769,  2.0059,  1.9652,  1.8961,  1.7970,  2.4474,\n",
              "                       1.8211,  2.0013,  2.0060,  2.0332,  1.9476,  1.8606,  1.5941,  1.8082,\n",
              "                       1.7755,  1.8575,  1.9413,  1.8115,  1.9075,  1.8915,  2.0193,  1.8199,\n",
              "                       1.8470,  2.0561,  0.7692,  1.8785,  0.9185,  1.9160,  1.9987,  2.0388,\n",
              "                       2.0034,  1.8048,  2.0580,  2.0063,  1.8769,  3.5738,  1.7555,  1.8429,\n",
              "                       2.0504,  1.7730,  1.7717,  1.7893,  2.0069,  1.6786,  1.9577,  1.7622,\n",
              "                       1.9165,  1.8362,  1.3792,  2.1268,  1.9067,  1.8021,  1.9024,  2.0344,\n",
              "                       0.9139,  1.8359,  2.0813,  2.0233,  1.8665,  2.0712,  1.9214,  2.0494,\n",
              "                       1.4248,  0.8230,  1.9599,  1.8275,  2.0245,  2.0054,  2.0596,  1.8178,\n",
              "                       2.0284,  2.0846,  2.0556,  1.9305,  1.8469,  2.0061,  2.0094,  1.8859,\n",
              "                       1.0267,  2.1106,  1.8583,  1.8346,  1.9326,  1.8752,  1.9990,  2.0927,\n",
              "                       2.8169,  2.1087,  2.0448,  1.7524,  0.5136,  2.0655,  1.8436,  1.3211,\n",
              "                       1.8756,  1.9966,  2.0831,  1.7630,  2.0066,  1.9675,  2.1240,  2.1818,\n",
              "                       1.9254,  1.9569,  2.1547,  2.1105,  1.8652,  1.2727,  1.8566,  2.0690,\n",
              "                       1.9056,  1.8663,  1.9746,  1.9480,  1.8421,  1.9866,  1.7193,  2.1007,\n",
              "                       2.0320,  1.9703,  1.4528,  2.1136,  1.9387,  1.7247,  2.6030,  2.1402,\n",
              "                       2.0993,  2.0578,  1.9139,  1.7683,  2.0802,  1.7288,  2.2180,  1.3555,\n",
              "                       1.9113,  1.7546,  1.5731,  1.9219,  1.8946,  2.0015,  1.6506,  1.9704,\n",
              "                       2.1281,  1.8861,  1.9058,  1.8561,  1.7990,  2.0005,  1.9073,  1.9466,\n",
              "                       1.9020,  1.9535,  1.8557,  1.9947,  1.8626,  1.8075,  1.6663,  1.6207,\n",
              "                       1.8227,  1.5632,  1.9702,  1.9488,  1.8432,  2.0577,  1.5574,  2.0833,\n",
              "                       1.7516,  1.7030,  0.8695,  2.5418,  2.0331,  1.6789,  1.9253,  1.9492,\n",
              "                       2.2587,  1.9249,  1.7944,  1.9559,  1.9873,  2.6055,  2.5510,  1.7502,\n",
              "                       1.9952,  1.8962,  1.7179,  0.4471,  1.4422,  2.1081,  2.2539,  1.9181,\n",
              "                       1.9590,  2.0269,  2.0599,  2.1860,  2.0695,  1.8900,  2.0120,  1.8421,\n",
              "                       1.8472,  1.6983,  1.9291,  2.1300,  1.3633,  1.9701,  2.4499,  1.9161,\n",
              "                       1.5979,  2.0106,  1.8693,  1.8185,  1.8664,  1.9365,  1.8944,  0.9986,\n",
              "                       2.0673,  1.9985,  2.0449,  2.1633,  1.9129,  1.9365,  1.9263,  2.1195,\n",
              "                       1.9776,  0.7175,  1.7764,  1.8732,  1.9548,  1.7250,  1.9636,  2.5151,\n",
              "                       2.4347,  2.1031,  2.0429,  1.9111,  1.8237,  1.8172,  1.5385,  2.0012,\n",
              "                       1.5617,  1.5652,  1.8595,  1.7443,  2.6023,  2.0234,  1.9002,  1.8407,\n",
              "                       1.8159,  1.6292,  1.9900,  1.8747,  1.5909,  2.1976,  1.3384,  1.8124,\n",
              "                       1.9879,  1.9510,  1.3687,  2.0928,  1.8169,  2.0904,  1.9375,  2.2490,\n",
              "                       1.7662,  2.3547,  2.1053,  2.1935,  1.7664,  1.9812,  1.7028,  1.8797,\n",
              "                       1.8933,  1.8819,  1.8848,  2.1318,  2.2457,  2.1271,  1.6613,  1.9532,\n",
              "                       2.0584,  1.7001,  1.9066,  1.9917,  1.8444,  1.9062,  1.8547,  2.0324,\n",
              "                       1.7708,  2.0827,  1.9567,  1.7948,  1.8509,  1.9478,  1.7980,  1.8656,\n",
              "                       2.0195,  1.8105,  2.1152,  1.9711,  1.6608,  1.8644,  1.8654,  1.7640,\n",
              "                       2.0283,  1.7176,  2.0300,  1.9708,  1.8851,  1.8730,  1.8237,  1.9000,\n",
              "                       1.6086,  2.0984,  1.9348,  2.4932,  1.5038,  1.9595,  1.8100,  1.8564,\n",
              "                       1.7788,  1.7489,  2.0795,  1.3065,  1.9683,  1.6637,  1.7814,  2.1062,\n",
              "                       1.8952,  1.8756,  1.7251,  1.9172,  1.9279,  1.3553,  1.7539,  1.8016,\n",
              "                       1.8967,  2.0060,  1.8485,  2.2335,  1.8670,  1.4185,  1.6347,  1.9432,\n",
              "                       1.9137,  1.7687,  1.9174,  1.8089,  1.7295,  2.1360,  1.9511,  2.0744,\n",
              "                       2.0896,  1.6670,  1.8370,  1.7537,  2.0342,  2.7029,  2.3046,  1.6936,\n",
              "                       1.9087,  1.7971,  1.9364,  1.9013,  1.9346,  1.7561,  1.5637,  1.8621,\n",
              "                       1.6182,  1.7865,  1.9747,  2.2646,  1.7529,  1.9578,  2.3166,  2.2722],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0267,  0.0280,  0.0116,  ..., -0.0454,  0.0455, -0.0186],\n",
              "                      [-0.0181,  0.0100,  0.0058,  ...,  0.0797, -0.0190,  0.0321],\n",
              "                      [ 0.0465,  0.0285,  0.0455,  ..., -0.0287,  0.0016,  0.0617],\n",
              "                      ...,\n",
              "                      [-0.0387,  0.0307, -0.0175,  ..., -0.0225,  0.0209,  0.0784],\n",
              "                      [-0.0196,  0.0572, -0.0068,  ..., -0.0659, -0.0236,  0.0201],\n",
              "                      [-0.0118, -0.0212,  0.0050,  ..., -0.0081,  0.0105,  0.0039]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.1169,  0.1313,  0.0349,  ...,  0.1246, -0.1542, -0.2397],\n",
              "                      [ 0.4791, -0.2740, -0.1163,  ..., -0.0499,  0.1899,  0.1735],\n",
              "                      [-0.5845,  0.1160, -0.3085,  ...,  0.1233, -0.0261, -0.6328],\n",
              "                      ...,\n",
              "                      [ 0.0668, -0.0626, -0.6116,  ...,  0.3353, -0.0769, -0.1568],\n",
              "                      [ 0.2443, -0.6431, -0.1877,  ..., -0.3250,  0.0759,  0.1818],\n",
              "                      [-0.5179,  0.6132, -0.1265,  ...,  0.0818, -0.0827, -0.2902]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 9.1231e-01,  3.5727e-01,  9.2312e-03,  ...,  8.8113e-01,\n",
              "                        6.3858e-01, -6.9177e-01],\n",
              "                      [-3.7316e-01, -3.8390e-01,  2.3210e-01,  ...,  1.0155e+00,\n",
              "                       -1.4960e-04, -1.5534e-01],\n",
              "                      [-1.1887e-01,  7.0991e-01,  8.1271e-01,  ..., -5.5886e-01,\n",
              "                        6.0016e-01,  3.8002e-01],\n",
              "                      ...,\n",
              "                      [-1.6131e-01,  1.2417e-01, -9.1176e-01,  ..., -1.2695e-02,\n",
              "                       -3.8476e-01, -3.3607e-01],\n",
              "                      [ 7.3112e-01, -9.7130e-01,  5.1749e-01,  ...,  7.5951e-03,\n",
              "                        1.5022e-02, -8.8336e-01],\n",
              "                      [ 6.9790e-01, -1.1521e-01, -3.7236e-01,  ...,  1.0742e-01,\n",
              "                       -1.3782e-01, -3.1651e-01]], device='cuda:0')),\n",
              "             ('decoder.block.4.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 0.2670,  0.0949, -0.9367,  ..., -0.4609,  0.2084,  0.5612],\n",
              "                      [-0.4406, -0.1948,  0.6319,  ..., -0.0818, -0.5555, -0.0455],\n",
              "                      [ 0.3531,  0.3218,  0.2933,  ..., -0.3551,  0.4114,  0.0422],\n",
              "                      ...,\n",
              "                      [-1.0257,  0.0616,  0.7634,  ..., -0.6839, -0.3185,  0.2635],\n",
              "                      [ 0.0935,  0.9503,  0.9837,  ...,  0.0198,  0.2883,  0.1645],\n",
              "                      [-0.2789,  0.0608,  0.0075,  ..., -0.3189,  0.4449, -0.1900]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2011,  0.0935,  0.1124,  0.2605,  0.2125,  0.1451,  0.1958,  0.2440,\n",
              "                       0.1597,  0.2049,  0.1504,  0.2295,  0.0912,  0.1428,  0.2079,  0.2209,\n",
              "                       0.1987,  0.1532,  0.1907,  0.2289,  0.2100,  0.2169,  0.2052,  0.2364,\n",
              "                       0.2177,  0.1646,  0.1937,  0.1268,  0.1986,  0.2115,  0.2320,  0.1473,\n",
              "                       0.2396,  0.2045,  0.2151,  0.1667,  0.2104,  0.1708,  0.2101,  0.2335,\n",
              "                       0.2123,  0.2070,  0.2090,  0.2164,  0.1243,  0.2044,  0.2381,  0.2029,\n",
              "                       0.2289,  0.2400,  0.1818,  0.1964,  0.1868,  0.2313,  0.2809,  0.1583,\n",
              "                       0.1800,  0.2302,  0.2237,  0.1962,  0.1770,  0.2294,  0.2113,  0.2030,\n",
              "                       0.2231,  0.1327,  0.2197,  0.2067,  0.1110,  0.2134,  0.2149,  0.2062,\n",
              "                       0.2017,  0.2154,  0.1827,  0.2046,  0.1355,  0.2119,  0.2108,  0.2004,\n",
              "                       0.2233,  0.2325,  0.2419,  0.1618,  0.2084,  0.2213,  0.1470,  0.2440,\n",
              "                       0.2014,  0.1934,  0.1824,  0.2050,  0.1925,  0.1713,  0.2337,  0.2238,\n",
              "                       0.2141,  0.2034,  0.2239,  0.2089,  0.1637,  0.1775,  0.0963,  0.2070,\n",
              "                       0.1844,  0.1900,  0.2082,  0.2054,  0.1956,  0.2246,  0.2131,  0.2390,\n",
              "                       0.1915,  0.2038,  0.1931,  0.1880,  0.2024,  0.2014,  0.0449,  0.1965,\n",
              "                       0.2263,  0.1968,  0.1698,  0.2046,  0.2205,  0.1961,  0.2207,  0.1692,\n",
              "                       0.1843,  0.1265,  0.1162,  0.1883,  0.1967,  0.2380,  0.1231,  0.2129,\n",
              "                       0.2101,  0.1678,  0.1652,  0.1256,  0.1547,  0.1990,  0.1917,  0.2307,\n",
              "                       0.1838,  0.1641,  0.2039,  0.1448,  0.1924,  0.1936,  0.2185,  0.2040,\n",
              "                       0.1815,  0.1638,  0.2085,  0.2300,  0.2168,  0.2334,  0.0572,  0.1020,\n",
              "                       0.2037,  0.1764,  0.1914,  0.1893,  0.1736,  0.1258,  0.2108,  0.1377,\n",
              "                       0.1061,  0.2218,  0.0915,  0.1945,  0.2284,  0.2212,  0.2189,  0.2366,\n",
              "                       0.2080,  0.2089, -0.0829,  0.1630,  0.2323,  0.2112,  0.2262,  0.2368,\n",
              "                       0.1832,  0.1979,  0.2149,  0.0488,  0.2129,  0.1386,  0.2058,  0.2198,\n",
              "                       0.1850,  0.2378,  0.1959,  0.2025,  0.2189,  0.2265,  0.2565,  0.1830,\n",
              "                       0.2548,  0.1915,  0.2143,  0.1755,  0.2090,  0.1665,  0.2242,  0.1956,\n",
              "                       0.1939,  0.2586,  0.1561,  0.1601,  0.1967,  0.1934,  0.2401,  0.2233,\n",
              "                       0.2019,  0.1812,  0.2168, -0.0240,  0.1337,  0.1918,  0.1786,  0.2064,\n",
              "                       0.1710,  0.2258,  0.3284,  0.2204,  0.2223,  0.2124,  0.1817,  0.2349,\n",
              "                       0.1834,  0.2261,  0.2084,  0.1864,  0.1861,  0.1944,  0.1080,  0.2206,\n",
              "                       0.1679,  0.2262,  0.1984,  0.1983,  0.2333,  0.2054,  0.2089,  0.2097,\n",
              "                       0.2020,  0.2244,  0.2026,  0.1971,  0.2250,  0.1995,  0.2002,  0.1783,\n",
              "                       0.2235, -0.1227,  0.2293,  0.1981,  0.2573,  0.1243,  0.2336,  0.2282,\n",
              "                       0.2120,  0.2123,  0.2053,  0.2006,  0.2071,  0.2207,  0.2017,  0.1021,\n",
              "                       0.2036,  0.2143,  0.0928,  0.2200,  0.1934,  0.2152,  0.1920,  0.1713,\n",
              "                       0.0283,  0.1269,  0.2160,  0.1824,  0.2354,  0.2292,  0.2139,  0.2245,\n",
              "                       0.1443,  0.1286,  0.1992,  0.2070,  0.1926,  0.2405,  0.1887,  0.2116,\n",
              "                       0.1231,  0.2127,  0.2256,  0.2496,  0.2233,  0.2042,  0.0265,  0.2142,\n",
              "                       0.2266,  0.1906,  0.2123,  0.2138,  0.2127,  0.2211,  0.2022,  0.2171,\n",
              "                       0.2062,  0.2160,  0.1848,  0.1940,  0.2164,  0.2405,  0.2247,  0.2197,\n",
              "                       0.2140,  0.1979,  0.1486,  0.2191,  0.1763,  0.2069,  0.1781,  0.2069,\n",
              "                       0.2337,  0.2109,  0.2053,  0.1752,  0.2207,  0.1695,  0.2032,  0.2019,\n",
              "                       0.2185,  0.2159,  0.1767,  0.1744,  0.1874,  0.2053,  0.2150,  0.2155,\n",
              "                       0.2101,  0.1769,  0.2206,  0.1533,  0.1248,  0.2044,  0.1811,  0.2002,\n",
              "                       0.1721,  0.2055,  0.2036,  0.2245,  0.2364,  0.0511,  0.2370,  0.2311,\n",
              "                       0.2232,  0.1587,  0.1210,  0.1915,  0.1834,  0.2044,  0.2077,  0.1858,\n",
              "                       0.1990,  0.2156,  0.2363,  0.2052,  0.1954,  0.1942,  0.2261,  0.2002,\n",
              "                       0.2220,  0.2292,  0.2292,  0.1463,  0.1825,  0.1950,  0.1348,  0.1767,\n",
              "                       0.2109,  0.2303,  0.2162,  0.2255,  0.1816,  0.2238,  0.2076,  0.2105,\n",
              "                       0.1731,  0.2356,  0.2061,  0.2257,  0.2245,  0.1855,  0.2045,  0.2207,\n",
              "                       0.1993,  0.2271,  0.2154,  0.2217,  0.1843,  0.2184,  0.1433,  0.1976,\n",
              "                       0.1734,  0.2156,  0.1792,  0.1912,  0.2302,  0.1994,  0.2459,  0.2108,\n",
              "                       0.1916,  0.2203,  0.1865,  0.2125,  0.0213,  0.2034,  0.2236,  0.0697,\n",
              "                       0.2223,  0.2135,  0.1740,  0.2261,  0.2004,  0.1360,  0.2161,  0.1913,\n",
              "                       0.2316,  0.1773,  0.2014,  0.1946,  0.2182,  0.1935,  0.2042,  0.2027,\n",
              "                       0.2016,  0.2026,  0.1870,  0.2190,  0.2295,  0.2015,  0.2009,  0.2044,\n",
              "                       0.0253,  0.2007,  0.2162,  0.2121,  0.1939,  0.2273,  0.1905,  0.1949,\n",
              "                       0.2026,  0.2595,  0.2128,  0.1993,  0.2105,  0.2079,  0.2138,  0.1917,\n",
              "                       0.2045,  0.2274,  0.1620,  0.1976,  0.1860,  0.2143,  0.2179,  0.2144,\n",
              "                       0.1023,  0.2237,  0.2232,  0.2027,  0.2304,  0.2091,  0.2042,  0.2214,\n",
              "                       0.1559,  0.2327,  0.2338,  0.1743,  0.0600,  0.2181,  0.2041,  0.0423,\n",
              "                       0.2021,  0.2024,  0.2242,  0.2123,  0.2193,  0.2171,  0.2138, -0.0679,\n",
              "                       0.1992,  0.1836,  0.2398,  0.2077,  0.2159,  0.1591,  0.2044,  0.1969,\n",
              "                       0.2117,  0.1946,  0.2125,  0.1762,  0.1996,  0.2155,  0.1928,  0.2251,\n",
              "                       0.2081,  0.1816,  0.1865,  0.2351,  0.1795,  0.1745,  0.1504,  0.2341,\n",
              "                       0.2145,  0.2157,  0.2188,  0.1995,  0.2075,  0.1754,  0.2216,  0.1365,\n",
              "                       0.1984,  0.1906,  0.1636,  0.2155,  0.2149,  0.2186,  0.1831,  0.2183,\n",
              "                       0.2287,  0.2016,  0.2037,  0.1976,  0.2054,  0.2007,  0.2083,  0.1982,\n",
              "                       0.1916,  0.2008,  0.2118,  0.1927,  0.2042,  0.2100,  0.1529,  0.1378,\n",
              "                       0.1997,  0.1596,  0.2309,  0.2019,  0.1916,  0.2158,  0.1689,  0.2021,\n",
              "                       0.2169,  0.1808,  0.1851,  0.3074,  0.2335,  0.1921,  0.2139,  0.2297,\n",
              "                       0.2029,  0.2190,  0.2053,  0.2194,  0.2109,  0.1750,  0.1272,  0.1945,\n",
              "                       0.2293,  0.2291,  0.1907,  0.0236,  0.1523,  0.2225,  0.2274,  0.1936,\n",
              "                       0.2211,  0.2153,  0.2190,  0.2092,  0.2228,  0.2009,  0.2206,  0.2124,\n",
              "                       0.1965,  0.1898,  0.1869,  0.2378,  0.1254,  0.2097,  0.2121,  0.1898,\n",
              "                       0.1847,  0.2032,  0.2272,  0.1844,  0.2125,  0.2038,  0.1947,  0.1134,\n",
              "                       0.2380,  0.2052,  0.2099,  0.1923,  0.2113,  0.1964,  0.2051,  0.2309,\n",
              "                       0.2117,  0.1957,  0.1848,  0.2178,  0.2135,  0.2001,  0.2030,  0.1358,\n",
              "                       0.2157,  0.2122,  0.2018,  0.1934,  0.2004,  0.2083,  0.1654,  0.2120,\n",
              "                       0.1864,  0.1885,  0.1935,  0.2033,  0.1508,  0.1857,  0.2346,  0.2085,\n",
              "                       0.1359,  0.1843,  0.2112,  0.2042,  0.1468,  0.1969,  0.1162,  0.1928,\n",
              "                       0.1984,  0.2159,  0.1299,  0.2109,  0.1816,  0.2198,  0.2263,  0.1019,\n",
              "                       0.1911,  0.1526,  0.2330,  0.2059,  0.2057,  0.2050,  0.1937,  0.2316,\n",
              "                       0.1959,  0.2099,  0.2065,  0.2183,  0.1810,  0.2241,  0.1831,  0.1998,\n",
              "                       0.2108,  0.1695,  0.2181,  0.2181,  0.1933,  0.2068,  0.2262,  0.2327,\n",
              "                       0.2195,  0.2146,  0.1665,  0.1834,  0.1781,  0.2003,  0.1842,  0.1812,\n",
              "                       0.2191,  0.2013,  0.2246,  0.2071,  0.1533,  0.1978,  0.2174,  0.2149,\n",
              "                       0.2074,  0.1958,  0.2086,  0.1974,  0.1878,  0.2202,  0.1988, -0.0946,\n",
              "                       0.1768,  0.2088,  0.2086,  0.1782,  0.1221,  0.2082,  0.1873,  0.2028,\n",
              "                       0.1756,  0.1822,  0.0815,  0.2036,  0.1825,  0.2028,  0.1947,  0.1768,\n",
              "                       0.2153,  0.1939,  0.1299,  0.2105,  0.2320,  0.0956,  0.1885,  0.2021,\n",
              "                       0.1966,  0.2104,  0.2192,  0.2160,  0.2115,  0.0666,  0.2072,  0.2029,\n",
              "                       0.2184,  0.2107,  0.2140,  0.1808,  0.1731, -0.1170,  0.2120,  0.1743,\n",
              "                       0.2223,  0.1798,  0.1307,  0.1886,  0.2068,  0.1352,  0.1839,  0.1954,\n",
              "                       0.1719,  0.2054,  0.2220,  0.2019,  0.1967,  0.1931,  0.0945,  0.2224,\n",
              "                       0.1696,  0.1588,  0.2011,  0.2072,  0.1992,  0.2030,  0.2561,  0.2135],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[ 0.0461, -0.0406,  0.0302,  ..., -0.0099,  0.0372, -0.0649],\n",
              "                      [-0.0306, -0.0299, -0.0276,  ..., -0.0095, -0.0261, -0.0017],\n",
              "                      [ 0.0070, -0.0135, -0.0275,  ...,  0.0565, -0.0234,  0.0432],\n",
              "                      ...,\n",
              "                      [ 0.0149, -0.0304,  0.0470,  ...,  0.0107,  0.0025,  0.0333],\n",
              "                      [ 0.0418,  0.0087, -0.0078,  ...,  0.0212,  0.0013, -0.0036],\n",
              "                      [-0.1028, -0.0238, -0.0155,  ...,  0.0056,  0.0290,  0.0079]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[-0.3879, -0.5870, -0.2177,  ..., -0.0697, -0.1028, -0.8829],\n",
              "                      [ 0.1641,  0.1760,  0.1917,  ...,  0.2961, -0.3789,  0.3008],\n",
              "                      [ 0.0818,  0.2665, -0.2305,  ..., -0.4526,  0.0793,  0.0312],\n",
              "                      ...,\n",
              "                      [-0.2725,  0.0290,  0.4159,  ...,  0.0058,  0.4189, -0.2248],\n",
              "                      [ 0.1493,  0.1311,  0.3317,  ...,  0.1343, -0.0215,  0.3366],\n",
              "                      [ 0.5786, -0.2645, -0.5771,  ..., -0.1733, -0.0495,  0.1023]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.4065, -0.3203, -0.0122,  ...,  0.3035,  0.5633, -0.2741],\n",
              "                      [ 0.2627, -0.1064, -0.4484,  ..., -0.0218,  0.3223, -1.1437],\n",
              "                      [ 0.2265, -0.2488, -0.2118,  ...,  0.1551, -0.8595, -0.2431],\n",
              "                      ...,\n",
              "                      [ 0.2533,  0.1601,  0.8432,  ..., -0.5413,  0.0301, -0.1329],\n",
              "                      [-0.7431,  0.0530, -0.1571,  ..., -0.4436, -0.7003,  0.2703],\n",
              "                      [ 0.2714,  0.3945, -0.1477,  ...,  0.3270, -0.8158,  0.1687]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[ 3.1087e-01,  5.1195e-01,  4.9965e-01,  ...,  2.6672e-01,\n",
              "                       -8.5210e-01,  1.8428e-01],\n",
              "                      [ 4.0606e-01,  9.4785e-01, -7.7246e-01,  ...,  1.2057e-04,\n",
              "                        3.0939e-01, -3.8193e-02],\n",
              "                      [ 2.8334e-01, -3.2415e-01,  8.2167e-01,  ...,  1.3458e-01,\n",
              "                        7.5378e-01, -4.9431e-01],\n",
              "                      ...,\n",
              "                      [ 1.5227e-01,  1.0448e-01,  4.5053e-01,  ..., -8.0238e-01,\n",
              "                        8.4604e-02,  1.9217e-01],\n",
              "                      [ 6.3910e-01, -5.2661e-01, -2.0259e-01,  ...,  8.0076e-02,\n",
              "                       -1.3728e-01, -3.9619e-01],\n",
              "                      [-3.2070e-03, -5.3247e-01,  4.1803e-01,  ...,  3.9896e-01,\n",
              "                       -9.8114e-02,  3.3748e-02]], device='cuda:0')),\n",
              "             ('decoder.block.4.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.0723,  0.0309,  0.0376,  0.1180,  0.0650,  0.0568,  0.1074,  0.1051,\n",
              "                       0.0796,  0.1044,  0.0656,  0.0968,  0.0619,  0.0617,  0.0797,  0.0904,\n",
              "                       0.0877,  0.0711,  0.0840,  0.0926,  0.0864,  0.0938,  0.0964,  0.1073,\n",
              "                       0.0940,  0.0876,  0.0960,  0.0562,  0.0779,  0.0985,  0.1080,  0.0551,\n",
              "                       0.1021,  0.0915,  0.1015,  0.0708,  0.1049,  0.0819,  0.0750,  0.1089,\n",
              "                       0.0845,  0.0778,  0.0793,  0.0777,  0.0514,  0.0975,  0.1174,  0.1027,\n",
              "                       0.1015,  0.0879,  0.0950,  0.0927,  0.0744,  0.1013,  0.1164,  0.0576,\n",
              "                       0.0805,  0.0914,  0.0986,  0.0871,  0.0785,  0.0966,  0.0872,  0.0829,\n",
              "                       0.0972,  0.0910,  0.0739,  0.0858,  0.0530,  0.0752,  0.1045,  0.1038,\n",
              "                       0.0696,  0.0836,  0.0873,  0.0867,  0.0626,  0.0764,  0.0985,  0.0753,\n",
              "                       0.0782,  0.0859,  0.0877,  0.0549,  0.0816,  0.0949,  0.0636,  0.0914,\n",
              "                       0.0880,  0.0857,  0.0723,  0.0844,  0.0880,  0.0841,  0.0944,  0.0878,\n",
              "                       0.0976,  0.0927,  0.0972,  0.0885,  0.0675,  0.0813,  0.0371,  0.0877,\n",
              "                       0.0784,  0.0797,  0.0957,  0.0630,  0.0984,  0.0980,  0.0822,  0.0934,\n",
              "                       0.0892,  0.0693,  0.0859,  0.0838,  0.0758,  0.0902, -0.0104,  0.0878,\n",
              "                       0.0853,  0.0940,  0.0699,  0.0779,  0.0802,  0.0631,  0.0906,  0.0732,\n",
              "                       0.0832,  0.0572,  0.0476,  0.0772,  0.0878,  0.1065,  0.0598,  0.1066,\n",
              "                       0.0864,  0.0723,  0.0847,  0.0592,  0.0682,  0.0848,  0.0792,  0.0906,\n",
              "                       0.0990,  0.0761,  0.0867,  0.0789,  0.0797,  0.0783,  0.0971,  0.0846,\n",
              "                       0.0935,  0.0743,  0.0887,  0.0932,  0.0989,  0.0961,  0.1164,  0.0569,\n",
              "                       0.0765,  0.0681,  0.0715,  0.0795,  0.0719,  0.0333,  0.0912,  0.0491,\n",
              "                       0.0297,  0.1021,  0.0443,  0.0833,  0.1092,  0.1013,  0.0899,  0.0904,\n",
              "                       0.0876,  0.1077,  0.0404,  0.0724,  0.0815,  0.0964,  0.1127,  0.1079,\n",
              "                       0.0780,  0.0836,  0.0958,  0.0731,  0.0916,  0.0385,  0.1052,  0.0901,\n",
              "                       0.0892,  0.1064,  0.0750,  0.0910,  0.0784,  0.1015,  0.0864,  0.0835,\n",
              "                       0.1035,  0.0898,  0.0978,  0.0734,  0.0776,  0.0743,  0.1182,  0.0862,\n",
              "                       0.0843,  0.1222,  0.0870,  0.0730,  0.0870,  0.0860,  0.1063,  0.0832,\n",
              "                       0.0881,  0.0703,  0.0847, -0.0017,  0.0501,  0.1025,  0.0874,  0.0855,\n",
              "                       0.0676,  0.1141,  0.1075,  0.1118,  0.0769,  0.0927,  0.0803,  0.0853,\n",
              "                       0.0735,  0.0971,  0.0889,  0.0810,  0.0789,  0.0850,  0.0585,  0.0899,\n",
              "                       0.0683,  0.1069,  0.0777,  0.0808,  0.0967,  0.0922,  0.0849, -0.0871,\n",
              "                       0.0930,  0.0916,  0.0839,  0.0797,  0.0894,  0.0697,  0.0914,  0.0638,\n",
              "                       0.0951,  0.0658,  0.0864,  0.0750,  0.1313,  0.0620,  0.1093,  0.0924,\n",
              "                       0.0934,  0.0755,  0.1009,  0.0846,  0.0870,  0.0869,  0.0948,  0.0616,\n",
              "                       0.1065,  0.0821,  0.0387,  0.0960,  0.0854,  0.0916,  0.0919,  0.0726,\n",
              "                      -0.0028,  0.0521,  0.0860,  0.0789,  0.0953,  0.0948,  0.0858,  0.1112,\n",
              "                       0.0662,  0.0629,  0.0803,  0.0782,  0.0923,  0.0965,  0.0760,  0.0773,\n",
              "                       0.0539,  0.0910,  0.0884,  0.1032,  0.0996,  0.0799, -0.0011,  0.0843,\n",
              "                       0.0925,  0.0884,  0.1045,  0.0887,  0.0763,  0.0885,  0.1020,  0.0898,\n",
              "                       0.0803,  0.0898,  0.1267,  0.0867,  0.1133,  0.0953,  0.1109,  0.0993,\n",
              "                       0.1071,  0.1042,  0.0789,  0.0804,  0.0822,  0.0805,  0.0806,  0.0792,\n",
              "                       0.0904,  0.1001,  0.1050,  0.0651,  0.0887,  0.0838,  0.0881,  0.0834,\n",
              "                       0.0792,  0.1052,  0.0726,  0.0700,  0.0726,  0.0875,  0.0922,  0.0942,\n",
              "                       0.0882,  0.0659,  0.0883,  0.0662,  0.0461,  0.0809,  0.0874,  0.0980,\n",
              "                       0.0658,  0.0842,  0.0958,  0.1015,  0.0965,  0.0016,  0.0857,  0.1076,\n",
              "                       0.1068,  0.0697,  0.0629,  0.0737,  0.0928,  0.1013,  0.0903,  0.0765,\n",
              "                       0.0809,  0.0951,  0.0823,  0.0934,  0.0748,  0.0815,  0.0901,  0.0840,\n",
              "                       0.0932,  0.0896,  0.0946,  0.0595,  0.0732,  0.0812,  0.0745,  0.0982,\n",
              "                       0.1014,  0.0964,  0.0853,  0.0908,  0.0667,  0.0971,  0.0921,  0.0721,\n",
              "                       0.0729,  0.0890,  0.0764,  0.0896,  0.1063,  0.0849,  0.0869,  0.0897,\n",
              "                       0.0851,  0.0831,  0.0795,  0.0957,  0.0712,  0.0781,  0.0701,  0.0813,\n",
              "                       0.0637,  0.0805,  0.0822,  0.0908,  0.0858,  0.1016,  0.0831,  0.1135,\n",
              "                       0.0771,  0.0931,  0.1373,  0.0976, -0.0014,  0.0861,  0.0937, -0.0261,\n",
              "                       0.1256,  0.0829,  0.0686,  0.0847,  0.0653,  0.0630,  0.0991,  0.0657,\n",
              "                       0.1052,  0.0825,  0.0753,  0.0682,  0.0937,  0.0842,  0.0776,  0.0761,\n",
              "                       0.0805,  0.0771, -0.0664,  0.1105,  0.1129,  0.0990,  0.0968,  0.0875,\n",
              "                      -0.0007,  0.0891,  0.0900,  0.0995,  0.0782,  0.0911,  0.0802,  0.0854,\n",
              "                       0.1214,  0.1155,  0.0767,  0.0743,  0.0820,  0.1034,  0.0911,  0.0821,\n",
              "                       0.0821,  0.0885,  0.0803,  0.0841,  0.0940,  0.0894,  0.0958,  0.0932,\n",
              "                       0.0226,  0.0835,  0.0883,  0.0968,  0.0878,  0.0712,  0.0768,  0.0855,\n",
              "                       0.0696,  0.0955,  0.1025,  0.0901,  0.0194,  0.1041,  0.0902,  0.1185,\n",
              "                       0.0926,  0.0805,  0.0928,  0.1029,  0.0985,  0.0834,  0.1041,  0.0548,\n",
              "                       0.0903,  0.0923,  0.0915,  0.0784,  0.0645,  0.0921,  0.0916,  0.0884,\n",
              "                       0.0794,  0.0885,  0.0871,  0.0805,  0.0828,  0.1014,  0.0822,  0.1085,\n",
              "                       0.0856,  0.0766,  0.0716,  0.0950,  0.0839,  0.0710,  0.0639,  0.0902,\n",
              "                       0.0754,  0.0847,  0.1049,  0.0927,  0.0850,  0.0811,  0.0914,  0.0641,\n",
              "                       0.0723,  0.0645,  0.0632,  0.0865,  0.0978,  0.0964,  0.0800,  0.0828,\n",
              "                       0.1098,  0.0835,  0.0876,  0.0852,  0.0886,  0.0883,  0.0872,  0.0812,\n",
              "                       0.0856,  0.0965,  0.0934,  0.0800,  0.0808,  0.0745,  0.0710,  0.0814,\n",
              "                       0.0794,  0.0588,  0.0906,  0.0961,  0.0699,  0.0899,  0.0558,  0.0989,\n",
              "                       0.0862,  0.0673,  0.0454,  0.1475,  0.1058,  0.0859,  0.0792,  0.0762,\n",
              "                       0.0796,  0.0900,  0.0923,  0.0902,  0.0762,  0.0741,  0.0529,  0.0886,\n",
              "                       0.0900,  0.0957,  0.0699, -0.0012,  0.0663,  0.1005,  0.0910,  0.0756,\n",
              "                       0.0816,  0.1073,  0.0883,  0.0739,  0.0884,  0.0689,  0.0917,  0.0833,\n",
              "                       0.0861,  0.0818,  0.0831,  0.0973,  0.0535,  0.0829,  0.1027,  0.0953,\n",
              "                       0.0608,  0.0831,  0.0987,  0.0675,  0.0780,  0.0778,  0.0926,  0.0510,\n",
              "                       0.1014,  0.0809,  0.0838,  0.0846,  0.0895,  0.0975,  0.0656,  0.0909,\n",
              "                       0.0673,  0.1170,  0.0933,  0.0889,  0.0784,  0.0750,  0.0859,  0.0579,\n",
              "                       0.0998,  0.0856,  0.0845,  0.0889,  0.0840,  0.0896,  0.0880,  0.0947,\n",
              "                       0.0742,  0.0666,  0.0878,  0.0885,  0.0722,  0.0735,  0.0822,  0.0871,\n",
              "                       0.0591,  0.0659,  0.1024,  0.0839,  0.0476,  0.0855,  0.0418,  0.0746,\n",
              "                       0.0824,  0.1019,  0.0666,  0.0809,  0.0837,  0.0911,  0.0874,  0.0381,\n",
              "                       0.0698,  0.0733,  0.0863,  0.1019,  0.0868,  0.0775,  0.0653,  0.1029,\n",
              "                       0.1058,  0.0902,  0.0851,  0.0940,  0.0836,  0.0878,  0.0778,  0.0879,\n",
              "                       0.0970,  0.0592,  0.0917,  0.0844,  0.0730,  0.0790,  0.0869,  0.0849,\n",
              "                       0.0942,  0.0930,  0.0556,  0.0871,  0.0820,  0.0888,  0.0839,  0.0775,\n",
              "                       0.1043,  0.0813,  0.0887,  0.0772,  0.0553,  0.0790,  0.0919,  0.0729,\n",
              "                       0.0951,  0.0827,  0.0961,  0.0690,  0.0796,  0.0808,  0.0746,  0.0394,\n",
              "                       0.0800,  0.0867,  0.0869,  0.0760,  0.0647,  0.0902,  0.0778,  0.0729,\n",
              "                       0.0945,  0.0827, -0.0352,  0.1038,  0.0824,  0.0956,  0.0893,  0.0712,\n",
              "                       0.1001,  0.0642,  0.0654,  0.0902,  0.0805,  0.0516,  0.0795,  0.0872,\n",
              "                       0.0790,  0.0963,  0.1011,  0.0823,  0.0956,  0.0568,  0.0789,  0.0964,\n",
              "                       0.1093,  0.0973,  0.0926,  0.0702,  0.0806,  0.0659,  0.0891,  0.0640,\n",
              "                       0.1008,  0.0705,  0.0624,  0.0752,  0.0773,  0.0631,  0.0825,  0.0698,\n",
              "                       0.0860,  0.0668,  0.0976,  0.0934,  0.0841,  0.0730,  0.0627,  0.0822,\n",
              "                       0.0676,  0.0719,  0.0814,  0.0815,  0.0797,  0.0929,  0.0979,  0.0937],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.4697, -0.3229, -0.0537,  ...,  0.0045,  0.5524, -0.0416],\n",
              "                      [-0.2639, -0.1271, -1.0469,  ..., -0.7000,  0.3633, -0.8510],\n",
              "                      [ 0.2065,  0.7035, -1.3316,  ..., -0.8145, -0.2611, -0.0545],\n",
              "                      ...,\n",
              "                      [-0.4719,  0.0840, -0.1395,  ...,  0.0261,  0.6275,  1.1107],\n",
              "                      [-0.7774, -0.3210, -1.1192,  ..., -0.5769,  0.3460, -1.5636],\n",
              "                      [ 0.2740,  0.4521, -0.7258,  ...,  0.4694,  0.6133,  0.0350]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.0595,  0.2144,  0.1320,  ..., -0.2981,  0.2656, -0.3363],\n",
              "                      [-0.3621,  0.0175,  0.1214,  ..., -0.2187, -0.2352,  0.5840],\n",
              "                      [-0.1561,  0.1051,  0.1506,  ..., -0.1819, -0.5536,  0.1350],\n",
              "                      ...,\n",
              "                      [ 0.1839,  0.1597, -0.1990,  ...,  0.2184, -0.2573, -0.1139],\n",
              "                      [-0.4380,  0.0801,  0.2048,  ..., -0.3928, -0.3397,  0.1096],\n",
              "                      [ 0.0209, -0.5762,  0.0932,  ..., -0.2245, -0.3074, -0.0573]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.4.layer.2.layer_norm.weight',\n",
              "              tensor([ 2.3487e+00,  1.7700e+00,  1.6569e+00,  2.2629e+00,  2.3869e+00,\n",
              "                       2.6540e+00,  2.0470e+00,  2.6608e+00,  1.8811e+00,  2.1279e+00,\n",
              "                       3.7511e+00,  2.5506e+00,  1.9520e+00,  2.8495e+00,  2.3001e+00,\n",
              "                       2.3803e+00,  2.2661e+00,  1.8062e+00,  2.3104e+00,  2.3676e+00,\n",
              "                       2.3413e+00,  2.4263e+00,  2.2774e+00,  2.3495e+00,  2.5053e+00,\n",
              "                       1.9378e+00,  2.3460e+00,  2.4958e+00,  2.3487e+00,  2.4063e+00,\n",
              "                       2.5045e+00,  1.6513e+00,  2.5609e+00,  2.2479e+00,  2.5102e+00,\n",
              "                       1.9359e+00,  2.3554e+00,  1.4997e+00,  2.1812e+00,  2.4882e+00,\n",
              "                       2.0715e+00,  2.3134e+00,  2.3003e+00,  2.4592e+00,  1.6087e+00,\n",
              "                       2.1876e+00,  2.2986e+00,  2.4706e+00,  2.3470e+00,  2.6004e+00,\n",
              "                       2.1613e+00,  2.3313e+00,  2.3882e+00,  2.2977e+00,  2.9179e+00,\n",
              "                       2.4973e+00,  2.2050e+00,  2.3336e+00,  2.2720e+00,  2.3784e+00,\n",
              "                       2.1512e+00,  2.5246e+00,  2.3195e+00,  2.4233e+00,  2.4395e+00,\n",
              "                       1.1066e+00,  2.3005e+00,  2.3328e+00,  1.9537e+00,  2.2803e+00,\n",
              "                       2.2139e+00,  2.2088e+00,  2.1362e+00,  2.2764e+00,  2.3285e+00,\n",
              "                       2.1950e+00,  2.4920e+00,  2.4468e+00,  2.3127e+00,  2.2536e+00,\n",
              "                       2.2407e+00,  2.2649e+00,  2.4657e+00,  1.8617e+00,  2.1444e+00,\n",
              "                       2.3803e+00,  2.3923e+00,  2.3985e+00,  2.3828e+00,  2.4813e+00,\n",
              "                       2.0645e+00,  2.2027e+00,  2.3017e+00,  2.5686e+00,  2.5270e+00,\n",
              "                       2.3894e+00,  2.3542e+00,  2.2364e+00,  2.4514e+00,  2.2878e+00,\n",
              "                       2.7765e+00,  1.9440e+00,  2.6368e+00,  2.4122e+00,  2.2161e+00,\n",
              "                       2.0743e+00,  2.3886e+00,  2.1016e+00,  2.0860e+00,  2.2573e+00,\n",
              "                       2.2881e+00,  2.4089e+00,  2.2640e+00,  2.1506e+00,  2.1156e+00,\n",
              "                       2.1206e+00,  2.3130e+00,  2.7840e+00,  2.2126e-03,  2.3048e+00,\n",
              "                       2.3654e+00,  1.9880e+00,  1.8785e+00,  2.1953e+00,  2.1912e+00,\n",
              "                       2.2227e+00,  2.4348e+00,  2.3477e+00,  2.3189e+00,  2.8452e+00,\n",
              "                       2.4956e+00,  2.0218e+00,  2.4317e+00,  2.4009e+00,  1.5579e+00,\n",
              "                       2.2277e+00,  2.3017e+00,  2.1316e+00,  2.9115e+00,  2.9487e+00,\n",
              "                       2.0956e+00,  2.2209e+00,  2.8462e+00,  2.2606e+00,  2.2755e+00,\n",
              "                       2.4165e+00,  2.1237e+00,  1.9230e+00,  2.1728e+00,  2.6105e+00,\n",
              "                       2.2089e+00,  2.1601e+00,  2.1551e+00,  1.9490e+00,  2.3876e+00,\n",
              "                       2.3805e+00,  2.3219e+00,  2.4295e+00,  1.8878e+00,  2.7372e+00,\n",
              "                       2.2395e+00,  2.0950e+00,  2.1966e+00,  2.1345e+00,  1.8775e+00,\n",
              "                       1.6930e+00,  2.4470e+00,  1.7650e+00,  1.6211e+00,  2.2153e+00,\n",
              "                       2.8110e+00,  2.1136e+00,  2.2340e+00,  2.1478e+00,  2.3492e+00,\n",
              "                       2.2230e+00,  2.1987e+00,  2.0904e+00,  2.5775e+00,  1.8110e+00,\n",
              "                       2.4831e+00,  2.3797e+00,  2.4983e+00,  2.5187e+00,  2.5172e+00,\n",
              "                       2.1818e+00,  2.2601e+00,  1.3394e+00,  2.3116e+00,  2.5337e+00,\n",
              "                       2.1875e+00,  2.2127e+00,  1.9941e+00,  2.6562e+00,  2.1185e+00,\n",
              "                       2.0461e+00,  2.3424e+00,  2.2789e+00,  2.3920e+00,  2.0648e+00,\n",
              "                       2.4548e+00,  2.3921e+00,  2.3697e+00,  2.0445e+00,  2.3021e+00,\n",
              "                       2.3871e+00,  2.3254e+00,  2.1709e+00,  2.2596e+00,  2.4482e+00,\n",
              "                       1.8378e+00,  3.0463e+00,  2.1166e+00,  2.1850e+00,  2.4034e+00,\n",
              "                       2.4725e+00,  2.4368e+00,  2.0150e+00,  2.5033e+00,  8.2743e-01,\n",
              "                       2.5395e+00,  2.1336e+00,  2.0219e+00,  2.2866e+00,  2.2234e+00,\n",
              "                       2.3641e+00,  6.8224e-01,  2.2517e+00,  2.3905e+00,  2.3003e+00,\n",
              "                       2.0168e+00,  2.3384e+00,  2.0738e+00,  2.3583e+00,  2.2737e+00,\n",
              "                       2.1216e+00,  2.4819e+00,  2.4485e+00,  2.9164e+00,  2.7282e+00,\n",
              "                       3.7952e+00,  2.2402e+00,  2.1660e+00,  2.1032e+00,  2.3311e+00,\n",
              "                       2.2139e+00,  2.0529e+00,  2.6795e+00,  2.1542e+00,  2.1918e+00,\n",
              "                       2.2579e+00,  2.3880e+00,  2.5183e+00,  2.2746e+00,  2.1555e+00,\n",
              "                       1.8680e+00,  2.4011e+00,  2.7601e+00,  2.3120e+00,  2.0800e+00,\n",
              "                       2.3968e+00,  3.1438e+00,  2.4076e+00,  2.6278e+00,  2.2705e+00,\n",
              "                       2.2421e+00,  2.1568e+00,  2.1828e+00,  2.3916e+00,  2.4796e+00,\n",
              "                       2.2900e+00,  1.5618e+00,  2.4288e+00,  2.2310e+00,  2.8715e+00,\n",
              "                       2.3518e+00,  2.3594e+00,  2.6607e+00,  2.3115e+00,  2.3353e+00,\n",
              "                       4.7493e-01,  1.9368e+00,  2.3183e+00,  2.1456e+00,  2.2706e+00,\n",
              "                       2.3350e+00,  2.4636e+00,  2.5416e+00,  1.9432e+00,  2.8964e+00,\n",
              "                       2.1787e+00,  2.2150e+00,  2.2504e+00,  2.4846e+00,  2.3434e+00,\n",
              "                       2.3231e+00,  1.6432e+00,  2.3925e+00,  2.3659e+00,  2.6853e+00,\n",
              "                       2.2529e+00,  2.2051e+00,  3.6208e-01,  2.2561e+00,  2.4762e+00,\n",
              "                       2.2437e+00,  2.3388e+00,  2.4730e+00,  2.4416e+00,  2.1095e+00,\n",
              "                       1.9245e+00,  2.3134e+00,  2.2186e+00,  2.1328e+00,  1.5259e+00,\n",
              "                       2.4729e+00,  1.9862e+00,  2.3323e+00,  2.3636e+00,  2.2381e+00,\n",
              "                       2.1578e+00,  2.3052e+00,  2.5624e+00,  2.2227e+00,  1.8675e+00,\n",
              "                       2.0640e+00,  2.3906e+00,  2.1410e+00,  2.3587e+00,  2.3455e+00,\n",
              "                       2.2625e+00,  2.1603e+00,  2.2143e+00,  2.0285e+00,  2.2614e+00,\n",
              "                       2.4374e+00,  2.2603e+00,  2.1973e+00,  2.1507e+00,  3.5347e+00,\n",
              "                       2.3355e+00,  2.2711e+00,  2.0813e+00,  2.2698e+00,  2.2592e+00,\n",
              "                       2.0545e+00,  2.3680e+00,  2.9757e+00,  1.5851e+00,  2.4580e+00,\n",
              "                       2.1567e+00,  2.0545e+00,  1.9662e+00,  2.2052e+00,  2.3328e+00,\n",
              "                       2.3108e+00,  2.5076e+00,  4.9442e-01,  2.4418e+00,  2.5753e+00,\n",
              "                       2.4176e+00,  1.8818e+00,  2.6341e+00,  2.1609e+00,  2.1404e+00,\n",
              "                       2.1728e+00,  2.3656e+00,  2.0888e+00,  2.3146e+00,  2.5885e+00,\n",
              "                       2.4036e+00,  2.1691e+00,  2.0332e+00,  2.2200e+00,  2.2483e+00,\n",
              "                       2.4915e+00,  2.2792e+00,  1.9381e+00,  2.3515e+00,  1.9749e+00,\n",
              "                       2.1898e+00,  2.0197e+00,  2.6019e+00,  2.3090e+00,  2.3422e+00,\n",
              "                       2.3303e+00,  2.2114e+00,  2.5863e+00,  2.1177e+00,  2.2942e+00,\n",
              "                       2.2477e+00,  2.1461e+00,  2.2332e+00,  2.6272e+00,  2.2859e+00,\n",
              "                       2.3976e+00,  2.3803e+00,  2.1978e+00,  2.1943e+00,  2.7608e+00,\n",
              "                       2.1402e+00,  2.2406e+00,  2.4017e+00,  2.4712e+00,  2.2693e+00,\n",
              "                       2.2236e+00,  1.9065e+00,  2.2168e+00,  2.1358e+00,  2.2195e+00,\n",
              "                       2.1518e+00,  2.1323e+00,  2.2787e+00,  2.2817e+00,  2.3189e+00,\n",
              "                       2.2224e+00,  2.1896e+00,  2.3573e+00,  1.1550e+00,  2.2118e+00,\n",
              "                       9.1279e-01,  2.2559e+00,  2.3521e+00,  1.9435e+00,  2.4060e+00,\n",
              "                       2.1374e+00,  2.3968e+00,  2.3131e+00,  2.2764e+00,  3.5980e+00,\n",
              "                       2.2246e+00,  2.2171e+00,  2.3990e+00,  2.1921e+00,  2.1078e+00,\n",
              "                       2.1377e+00,  2.4032e+00,  2.1368e+00,  2.3297e+00,  2.1534e+00,\n",
              "                       2.2026e+00,  2.1610e+00,  1.7552e+00,  2.4011e+00,  2.2240e+00,\n",
              "                       2.1863e+00,  2.1603e+00,  2.2813e+00,  9.7045e-01,  2.2565e+00,\n",
              "                       2.3116e+00,  2.3003e+00,  2.2490e+00,  2.3719e+00,  2.1289e+00,\n",
              "                       2.4719e+00,  1.7894e+00,  1.0243e+00,  2.2991e+00,  2.2075e+00,\n",
              "                       2.4180e+00,  2.2065e+00,  2.2755e+00,  2.2588e+00,  2.3606e+00,\n",
              "                       2.4525e+00,  2.5081e+00,  2.3269e+00,  2.2167e+00,  2.3454e+00,\n",
              "                       2.3958e+00,  2.1905e+00,  1.1991e+00,  2.3862e+00,  2.2483e+00,\n",
              "                       2.1453e+00,  2.3163e+00,  2.2456e+00,  2.3200e+00,  2.3666e+00,\n",
              "                       3.1382e+00,  2.5211e+00,  2.3742e+00,  2.0862e+00,  5.2563e-01,\n",
              "                       2.4588e+00,  2.1488e+00,  7.9823e-01,  2.2713e+00,  2.3776e+00,\n",
              "                       2.3857e+00,  2.1012e+00,  2.3598e+00,  2.3114e+00,  2.3507e+00,\n",
              "                       2.6266e+00,  2.1458e+00,  2.2705e+00,  2.5129e+00,  2.4699e+00,\n",
              "                       2.2431e+00,  1.8015e+00,  2.2339e+00,  2.3396e+00,  2.2560e+00,\n",
              "                       2.1818e+00,  2.1566e+00,  2.3397e+00,  2.1556e+00,  2.3361e+00,\n",
              "                       2.1244e+00,  2.4463e+00,  2.3765e+00,  2.3660e+00,  1.8003e+00,\n",
              "                       2.4717e+00,  2.2209e+00,  2.0771e+00,  2.8927e+00,  2.3531e+00,\n",
              "                       2.2913e+00,  2.3701e+00,  2.2397e+00,  2.2293e+00,  2.3349e+00,\n",
              "                       1.9978e+00,  2.5753e+00,  1.7110e+00,  2.3355e+00,  2.2480e+00,\n",
              "                       1.8463e+00,  2.2500e+00,  2.2862e+00,  2.2770e+00,  2.0560e+00,\n",
              "                       2.3697e+00,  2.4669e+00,  2.2068e+00,  2.1945e+00,  2.2723e+00,\n",
              "                       2.1915e+00,  2.4174e+00,  2.1665e+00,  2.1553e+00,  2.2740e+00,\n",
              "                       2.3361e+00,  2.1891e+00,  2.2747e+00,  2.1200e+00,  2.1888e+00,\n",
              "                       2.1753e+00,  2.1664e+00,  2.1693e+00,  1.9765e+00,  2.2269e+00,\n",
              "                       2.1604e+00,  2.1674e+00,  2.5060e+00,  2.0138e+00,  2.4018e+00,\n",
              "                       2.1493e+00,  2.1558e+00,  8.9548e-01,  2.7390e+00,  2.3928e+00,\n",
              "                       2.1017e+00,  2.2608e+00,  2.2472e+00,  2.6040e+00,  2.2382e+00,\n",
              "                       2.1770e+00,  2.3333e+00,  2.2690e+00,  2.8597e+00,  3.0333e+00,\n",
              "                       2.0595e+00,  2.4085e+00,  2.3125e+00,  2.1316e+00, -3.9740e-02,\n",
              "                       1.8520e+00,  2.3848e+00,  2.5342e+00,  2.2694e+00,  2.2600e+00,\n",
              "                       2.2988e+00,  2.4808e+00,  2.4250e+00,  2.4629e+00,  2.1661e+00,\n",
              "                       2.3711e+00,  2.3928e+00,  2.3478e+00,  2.0429e+00,  2.2000e+00,\n",
              "                       2.4400e+00,  1.8418e+00,  2.2224e+00,  2.9556e+00,  2.3708e+00,\n",
              "                       1.9947e+00,  2.2767e+00,  2.2259e+00,  2.1400e+00,  2.3492e+00,\n",
              "                       2.2189e+00,  2.1913e+00,  1.4176e+00,  2.4642e+00,  2.3496e+00,\n",
              "                       2.2774e+00,  2.4772e+00,  2.3927e+00,  2.2045e+00,  2.1751e+00,\n",
              "                       2.4589e+00,  2.3525e+00,  1.1731e+00,  2.0643e+00,  2.2796e+00,\n",
              "                       2.2600e+00,  2.1296e+00,  2.2067e+00,  3.0070e+00,  2.5723e+00,\n",
              "                       2.2982e+00,  2.4893e+00,  2.1996e+00,  2.2649e+00,  2.1746e+00,\n",
              "                       1.9258e+00,  2.2501e+00,  1.9575e+00,  2.1499e+00,  2.1492e+00,\n",
              "                       2.1297e+00,  3.0812e+00,  2.3755e+00,  2.2094e+00,  2.2552e+00,\n",
              "                       2.2353e+00,  1.9260e+00,  2.3414e+00,  2.3001e+00,  1.9203e+00,\n",
              "                       2.5299e+00,  1.6674e+00,  2.2282e+00,  2.2427e+00,  2.3974e+00,\n",
              "                       1.5986e+00,  2.4835e+00,  2.1231e+00,  2.4953e+00,  2.3305e+00,\n",
              "                       2.6071e+00,  2.1863e+00,  2.7091e+00,  2.5422e+00,  2.6442e+00,\n",
              "                       2.2697e+00,  2.2814e+00,  1.9548e+00,  2.2527e+00,  2.1995e+00,\n",
              "                       2.1825e+00,  2.3188e+00,  2.4336e+00,  2.7040e+00,  2.3859e+00,\n",
              "                       2.1050e+00,  2.3236e+00,  2.4241e+00,  1.8678e+00,  2.2458e+00,\n",
              "                       2.3406e+00,  2.0182e+00,  2.1602e+00,  2.2191e+00,  2.4452e+00,\n",
              "                       2.2372e+00,  2.3448e+00,  2.3744e+00,  2.0337e+00,  2.2225e+00,\n",
              "                       2.2301e+00,  2.0364e+00,  2.1458e+00,  2.4709e+00,  2.1490e+00,\n",
              "                       2.3450e+00,  2.3018e+00,  2.0520e+00,  2.1037e+00,  2.3263e+00,\n",
              "                       2.1736e+00,  2.3628e+00,  2.1048e+00,  2.4295e+00,  2.3328e+00,\n",
              "                       2.1232e+00,  2.2724e+00,  2.1970e+00,  2.1707e+00,  1.9808e+00,\n",
              "                       2.3972e+00,  2.2514e+00,  2.7889e+00,  2.0422e+00,  2.2858e+00,\n",
              "                       2.1747e+00,  2.1682e+00,  2.0524e+00,  2.0846e+00,  2.1632e+00,\n",
              "                       1.6545e+00,  2.2848e+00,  1.9646e+00,  2.1441e+00,  2.5031e+00,\n",
              "                       2.2747e+00,  2.2248e+00,  2.0597e+00,  2.2128e+00,  2.2991e+00,\n",
              "                       1.6630e+00,  1.9813e+00,  2.1354e+00,  2.1400e+00,  2.3082e+00,\n",
              "                       2.1552e+00,  2.4948e+00,  2.2765e+00,  1.7761e+00,  1.9269e+00,\n",
              "                       2.2649e+00,  2.3117e+00,  2.1694e+00,  2.2790e+00,  2.1496e+00,\n",
              "                       2.1966e+00,  2.6244e+00,  2.4284e+00,  2.4091e+00,  2.4318e+00,\n",
              "                       2.0156e+00,  2.1086e+00,  2.0769e+00,  2.3710e+00,  2.7184e+00,\n",
              "                       2.6735e+00,  2.0941e+00,  2.3298e+00,  2.0880e+00,  2.3845e+00,\n",
              "                       2.1707e+00,  2.3152e+00,  2.1768e+00,  1.9623e+00,  2.3054e+00,\n",
              "                       1.9833e+00,  2.0651e+00,  2.3584e+00,  2.5408e+00,  2.0743e+00,\n",
              "                       2.2143e+00,  2.6690e+00,  2.6739e+00], device='cuda:0')),\n",
              "             ('decoder.block.5.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0227,  0.0529, -0.0246,  ...,  0.0388,  0.0258,  0.0236],\n",
              "                      [-0.0109,  0.0133, -0.0180,  ..., -0.0376, -0.0236, -0.0107],\n",
              "                      [ 0.0406, -0.0347, -0.0015,  ..., -0.0016, -0.0181,  0.0165],\n",
              "                      ...,\n",
              "                      [-0.0060, -0.0198,  0.0296,  ...,  0.0355, -0.0250, -0.0194],\n",
              "                      [-0.0011, -0.0547, -0.0064,  ...,  0.0200,  0.0517,  0.0095],\n",
              "                      [ 0.0493, -0.0117, -0.0261,  ..., -0.0090,  0.0078, -0.0622]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.0513, -0.2934, -0.0141,  ..., -0.0629, -0.2183, -0.3108],\n",
              "                      [ 0.1162, -0.1745, -0.1604,  ..., -0.1527, -0.2280,  0.4040],\n",
              "                      [ 0.3041,  0.5470, -0.2509,  ...,  0.1717, -0.3596, -0.1115],\n",
              "                      ...,\n",
              "                      [ 0.5025,  0.0615, -0.1916,  ..., -0.5391, -0.0298,  0.4398],\n",
              "                      [ 0.1450,  0.4529,  0.1076,  ..., -0.5029, -0.2077,  1.1406],\n",
              "                      [ 0.4218, -0.2570,  0.2260,  ...,  0.7732,  0.2495,  0.0409]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-1.5103,  0.3723, -0.5063,  ..., -0.0570, -0.3501,  0.1398],\n",
              "                      [-0.5778,  0.8243,  0.3121,  ...,  0.8592,  0.1166, -1.2710],\n",
              "                      [-0.2726, -0.0912, -0.6001,  ..., -0.5259, -0.8941, -0.3232],\n",
              "                      ...,\n",
              "                      [ 0.6888,  0.2716,  0.5074,  ..., -0.9455,  0.1931,  0.7646],\n",
              "                      [ 1.5696,  0.3548,  0.0991,  ..., -0.8087, -0.7697, -0.4741],\n",
              "                      [ 1.0438,  0.2166,  0.6731,  ..., -0.2151, -0.2888, -0.1816]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.8576,  0.8433, -0.7507,  ...,  0.1158,  0.3004,  0.5867],\n",
              "                      [-0.4515, -0.1460,  0.7017,  ..., -0.0328, -0.3130,  0.1994],\n",
              "                      [ 0.2164, -0.8844,  0.2896,  ...,  0.1844, -0.1231,  0.2703],\n",
              "                      ...,\n",
              "                      [-0.0048,  0.9925,  0.1659,  ..., -0.1761,  1.7894,  0.6199],\n",
              "                      [ 1.1459,  0.3701, -1.1424,  ...,  0.8256, -0.0574,  0.0228],\n",
              "                      [-1.2591, -0.7342, -1.3278,  ..., -0.1059, -0.4867,  0.4939]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.1914,  0.1104,  0.1214,  0.2336,  0.2098,  0.1533,  0.2131,  0.2438,\n",
              "                       0.1748,  0.2201, -0.1431,  0.2236,  0.1030,  0.1430,  0.1946,  0.2126,\n",
              "                       0.1912,  0.1682,  0.1670,  0.2241,  0.2099,  0.2125,  0.2065,  0.2298,\n",
              "                       0.2038,  0.1575,  0.1864,  0.1403,  0.2004,  0.2126,  0.2211,  0.1546,\n",
              "                       0.2197,  0.1932,  0.2083,  0.1688,  0.2236,  0.1869,  0.1948,  0.2226,\n",
              "                       0.2184,  0.1940,  0.2131,  0.2140,  0.1468,  0.1949,  0.2121,  0.2352,\n",
              "                       0.2496,  0.2425,  0.1876,  0.2073,  0.1905,  0.2284,  0.2750,  0.1632,\n",
              "                       0.1790,  0.2268,  0.2187,  0.2058,  0.1904,  0.2196,  0.1992,  0.2059,\n",
              "                       0.2034,  0.1440,  0.2011,  0.1925,  0.1228,  0.2163,  0.2294,  0.2173,\n",
              "                       0.2243,  0.2181,  0.1912,  0.1966,  0.1349,  0.2060,  0.2070,  0.1957,\n",
              "                       0.2131,  0.2089,  0.2267,  0.1627,  0.1954,  0.2206,  0.1116,  0.2361,\n",
              "                       0.2157,  0.2191,  0.1822,  0.2071,  0.2092,  0.1621,  0.2130,  0.2227,\n",
              "                       0.2129,  0.2124,  0.2138,  0.2160,  0.1903,  0.1713,  0.1096,  0.2015,\n",
              "                       0.1899,  0.1844,  0.1877,  0.1746,  0.1966,  0.2077,  0.2210,  0.2298,\n",
              "                       0.1966,  0.2061,  0.1789,  0.1868,  0.1998,  0.2012,  0.0302,  0.1947,\n",
              "                       0.1965,  0.1926,  0.1780,  0.1989,  0.2290,  0.1860,  0.2120,  0.1720,\n",
              "                       0.1909,  0.1304,  0.1291,  0.1988,  0.1960,  0.2429,  0.1205,  0.2051,\n",
              "                       0.2018,  0.1724,  0.1860,  0.1479,  0.1670,  0.2147,  0.2130,  0.2212,\n",
              "                       0.1940,  0.1595,  0.1856,  0.1683,  0.1944,  0.1881,  0.2235,  0.1903,\n",
              "                       0.2153,  0.1774,  0.2195,  0.2215,  0.2196,  0.2330, -0.0721,  0.1075,\n",
              "                       0.2073,  0.1712,  0.1841,  0.1759,  0.1768,  0.1290,  0.2142,  0.1567,\n",
              "                       0.1174,  0.2088, -0.1121,  0.2085,  0.2186,  0.2188,  0.2111,  0.2302,\n",
              "                       0.2028,  0.2322, -0.0963,  0.1679,  0.2271,  0.2083,  0.2382,  0.2311,\n",
              "                       0.1752,  0.1941,  0.2090,  0.0353,  0.2010,  0.1341,  0.2231,  0.2110,\n",
              "                       0.1838,  0.2514,  0.1960,  0.1868,  0.2058,  0.2351,  0.2213,  0.1981,\n",
              "                       0.2261,  0.1904,  0.2107,  0.1972,  0.2084,  0.1719,  0.2209,  0.1920,\n",
              "                       0.1946,  0.2516,  0.1911,  0.1565,  0.2171,  0.1770,  0.2300,  0.2146,\n",
              "                       0.1905,  0.1933,  0.2088,  0.0117,  0.1392,  0.1900,  0.1813,  0.1900,\n",
              "                       0.1835,  0.2221,  0.3899,  0.2353,  0.2219,  0.2241,  0.2045,  0.2182,\n",
              "                       0.1778,  0.2406,  0.2119,  0.1800,  0.1923,  0.1903,  0.1170,  0.2095,\n",
              "                       0.1741,  0.2122,  0.1972,  0.1903,  0.2293,  0.2119,  0.2088,  0.1813,\n",
              "                       0.2042,  0.2337,  0.1894,  0.1927,  0.2133,  0.2108,  0.1970,  0.1711,\n",
              "                       0.2316, -0.1272,  0.2109,  0.1944,  0.2564,  0.1271,  0.2267,  0.2290,\n",
              "                       0.2222,  0.1923,  0.2128,  0.2032,  0.2165,  0.2121,  0.2207,  0.1291,\n",
              "                       0.2326,  0.2032, -0.0867,  0.2177,  0.2027,  0.2023,  0.1873,  0.1724,\n",
              "                       0.0197,  0.1328,  0.2026,  0.1840,  0.2234,  0.2163,  0.2183,  0.2283,\n",
              "                       0.1439,  0.1407,  0.2004,  0.1923,  0.1941,  0.2184,  0.1939,  0.2144,\n",
              "                       0.1189,  0.2228,  0.2137,  0.2359,  0.2258,  0.1890,  0.0329,  0.2075,\n",
              "                       0.2075,  0.1889,  0.2011,  0.2081,  0.1799,  0.1975,  0.2140,  0.2134,\n",
              "                       0.2172,  0.2071,  0.2006,  0.1984,  0.2078,  0.2104,  0.2189,  0.2142,\n",
              "                       0.2222,  0.2079,  0.1657,  0.2165,  0.1948,  0.1910,  0.1970,  0.1914,\n",
              "                       0.2158,  0.2264,  0.2106,  0.1735,  0.2037,  0.1717,  0.2030,  0.1991,\n",
              "                       0.2166,  0.2137,  0.1794,  0.1685,  0.1861,  0.2054,  0.2166,  0.2051,\n",
              "                       0.2224,  0.1817,  0.2131,  0.1479,  0.1232,  0.1888,  0.2132,  0.1849,\n",
              "                       0.1521,  0.1969,  0.1947,  0.2255,  0.2252,  0.0393,  0.2202,  0.2248,\n",
              "                       0.2253,  0.1678,  0.1297,  0.1818,  0.2042,  0.2097,  0.2270,  0.1896,\n",
              "                       0.2034,  0.1990,  0.2305,  0.2266,  0.1942,  0.2067,  0.2301,  0.1878,\n",
              "                       0.2128,  0.2202,  0.2032,  0.1459,  0.1985,  0.1862, -0.1392,  0.1880,\n",
              "                       0.2156,  0.2355,  0.2128,  0.2166,  0.1805,  0.2172,  0.1920,  0.1993,\n",
              "                       0.1884,  0.2200,  0.1899,  0.2018,  0.2150,  0.1883,  0.2080,  0.2093,\n",
              "                       0.2146,  0.2172,  0.2031,  0.2088,  0.1860,  0.2146,  0.1468,  0.1964,\n",
              "                       0.1818,  0.2240,  0.1834,  0.1919,  0.2106,  0.1908,  0.2354,  0.2180,\n",
              "                       0.1942,  0.2190,  0.2375,  0.1996, -0.0107,  0.1920,  0.2187,  0.0657,\n",
              "                       0.2077,  0.2050,  0.1831,  0.2282,  0.1732,  0.1247,  0.2171,  0.1991,\n",
              "                       0.2257,  0.1602,  0.1889,  0.1898,  0.2040,  0.1959,  0.2156,  0.2023,\n",
              "                       0.2134,  0.1838,  0.1749,  0.2317,  0.2281,  0.2183,  0.1839,  0.2229,\n",
              "                      -0.0227,  0.1974,  0.2191,  0.2143,  0.2072,  0.2185,  0.1886,  0.1926,\n",
              "                       0.1955,  0.2741,  0.2036,  0.1995,  0.2313,  0.2214,  0.2019,  0.1955,\n",
              "                       0.2025,  0.2227,  0.1604,  0.1977,  0.1895,  0.2213,  0.2141,  0.2286,\n",
              "                       0.0946,  0.2204,  0.2173,  0.2014,  0.2189,  0.2108,  0.2021,  0.2093,\n",
              "                       0.1560,  0.2205,  0.2006,  0.1923,  0.0622,  0.2170,  0.2108,  0.0430,\n",
              "                       0.1956,  0.2227,  0.2188,  0.1967,  0.2235,  0.2074,  0.2090,  0.0809,\n",
              "                       0.1991,  0.2034,  0.2305,  0.2001,  0.1972,  0.1746,  0.1979,  0.2042,\n",
              "                       0.1940,  0.2027,  0.2132,  0.1864,  0.1939,  0.2072,  0.1808,  0.2173,\n",
              "                       0.2015,  0.1698,  0.1729,  0.2279,  0.1773,  0.1989,  0.1457,  0.2359,\n",
              "                       0.2158,  0.2092,  0.2045,  0.2141,  0.2001,  0.1937,  0.2276,  0.1315,\n",
              "                       0.1923,  0.1932,  0.1547,  0.2256,  0.2070,  0.2115,  0.2040,  0.2217,\n",
              "                       0.2224,  0.2074,  0.2272,  0.1778,  0.1951,  0.1970,  0.2089,  0.1969,\n",
              "                       0.1899,  0.2043,  0.2118,  0.2078,  0.1938,  0.2120,  0.1593,  0.1701,\n",
              "                       0.1970,  0.1367,  0.2242,  0.2034,  0.1750,  0.2137,  0.1725,  0.2180,\n",
              "                       0.1839,  0.1947,  0.1666,  0.3048,  0.2342,  0.1960,  0.2057,  0.2068,\n",
              "                       0.1950,  0.1951,  0.2040,  0.2153,  0.1936,  0.1755,  0.1268,  0.1870,\n",
              "                       0.2084,  0.2203,  0.1996,  0.0200,  0.1523,  0.2298,  0.2194,  0.2089,\n",
              "                       0.2010,  0.2000,  0.1940,  0.2081,  0.2211,  0.1913,  0.2414,  0.2251,\n",
              "                       0.2078,  0.1928,  0.1957,  0.2294,  0.1332,  0.2064,  0.2188,  0.1995,\n",
              "                       0.1749,  0.2054,  0.2158,  0.1857,  0.1998,  0.2024,  0.1958,  0.1274,\n",
              "                       0.2452,  0.2048,  0.2020,  0.2039,  0.2011,  0.2111,  0.1976,  0.2219,\n",
              "                       0.1977,  0.2063,  0.2009,  0.2109,  0.2034,  0.2012,  0.2060,  0.1279,\n",
              "                       0.1976,  0.2035,  0.1996,  0.2058,  0.2004,  0.2041,  0.1769,  0.2009,\n",
              "                       0.1757,  0.1967,  0.1964,  0.1996,  0.1683,  0.2017,  0.2265,  0.2040,\n",
              "                       0.1412,  0.1833,  0.2175,  0.1955,  0.1363,  0.1907,  0.1229,  0.2059,\n",
              "                       0.1994,  0.2386,  0.1250,  0.2274,  0.1854,  0.2228,  0.2237,  0.1188,\n",
              "                       0.2041,  0.1623,  0.2263,  0.2042,  0.2064,  0.1931,  0.2075,  0.2166,\n",
              "                       0.1951,  0.2058,  0.2237,  0.2200,  0.1986,  0.2219,  0.1982,  0.2060,\n",
              "                       0.1940,  0.1679,  0.2181,  0.2141,  0.1871,  0.2241,  0.2160,  0.2267,\n",
              "                       0.2117,  0.2223,  0.1682,  0.1754,  0.1877,  0.2020,  0.2077,  0.1873,\n",
              "                       0.2214,  0.1990,  0.2275,  0.1970,  0.1353,  0.1880,  0.2239,  0.2050,\n",
              "                       0.2270,  0.2098,  0.2213,  0.1961,  0.1848,  0.2009,  0.2068,  0.1000,\n",
              "                       0.1927,  0.1993,  0.2031,  0.1449,  0.1266,  0.2025,  0.1811,  0.1821,\n",
              "                       0.1796,  0.1873,  0.0877,  0.2163,  0.1988,  0.2025,  0.1990,  0.1779,\n",
              "                       0.2226,  0.1837,  0.1533,  0.2230,  0.2099,  0.1051,  0.1896,  0.1943,\n",
              "                       0.1844,  0.2234,  0.2258,  0.1975,  0.2172,  0.0576,  0.2090,  0.1953,\n",
              "                       0.2178,  0.2000,  0.2020,  0.1850,  0.1979,  0.1081,  0.2230,  0.1632,\n",
              "                       0.2245,  0.1946,  0.1473,  0.1841,  0.2100,  0.1160,  0.1801,  0.1861,\n",
              "                       0.1773,  0.2051,  0.2041,  0.2056,  0.2069,  0.2046,  0.1124,  0.2063,\n",
              "                       0.1716,  0.1623,  0.2092,  0.2062,  0.1966,  0.2052,  0.2484,  0.1896],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0052, -0.0365,  0.0353,  ..., -0.0184,  0.0046,  0.0009],\n",
              "                      [ 0.0207,  0.0375,  0.0239,  ...,  0.0096,  0.0447, -0.0234],\n",
              "                      [-0.0682,  0.0180,  0.0414,  ...,  0.0245,  0.0591, -0.0386],\n",
              "                      ...,\n",
              "                      [ 0.0426, -0.0436,  0.0505,  ...,  0.0501, -0.0162, -0.0219],\n",
              "                      [-0.0047, -0.0473, -0.0477,  ...,  0.0792, -0.0574,  0.0853],\n",
              "                      [ 0.0818,  0.0995, -0.0728,  ...,  0.0326,  0.0086,  0.0181]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[-0.4628, -0.3444, -0.0582,  ...,  0.1836,  0.1183,  0.1650],\n",
              "                      [-0.3804,  0.0884,  0.0061,  ..., -0.0430, -0.0834, -0.2799],\n",
              "                      [ 0.2296,  0.0268, -0.2065,  ..., -1.0055,  0.1433, -0.1395],\n",
              "                      ...,\n",
              "                      [-0.3977, -0.4439, -0.5971,  ...,  0.2573, -0.6565,  0.4844],\n",
              "                      [ 0.1486, -0.7684, -0.1448,  ..., -0.0427,  0.2042,  0.0644],\n",
              "                      [ 0.5596,  0.1896,  1.1174,  ..., -0.3316,  0.6554, -0.1407]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[-0.9302,  0.4903, -0.4879,  ..., -0.1698,  0.0102, -0.2811],\n",
              "                      [ 1.1940, -0.2959, -0.2826,  ...,  0.6531, -0.6268,  0.1249],\n",
              "                      [ 0.5693, -0.2844, -0.2358,  ..., -0.6743,  0.1803, -0.4301],\n",
              "                      ...,\n",
              "                      [ 0.0991, -0.1904,  0.4972,  ..., -0.3355,  0.1439, -0.1955],\n",
              "                      [ 0.2840,  0.1843, -0.6886,  ...,  0.0359, -0.0075, -0.5742],\n",
              "                      [-0.3431, -0.2088, -0.5488,  ...,  0.2017,  0.2089,  0.0164]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[ 0.1833, -0.0338,  0.3362,  ..., -0.4828, -0.1207,  0.1400],\n",
              "                      [-0.2054, -0.3246, -0.1275,  ..., -0.3738,  0.3670,  0.3742],\n",
              "                      [-0.0703, -0.3074,  0.3626,  ...,  0.4592, -0.5857, -0.3461],\n",
              "                      ...,\n",
              "                      [ 0.1899, -1.0109,  0.4406,  ...,  0.1478, -0.4051,  0.0313],\n",
              "                      [ 0.0917,  0.6977,  0.4055,  ..., -0.1167,  0.7110, -1.0967],\n",
              "                      [-0.0884,  0.2129, -0.1654,  ..., -0.1618,  0.6036,  0.1886]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.1.layer_norm.weight',\n",
              "              tensor([ 0.0551,  0.0399,  0.0440,  0.0682,  0.0514, -0.0567,  0.0763,  0.0706,\n",
              "                       0.0615,  0.0722,  0.0505,  0.0783,  0.0504,  0.0405,  0.0645,  0.0735,\n",
              "                       0.0618,  0.0517,  0.0493,  0.0702,  0.0510,  0.0715,  0.0603,  0.0751,\n",
              "                       0.0711,  0.0589,  0.0647,  0.0432,  0.0671,  0.0648,  0.0763,  0.0412,\n",
              "                       0.0697,  0.0625,  0.0674,  0.0496,  0.0823,  0.0838,  0.0521,  0.0774,\n",
              "                       0.0626,  0.0597,  0.0635,  0.0600,  0.0476,  0.0684,  0.0938,  0.0684,\n",
              "                       0.0763,  0.0571,  0.0650,  0.0561,  0.0641,  0.0742,  0.0965,  0.0531,\n",
              "                       0.0545,  0.0717,  0.0636,  0.0594,  0.0545,  0.0710,  0.0634,  0.0518,\n",
              "                       0.0681,  0.1022,  0.0687,  0.0480,  0.0361,  0.0599,  0.0686,  0.0711,\n",
              "                       0.0592,  0.0683,  0.0597,  0.0646,  0.0426,  0.0590,  0.0682,  0.0636,\n",
              "                       0.0711,  0.0618,  0.0632,  0.0743,  0.0708,  0.0630,  0.0345,  0.0692,\n",
              "                       0.0584,  0.0545,  0.0651,  0.0559,  0.0594,  0.0502,  0.0667,  0.0683,\n",
              "                       0.0721,  0.0736,  0.0667,  0.0641,  0.0602,  0.0564,  0.0317,  0.0657,\n",
              "                       0.0594,  0.0570,  0.0627,  0.0704,  0.0715,  0.0702,  0.0626,  0.0800,\n",
              "                       0.0566,  0.0531,  0.0617,  0.0709,  0.0499,  0.0565, -0.0024,  0.0651,\n",
              "                       0.0589,  0.0553,  0.0422,  0.0608,  0.0657,  0.0616,  0.0704,  0.0599,\n",
              "                       0.0530,  0.0428,  0.0341,  0.0633,  0.0652,  0.0688,  0.0517,  0.0615,\n",
              "                       0.0601,  0.0596,  0.0679,  0.0436,  0.0592,  0.0670,  0.0539,  0.0636,\n",
              "                       0.0587,  0.0562,  0.0602,  0.0445,  0.0687,  0.0560,  0.0761,  0.0502,\n",
              "                       0.0697,  0.0592,  0.0680,  0.0749,  0.0661,  0.0671,  0.1132,  0.0443,\n",
              "                       0.0719,  0.0518,  0.0565,  0.0502,  0.0664,  0.0306,  0.0723,  0.0468,\n",
              "                       0.0285,  0.0706, -0.0357,  0.0636,  0.0805,  0.0629,  0.0695,  0.0656,\n",
              "                       0.0514,  0.0650,  0.0349,  0.0614,  0.0722,  0.0684,  0.0808,  0.0687,\n",
              "                       0.0581,  0.0595,  0.0573,  0.0702,  0.0529,  0.0297,  0.0704,  0.0737,\n",
              "                       0.0737,  0.0581,  0.0521,  0.0652,  0.0534,  0.0731,  0.0670,  0.0509,\n",
              "                       0.0693,  0.0625,  0.0617,  0.0595,  0.0586,  0.0425,  0.0650,  0.0781,\n",
              "                       0.0528,  0.0801,  0.0813,  0.0482,  0.0729,  0.0665,  0.0745,  0.0652,\n",
              "                       0.0681,  0.0610,  0.0813, -0.0009,  0.0432,  0.0715,  0.0563,  0.0708,\n",
              "                       0.0429,  0.0720,  0.1222,  0.0849,  0.0586,  0.0652,  0.0524,  0.0647,\n",
              "                       0.0566,  0.0662,  0.0595,  0.0527,  0.0495,  0.0571,  0.0459,  0.0692,\n",
              "                       0.0644,  0.0608,  0.0541,  0.0565,  0.0719,  0.0582,  0.0662,  0.0707,\n",
              "                       0.0656,  0.0623,  0.0553,  0.0637,  0.0672,  0.0507,  0.0582,  0.0498,\n",
              "                       0.0619,  0.0400,  0.0720,  0.0702,  0.0772, -0.0474,  0.0789,  0.0558,\n",
              "                       0.0736,  0.0544,  0.0591,  0.0740,  0.0639,  0.0661,  0.0531,  0.0693,\n",
              "                       0.0625,  0.0597,  0.0211,  0.0634,  0.0562,  0.0570,  0.0702,  0.0486,\n",
              "                      -0.0007,  0.0333,  0.0748,  0.0628,  0.0760,  0.0704,  0.0650,  0.0644,\n",
              "                       0.0439,  0.0500,  0.0651,  0.0621,  0.0608,  0.0678,  0.0593,  0.0613,\n",
              "                       0.0372,  0.0677,  0.0667,  0.0799,  0.0694,  0.0584, -0.0107,  0.0507,\n",
              "                       0.0631,  0.0713,  0.0674,  0.0647,  0.0555,  0.0756,  0.0733,  0.0632,\n",
              "                       0.0561,  0.0771,  0.1121,  0.0639,  0.0696,  0.0596,  0.0756,  0.0761,\n",
              "                       0.0673,  0.0558,  0.0613,  0.0513,  0.0647,  0.0510,  0.0498,  0.0684,\n",
              "                       0.0815,  0.0717,  0.0571,  0.0434,  0.0626,  0.0628,  0.0519,  0.0636,\n",
              "                       0.0601,  0.0684,  0.0547,  0.0423,  0.0570,  0.0624,  0.0598,  0.0603,\n",
              "                       0.0723,  0.0465,  0.0702,  0.0440,  0.0362,  0.0556,  0.0652,  0.0616,\n",
              "                       0.0513,  0.0709,  0.0514,  0.0714,  0.0835,  0.0021,  0.0648,  0.0709,\n",
              "                       0.0690, -0.0482,  0.0568,  0.0567,  0.0650,  0.0816,  0.0614,  0.0568,\n",
              "                       0.0667,  0.0636,  0.0605,  0.0576,  0.0520,  0.0568,  0.0778,  0.0603,\n",
              "                       0.0688,  0.0671,  0.0671,  0.0498,  0.0438,  0.0618,  0.0466,  0.0720,\n",
              "                       0.0600,  0.0532,  0.0681,  0.0595,  0.0514,  0.0776,  0.0675,  0.0478,\n",
              "                       0.0577,  0.0602,  0.0494,  0.0654,  0.0733,  0.0654,  0.0672,  0.0634,\n",
              "                       0.0527,  0.0601,  0.0736,  0.0665,  0.0511,  0.0654,  0.0586,  0.0568,\n",
              "                       0.0517,  0.0533,  0.0621,  0.0738,  0.0487,  0.0636,  0.0757,  0.0643,\n",
              "                       0.0599,  0.0683,  0.1468,  0.0591, -0.0011,  0.0644,  0.0841,  0.0205,\n",
              "                       0.0675,  0.0614,  0.0478,  0.0651,  0.0581,  0.0443,  0.0699,  0.0651,\n",
              "                       0.0891,  0.0520,  0.0555,  0.0578,  0.0719,  0.0520,  0.0545,  0.0560,\n",
              "                       0.0717,  0.0550,  0.0459,  0.0686,  0.0798,  0.0647,  0.0588,  0.0587,\n",
              "                      -0.0005,  0.0664,  0.0745,  0.0686,  0.0678,  0.0563,  0.0547,  0.0525,\n",
              "                       0.0979,  0.0997,  0.0564,  0.0484,  0.0604,  0.0645,  0.0656,  0.0576,\n",
              "                       0.0591,  0.0583,  0.0387,  0.0663,  0.0615,  0.0624,  0.0693,  0.0638,\n",
              "                       0.0259,  0.0571,  0.0689,  0.0525,  0.0748,  0.0525,  0.0630,  0.0523,\n",
              "                       0.0473,  0.0605,  0.0726,  0.0503, -0.0003,  0.0633,  0.0673,  0.1063,\n",
              "                       0.0575,  0.0629,  0.0548,  0.0786,  0.0663,  0.0656,  0.0610,  0.0489,\n",
              "                       0.0534,  0.0590,  0.0789,  0.0552,  0.0616,  0.0943,  0.0593,  0.0552,\n",
              "                       0.0541,  0.0681,  0.0638,  0.0651,  0.0673,  0.0679,  0.0647,  0.0733,\n",
              "                       0.0659,  0.0588,  0.0486,  0.0684,  0.0582,  0.0701,  0.0411,  0.0725,\n",
              "                       0.0661,  0.0582,  0.0749,  0.0485,  0.0673,  0.0680,  0.0655,  0.0571,\n",
              "                       0.0525,  0.0557,  0.0397,  0.0603,  0.0566,  0.0730,  0.0648,  0.0745,\n",
              "                       0.0559,  0.0580,  0.0584,  0.0682,  0.0614,  0.0626,  0.0713,  0.0486,\n",
              "                       0.0409,  0.0650,  0.0668,  0.0604,  0.0534,  0.0691,  0.0607,  0.0559,\n",
              "                       0.0526,  0.0561,  0.0617,  0.0737,  0.0508,  0.0602,  0.0508,  0.0688,\n",
              "                       0.0576,  0.0685,  0.0324,  0.0927,  0.0616,  0.0569,  0.0642,  0.0615,\n",
              "                       0.0687,  0.0579,  0.0703,  0.0568,  0.0569,  0.0581,  0.0453,  0.0554,\n",
              "                       0.0694,  0.0627,  0.0598, -0.0004,  0.0584,  0.0705,  0.0568,  0.0460,\n",
              "                       0.0779,  0.0713,  0.0541,  0.0645,  0.0691,  0.0545,  0.0744,  0.0627,\n",
              "                       0.0663,  0.0647,  0.0602,  0.0738,  0.0415,  0.0590,  0.0614,  0.0520,\n",
              "                       0.0434,  0.0534,  0.0628,  0.0484,  0.0547,  0.0442,  0.0705, -0.0423,\n",
              "                       0.0676,  0.0680,  0.0625,  0.0498,  0.0684,  0.0608,  0.0598,  0.0762,\n",
              "                       0.0577,  0.1438,  0.0714,  0.0652,  0.0669,  0.0554,  0.0616,  0.0478,\n",
              "                       0.0667,  0.0546,  0.0639,  0.0571,  0.0794,  0.0466,  0.0640,  0.0595,\n",
              "                       0.0518,  0.0514,  0.0555,  0.0702,  0.0551,  0.0562,  0.0571,  0.0518,\n",
              "                       0.0543,  0.0626,  0.0690,  0.0598,  0.0328,  0.0522,  0.0357,  0.0622,\n",
              "                       0.0677,  0.0638,  0.0556,  0.0478,  0.0682,  0.0710,  0.0612,  0.0305,\n",
              "                       0.0477,  0.0686,  0.0757,  0.0669,  0.0606,  0.0509, -0.0552,  0.0751,\n",
              "                       0.0699,  0.0668,  0.0578,  0.0771,  0.0534,  0.0630,  0.0609,  0.0523,\n",
              "                       0.0459,  0.0417,  0.0787,  0.0595,  0.0642,  0.0567,  0.0466,  0.0551,\n",
              "                       0.0644,  0.0671,  0.0405,  0.0552,  0.0543,  0.0581,  0.0623,  0.0567,\n",
              "                       0.0585,  0.0621,  0.0659,  0.0593,  0.0415,  0.0571,  0.0672,  0.0606,\n",
              "                       0.0706,  0.0633,  0.0620,  0.0625,  0.0694,  0.0717,  0.0526,  0.0272,\n",
              "                       0.0680,  0.0614,  0.0573,  0.0464,  0.0555,  0.0559,  0.0595,  0.0556,\n",
              "                       0.0678,  0.0542,  0.0185,  0.0947,  0.0639,  0.0705,  0.0722,  0.0609,\n",
              "                       0.0707,  0.0710,  0.0588,  0.0686,  0.0708,  0.0449,  0.0536,  0.0675,\n",
              "                       0.0493,  0.0785,  0.0707,  0.0581,  0.0632,  0.0448,  0.0725,  0.0667,\n",
              "                       0.0768,  0.0580,  0.0638,  0.0379,  0.0674,  0.0525,  0.0657,  0.0562,\n",
              "                       0.0616,  0.0513,  0.0514,  0.0629,  0.0626,  0.0387,  0.0623,  0.0626,\n",
              "                       0.0519,  0.0587,  0.0674,  0.0690,  0.0601,  0.0574,  0.0454,  0.0672,\n",
              "                       0.0623,  0.0459,  0.0467,  0.0555,  0.0636,  0.0646,  0.0648,  0.0488],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.2822,  0.0365, -0.4653,  ..., -0.8350, -1.1864, -0.6955],\n",
              "                      [ 0.4422,  0.7979, -0.5437,  ..., -0.8100, -0.3762, -0.1050],\n",
              "                      [ 0.8654,  0.3481, -0.3040,  ..., -0.0259,  0.1943,  0.5670],\n",
              "                      ...,\n",
              "                      [ 0.1963,  0.0981, -0.5158,  ..., -0.2469,  0.3575,  0.1778],\n",
              "                      [-0.1552,  0.5887, -0.2626,  ..., -1.1730,  0.0483,  0.7906],\n",
              "                      [ 0.6695,  0.9416,  0.8053,  ..., -1.0566, -0.2771,  0.3974]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.0209,  0.2537,  0.0884,  ...,  0.2716, -0.3047,  0.2434],\n",
              "                      [-0.4613, -0.4732, -0.2097,  ..., -0.1059,  0.3079,  0.4985],\n",
              "                      [-0.2901,  0.0569,  0.0096,  ...,  0.2242,  0.1536,  0.2489],\n",
              "                      ...,\n",
              "                      [ 0.2619,  0.1406, -0.3092,  ..., -0.0122,  0.2468, -0.1442],\n",
              "                      [ 0.2177,  0.2167, -0.4545,  ...,  0.2668, -0.0439, -0.3388],\n",
              "                      [ 0.7230,  0.3787, -0.0575,  ..., -0.0048,  0.1899, -0.1683]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.5.layer.2.layer_norm.weight',\n",
              "              tensor([ 2.5503e+00,  2.0221e+00,  1.9380e+00,  2.3523e+00,  2.6152e+00,\n",
              "                       2.6625e+00,  2.1906e+00,  2.8459e+00,  2.0498e+00,  2.4931e+00,\n",
              "                       3.7262e+00,  2.7130e+00,  2.3602e+00,  3.1233e+00,  2.4245e+00,\n",
              "                       2.6636e+00,  2.4870e+00,  2.0176e+00,  2.5525e+00,  2.6332e+00,\n",
              "                       2.5720e+00,  2.7853e+00,  2.4480e+00,  2.5511e+00,  2.6190e+00,\n",
              "                       2.2254e+00,  2.5863e+00,  2.6865e+00,  2.6200e+00,  2.7148e+00,\n",
              "                       2.7032e+00,  2.1737e+00,  2.7658e+00,  2.4482e+00,  2.8007e+00,\n",
              "                       2.2792e+00,  2.5920e+00,  1.7953e+00,  2.3820e+00,  2.7036e+00,\n",
              "                       2.3596e+00,  2.4124e+00,  2.4683e+00,  2.6943e+00,  1.9749e+00,\n",
              "                       2.4868e+00,  2.4705e+00,  2.6263e+00,  2.5764e+00,  2.7924e+00,\n",
              "                       2.3291e+00,  2.4590e+00,  2.5858e+00,  2.5800e+00,  3.1264e+00,\n",
              "                       2.6316e+00,  2.5459e+00,  2.6018e+00,  2.5818e+00,  2.7148e+00,\n",
              "                       2.4503e+00,  2.6257e+00,  2.5216e+00,  2.5465e+00,  2.6084e+00,\n",
              "                       1.3803e+00,  2.5580e+00,  2.6441e+00,  2.4359e+00,  2.5395e+00,\n",
              "                       2.4814e+00,  2.5229e+00,  2.4224e+00,  2.4125e+00,  2.7362e+00,\n",
              "                       2.4365e+00,  2.7342e+00,  2.6177e+00,  2.5912e+00,  2.4929e+00,\n",
              "                       2.5632e+00,  2.4610e+00,  2.5987e+00,  2.1785e+00,  2.4495e+00,\n",
              "                       2.5475e+00,  2.3162e+00,  2.6694e+00,  2.6207e+00,  2.6767e+00,\n",
              "                       2.2894e+00,  2.4957e+00,  2.5534e+00,  2.7755e+00,  2.7643e+00,\n",
              "                       2.6102e+00,  2.6299e+00,  2.5200e+00,  2.6243e+00,  2.4774e+00,\n",
              "                       2.9065e+00,  2.1844e+00,  2.8354e+00,  2.6466e+00,  2.4032e+00,\n",
              "                       2.4164e+00,  2.5762e+00,  2.4267e+00,  2.3677e+00,  2.5996e+00,\n",
              "                       2.5574e+00,  2.6879e+00,  2.5790e+00,  2.3637e+00,  2.3959e+00,\n",
              "                       2.3513e+00,  2.5253e+00,  2.9672e+00,  4.0613e-02,  2.4430e+00,\n",
              "                       2.6083e+00,  2.1958e+00,  2.2497e+00,  2.4405e+00,  2.5210e+00,\n",
              "                       2.3578e+00,  2.5799e+00,  2.5218e+00,  2.6395e+00,  3.0309e+00,\n",
              "                       2.7308e+00,  2.3168e+00,  2.6746e+00,  2.5624e+00,  1.7089e+00,\n",
              "                       2.4808e+00,  2.4316e+00,  2.3279e+00,  2.8693e+00,  2.9040e+00,\n",
              "                       2.4628e+00,  2.4320e+00,  2.9690e+00,  2.5864e+00,  2.4255e+00,\n",
              "                       2.6200e+00,  2.3033e+00,  2.1205e+00,  2.5037e+00,  2.7872e+00,\n",
              "                       2.4087e+00,  2.3355e+00,  2.3333e+00,  2.1931e+00,  2.6013e+00,\n",
              "                       2.6003e+00,  2.5465e+00,  2.6718e+00,  2.0007e+00,  2.7689e+00,\n",
              "                       2.4713e+00,  2.3374e+00,  2.3686e+00,  2.5208e+00,  2.1439e+00,\n",
              "                       2.0889e+00,  2.6368e+00,  2.2133e+00,  2.0828e+00,  2.4640e+00,\n",
              "                       3.0636e+00,  2.3497e+00,  2.4786e+00,  2.4123e+00,  2.5338e+00,\n",
              "                       2.4347e+00,  2.4669e+00,  2.3377e+00,  2.6417e+00,  2.1738e+00,\n",
              "                       2.6790e+00,  2.6076e+00,  2.6859e+00,  2.6772e+00,  2.7555e+00,\n",
              "                       2.4356e+00,  2.5120e+00,  1.4339e+00,  2.5269e+00,  2.5315e+00,\n",
              "                       2.4129e+00,  2.4183e+00,  2.3306e+00,  2.8871e+00,  2.3683e+00,\n",
              "                       2.2806e+00,  2.5143e+00,  2.4743e+00,  2.6422e+00,  2.3265e+00,\n",
              "                       2.6563e+00,  2.5997e+00,  2.6193e+00,  2.2973e+00,  2.5025e+00,\n",
              "                       2.5250e+00,  2.4876e+00,  2.4608e+00,  2.3943e+00,  2.6616e+00,\n",
              "                       2.1533e+00,  2.9777e+00,  2.4201e+00,  2.4936e+00,  2.6389e+00,\n",
              "                       2.6789e+00,  2.7331e+00,  2.2110e+00,  2.6948e+00,  7.8978e-01,\n",
              "                       2.7790e+00,  2.2715e+00,  2.3653e+00,  2.5047e+00,  2.4976e+00,\n",
              "                       2.5846e+00,  1.2687e+00,  2.4674e+00,  2.5408e+00,  2.5706e+00,\n",
              "                       2.3538e+00,  2.6886e+00,  2.3896e+00,  2.7522e+00,  2.4549e+00,\n",
              "                       2.3804e+00,  2.7461e+00,  2.6468e+00,  3.0640e+00,  2.8173e+00,\n",
              "                       3.8460e+00,  2.5887e+00,  2.4553e+00,  2.4345e+00,  2.6107e+00,\n",
              "                       2.4271e+00,  2.3120e+00,  2.7177e+00,  2.3689e+00,  2.5205e+00,\n",
              "                       2.4251e+00,  2.6278e+00,  2.6322e+00,  2.5612e+00,  2.4403e+00,\n",
              "                       2.1059e+00,  2.4903e+00,  3.0366e+00,  2.4312e+00,  2.4072e+00,\n",
              "                       2.6479e+00,  3.2329e+00,  2.5955e+00,  2.8550e+00,  2.4222e+00,\n",
              "                       2.5610e+00,  2.3734e+00,  2.3123e+00,  2.5969e+00,  2.6937e+00,\n",
              "                       2.4714e+00,  1.9883e+00,  2.6446e+00,  2.3026e+00,  2.8310e+00,\n",
              "                       2.6498e+00,  2.7015e+00,  2.7931e+00,  2.5772e+00,  2.5729e+00,\n",
              "                       7.2443e-01,  2.2771e+00,  2.5264e+00,  2.3598e+00,  2.5368e+00,\n",
              "                       2.4729e+00,  2.5694e+00,  2.7981e+00,  2.2767e+00,  3.0495e+00,\n",
              "                       2.4318e+00,  2.4436e+00,  2.4019e+00,  2.6380e+00,  2.4360e+00,\n",
              "                       2.5697e+00,  1.9844e+00,  2.5656e+00,  2.6084e+00,  2.8545e+00,\n",
              "                       2.5246e+00,  2.5227e+00,  5.8938e-01,  2.4691e+00,  2.6794e+00,\n",
              "                       2.5952e+00,  2.5942e+00,  2.6086e+00,  2.7075e+00,  2.3187e+00,\n",
              "                       2.1947e+00,  2.5037e+00,  2.4777e+00,  2.3480e+00,  1.7821e+00,\n",
              "                       2.7164e+00,  2.2771e+00,  2.7099e+00,  2.4975e+00,  2.4373e+00,\n",
              "                       2.5452e+00,  2.5805e+00,  2.7092e+00,  2.4203e+00,  2.0861e+00,\n",
              "                       2.2997e+00,  2.5613e+00,  2.4373e+00,  2.4956e+00,  2.4688e+00,\n",
              "                       2.5337e+00,  2.4137e+00,  2.4214e+00,  2.3766e+00,  2.4708e+00,\n",
              "                       2.7964e+00,  2.5156e+00,  2.4016e+00,  2.2943e+00,  3.3052e+00,\n",
              "                       2.6562e+00,  2.4281e+00,  2.3204e+00,  2.5610e+00,  2.4805e+00,\n",
              "                       2.2332e+00,  2.5340e+00,  3.1715e+00,  1.8863e+00,  2.7882e+00,\n",
              "                       2.2718e+00,  2.2392e+00,  2.1805e+00,  2.3194e+00,  2.5947e+00,\n",
              "                       2.5354e+00,  2.8032e+00,  8.8888e-03,  2.6661e+00,  2.7567e+00,\n",
              "                       2.5772e+00,  2.1554e+00,  2.9125e+00,  2.4356e+00,  2.4659e+00,\n",
              "                       2.3971e+00,  2.6691e+00,  2.4169e+00,  2.5004e+00,  2.7836e+00,\n",
              "                       2.6506e+00,  2.3653e+00,  2.3153e+00,  2.4289e+00,  2.6351e+00,\n",
              "                       2.7003e+00,  2.5200e+00,  2.2236e+00,  2.5667e+00,  2.2669e+00,\n",
              "                       2.4229e+00,  2.2772e+00,  2.7335e+00,  2.4613e+00,  2.7021e+00,\n",
              "                       2.6014e+00,  2.4892e+00,  2.6585e+00,  2.3920e+00,  2.5449e+00,\n",
              "                       2.4227e+00,  2.3730e+00,  2.4611e+00,  2.6795e+00,  2.5289e+00,\n",
              "                       2.4639e+00,  2.6372e+00,  2.5027e+00,  2.4103e+00,  2.9338e+00,\n",
              "                       2.4161e+00,  2.6030e+00,  2.6367e+00,  2.5845e+00,  2.4327e+00,\n",
              "                       2.4643e+00,  2.2501e+00,  2.4477e+00,  2.4267e+00,  2.5077e+00,\n",
              "                       2.4047e+00,  2.3261e+00,  2.5043e+00,  2.5488e+00,  2.5625e+00,\n",
              "                       2.4520e+00,  2.4036e+00,  2.4743e+00,  1.4611e+00,  2.3484e+00,\n",
              "                       8.2348e-01,  2.5570e+00,  2.5936e+00,  1.8197e+00,  2.6856e+00,\n",
              "                       2.4454e+00,  2.7253e+00,  2.5972e+00,  2.6081e+00,  3.3826e+00,\n",
              "                       2.4031e+00,  2.4411e+00,  2.6886e+00,  2.3460e+00,  2.3106e+00,\n",
              "                       2.3611e+00,  2.5748e+00,  2.3634e+00,  2.5558e+00,  2.4147e+00,\n",
              "                       2.3843e+00,  2.4262e+00,  2.0267e+00,  2.5903e+00,  2.5092e+00,\n",
              "                       2.3942e+00,  2.4176e+00,  2.5485e+00,  9.4561e-01,  2.3443e+00,\n",
              "                       2.5007e+00,  2.5568e+00,  2.4994e+00,  2.5855e+00,  2.3789e+00,\n",
              "                       2.6722e+00,  2.0627e+00,  1.3712e+00,  2.5250e+00,  2.4028e+00,\n",
              "                       2.7012e+00,  2.4709e+00,  2.5845e+00,  2.4311e+00,  2.4909e+00,\n",
              "                       2.7191e+00,  2.5703e+00,  2.4870e+00,  2.4047e+00,  2.5732e+00,\n",
              "                       2.5677e+00,  2.4144e+00,  1.4350e+00,  2.7060e+00,  2.4918e+00,\n",
              "                       2.4488e+00,  2.6032e+00,  2.4502e+00,  2.5644e+00,  2.5797e+00,\n",
              "                       3.1669e+00,  2.7521e+00,  2.5467e+00,  2.2852e+00,  5.2614e-01,\n",
              "                       2.6314e+00,  2.4202e+00, -5.5158e-01,  2.5100e+00,  2.6558e+00,\n",
              "                       2.5755e+00,  2.3392e+00,  2.5291e+00,  2.4733e+00,  2.6231e+00,\n",
              "                       3.1675e+00,  2.4827e+00,  2.5126e+00,  2.7034e+00,  2.6600e+00,\n",
              "                       2.4837e+00,  2.0913e+00,  2.4721e+00,  2.5444e+00,  2.4607e+00,\n",
              "                       2.5301e+00,  2.4705e+00,  2.6477e+00,  2.3795e+00,  2.6602e+00,\n",
              "                       2.3405e+00,  2.6315e+00,  2.6283e+00,  2.4280e+00,  2.0868e+00,\n",
              "                       2.5703e+00,  2.4836e+00,  2.2810e+00,  2.9818e+00,  2.6291e+00,\n",
              "                       2.5594e+00,  2.5778e+00,  2.4959e+00,  2.4701e+00,  2.5409e+00,\n",
              "                       2.2816e+00,  2.8808e+00,  2.0799e+00,  2.5005e+00,  2.3564e+00,\n",
              "                       2.1348e+00,  2.3656e+00,  2.4433e+00,  2.4477e+00,  2.2893e+00,\n",
              "                       2.5667e+00,  2.7265e+00,  2.4288e+00,  2.5702e+00,  2.5868e+00,\n",
              "                       2.3172e+00,  2.6170e+00,  2.4859e+00,  2.4924e+00,  2.5007e+00,\n",
              "                       2.5810e+00,  2.4274e+00,  2.4910e+00,  2.3749e+00,  2.4579e+00,\n",
              "                       2.3175e+00,  2.5444e+00,  2.4372e+00,  2.1943e+00,  2.4592e+00,\n",
              "                       2.4882e+00,  2.3902e+00,  2.7160e+00,  2.2437e+00,  2.5072e+00,\n",
              "                       2.4140e+00,  2.4242e+00,  1.1184e+00,  3.0542e+00,  2.6354e+00,\n",
              "                       2.4176e+00,  2.4733e+00,  2.4093e+00,  2.6131e+00,  2.3705e+00,\n",
              "                       2.4514e+00,  2.5131e+00,  2.5210e+00,  2.8552e+00,  3.0990e+00,\n",
              "                       2.2998e+00,  2.5892e+00,  2.4769e+00,  2.4660e+00, -2.7457e-03,\n",
              "                       2.1098e+00,  2.6399e+00,  2.7157e+00,  2.5344e+00,  2.5710e+00,\n",
              "                       2.4597e+00,  2.5878e+00,  2.5564e+00,  2.6207e+00,  2.4803e+00,\n",
              "                       2.4796e+00,  2.6996e+00,  2.5403e+00,  2.3804e+00,  2.2973e+00,\n",
              "                       2.6315e+00,  2.2108e+00,  2.5129e+00,  3.3412e+00,  2.6145e+00,\n",
              "                       2.1769e+00,  2.4935e+00,  2.4554e+00,  2.4362e+00,  2.5284e+00,\n",
              "                       2.6267e+00,  2.2679e+00,  1.8210e+00,  2.7349e+00,  2.5289e+00,\n",
              "                       2.4848e+00,  2.6155e+00,  2.4810e+00,  2.4131e+00,  2.5916e+00,\n",
              "                       2.6981e+00,  2.5474e+00,  1.2614e+00,  2.2998e+00,  2.6257e+00,\n",
              "                       2.4032e+00,  2.4162e+00,  2.4777e+00,  3.2060e+00,  2.6066e+00,\n",
              "                       2.6284e+00,  2.7626e+00,  2.4654e+00,  2.5196e+00,  2.4045e+00,\n",
              "                       2.1082e+00,  2.5113e+00,  2.2398e+00,  2.5555e+00,  2.4382e+00,\n",
              "                       2.4234e+00,  3.0443e+00,  2.6086e+00,  2.4806e+00,  2.4990e+00,\n",
              "                       2.3270e+00,  2.1839e+00,  2.5284e+00,  2.4787e+00,  2.0670e+00,\n",
              "                       2.7443e+00,  2.0903e+00,  2.4467e+00,  2.4898e+00,  2.5907e+00,\n",
              "                       1.9182e+00,  2.8059e+00,  2.4193e+00,  2.7815e+00,  2.4630e+00,\n",
              "                       2.6584e+00,  2.3825e+00,  2.7681e+00,  2.6654e+00,  2.9857e+00,\n",
              "                       2.4983e+00,  2.4386e+00,  2.1155e+00,  2.5280e+00,  2.5102e+00,\n",
              "                       2.4684e+00,  2.4994e+00,  2.6700e+00,  2.9019e+00,  2.6338e+00,\n",
              "                       2.2853e+00,  2.6359e+00,  2.7259e+00,  2.0940e+00,  2.5197e+00,\n",
              "                       2.5966e+00,  2.2854e+00,  2.4820e+00,  2.4941e+00,  2.6764e+00,\n",
              "                       2.5247e+00,  2.5056e+00,  2.5647e+00,  2.2814e+00,  2.4087e+00,\n",
              "                       2.4785e+00,  2.3335e+00,  2.3316e+00,  2.5876e+00,  2.4088e+00,\n",
              "                       2.6366e+00,  2.5902e+00,  2.2150e+00,  2.3898e+00,  2.5747e+00,\n",
              "                       2.3517e+00,  2.5367e+00,  2.3416e+00,  2.7082e+00,  2.5156e+00,\n",
              "                       2.2756e+00,  2.3749e+00,  2.2989e+00,  2.3345e+00,  2.3302e+00,\n",
              "                       2.6505e+00,  2.5342e+00,  2.7669e+00,  2.3127e+00,  2.5047e+00,\n",
              "                       2.3884e+00,  2.4071e+00,  2.3948e+00,  2.4362e+00,  2.2244e+00,\n",
              "                       1.9340e+00,  2.4000e+00,  2.3036e+00,  2.3853e+00,  2.7383e+00,\n",
              "                       2.3912e+00,  2.5202e+00,  2.5178e+00,  2.4399e+00,  2.5146e+00,\n",
              "                       1.9943e+00,  2.3256e+00,  2.3877e+00,  2.4077e+00,  2.5937e+00,\n",
              "                       2.4805e+00,  2.6913e+00,  2.5238e+00,  2.0408e+00,  2.1981e+00,\n",
              "                       2.4852e+00,  2.5240e+00,  2.4376e+00,  2.3937e+00,  2.5189e+00,\n",
              "                       2.5003e+00,  2.7420e+00,  2.5156e+00,  2.7202e+00,  2.5933e+00,\n",
              "                       2.2744e+00,  2.3059e+00,  2.3067e+00,  2.5827e+00,  2.7912e+00,\n",
              "                       2.8774e+00,  2.3382e+00,  2.5382e+00,  2.3347e+00,  2.5811e+00,\n",
              "                       2.4354e+00,  2.4516e+00,  2.3902e+00,  2.2167e+00,  2.5313e+00,\n",
              "                       2.2429e+00,  2.2773e+00,  2.5931e+00,  2.6696e+00,  2.3444e+00,\n",
              "                       2.2960e+00,  2.8885e+00,  2.9064e+00], device='cuda:0')),\n",
              "             ('decoder.block.6.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0110, -0.0502,  0.0128,  ...,  0.0294,  0.0505,  0.0117],\n",
              "                      [-0.0310,  0.0066, -0.0250,  ..., -0.0522,  0.0285, -0.0113],\n",
              "                      [ 0.0105,  0.0159, -0.0555,  ...,  0.0290, -0.0307,  0.0124],\n",
              "                      ...,\n",
              "                      [ 0.0097,  0.0104, -0.0028,  ..., -0.0023, -0.0121,  0.0143],\n",
              "                      [ 0.0172, -0.0493, -0.0142,  ...,  0.0340,  0.0058, -0.0223],\n",
              "                      [ 0.0106,  0.0112, -0.0076,  ...,  0.0293,  0.0337, -0.0019]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.3486, -0.1759, -0.0868,  ...,  0.3085, -0.2831, -0.1161],\n",
              "                      [-0.0139,  0.1174,  0.1126,  ..., -0.1979, -0.3031,  0.2157],\n",
              "                      [-0.2303, -0.0947,  0.3305,  ...,  0.2439, -0.2297, -0.4252],\n",
              "                      ...,\n",
              "                      [ 0.1723, -0.6232,  0.4914,  ..., -0.2212, -0.3404,  0.1077],\n",
              "                      [ 0.2116,  0.3133, -0.0024,  ..., -0.2608, -0.3007, -0.1554],\n",
              "                      [-0.6588,  0.0261,  0.2643,  ...,  0.0478, -0.6317,  0.3997]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-0.7663, -0.3805,  0.5594,  ..., -0.7331, -1.0454, -0.2729],\n",
              "                      [ 0.1566, -0.5495, -0.8903,  ..., -0.5720,  0.0310, -0.8828],\n",
              "                      [-0.2058, -0.5689,  1.0030,  ..., -0.1151, -0.1662, -0.3054],\n",
              "                      ...,\n",
              "                      [-0.6233, -0.0967,  0.3747,  ...,  0.1878,  0.0739,  0.9100],\n",
              "                      [-0.3855, -0.8065,  0.1871,  ..., -0.3382, -1.2958,  0.7621],\n",
              "                      [-0.2928,  0.7158, -0.1692,  ...,  0.8152,  1.4893, -0.0803]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.4458,  0.6951,  0.7096,  ..., -0.2500,  0.2881,  0.3202],\n",
              "                      [-0.4555, -0.0180,  0.4379,  ...,  0.4295,  0.0925,  0.4018],\n",
              "                      [ 1.5140, -0.9625,  1.1375,  ..., -0.0650, -0.7450, -0.5435],\n",
              "                      ...,\n",
              "                      [-0.1488,  0.4739, -1.3328,  ...,  1.4345, -0.4996, -0.6518],\n",
              "                      [ 0.0315, -0.7450,  1.7092,  ..., -0.5031,  0.4459, -1.1120],\n",
              "                      [ 0.9067,  0.3061, -1.3128,  ..., -0.2131, -0.7783,  1.2704]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2212,  0.1251,  0.1508,  0.2197,  0.2146,  0.1971,  0.2192,  0.2437,\n",
              "                       0.1875,  0.2441,  0.1842,  0.2380,  0.1247,  0.1546,  0.2329,  0.2424,\n",
              "                       0.2154,  0.2136,  0.1999,  0.2390,  0.2254,  0.2311,  0.2202,  0.2415,\n",
              "                       0.2473,  0.1996,  0.2277,  0.1608,  0.2171,  0.2317,  0.2382,  0.2018,\n",
              "                       0.2550,  0.2264,  0.2401,  0.1979,  0.2610,  0.1856,  0.2231,  0.2574,\n",
              "                       0.2258,  0.2028,  0.2271,  0.2289,  0.1820,  0.2388,  0.2529,  0.2426,\n",
              "                       0.2419,  0.2630,  0.2174,  0.2435,  0.2183,  0.2444,  0.2844,  0.1941,\n",
              "                       0.2113,  0.2509,  0.2328,  0.2354,  0.1989,  0.2394,  0.2208,  0.2387,\n",
              "                       0.2294,  0.1830,  0.2314,  0.2329,  0.1648,  0.2281,  0.2555,  0.2409,\n",
              "                       0.2436,  0.2239,  0.2329,  0.2254, -0.1492,  0.2023,  0.2461,  0.2339,\n",
              "                       0.2515,  0.2252,  0.2354,  0.1596,  0.2233,  0.2421,  0.1014,  0.2444,\n",
              "                       0.2408,  0.2372,  0.2128,  0.2195,  0.2147,  0.1935,  0.2615,  0.2507,\n",
              "                       0.2268,  0.2368,  0.2652,  0.2317,  0.1904,  0.1962,  0.1349,  0.2269,\n",
              "                       0.2151,  0.1911,  0.2232,  0.2140,  0.2278,  0.2473,  0.2378,  0.2534,\n",
              "                       0.2095,  0.2295,  0.2154,  0.2210,  0.2237,  0.2159,  0.0324,  0.2502,\n",
              "                       0.2451,  0.2142,  0.1920,  0.2221,  0.2258,  0.2140,  0.2348,  0.2073,\n",
              "                       0.1986,  0.1471,  0.1528,  0.2172,  0.2263,  0.2406,  0.1233,  0.2401,\n",
              "                       0.2236,  0.2095,  0.2109,  0.1642,  0.1929,  0.2103,  0.2231,  0.2478,\n",
              "                       0.2022,  0.1911,  0.2229,  0.1850,  0.2345,  0.1913,  0.2539,  0.2237,\n",
              "                       0.2393,  0.1987,  0.2436,  0.2525,  0.2340,  0.2582,  0.0644, -0.1338,\n",
              "                       0.2178,  0.1731,  0.1985,  0.2157,  0.2171,  0.1345,  0.2362,  0.1680,\n",
              "                       0.1436,  0.2478,  0.1243,  0.2166,  0.2521,  0.2426,  0.2537,  0.2329,\n",
              "                       0.2170,  0.2148,  0.1030,  0.1927,  0.2595,  0.2247,  0.2688,  0.2534,\n",
              "                       0.1810,  0.2225,  0.2272,  0.0496,  0.2233,  0.1699,  0.2383,  0.2262,\n",
              "                       0.2215,  0.2681,  0.2198,  0.2083,  0.2451,  0.2532,  0.2402,  0.2049,\n",
              "                       0.2576,  0.2166,  0.2317,  0.2146,  0.2303,  0.1909,  0.2271,  0.2268,\n",
              "                       0.2275,  0.2579,  0.1906,  0.1807,  0.2333,  0.2319,  0.2407,  0.2476,\n",
              "                       0.2338,  0.2185,  0.2566,  0.0149,  0.1594,  0.2072,  0.2126,  0.2226,\n",
              "                       0.2013,  0.2469,  0.4106,  0.2395,  0.2369,  0.2548,  0.2252,  0.2410,\n",
              "                       0.2061,  0.2508,  0.2258,  0.1939,  0.2004,  0.2119,  0.1521,  0.2217,\n",
              "                       0.2164,  0.2250,  0.2137,  0.2268,  0.2682,  0.2315,  0.2370,  0.2161,\n",
              "                       0.2173,  0.2309,  0.2188,  0.2341,  0.2319,  0.2343,  0.2381,  0.2041,\n",
              "                       0.2379, -0.1500,  0.2255,  0.2114,  0.2539,  0.1503,  0.2546,  0.2528,\n",
              "                       0.2429,  0.2247,  0.2412,  0.2208,  0.2287,  0.2252,  0.2217,  0.1535,\n",
              "                       0.2312,  0.2209,  0.1061,  0.2504,  0.2385,  0.2249,  0.2193,  0.2002,\n",
              "                       0.0414,  0.1589,  0.2298,  0.2100,  0.2418,  0.2447,  0.2347,  0.2491,\n",
              "                       0.1596,  0.1679,  0.2327,  0.2200,  0.2200,  0.2433,  0.2091,  0.2508,\n",
              "                       0.1322,  0.2373,  0.2400,  0.2596,  0.2527,  0.2248, -0.0389,  0.2361,\n",
              "                       0.2259,  0.2371,  0.2272,  0.2356,  0.2140,  0.2201,  0.2187,  0.2326,\n",
              "                       0.2142,  0.2287,  0.2182,  0.2179,  0.2448,  0.2453,  0.2448,  0.2172,\n",
              "                       0.2258,  0.2266,  0.1842,  0.2288,  0.1995,  0.2193,  0.2038,  0.2340,\n",
              "                       0.2175,  0.2369,  0.2327,  0.1954,  0.2395,  0.2076,  0.2372,  0.2305,\n",
              "                       0.2453,  0.2332,  0.2169,  0.1907,  0.2154,  0.2256,  0.2356,  0.2189,\n",
              "                       0.2158,  0.2178,  0.2351,  0.1886,  0.1401,  0.2106,  0.2235,  0.2102,\n",
              "                       0.1937,  0.2431,  0.2055,  0.2467,  0.2497,  0.0467,  0.2444,  0.2580,\n",
              "                       0.2434,  0.1792,  0.1513,  0.1956,  0.2377,  0.2327,  0.2299,  0.2133,\n",
              "                       0.2402,  0.2131,  0.2507,  0.2242,  0.2231,  0.2196,  0.2622,  0.2436,\n",
              "                       0.2279,  0.2276,  0.2423,  0.1497,  0.2198,  0.2007,  0.1530,  0.2296,\n",
              "                       0.2334,  0.2465,  0.2416,  0.2532,  0.2106,  0.2427,  0.2330,  0.2369,\n",
              "                       0.2080,  0.2197,  0.2305,  0.2288,  0.2522,  0.2202,  0.2210,  0.2418,\n",
              "                       0.2378,  0.2368,  0.2424,  0.2296,  0.2077,  0.2418,  0.1656,  0.2269,\n",
              "                       0.2209,  0.2555,  0.2096,  0.2195,  0.2251,  0.2098,  0.2490,  0.2454,\n",
              "                       0.2200,  0.2283,  0.2473,  0.2309,  0.0243,  0.2227,  0.2369,  0.0792,\n",
              "                       0.2232,  0.2300,  0.1920,  0.2410,  0.2242,  0.1676,  0.2279,  0.2215,\n",
              "                       0.2251,  0.1979,  0.2196,  0.2248,  0.2288,  0.2307,  0.2377,  0.2111,\n",
              "                       0.2383,  0.2247,  0.1948,  0.2530,  0.2389,  0.2324,  0.2265,  0.2333,\n",
              "                      -0.0209,  0.2272,  0.2263,  0.2515,  0.2278,  0.2524,  0.2120,  0.2123,\n",
              "                       0.2031,  0.3703,  0.2153,  0.2270,  0.2447,  0.2260,  0.2400,  0.2180,\n",
              "                       0.2157,  0.2545,  0.1762,  0.2368,  0.2107,  0.2321,  0.2562,  0.2267,\n",
              "                       0.1224,  0.2372,  0.2347,  0.2356,  0.2406,  0.2301,  0.2460,  0.2315,\n",
              "                       0.1791,  0.2518,  0.2429,  0.2134,  0.0648,  0.2345,  0.2083, -0.0472,\n",
              "                       0.2407,  0.2410,  0.2491,  0.2226,  0.2415,  0.2458,  0.2582,  0.0869,\n",
              "                       0.2154,  0.2271,  0.2606,  0.2200,  0.2315,  0.2151,  0.2246,  0.2322,\n",
              "                       0.2271,  0.2227,  0.2194,  0.2095,  0.2333,  0.2483,  0.1994,  0.2454,\n",
              "                       0.2180,  0.2354,  0.1994,  0.2581,  0.1914,  0.2137,  0.1649,  0.2580,\n",
              "                       0.2127,  0.2379,  0.2136,  0.2380,  0.2422,  0.2127,  0.2335,  0.1830,\n",
              "                       0.2290,  0.2081,  0.1797,  0.2268,  0.2447,  0.2371,  0.2165,  0.2398,\n",
              "                       0.2610,  0.2190,  0.2190,  0.2125,  0.2329,  0.2405,  0.2263,  0.2142,\n",
              "                       0.2069,  0.2350,  0.2393,  0.2273,  0.2239,  0.2308,  0.1657,  0.1824,\n",
              "                       0.2269,  0.1725,  0.2254,  0.2264,  0.1887,  0.2293,  0.1967,  0.2389,\n",
              "                       0.2097,  0.2140,  0.1540,  0.2879,  0.2448,  0.2199,  0.2335,  0.2300,\n",
              "                       0.2150,  0.2348,  0.2230,  0.2419,  0.2176,  0.2068,  0.1582,  0.2155,\n",
              "                       0.2429,  0.2448,  0.2202, -0.0039,  0.1943,  0.2443,  0.2385,  0.2188,\n",
              "                       0.2324,  0.2394,  0.2200,  0.2247,  0.2342,  0.2169,  0.2422,  0.2375,\n",
              "                       0.2247,  0.2057,  0.2147,  0.2408,  0.1805,  0.2258,  0.2351,  0.2390,\n",
              "                       0.1907,  0.2437,  0.2485,  0.2020,  0.2226,  0.2360,  0.2326,  0.1301,\n",
              "                       0.2496,  0.2239,  0.2509,  0.2178,  0.2248,  0.2228,  0.2256,  0.2596,\n",
              "                       0.2043,  0.2124,  0.2326,  0.2363,  0.2274,  0.2256,  0.2350,  0.1602,\n",
              "                       0.2178,  0.2410,  0.2342,  0.2274,  0.2252,  0.2164,  0.1907,  0.2222,\n",
              "                       0.2024,  0.2199,  0.2109,  0.2270,  0.2073,  0.2162,  0.2588,  0.2273,\n",
              "                       0.1846,  0.2102,  0.2419,  0.2259,  0.1582,  0.2225,  0.1457,  0.2249,\n",
              "                       0.2105,  0.2494,  0.1464,  0.2508,  0.2168,  0.2218,  0.2362,  0.1443,\n",
              "                       0.2194,  0.1716,  0.2357,  0.2161,  0.2391,  0.2091,  0.2098,  0.2294,\n",
              "                       0.2161,  0.2122,  0.2474,  0.2417,  0.2106,  0.2348,  0.2211,  0.2420,\n",
              "                       0.2495,  0.1774,  0.2279,  0.2502,  0.2132,  0.2479,  0.2233,  0.2449,\n",
              "                       0.2328,  0.2322,  0.2011,  0.2170,  0.2196,  0.2080,  0.2245,  0.2020,\n",
              "                       0.2622,  0.2180,  0.2437,  0.2166,  0.1578,  0.2167,  0.2346,  0.2136,\n",
              "                       0.2420,  0.2324,  0.2101,  0.2254,  0.2216,  0.2285,  0.2031,  0.1289,\n",
              "                       0.2151,  0.2392,  0.2412,  0.1705,  0.1534,  0.2246,  0.2077,  0.2162,\n",
              "                       0.2029,  0.2235,  0.1100,  0.2255,  0.2152,  0.2075,  0.2229,  0.2009,\n",
              "                       0.2468,  0.2123,  0.1895,  0.2478,  0.2236,  0.1353,  0.2204,  0.2276,\n",
              "                       0.2187,  0.2417,  0.2450,  0.2381,  0.2341,  0.0714,  0.2149,  0.2375,\n",
              "                       0.2206,  0.2150,  0.2340,  0.2182,  0.2092,  0.1341,  0.2350,  0.1901,\n",
              "                       0.2575,  0.2102,  0.1699,  0.2219,  0.2289,  0.1844,  0.2053,  0.2014,\n",
              "                       0.1780,  0.2350,  0.2458,  0.2472,  0.2182,  0.2079,  0.1270,  0.2235,\n",
              "                       0.1904,  0.1864,  0.2009,  0.2151,  0.2264,  0.2149,  0.2578,  0.2086],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0820, -0.0083,  0.0729,  ...,  0.0439,  0.0652,  0.0160],\n",
              "                      [ 0.0123, -0.0250,  0.0371,  ..., -0.0205, -0.0326, -0.0079],\n",
              "                      [-0.0086,  0.0343, -0.0106,  ..., -0.0734, -0.0439,  0.0584],\n",
              "                      ...,\n",
              "                      [ 0.0360,  0.0751, -0.0519,  ...,  0.0259,  0.0057, -0.1168],\n",
              "                      [ 0.0199,  0.0163,  0.0133,  ...,  0.0867, -0.0705,  0.0405],\n",
              "                      [-0.0293,  0.0672, -0.0100,  ...,  0.0102, -0.0221,  0.0332]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[-1.9129e-01,  6.7383e-01,  8.8788e-01,  ..., -1.6260e-01,\n",
              "                        2.0191e-01, -2.6181e-01],\n",
              "                      [ 3.5143e-02,  2.0452e-02,  5.7253e-04,  ..., -4.5343e-01,\n",
              "                       -1.3372e-02, -1.7447e-01],\n",
              "                      [ 2.3256e-01, -6.8527e-01,  2.1548e-01,  ...,  1.0689e-01,\n",
              "                       -5.6331e-01, -5.2844e-03],\n",
              "                      ...,\n",
              "                      [ 5.4056e-01,  1.6040e-01, -3.9249e-01,  ..., -4.8393e-02,\n",
              "                        4.1761e-01,  2.4863e-01],\n",
              "                      [-5.6997e-01, -3.0671e-01, -1.3667e-02,  ...,  1.5448e-01,\n",
              "                       -3.7808e-01, -4.4749e-01],\n",
              "                      [ 6.3294e-01,  2.8582e-01, -5.9699e-01,  ..., -1.9781e-01,\n",
              "                        5.0127e-03,  3.5037e-01]], device='cuda:0')),\n",
              "             ('decoder.block.6.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.1253,  0.5873, -0.5356,  ...,  0.5097, -1.2042, -0.0293],\n",
              "                      [ 1.1574,  0.0970,  0.1556,  ..., -0.0609, -0.2453,  0.2000],\n",
              "                      [-0.0547,  0.4901,  0.8434,  ...,  0.3649,  0.2050,  0.2722],\n",
              "                      ...,\n",
              "                      [-0.0196, -1.1782, -0.5792,  ..., -0.2179,  0.6793,  1.5362],\n",
              "                      [-0.7418, -0.1465,  0.8637,  ...,  0.9913, -0.9845,  1.2405],\n",
              "                      [ 0.1104, -0.6732,  0.5081,  ..., -0.9099,  0.7562, -0.5972]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[-0.2231,  0.4935, -0.1420,  ..., -0.8951,  0.1187,  0.7112],\n",
              "                      [ 0.0392, -0.0088, -0.4091,  ...,  0.0968, -0.0958,  0.3047],\n",
              "                      [ 0.1449,  0.3965, -0.0492,  ..., -0.0031,  0.1434, -0.2214],\n",
              "                      ...,\n",
              "                      [ 0.3367, -0.1859, -0.8707,  ..., -0.8614,  0.4353,  0.4035],\n",
              "                      [-0.4232,  0.1151, -1.4267,  ..., -0.4070, -0.4923,  0.3843],\n",
              "                      [ 0.0830,  0.1316,  0.1303,  ...,  0.3353,  0.0771,  0.2073]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.1.layer_norm.weight',\n",
              "              tensor([ 5.2826e-02,  3.8431e-02,  3.9698e-02, -5.7484e-02,  4.0008e-02,\n",
              "                       5.3297e-02,  6.7691e-02,  6.6558e-02,  5.3770e-02,  6.8935e-02,\n",
              "                       4.5380e-02,  5.9919e-02,  4.9252e-02,  4.2681e-02,  5.0486e-02,\n",
              "                       6.2216e-02,  4.8917e-02,  4.6569e-02,  4.9314e-02,  7.1483e-02,\n",
              "                       5.6786e-02,  5.7808e-02,  6.7367e-02,  8.0658e-02,  6.3110e-02,\n",
              "                       6.2260e-02,  5.6062e-02,  3.6368e-02,  5.9137e-02,  5.5130e-02,\n",
              "                       6.9670e-02,  4.9564e-02,  7.1590e-02,  7.3811e-02,  6.1387e-02,\n",
              "                       3.6812e-02,  7.7940e-02,  6.6767e-02,  5.3683e-02,  6.4185e-02,\n",
              "                       5.6284e-02,  5.2893e-02,  7.7680e-02,  6.8164e-02,  5.0084e-02,\n",
              "                       6.5119e-02,  7.6753e-02,  7.8709e-02,  6.9538e-02,  6.3734e-02,\n",
              "                       6.4260e-02,  5.5078e-02,  4.9814e-02,  6.1155e-02,  7.6257e-02,\n",
              "                       3.9520e-02,  4.6036e-02,  5.7240e-02,  7.7807e-02,  6.6232e-02,\n",
              "                       5.2949e-02,  5.9938e-02,  6.7682e-02,  7.1308e-02,  6.5283e-02,\n",
              "                       1.2184e-01,  5.7776e-02,  7.1490e-02,  4.0577e-02,  6.7006e-02,\n",
              "                       6.9818e-02,  7.4581e-02,  6.7774e-02,  5.6260e-02,  7.7481e-02,\n",
              "                       5.0980e-02,  4.4976e-02,  5.0792e-02,  5.4966e-02,  6.0699e-02,\n",
              "                       5.7562e-02,  6.0114e-02, -5.1955e-02,  5.2849e-02,  7.4409e-02,\n",
              "                       6.4823e-02, -2.2778e-02,  7.0120e-02,  7.1944e-02,  5.0853e-02,\n",
              "                       5.1054e-02,  6.3241e-02,  6.1608e-02,  4.5284e-02,  6.6056e-02,\n",
              "                       7.1905e-02,  6.0502e-02,  7.2240e-02,  5.8569e-02,  6.1226e-02,\n",
              "                       6.3143e-02,  5.9749e-02,  3.1133e-02,  5.9178e-02,  5.0857e-02,\n",
              "                       4.8707e-02,  7.1098e-02,  4.9002e-02,  7.4795e-02,  6.4819e-02,\n",
              "                       6.6919e-02,  7.0865e-02,  4.5896e-02,  5.1041e-02,  6.0953e-02,\n",
              "                       8.3695e-02,  4.2970e-02,  6.2996e-02,  5.2512e-04,  6.0305e-02,\n",
              "                       5.7546e-02,  6.0106e-02,  4.8603e-02,  5.1042e-02,  4.9527e-02,\n",
              "                       4.4284e-02,  6.5081e-02,  5.8336e-02,  5.6663e-02,  4.4652e-02,\n",
              "                       3.7120e-02,  5.6134e-02,  5.6077e-02,  6.1668e-02,  4.2927e-02,\n",
              "                       5.0998e-02,  6.0383e-02,  5.5794e-02,  5.3021e-02,  5.0618e-02,\n",
              "                       5.5366e-02,  6.8886e-02,  5.9198e-02,  5.8889e-02,  5.6005e-02,\n",
              "                       4.3259e-02,  6.8287e-02,  4.6888e-02,  5.8550e-02,  5.1410e-02,\n",
              "                       7.1661e-02,  4.9162e-02,  6.1926e-02,  5.7437e-02,  6.9099e-02,\n",
              "                       6.5270e-02,  6.3814e-02,  7.5434e-02,  1.0615e-01,  4.6762e-02,\n",
              "                       4.9848e-02,  5.3804e-02,  4.8168e-02,  5.1562e-02,  5.8299e-02,\n",
              "                       2.9301e-02,  6.6793e-02,  6.2921e-02,  3.5572e-02,  7.0256e-02,\n",
              "                       2.8497e-02,  6.0275e-02,  7.0380e-02,  6.5441e-02,  6.3143e-02,\n",
              "                       6.1134e-02, -5.7647e-02,  5.5436e-02,  2.8727e-02,  5.6535e-02,\n",
              "                       6.2552e-02,  6.9783e-02,  7.2588e-02,  6.2103e-02,  4.6897e-02,\n",
              "                       6.1768e-02,  5.2440e-02,  7.1598e-02,  6.3210e-02,  4.4475e-02,\n",
              "                       6.7689e-02,  6.0432e-02,  7.0618e-02,  4.5532e-02,  4.2259e-02,\n",
              "                       5.6753e-02,  6.4469e-02,  7.3463e-02,  6.0354e-02,  6.3934e-02,\n",
              "                       6.5207e-02,  5.3935e-02,  5.8241e-02,  5.6589e-02,  6.4140e-02,\n",
              "                       5.1744e-02,  6.0996e-02,  6.7851e-02,  6.0644e-02,  7.5271e-02,\n",
              "                       7.7358e-02,  5.2997e-02,  5.0013e-02,  6.2945e-02,  7.9014e-02,\n",
              "                       6.7253e-02,  5.1348e-02,  4.9614e-02,  6.1166e-02,  1.3304e-04,\n",
              "                       3.9765e-02,  6.9985e-02,  4.8419e-02,  6.9662e-02,  5.2658e-02,\n",
              "                       6.6754e-02,  1.3789e-01,  6.9278e-02,  7.1548e-02,  7.3046e-02,\n",
              "                       5.9711e-02,  7.2830e-02,  4.3310e-02,  7.1548e-02,  5.5179e-02,\n",
              "                       4.7172e-02,  4.7429e-02,  5.1281e-02,  3.8111e-02,  6.1406e-02,\n",
              "                      -7.4311e-02,  7.0920e-02,  5.4276e-02,  5.8692e-02,  7.1006e-02,\n",
              "                       6.7010e-02,  6.0925e-02,  4.4981e-02,  6.7673e-02,  5.9451e-02,\n",
              "                       4.9185e-02,  5.2718e-02,  5.9769e-02,  5.6522e-02,  6.8146e-02,\n",
              "                       4.8707e-02,  6.2486e-02, -3.7304e-02,  6.4568e-02,  7.0297e-02,\n",
              "                       6.9755e-02,  5.2145e-02,  7.4518e-02,  5.3036e-02,  6.3153e-02,\n",
              "                       5.9560e-02,  4.9837e-02,  6.5330e-02,  6.3530e-02,  6.9304e-02,\n",
              "                       5.1022e-02,  7.2419e-02,  5.6496e-02,  5.9663e-02,  3.2061e-02,\n",
              "                       6.1569e-02,  5.5791e-02,  5.9882e-02,  7.5721e-02,  5.6453e-02,\n",
              "                      -2.3111e-03,  4.1386e-02,  5.1511e-02,  6.6306e-02,  6.1637e-02,\n",
              "                       6.8388e-02,  4.3669e-02,  6.9105e-02,  4.3348e-02,  3.7738e-02,\n",
              "                       5.7253e-02,  4.0739e-02,  6.6920e-02,  6.0331e-02,  4.8068e-02,\n",
              "                       5.2701e-02,  4.4148e-02,  5.6767e-02,  6.2314e-02,  6.9336e-02,\n",
              "                       7.6235e-02,  6.2265e-02,  2.2127e-02,  5.7991e-02,  5.3920e-02,\n",
              "                       6.1950e-02,  6.9664e-02,  5.8245e-02,  5.6348e-02,  6.5101e-02,\n",
              "                       6.1350e-02,  5.9673e-02,  5.6334e-02,  6.1256e-02,  1.1816e-01,\n",
              "                       5.9834e-02,  7.2310e-02,  6.3507e-02,  6.4895e-02,  7.3263e-02,\n",
              "                       7.0782e-02,  6.4181e-02,  5.0918e-02,  5.6549e-02,  6.3520e-02,\n",
              "                       5.3682e-02,  6.2288e-02,  6.6309e-02,  6.7318e-02,  6.3997e-02,\n",
              "                       7.2136e-02,  4.6670e-02,  6.5174e-02,  6.6390e-02,  5.3746e-02,\n",
              "                       6.4054e-02,  7.0626e-02,  8.2204e-02,  5.0444e-02,  3.6578e-02,\n",
              "                       6.5923e-02,  6.7071e-02,  6.8848e-02,  5.7267e-02,  6.3737e-02,\n",
              "                       5.1800e-02,  5.5732e-02,  4.3394e-02,  4.0415e-02,  5.3775e-02,\n",
              "                       5.6241e-02,  5.2299e-02,  4.7095e-02,  5.7546e-02,  5.9471e-02,\n",
              "                       7.1356e-02,  6.3322e-02, -5.6812e-04,  5.3959e-02,  6.7765e-02,\n",
              "                       6.4035e-02,  5.1924e-02,  5.3915e-02,  5.7368e-02,  5.6783e-02,\n",
              "                       7.9883e-02,  6.4743e-02,  5.7954e-02,  6.7768e-02,  5.3091e-02,\n",
              "                       5.2618e-02,  7.3520e-02,  5.3189e-02,  6.0000e-02,  7.8649e-02,\n",
              "                       6.0414e-02,  6.3621e-02,  7.3884e-02,  5.7715e-02,  5.6952e-02,\n",
              "                       5.5339e-02,  4.3006e-02,  6.4241e-02,  6.5986e-02,  6.4605e-02,\n",
              "                       7.0658e-02,  6.2656e-02,  6.1610e-02,  5.0013e-02,  6.1505e-02,\n",
              "                       5.6757e-02,  5.5818e-02,  4.4550e-02,  6.1728e-02,  5.4446e-02,\n",
              "                       5.4208e-02,  6.4068e-02,  6.0101e-02,  5.9633e-02,  6.2637e-02,\n",
              "                       5.9848e-02,  6.0397e-02,  5.8844e-02,  6.1523e-02,  5.9185e-02,\n",
              "                       7.1916e-02,  5.8721e-02,  4.7332e-02,  5.1713e-02,  5.6322e-02,\n",
              "                       5.2297e-02,  6.8298e-02,  6.0747e-02,  7.8188e-02,  7.2540e-02,\n",
              "                       6.2871e-02,  6.0248e-02,  7.0242e-02,  1.5035e-01,  6.9266e-02,\n",
              "                       9.8416e-04,  6.6682e-02,  6.4172e-02, -1.7124e-02,  6.0399e-02,\n",
              "                       6.4202e-02,  4.6365e-02,  6.3651e-02,  6.1153e-02,  4.5882e-02,\n",
              "                       6.0587e-02,  6.1052e-02,  7.6183e-02,  5.7533e-02,  5.8571e-02,\n",
              "                       4.7568e-02,  6.6492e-02,  5.9784e-02,  7.0045e-02,  5.1010e-02,\n",
              "                       6.1855e-02,  6.1260e-02,  4.8713e-02,  6.6834e-02,  5.6291e-02,\n",
              "                       7.0059e-02,  6.2306e-02,  6.5361e-02,  1.1541e-03,  7.3599e-02,\n",
              "                       7.0379e-02,  7.3567e-02,  6.8828e-02,  5.9301e-02,  4.9343e-02,\n",
              "                       5.1423e-02,  1.1006e-01,  1.0275e-01,  5.2496e-02,  5.4072e-02,\n",
              "                       4.8149e-02,  5.7528e-02,  5.8369e-02,  6.5170e-02,  5.2911e-02,\n",
              "                       6.3591e-02,  4.6539e-02,  6.9436e-02,  5.3163e-02,  5.6955e-02,\n",
              "                       6.6559e-02,  6.2277e-02,  3.2113e-02,  7.1844e-02,  7.2112e-02,\n",
              "                       7.0608e-02,  6.3670e-02,  7.0861e-02,  7.3670e-02,  6.5431e-02,\n",
              "                       4.6503e-02,  6.6652e-02,  6.3201e-02,  5.5302e-02, -1.0213e-03,\n",
              "                       5.2678e-02,  6.1239e-02,  9.1967e-02,  6.6745e-02,  5.4754e-02,\n",
              "                       7.3420e-02,  7.7435e-02,  5.3445e-02,  6.3527e-02,  6.0431e-02,\n",
              "                       5.7085e-02,  5.6345e-02,  6.3204e-02,  6.0131e-02,  6.4037e-02,\n",
              "                       6.0852e-02,  9.4589e-02,  6.5677e-02,  6.2931e-02,  4.7129e-02,\n",
              "                       7.0222e-02,  5.3279e-02,  5.8976e-02,  5.4846e-02,  6.1117e-02,\n",
              "                       5.4270e-02,  7.1098e-02,  5.1407e-02,  6.3059e-02,  5.6545e-02,\n",
              "                       6.9206e-02,  6.1190e-02,  4.8973e-02,  4.5500e-02,  6.4812e-02,\n",
              "                       7.1141e-02,  6.8426e-02,  6.6140e-02,  6.4145e-02,  5.6924e-02,\n",
              "                       6.2331e-02,  5.3469e-02,  5.5505e-02,  5.6140e-02,  5.3529e-02,\n",
              "                       3.8893e-02,  6.6641e-02,  6.7957e-02,  6.0557e-02,  6.9880e-02,\n",
              "                       6.3926e-02,  6.1177e-02,  6.5583e-02,  6.0319e-02,  6.9873e-02,\n",
              "                       6.0231e-02,  6.6931e-02,  4.8045e-02,  5.4655e-02,  6.8221e-02,\n",
              "                       6.3588e-02,  6.4574e-02,  5.1113e-02,  5.9704e-02,  5.9647e-02,\n",
              "                      -4.9743e-02,  6.1169e-02,  5.2709e-02,  5.2381e-02,  5.4877e-02,\n",
              "                       5.9660e-02,  4.7119e-02,  5.8055e-02,  3.5355e-02,  7.2993e-02,\n",
              "                       5.0618e-02,  4.2379e-02,  3.4261e-02,  7.4733e-02,  6.1408e-02,\n",
              "                       5.8172e-02,  6.0982e-02,  4.4606e-02,  6.2048e-02,  7.6808e-02,\n",
              "                       7.0578e-02,  5.6295e-02,  6.1494e-02,  5.5038e-02,  5.0022e-02,\n",
              "                       5.2020e-02,  5.5811e-02,  7.0266e-02,  6.3980e-02,  5.7912e-04,\n",
              "                       5.0566e-02,  7.5604e-02,  5.6738e-02,  5.4736e-02,  5.8062e-02,\n",
              "                       5.9573e-02,  5.9225e-02,  6.3667e-02,  5.6450e-02,  4.7894e-02,\n",
              "                       6.8782e-02,  6.4721e-02,  6.6997e-02,  5.1323e-02,  5.3555e-02,\n",
              "                       5.6109e-02,  5.1197e-02,  6.0241e-02,  4.8006e-02,  6.2783e-02,\n",
              "                       6.4701e-02,  5.3940e-02,  6.3946e-02,  5.3719e-02,  5.2182e-02,\n",
              "                       5.7868e-02,  6.9749e-02, -4.2479e-02,  5.8815e-02,  5.7584e-02,\n",
              "                       6.0241e-02,  5.6952e-02,  5.8465e-02,  5.6567e-02,  4.7850e-02,\n",
              "                       6.8165e-02,  4.5188e-02,  1.5618e-01,  6.8047e-02,  6.8046e-02,\n",
              "                       6.2913e-02,  6.4860e-02,  6.8661e-02,  4.0520e-02,  6.7122e-02,\n",
              "                       5.8219e-02,  6.8627e-02,  5.3111e-02,  6.7443e-02,  6.1610e-02,\n",
              "                       5.9096e-02,  6.0657e-02,  5.7362e-02,  5.8176e-02,  5.5795e-02,\n",
              "                       5.8905e-02,  5.2260e-02,  5.6463e-02,  6.4180e-02,  6.1413e-02,\n",
              "                       3.5683e-02,  4.7905e-02,  6.8300e-02,  5.8079e-02,  3.7449e-02,\n",
              "                       6.7591e-02,  3.1953e-02,  6.1441e-02,  6.6125e-02,  6.9625e-02,\n",
              "                       5.2141e-02,  5.5921e-02,  5.6247e-02,  6.6539e-02,  7.7368e-02,\n",
              "                       3.5160e-02,  5.0118e-02,  5.5260e-02,  5.5225e-02,  6.5151e-02,\n",
              "                       6.2124e-02,  3.9120e-02,  5.4871e-02,  8.1264e-02,  7.4242e-02,\n",
              "                       6.9531e-02,  6.4678e-02,  6.8795e-02,  6.5406e-02,  6.5164e-02,\n",
              "                       5.5104e-02,  5.5783e-02,  5.4523e-02,  4.8924e-02,  6.5507e-02,\n",
              "                       5.7153e-02,  7.2662e-02,  6.3103e-02,  5.8043e-02,  6.3718e-02,\n",
              "                       5.9728e-02,  5.7177e-02,  4.4633e-02,  5.7317e-02,  5.9800e-02,\n",
              "                       5.7657e-02,  4.9483e-02,  5.5078e-02,  6.0243e-02,  5.0845e-02,\n",
              "                       6.4868e-02,  5.5821e-02, -4.4146e-02,  6.0578e-02,  5.7679e-02,\n",
              "                       5.4527e-02,  6.0789e-02,  6.5892e-02,  7.0274e-02,  4.8152e-02,\n",
              "                       5.9347e-02,  6.6701e-02,  6.1032e-02, -2.7588e-02,  6.5103e-02,\n",
              "                       6.5703e-02,  5.5639e-02, -4.3433e-02,  6.2320e-02,  5.9081e-02,\n",
              "                       6.5436e-02,  5.3093e-02,  6.3120e-02,  4.6390e-02, -3.5760e-02,\n",
              "                       1.0229e-01,  6.2124e-02,  6.8456e-02,  6.6908e-02,  5.2374e-02,\n",
              "                       6.9125e-02,  6.7563e-02,  4.3369e-02,  5.9182e-02,  7.0464e-02,\n",
              "                       5.3068e-02,  6.0568e-02,  6.0678e-02,  5.4400e-02,  6.4390e-02,\n",
              "                       6.7178e-02,  6.1399e-02,  6.8268e-02,  5.7393e-02,  7.0182e-02,\n",
              "                       6.6000e-02,  5.8035e-02,  6.1131e-02,  5.1342e-02,  4.2850e-02,\n",
              "                       6.3399e-02,  4.7483e-02,  5.8439e-02,  5.2506e-02,  7.1186e-02,\n",
              "                       4.8166e-02,  4.5526e-02,  5.3984e-02,  5.4796e-02, -3.9700e-02,\n",
              "                       5.5483e-02,  6.1090e-02,  5.6218e-02,  6.1145e-02,  5.5097e-02,\n",
              "                       7.5754e-02,  5.0483e-02,  5.3273e-02,  4.8436e-02,  6.4719e-02,\n",
              "                       5.9790e-02,  4.4039e-02,  5.5383e-02,  6.0340e-02,  5.8252e-02,\n",
              "                       6.0033e-02,  6.8572e-02,  5.9278e-02], device='cuda:0')),\n",
              "             ('decoder.block.6.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[-4.4854e-01,  4.4948e-01, -3.6747e-01,  ...,  1.1152e-01,\n",
              "                       -8.5767e-01, -1.0046e-01],\n",
              "                      [ 1.6773e-01,  3.9846e-04,  7.0695e-01,  ...,  4.0653e-01,\n",
              "                        8.1238e-02,  1.0495e-01],\n",
              "                      [-1.1167e-01,  2.3297e-01, -7.7493e-01,  ..., -8.3741e-02,\n",
              "                       -3.4809e-01,  6.3969e-01],\n",
              "                      ...,\n",
              "                      [ 6.2062e-01,  3.0209e-02,  8.7581e-01,  ..., -8.0923e-01,\n",
              "                       -6.8672e-01,  1.0956e-01],\n",
              "                      [-1.8794e-01,  7.3289e-01, -4.0407e-01,  ..., -1.4481e+00,\n",
              "                        3.6833e-01,  3.4154e-01],\n",
              "                      [ 3.2870e-02,  2.4262e-01, -3.2343e-02,  ..., -4.1826e-01,\n",
              "                        2.6834e-01,  5.1146e-01]], device='cuda:0')),\n",
              "             ('decoder.block.6.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.2903,  0.2371,  0.1765,  ..., -0.0518,  0.3902, -0.2085],\n",
              "                      [-0.0342,  0.2299, -0.1523,  ...,  0.0731,  0.0099,  0.1055],\n",
              "                      [ 0.1436,  0.0427, -0.1901,  ..., -0.3298, -0.2352, -0.0622],\n",
              "                      ...,\n",
              "                      [ 0.1531,  0.3410, -0.0171,  ...,  0.1279, -0.1247, -0.1724],\n",
              "                      [-0.0006, -0.0283,  0.4397,  ..., -0.1833, -0.2812, -0.2343],\n",
              "                      [ 0.1239,  0.0475,  0.0127,  ..., -0.1136, -0.1133, -0.3648]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.6.layer.2.layer_norm.weight',\n",
              "              tensor([2.8146, 2.5989, 2.4241, 2.3383, 2.8781, 2.7334, 2.4495, 3.2726, 2.4588,\n",
              "                      2.7795, 3.7035, 2.8939, 2.9785, 3.2672, 2.7849, 3.0597, 2.8654, 2.3698,\n",
              "                      2.9147, 2.9818, 2.9021, 3.0561, 2.7164, 2.8137, 2.9815, 2.5636, 2.7593,\n",
              "                      3.0456, 2.9362, 2.9622, 3.1054, 2.9031, 3.0541, 2.6447, 3.0801, 2.6455,\n",
              "                      2.8260, 2.3090, 2.7593, 3.0018, 2.6229, 2.7195, 2.7223, 2.8475, 2.5851,\n",
              "                      2.7554, 2.9012, 2.7607, 3.0554, 3.1026, 2.6662, 2.7957, 3.0755, 2.8979,\n",
              "                      3.5217, 2.8318, 2.7777, 2.8399, 2.8349, 2.8979, 2.7043, 2.8721, 2.9601,\n",
              "                      2.8236, 2.8107, 2.0813, 2.8306, 2.9057, 2.9922, 2.8117, 2.7996, 2.7750,\n",
              "                      2.7156, 2.7140, 3.0859, 2.8088, 2.9385, 2.9376, 2.9554, 2.6461, 2.7587,\n",
              "                      2.7143, 2.7417, 2.5399, 2.7396, 2.7631, 2.0692, 2.9031, 2.9314, 3.0468,\n",
              "                      2.5848, 2.7139, 2.8426, 3.0350, 3.0627, 2.8339, 2.9277, 2.7076, 2.9372,\n",
              "                      2.7697, 3.3254, 2.5875, 3.2543, 2.9066, 2.7565, 2.4591, 2.8404, 2.6407,\n",
              "                      2.6372, 2.6965, 2.8289, 2.8507, 2.9946, 2.6866, 2.7240, 2.6024, 2.8434,\n",
              "                      3.0502, 0.0121, 2.7847, 2.9563, 2.5540, 2.6604, 2.6186, 2.7862, 2.6294,\n",
              "                      2.9684, 2.7088, 3.0985, 3.0716, 3.4166, 2.6916, 2.9766, 2.7932, 2.0612,\n",
              "                      2.6815, 2.6965, 2.7564, 3.0271, 3.0256, 2.8550, 2.8262, 3.0290, 2.8843,\n",
              "                      2.8247, 2.7310, 2.6459, 2.6086, 2.7637, 2.9798, 2.8219, 2.8551, 2.7912,\n",
              "                      2.5961, 2.8751, 2.9636, 2.8627, 2.9348, 2.2841, 2.9613, 2.7346, 2.6695,\n",
              "                      2.7318, 2.8817, 2.5403, 2.5665, 3.0070, 2.5859, 2.6709, 2.8531, 3.2863,\n",
              "                      2.7010, 2.7374, 2.7095, 2.7629, 2.7784, 2.7458, 2.5605, 2.9401, 2.3991,\n",
              "                      2.9089, 3.0193, 2.9984, 2.7513, 3.2741, 2.8575, 2.8628, 1.5889, 2.8013,\n",
              "                      2.7391, 2.7321, 2.6886, 2.5887, 3.0904, 2.5798, 2.6409, 2.7636, 2.7949,\n",
              "                      2.9200, 2.6194, 3.0368, 2.8075, 2.9283, 2.5822, 2.7197, 2.7122, 2.6787,\n",
              "                      2.7711, 2.6607, 2.9283, 2.5651, 3.1666, 2.5862, 2.7589, 2.8978, 2.9166,\n",
              "                      3.0479, 2.5762, 2.9227, 0.7399, 3.0291, 2.6619, 2.7246, 2.7361, 2.8199,\n",
              "                      2.7055, 1.4459, 2.7465, 2.9654, 2.9397, 2.6485, 2.9770, 2.7511, 2.8917,\n",
              "                      2.8399, 2.7313, 3.0352, 2.8774, 3.4078, 3.0447, 4.0582, 2.8101, 2.7895,\n",
              "                      2.5822, 2.9393, 2.6930, 2.6681, 2.8787, 2.6216, 2.9019, 2.7634, 2.8778,\n",
              "                      2.9491, 2.7726, 2.8601, 2.5033, 2.8148, 3.1792, 2.7590, 2.7316, 2.8872,\n",
              "                      3.1702, 2.8821, 3.0613, 2.7802, 2.9147, 2.6723, 2.5998, 2.8591, 2.9245,\n",
              "                      2.7316, 2.6563, 2.8458, 2.3911, 2.9971, 2.9053, 2.9912, 3.0918, 2.7443,\n",
              "                      2.8251, 0.6113, 2.7832, 2.9172, 2.6775, 2.9313, 2.7391, 2.8509, 3.0550,\n",
              "                      2.7467, 3.1319, 2.6977, 2.6655, 2.6522, 2.8961, 2.6728, 2.9731, 2.4568,\n",
              "                      2.8888, 2.9685, 3.0356, 2.7002, 2.8554, 0.7641, 2.8258, 2.8422, 2.7938,\n",
              "                      2.9286, 3.0935, 2.9715, 2.6125, 2.4931, 2.6891, 2.8199, 2.7648, 2.1160,\n",
              "                      2.9465, 2.4797, 3.0168, 2.9264, 2.7876, 2.6754, 2.8509, 2.8754, 2.8160,\n",
              "                      2.5221, 2.7138, 2.8107, 2.7154, 2.9577, 2.8692, 2.8735, 2.8949, 2.7161,\n",
              "                      2.7047, 2.7521, 3.0286, 2.7426, 2.7199, 2.4797, 3.1663, 2.9598, 2.7724,\n",
              "                      2.6314, 2.7404, 2.9165, 2.7377, 2.9467, 3.1858, 2.3556, 3.0268, 2.6498,\n",
              "                      2.5166, 2.5186, 2.6557, 2.8738, 2.9466, 2.9836, 0.0182, 2.9405, 3.2617,\n",
              "                      2.9495, 2.4929, 3.2345, 2.7286, 2.7550, 2.8181, 3.0400, 2.6244, 2.8745,\n",
              "                      2.9719, 2.9377, 2.7731, 2.6542, 2.7328, 2.8855, 2.8844, 2.7427, 2.5420,\n",
              "                      2.8703, 2.6444, 2.7574, 2.5384, 3.1298, 2.7090, 2.9183, 2.8865, 2.8578,\n",
              "                      2.9431, 2.5956, 2.7117, 2.7510, 2.6685, 2.7510, 2.8926, 2.7966, 2.8591,\n",
              "                      2.9947, 2.6881, 2.6988, 3.1066, 2.7319, 2.8774, 2.8829, 3.0467, 2.6317,\n",
              "                      2.7494, 2.5535, 2.7772, 2.6626, 2.8116, 2.7011, 2.6654, 2.7489, 2.7258,\n",
              "                      2.7616, 2.7564, 2.8476, 2.7313, 1.7972, 2.6539, 0.7381, 2.7354, 2.8622,\n",
              "                      1.7773, 3.1075, 2.7582, 2.9012, 2.8889, 2.8385, 3.4250, 2.6803, 2.7652,\n",
              "                      3.1023, 2.5966, 2.6057, 2.6640, 2.8553, 2.7038, 2.9152, 2.6342, 2.7876,\n",
              "                      2.8582, 2.3013, 2.8343, 2.6435, 2.6027, 2.6669, 2.8635, 0.7900, 2.7929,\n",
              "                      2.7184, 2.8069, 2.7078, 2.8389, 2.6595, 2.8620, 2.7211, 1.8136, 2.7315,\n",
              "                      2.8444, 2.9430, 2.7656, 2.7960, 2.8184, 2.7792, 3.0759, 2.8575, 2.8677,\n",
              "                      2.6671, 2.7541, 2.8732, 2.6100, 2.0141, 2.8766, 2.7620, 2.6846, 2.7424,\n",
              "                      2.7889, 2.8747, 2.7629, 3.0008, 2.9841, 2.8304, 2.7486, 0.0462, 2.8489,\n",
              "                      2.6470, 0.6181, 2.9124, 2.8254, 2.9264, 2.6830, 2.7373, 2.7526, 2.8918,\n",
              "                      3.9104, 2.8619, 2.8000, 3.0051, 2.9983, 2.8157, 2.3938, 2.9036, 2.8824,\n",
              "                      2.7011, 2.6700, 2.8084, 2.7548, 2.8384, 2.9050, 2.6871, 2.9084, 3.0867,\n",
              "                      2.7106, 2.4661, 2.8540, 2.7164, 2.5915, 2.9737, 2.9060, 2.8408, 2.7802,\n",
              "                      2.7792, 2.7709, 2.9010, 2.6419, 3.0353, 2.6787, 2.8877, 2.6381, 2.4814,\n",
              "                      2.7063, 2.7476, 2.7080, 2.6429, 2.7139, 2.9176, 2.8014, 2.7724, 2.7207,\n",
              "                      2.6685, 2.9667, 2.7001, 2.6800, 2.6829, 2.7815, 2.7814, 2.8427, 2.7159,\n",
              "                      2.8765, 2.6170, 2.9147, 2.7730, 2.6709, 2.7711, 2.7531, 2.6491, 2.9466,\n",
              "                      2.5826, 2.7819, 2.7499, 2.7898, 1.0810, 3.6698, 2.8050, 2.7615, 2.8271,\n",
              "                      2.6169, 2.8978, 2.7167, 2.6870, 2.7449, 2.8140, 3.0588, 3.2540, 2.5921,\n",
              "                      2.8081, 2.8528, 2.8614, 0.0108, 2.5012, 2.7959, 2.8749, 2.7682, 2.9785,\n",
              "                      2.8133, 2.8660, 2.7532, 2.9764, 2.7442, 2.8789, 2.8155, 2.8685, 2.6057,\n",
              "                      2.5869, 2.8547, 2.8301, 2.8237, 3.8355, 3.0620, 2.4620, 2.7785, 2.6760,\n",
              "                      2.6806, 2.9120, 2.8250, 2.7462, 2.3838, 3.0895, 2.9458, 2.8498, 2.7685,\n",
              "                      2.7352, 2.6633, 2.8273, 2.9924, 2.8663, 1.8581, 2.6159, 2.8642, 2.7334,\n",
              "                      2.6146, 2.8620, 3.3394, 2.8673, 2.9464, 3.0978, 2.7797, 2.8660, 2.5737,\n",
              "                      2.4722, 2.7529, 2.5417, 3.2033, 2.8229, 2.7194, 3.0615, 2.8947, 2.7741,\n",
              "                      2.7660, 2.7523, 2.5051, 2.6956, 2.8051, 2.5254, 2.9342, 2.9204, 2.7711,\n",
              "                      2.9190, 2.8781, 2.2249, 3.0725, 2.7961, 3.0110, 3.0158, 2.9484, 2.6322,\n",
              "                      2.9951, 2.9489, 3.2300, 2.7250, 2.6910, 2.3963, 2.7173, 2.7282, 2.7224,\n",
              "                      2.8767, 3.0324, 2.9691, 2.9013, 2.5923, 2.8765, 3.1280, 2.3914, 2.7662,\n",
              "                      2.9113, 2.5275, 2.7872, 2.7353, 2.9879, 2.8450, 2.8120, 3.0810, 2.5322,\n",
              "                      2.6928, 2.7162, 2.5510, 2.6295, 2.9787, 2.6133, 2.9639, 2.9047, 2.4544,\n",
              "                      2.5825, 2.7024, 2.5203, 2.8850, 2.7770, 3.0422, 2.7485, 2.5660, 2.6489,\n",
              "                      2.5290, 2.6163, 2.6055, 2.9668, 2.8180, 2.8919, 2.8610, 2.7740, 2.6423,\n",
              "                      2.6459, 2.7182, 2.6600, 2.3045, 2.3189, 2.6873, 2.6336, 2.6057, 2.9156,\n",
              "                      2.7593, 2.9345, 3.2178, 2.8964, 2.7588, 2.3813, 2.7265, 2.6900, 2.6233,\n",
              "                      2.8449, 2.7161, 2.9575, 2.7803, 2.3992, 2.5971, 2.7305, 2.7181, 2.7157,\n",
              "                      2.7102, 2.7734, 2.7461, 2.9594, 3.0107, 3.0949, 2.8046, 2.4984, 2.6979,\n",
              "                      2.6503, 2.7350, 3.1247, 3.0005, 2.6669, 2.9169, 2.6966, 2.9773, 2.7910,\n",
              "                      2.7731, 2.5301, 2.5685, 2.7789, 2.7077, 2.5905, 2.7430, 2.9340, 2.5888,\n",
              "                      2.6735, 3.0876, 3.2081], device='cuda:0')),\n",
              "             ('decoder.block.7.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0504,  0.0013, -0.0269,  ...,  0.0096,  0.0029,  0.0317],\n",
              "                      [ 0.0093,  0.0110,  0.0304,  ...,  0.0597,  0.0226,  0.0037],\n",
              "                      [-0.0257, -0.0342,  0.0718,  ...,  0.0389,  0.0204, -0.0046],\n",
              "                      ...,\n",
              "                      [-0.0497, -0.0274,  0.0031,  ...,  0.0290,  0.0102, -0.0343],\n",
              "                      [-0.0610, -0.0199, -0.0132,  ..., -0.0021,  0.0042, -0.0326],\n",
              "                      [-0.0171,  0.0258, -0.0638,  ...,  0.0234, -0.0366,  0.0082]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.2334, -0.3940,  0.0155,  ..., -0.1261,  0.3654, -0.1255],\n",
              "                      [-0.1224, -0.0986,  0.0255,  ...,  0.0377,  0.0717,  0.0983],\n",
              "                      [-0.3040,  0.3558, -0.1698,  ...,  0.0168,  0.1555,  0.1053],\n",
              "                      ...,\n",
              "                      [ 0.0176, -0.4351, -0.0085,  ...,  0.0753,  0.0235, -0.3065],\n",
              "                      [-0.2826, -0.0424, -0.1510,  ..., -0.0834, -0.3645,  0.1117],\n",
              "                      [-0.3821, -0.8431, -0.0163,  ...,  0.0595, -0.3631, -0.0312]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-0.3525,  0.0976, -0.5290,  ..., -1.0583, -0.1993,  0.7824],\n",
              "                      [-0.3263, -0.1092, -0.5547,  ...,  1.4947, -1.1229, -0.7554],\n",
              "                      [-1.6547,  0.7535,  0.5359,  ..., -1.5785, -0.8707,  0.0751],\n",
              "                      ...,\n",
              "                      [ 0.0890, -0.0866,  0.8440,  ...,  0.0128,  0.2261, -0.2720],\n",
              "                      [-0.6118, -0.0814,  0.1522,  ..., -0.3852, -0.2604, -0.3209],\n",
              "                      [-0.1696, -0.3773,  0.7128,  ...,  0.6689, -0.4694,  0.5937]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.6720, -0.4314, -2.1729,  ...,  0.7349, -1.0466, -0.5869],\n",
              "                      [-0.5747, -0.8954,  0.9704,  ...,  0.3192, -0.3553, -0.3546],\n",
              "                      [-1.5529,  0.7938,  0.3383,  ...,  0.4064,  0.5850, -0.2582],\n",
              "                      ...,\n",
              "                      [-0.9060,  0.1653, -3.8105,  ...,  0.0673, -1.6534, -0.8393],\n",
              "                      [-3.1765,  0.5396, -0.1849,  ..., -0.3544, -0.1482, -1.1934],\n",
              "                      [-0.2465,  1.2892,  1.2941,  ...,  0.9718, -1.2880,  0.9241]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.0.layer_norm.weight',\n",
              "              tensor([ 2.1075e-01,  1.6590e-01,  1.7273e-01,  1.7599e-01,  2.5138e-01,\n",
              "                       1.9255e-01,  2.3492e-01,  2.5712e-01,  1.9378e-01,  2.4955e-01,\n",
              "                      -1.7317e-01,  2.4624e-01,  1.2508e-01,  1.6734e-01,  2.4204e-01,\n",
              "                       2.5032e-01,  1.9219e-01,  2.1392e-01,  1.8819e-01,  2.5117e-01,\n",
              "                       2.2844e-01,  2.5994e-01,  2.2621e-01,  2.4477e-01,  2.4435e-01,\n",
              "                       2.0628e-01,  2.3712e-01,  1.6046e-01,  2.5294e-01,  2.5981e-01,\n",
              "                       2.6636e-01,  2.2334e-01,  2.4951e-01,  2.5192e-01,  2.3403e-01,\n",
              "                       2.1289e-01,  2.3354e-01,  2.1109e-01,  2.4301e-01,  2.4843e-01,\n",
              "                       2.1717e-01,  2.2152e-01,  2.2060e-01,  2.3723e-01,  2.0764e-01,\n",
              "                       2.0801e-01,  2.4289e-01,  2.4290e-01,  2.5660e-01,  2.5566e-01,\n",
              "                       2.2829e-01,  2.1786e-01,  2.3014e-01,  2.4681e-01,  2.9985e-01,\n",
              "                       1.9514e-01,  1.9180e-01,  2.4703e-01,  2.4946e-01,  2.3004e-01,\n",
              "                       2.2760e-01,  2.8152e-01,  2.4082e-01,  2.3298e-01,  2.5457e-01,\n",
              "                       2.2176e-01,  2.3518e-01,  2.2904e-01,  1.9128e-01,  2.4011e-01,\n",
              "                       2.5068e-01,  2.5107e-01,  2.5379e-01,  2.3941e-01,  2.4474e-01,\n",
              "                       2.3728e-01,  1.6460e-01,  2.1229e-01,  2.4914e-01,  2.4450e-01,\n",
              "                       2.6173e-01,  2.1456e-01,  2.5836e-01,  1.8352e-01,  2.5979e-01,\n",
              "                       2.5930e-01, -7.3793e-02,  2.4956e-01,  2.6055e-01,  2.3669e-01,\n",
              "                       2.1680e-01,  2.3068e-01,  2.2940e-01,  1.9664e-01,  2.4204e-01,\n",
              "                       2.5364e-01,  2.4873e-01,  2.3782e-01,  2.8306e-01,  2.3725e-01,\n",
              "                       2.1340e-01,  2.1129e-01,  1.5032e-01,  2.3995e-01,  2.4530e-01,\n",
              "                       1.9268e-01,  2.5131e-01,  2.4379e-01,  2.5950e-01,  2.5510e-01,\n",
              "                       2.6581e-01,  2.5069e-01,  2.1093e-01,  2.5050e-01,  2.3738e-01,\n",
              "                       2.5094e-01,  2.3969e-01,  2.2178e-01,  3.9731e-02,  2.4192e-01,\n",
              "                       2.5103e-01,  2.5400e-01,  2.1403e-01,  2.4264e-01,  2.5700e-01,\n",
              "                       2.2991e-01,  2.2973e-01,  2.1269e-01,  2.1269e-01,  1.7213e-01,\n",
              "                       1.6661e-01,  2.2894e-01,  2.4488e-01,  2.3040e-01,  1.4063e-01,\n",
              "                       2.0909e-01,  2.2756e-01,  2.1973e-01,  2.1950e-01,  1.8841e-01,\n",
              "                       2.1057e-01,  2.5047e-01,  2.1621e-01,  2.3544e-01,  2.0849e-01,\n",
              "                       1.9688e-01,  2.4445e-01,  2.1243e-01,  2.4702e-01,  1.9878e-01,\n",
              "                       2.6076e-01,  2.3589e-01,  2.7077e-01,  2.0976e-01,  2.4924e-01,\n",
              "                       2.6914e-01,  2.3661e-01,  2.6811e-01,  8.4245e-02,  1.4497e-01,\n",
              "                       2.3679e-01,  2.0971e-01,  1.9586e-01,  2.1813e-01,  2.2639e-01,\n",
              "                       1.7811e-01,  2.6822e-01,  1.8742e-01,  1.7630e-01,  2.5442e-01,\n",
              "                       1.4240e-01,  2.3991e-01,  2.6167e-01,  2.3279e-01,  2.5058e-01,\n",
              "                       2.4962e-01,  2.3366e-01,  2.3932e-01,  1.2248e-01,  2.1703e-01,\n",
              "                       2.3748e-01,  2.3659e-01,  2.5561e-01,  2.7083e-01,  1.9415e-01,\n",
              "                       2.4406e-01,  2.5171e-01,  5.2200e-02,  2.3621e-01, -1.7215e-01,\n",
              "                       2.3256e-01,  2.2497e-01,  2.4158e-01,  2.4147e-01,  2.4630e-01,\n",
              "                       2.1517e-01,  2.4086e-01,  2.5971e-01,  2.6271e-01,  2.1370e-01,\n",
              "                       2.4922e-01,  2.3350e-01,  2.4269e-01,  2.2029e-01,  2.4831e-01,\n",
              "                       1.8140e-01,  2.2381e-01,  2.3364e-01,  2.2515e-01,  2.6738e-01,\n",
              "                       2.1681e-01,  1.8963e-01,  2.1950e-01,  2.4354e-01,  2.5398e-01,\n",
              "                       2.4843e-01,  2.2821e-01,  2.4051e-01,  2.4176e-01,  1.5355e-02,\n",
              "                       1.7144e-01,  2.5046e-01,  2.4371e-01,  2.3814e-01,  2.0008e-01,\n",
              "                       2.5596e-01,  4.5621e-01,  2.5080e-01,  2.3103e-01,  2.6767e-01,\n",
              "                       2.3477e-01,  2.2505e-01,  2.2350e-01,  2.6706e-01,  2.3489e-01,\n",
              "                       2.0553e-01,  1.9945e-01,  2.1835e-01,  1.6130e-01,  2.3235e-01,\n",
              "                      -2.1426e-01,  2.3529e-01,  2.2660e-01,  2.2659e-01,  2.5481e-01,\n",
              "                       2.3520e-01,  2.4261e-01,  2.2420e-01,  2.4227e-01,  2.4284e-01,\n",
              "                       2.1713e-01,  2.3149e-01,  2.3443e-01,  2.5373e-01,  2.4278e-01,\n",
              "                       2.2405e-01,  2.7571e-01, -1.6654e-01,  2.2692e-01,  2.2660e-01,\n",
              "                       2.3962e-01,  1.7604e-01,  2.5932e-01,  2.5642e-01,  2.3711e-01,\n",
              "                       2.4716e-01,  2.4996e-01,  2.5754e-01,  2.4534e-01,  2.3705e-01,\n",
              "                       2.3093e-01,  2.0535e-01,  2.4762e-01,  2.2859e-01,  1.3116e-01,\n",
              "                       2.4345e-01,  2.4027e-01,  2.2719e-01,  2.3155e-01,  1.8160e-01,\n",
              "                       4.3973e-02,  1.8319e-01,  2.5784e-01,  2.3996e-01,  2.3586e-01,\n",
              "                       2.3063e-01,  2.3074e-01,  2.8247e-01,  1.7974e-01,  1.8683e-01,\n",
              "                       2.2863e-01,  2.3585e-01,  2.3513e-01,  2.5758e-01,  2.2262e-01,\n",
              "                       2.5611e-01,  1.7394e-01,  2.6547e-01,  2.3529e-01,  2.6182e-01,\n",
              "                       2.3880e-01,  2.4364e-01, -4.1906e-02,  2.2666e-01,  2.5006e-01,\n",
              "                       2.5511e-01,  2.0203e-01,  2.3916e-01,  2.3300e-01,  2.3847e-01,\n",
              "                       2.5129e-01,  2.4179e-01,  2.3085e-01,  2.1244e-01,  2.6982e-01,\n",
              "                       2.3364e-01,  2.4403e-01,  2.2967e-01,  2.6060e-01,  2.4411e-01,\n",
              "                       2.4758e-01,  2.4430e-01,  1.9883e-01,  2.5771e-01,  2.2513e-01,\n",
              "                       2.2484e-01,  2.2308e-01,  2.3805e-01,  2.2778e-01,  2.3614e-01,\n",
              "                       2.3892e-01,  2.0435e-01,  2.3494e-01,  2.2572e-01,  2.3401e-01,\n",
              "                       2.4174e-01,  2.6073e-01,  2.8438e-01,  2.1321e-01,  1.6195e-01,\n",
              "                       2.1329e-01,  2.3935e-01,  2.4797e-01,  2.3827e-01,  2.4239e-01,\n",
              "                       2.2402e-01,  2.6664e-01,  2.0517e-01,  1.5740e-01,  2.3555e-01,\n",
              "                       2.3657e-01,  2.4237e-01,  2.0710e-01,  2.2412e-01,  2.1478e-01,\n",
              "                       2.7699e-01,  2.5111e-01,  6.7004e-02,  2.5647e-01,  2.3703e-01,\n",
              "                       2.4809e-01,  1.9791e-01,  1.5564e-01,  2.1373e-01,  2.4920e-01,\n",
              "                       2.6094e-01,  2.1733e-01,  2.2285e-01,  2.3944e-01,  2.1061e-01,\n",
              "                       2.5079e-01,  2.4316e-01,  2.4753e-01,  2.3348e-01,  2.4156e-01,\n",
              "                       2.4967e-01,  2.4619e-01,  2.7083e-01,  2.5864e-01,  1.8368e-01,\n",
              "                       2.3577e-01,  2.2143e-01, -1.5728e-01,  2.3414e-01,  2.7630e-01,\n",
              "                       2.5693e-01,  2.5646e-01,  2.4820e-01,  2.3354e-01,  2.5692e-01,\n",
              "                       2.5551e-01,  2.1140e-01,  1.9753e-01,  2.0029e-01,  2.3824e-01,\n",
              "                       2.4895e-01,  2.6649e-01,  2.2552e-01,  2.3638e-01,  2.3951e-01,\n",
              "                       2.4195e-01,  2.3029e-01,  2.5565e-01,  2.6293e-01,  2.2071e-01,\n",
              "                       2.3802e-01,  1.7320e-01,  2.2838e-01,  2.4647e-01,  2.4649e-01,\n",
              "                       2.4034e-01,  2.2651e-01,  2.4011e-01,  2.1999e-01,  2.4877e-01,\n",
              "                       2.4021e-01,  2.3616e-01,  2.4486e-01,  3.0601e-01,  2.5802e-01,\n",
              "                      -1.2405e-04,  2.5121e-01,  2.4597e-01,  8.0513e-02,  2.3000e-01,\n",
              "                       2.5957e-01,  1.8620e-01,  2.3838e-01,  2.3217e-01,  1.7907e-01,\n",
              "                       2.3442e-01,  2.3661e-01,  2.4198e-01,  2.1949e-01,  2.2406e-01,\n",
              "                       2.2950e-01,  2.3170e-01,  2.6243e-01,  2.4905e-01,  2.2465e-01,\n",
              "                       2.5545e-01,  2.2495e-01,  2.2021e-01,  2.6328e-01,  2.4609e-01,\n",
              "                       2.2182e-01,  2.3813e-01,  2.5088e-01, -1.2130e-02,  2.4174e-01,\n",
              "                       2.2464e-01,  2.4950e-01,  2.3975e-01,  2.3375e-01,  2.1694e-01,\n",
              "                       2.0353e-01,  1.9897e-01,  4.5935e-01,  2.2265e-01,  2.4861e-01,\n",
              "                       2.4716e-01,  2.4358e-01,  2.4182e-01,  2.1960e-01,  2.2978e-01,\n",
              "                       2.6806e-01,  1.8140e-01,  2.4479e-01,  2.2023e-01,  2.3824e-01,\n",
              "                       2.5510e-01,  2.4288e-01,  1.4688e-01,  2.5780e-01,  2.4507e-01,\n",
              "                       2.4831e-01,  2.2477e-01,  2.8304e-01,  2.4354e-01,  2.3310e-01,\n",
              "                       1.8565e-01,  2.4228e-01,  2.4769e-01,  2.3107e-01,  7.2619e-02,\n",
              "                       2.3476e-01,  2.3223e-01, -3.3197e-02,  2.5082e-01,  2.2896e-01,\n",
              "                       2.5211e-01,  2.4849e-01,  2.3321e-01,  2.4513e-01,  2.3770e-01,\n",
              "                       1.1063e-01,  2.3881e-01,  2.2798e-01,  2.7263e-01,  2.3743e-01,\n",
              "                       2.3346e-01,  2.3326e-01,  2.4464e-01,  2.3937e-01,  2.4768e-01,\n",
              "                       2.3609e-01,  2.4122e-01,  1.9691e-01,  2.4149e-01,  2.4853e-01,\n",
              "                       2.2657e-01,  2.5386e-01,  2.2390e-01,  2.2809e-01,  2.0638e-01,\n",
              "                       2.6230e-01,  2.1669e-01,  2.2017e-01, -1.7475e-01,  2.4352e-01,\n",
              "                       2.2323e-01,  2.2688e-01,  2.3392e-01,  2.5394e-01,  2.4035e-01,\n",
              "                       2.3753e-01,  2.2130e-01,  2.1296e-01,  2.3934e-01,  2.3460e-01,\n",
              "                       2.0544e-01,  2.2249e-01,  2.3187e-01,  2.4261e-01,  2.2453e-01,\n",
              "                       2.6589e-01,  2.3823e-01,  2.3439e-01,  2.3064e-01,  2.1435e-01,\n",
              "                       2.3408e-01,  2.6376e-01,  2.0574e-01,  2.2463e-01,  2.2553e-01,\n",
              "                       2.5858e-01,  2.2223e-01,  2.2997e-01,  2.3526e-01,  2.2100e-01,\n",
              "                       1.9121e-01,  2.0294e-01,  2.3587e-01,  2.0005e-01,  2.4644e-01,\n",
              "                       2.4708e-01,  2.0663e-01,  2.4842e-01,  2.0185e-01,  2.2448e-01,\n",
              "                       2.3534e-01,  2.3181e-01,  1.1298e-01,  2.5330e-01,  2.4938e-01,\n",
              "                       2.3838e-01,  2.4547e-01,  2.3286e-01,  2.1807e-01,  2.4374e-01,\n",
              "                       2.3570e-01,  2.5211e-01,  2.4210e-01,  2.3582e-01,  1.7388e-01,\n",
              "                       2.1833e-01,  2.6336e-01,  2.5110e-01,  2.3742e-01, -4.5162e-04,\n",
              "                       2.1321e-01,  2.5959e-01,  2.4922e-01,  2.3063e-01,  2.3010e-01,\n",
              "                       2.4218e-01,  2.2302e-01,  2.3411e-01,  2.4414e-01,  2.4481e-01,\n",
              "                       2.5120e-01,  2.4863e-01,  2.6701e-01,  2.2350e-01,  2.2762e-01,\n",
              "                       2.6197e-01,  1.9986e-01,  2.3664e-01,  2.1360e-01,  2.3599e-01,\n",
              "                       1.9305e-01,  2.5043e-01,  2.3700e-01,  2.1085e-01,  2.3269e-01,\n",
              "                       2.5194e-01,  2.6035e-01,  1.5714e-01,  2.4690e-01,  2.2856e-01,\n",
              "                       2.1922e-01,  2.4407e-01,  2.3338e-01,  2.3800e-01,  2.1584e-01,\n",
              "                       2.5640e-01,  2.4253e-01,  2.6411e-01,  2.5337e-01,  2.5171e-01,\n",
              "                       2.2701e-01,  2.4441e-01,  2.4989e-01,  1.8518e-01,  2.1647e-01,\n",
              "                       2.3053e-01,  2.2706e-01,  2.1525e-01,  2.4548e-01,  2.2533e-01,\n",
              "                       2.1086e-01,  2.3702e-01,  2.1036e-01,  2.3675e-01,  2.4344e-01,\n",
              "                       2.4316e-01,  2.1867e-01,  2.2260e-01,  2.3914e-01,  2.3869e-01,\n",
              "                       1.7859e-01,  2.1825e-01,  2.4754e-01,  2.5468e-01,  1.6097e-01,\n",
              "                       2.1774e-01,  1.6080e-01,  2.5456e-01,  2.3155e-01,  2.7813e-01,\n",
              "                       1.6677e-01,  2.7127e-01,  2.2486e-01,  2.2123e-01,  2.5766e-01,\n",
              "                       1.4331e-01,  2.2796e-01,  1.9210e-01,  2.2723e-01,  2.1631e-01,\n",
              "                       2.6381e-01,  2.1418e-01,  2.1990e-01,  2.5439e-01,  2.2632e-01,\n",
              "                       2.2997e-01,  2.5845e-01,  2.6120e-01,  2.3986e-01,  2.5383e-01,\n",
              "                       2.4273e-01,  2.4319e-01,  2.5147e-01,  1.9795e-01,  2.4031e-01,\n",
              "                       2.5346e-01,  2.2846e-01,  2.5892e-01,  2.2937e-01,  2.4923e-01,\n",
              "                       2.4195e-01,  2.3402e-01,  2.1872e-01,  2.3014e-01,  2.2750e-01,\n",
              "                       2.1418e-01,  2.3914e-01,  2.1982e-01,  2.6596e-01,  2.3128e-01,\n",
              "                       2.6879e-01,  2.3068e-01,  1.8292e-01,  2.2872e-01,  2.4538e-01,\n",
              "                       2.3598e-01,  2.6340e-01,  2.6109e-01,  2.5491e-01,  2.2406e-01,\n",
              "                       2.4202e-01,  2.4617e-01,  2.3102e-01,  1.2118e-01,  2.4718e-01,\n",
              "                       2.4381e-01,  2.5099e-01,  1.6809e-01,  1.8600e-01,  2.4044e-01,\n",
              "                       2.2818e-01,  2.3820e-01,  1.9254e-01,  2.1939e-01,  1.2520e-01,\n",
              "                       2.7125e-01,  2.2478e-01,  2.3529e-01,  2.1609e-01,  2.0008e-01,\n",
              "                       2.4581e-01,  2.1231e-01,  1.9855e-01,  2.7276e-01,  2.3278e-01,\n",
              "                       1.4261e-01,  2.0815e-01,  2.3337e-01,  2.3119e-01,  2.5080e-01,\n",
              "                       2.5686e-01,  2.4130e-01,  2.3037e-01,  9.4608e-02,  2.3999e-01,\n",
              "                       2.3908e-01,  2.4337e-01,  2.1247e-01,  2.3239e-01,  2.0341e-01,\n",
              "                       2.2892e-01,  1.4591e-01,  2.5218e-01,  1.8520e-01,  2.6108e-01,\n",
              "                       2.1325e-01,  1.8524e-01,  2.4072e-01,  2.2243e-01,  1.5942e-01,\n",
              "                       2.2038e-01,  2.1298e-01,  1.8194e-01,  2.3903e-01,  2.4472e-01,\n",
              "                       2.5838e-01,  2.3099e-01,  2.2138e-01,  1.4268e-01,  2.3730e-01,\n",
              "                       1.9796e-01,  2.0216e-01,  2.2276e-01,  2.3883e-01,  2.1630e-01,\n",
              "                       2.2774e-01,  2.6976e-01,  2.1480e-01], device='cuda:0')),\n",
              "             ('decoder.block.7.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0698,  0.0009, -0.0207,  ...,  0.0850,  0.0120,  0.0142],\n",
              "                      [ 0.0755,  0.0151, -0.0085,  ...,  0.0329,  0.0477, -0.0374],\n",
              "                      [ 0.0100, -0.0047, -0.0506,  ...,  0.0247, -0.0323, -0.0483],\n",
              "                      ...,\n",
              "                      [ 0.0337,  0.0079,  0.0216,  ...,  0.0122,  0.0789, -0.0344],\n",
              "                      [-0.0334, -0.0417,  0.0256,  ..., -0.0568, -0.0027, -0.0129],\n",
              "                      [-0.0236,  0.0556,  0.0452,  ...,  0.0122, -0.0603, -0.0150]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[ 0.4814, -0.4965,  0.3838,  ..., -0.1385, -0.0732,  0.2462],\n",
              "                      [-0.3968, -0.2419, -0.5746,  ...,  0.0893,  0.8013, -0.1434],\n",
              "                      [-0.2414,  0.5204, -0.2486,  ...,  0.3971, -0.0915,  0.8750],\n",
              "                      ...,\n",
              "                      [-0.4633, -0.4929,  0.7198,  ...,  0.5667,  0.2542, -0.4598],\n",
              "                      [-0.4249,  0.0039,  0.2246,  ..., -0.1385, -0.2082, -0.1247],\n",
              "                      [-0.2156, -0.0586,  0.4379,  ..., -0.2667, -0.2413,  0.2800]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.2054,  0.1725, -0.4180,  ..., -0.5485,  0.8532,  0.4833],\n",
              "                      [ 0.0184, -0.0935,  0.9095,  ..., -0.5949, -0.1520,  0.2130],\n",
              "                      [-0.6386, -0.0678,  0.7528,  ..., -0.3590,  0.2029,  0.7175],\n",
              "                      ...,\n",
              "                      [-0.6879, -0.3161, -0.6050,  ...,  0.7860, -0.1230, -0.4099],\n",
              "                      [ 1.0134,  0.3642,  0.4703,  ..., -0.4780,  0.5764, -0.1049],\n",
              "                      [-0.0262,  1.2661,  0.6726,  ...,  0.4155, -0.6590, -0.1847]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[-0.1002, -0.3217,  0.0744,  ..., -0.9469,  0.9599,  0.8479],\n",
              "                      [-0.4506,  0.6178, -0.0168,  ...,  0.1064, -0.2706,  1.1392],\n",
              "                      [ 0.1740, -0.1958, -0.2562,  ...,  0.7874,  0.5664,  0.9615],\n",
              "                      ...,\n",
              "                      [-0.3718,  0.3944,  0.9375,  ..., -0.3329,  0.2095,  0.3822],\n",
              "                      [ 1.3882,  0.0498, -0.4929,  ..., -0.7790, -0.5430, -0.8020],\n",
              "                      [ 0.5630, -0.2126,  0.4983,  ...,  0.3587,  0.7370, -1.3562]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.1.layer_norm.weight',\n",
              "              tensor([ 6.1559e-02,  5.5761e-02,  5.6495e-02, -5.5009e-02,  4.9381e-02,\n",
              "                       5.6759e-02,  7.0496e-02,  7.3514e-02,  5.1386e-02,  6.5474e-02,\n",
              "                       6.0089e-02,  6.9846e-02,  5.1724e-02,  5.3188e-02,  4.7379e-02,\n",
              "                       6.3704e-02,  6.4720e-02,  5.5371e-02,  5.3279e-02,  7.3619e-02,\n",
              "                       5.7807e-02,  7.0061e-02,  6.0714e-02,  6.5629e-02,  6.5525e-02,\n",
              "                       5.0215e-02,  5.5293e-02,  3.7822e-02,  6.3814e-02,  5.3575e-02,\n",
              "                       7.2246e-02,  6.4671e-02,  6.2363e-02,  6.7216e-02,  6.2064e-02,\n",
              "                       6.0693e-02,  7.5408e-02,  6.5068e-02,  6.3820e-02,  6.8207e-02,\n",
              "                       6.0289e-02,  5.4466e-02,  5.8877e-02,  5.8423e-02,  5.2688e-02,\n",
              "                       6.4410e-02,  7.7505e-02,  7.3076e-02,  6.4427e-02,  6.3501e-02,\n",
              "                       6.2308e-02,  6.8427e-02,  5.6927e-02,  6.7812e-02,  6.7871e-02,\n",
              "                       4.8435e-02,  6.0077e-02,  6.5045e-02,  5.5962e-02,  7.0052e-02,\n",
              "                       5.0505e-02,  7.1132e-02,  5.7067e-02,  6.1334e-02,  6.0037e-02,\n",
              "                       9.9121e-02,  5.1506e-02,  6.0362e-02,  3.7025e-02,  5.9189e-02,\n",
              "                       6.0991e-02,  7.7354e-02,  6.9399e-02,  6.4545e-02,  6.2241e-02,\n",
              "                       5.3780e-02, -4.2096e-02,  5.0595e-02,  6.3819e-02,  5.9795e-02,\n",
              "                       6.1773e-02,  6.1484e-02,  5.8766e-02,  5.8601e-02,  6.9161e-02,\n",
              "                       6.1297e-02, -1.3963e-02,  7.2868e-02,  6.2511e-02,  6.1836e-02,\n",
              "                       5.3323e-02,  7.0001e-02,  6.4423e-02,  5.8574e-02,  6.0089e-02,\n",
              "                       6.6769e-02,  5.9755e-02,  7.1886e-02,  5.9262e-02,  6.1693e-02,\n",
              "                       3.8119e-02,  4.6571e-02,  3.3220e-02,  5.0366e-02,  5.2079e-02,\n",
              "                      -4.6334e-02,  7.2714e-02,  6.2528e-02,  6.8046e-02,  6.8965e-02,\n",
              "                       6.5871e-02,  6.7627e-02,  3.5561e-02,  5.8944e-02,  5.0982e-02,\n",
              "                       6.9408e-02,  5.7625e-02,  4.6079e-02, -7.0214e-05,  6.7598e-02,\n",
              "                       6.6516e-02,  7.2560e-02,  4.9906e-02,  5.6681e-02,  6.9557e-02,\n",
              "                       6.0189e-02,  6.9188e-02,  4.4958e-02,  5.7736e-02, -4.0151e-02,\n",
              "                      -3.5941e-02,  5.4103e-02,  7.4690e-02,  5.5260e-02,  4.0739e-02,\n",
              "                       6.1070e-02,  5.3195e-02,  6.1648e-02,  4.9348e-02,  4.5908e-02,\n",
              "                       5.2699e-02,  7.0163e-02, -5.4474e-02,  5.4341e-02,  5.1477e-02,\n",
              "                       5.4099e-02,  6.6476e-02,  4.6147e-02,  7.2510e-02,  4.5921e-02,\n",
              "                       7.4718e-02,  4.7952e-02,  6.9009e-02,  5.8001e-02,  7.0551e-02,\n",
              "                       6.6920e-02,  4.9022e-02,  7.2462e-02,  9.8772e-02,  4.0700e-02,\n",
              "                       6.7916e-02,  4.1562e-02,  5.4781e-02,  5.2047e-02,  5.8174e-02,\n",
              "                       4.4295e-02,  7.1264e-02,  5.2770e-02,  5.4652e-02,  6.8314e-02,\n",
              "                       3.1208e-02,  5.3558e-02,  6.7378e-02,  4.9697e-02,  6.3639e-02,\n",
              "                       5.2487e-02,  4.9998e-02,  6.8548e-02,  3.1507e-02,  5.9580e-02,\n",
              "                       6.5715e-02,  6.4170e-02,  6.1768e-02,  5.8813e-02,  4.7494e-02,\n",
              "                       5.8513e-02,  5.6604e-02,  6.2667e-02,  5.8211e-02, -4.8764e-02,\n",
              "                       7.4999e-02,  6.6142e-02,  6.5078e-02,  5.4312e-02,  5.8607e-02,\n",
              "                       5.7482e-02,  6.6928e-02,  6.6564e-02,  7.5287e-02,  5.9818e-02,\n",
              "                       5.7246e-02,  5.1735e-02,  6.3870e-02,  7.3436e-02,  6.1126e-02,\n",
              "                      -4.8014e-02,  7.9178e-02,  6.8191e-02,  5.2044e-02,  7.1289e-02,\n",
              "                       8.7630e-02,  4.1796e-02,  5.0724e-02,  6.0435e-02,  6.9739e-02,\n",
              "                       6.1458e-02,  5.1525e-02,  6.2634e-02,  6.3551e-02,  1.3027e-03,\n",
              "                       4.2626e-02,  7.1886e-02,  6.0105e-02,  6.9752e-02,  5.4789e-02,\n",
              "                       6.5548e-02,  1.3791e-01,  7.2269e-02,  5.8581e-02,  7.0124e-02,\n",
              "                       6.5810e-02,  5.4608e-02,  5.5836e-02,  6.6869e-02,  6.3457e-02,\n",
              "                       5.6297e-02,  4.4225e-02,  5.3364e-02, -4.2397e-02,  6.3443e-02,\n",
              "                       5.0457e-02,  6.9090e-02,  6.3287e-02,  6.3999e-02,  6.3510e-02,\n",
              "                       6.0144e-02,  6.9423e-02,  5.9090e-02,  5.6567e-02,  6.0782e-02,\n",
              "                       6.0134e-02,  6.4559e-02,  6.5557e-02,  5.4568e-02,  6.6978e-02,\n",
              "                       5.0333e-02,  6.0333e-02, -3.7225e-02,  7.5344e-02,  6.5741e-02,\n",
              "                       6.1512e-02,  3.8559e-02,  6.1909e-02,  5.2731e-02,  7.2530e-02,\n",
              "                       6.4591e-02,  6.5016e-02,  5.7724e-02,  5.3249e-02,  6.7706e-02,\n",
              "                       5.0969e-02,  5.6039e-02,  5.8644e-02,  6.3121e-02, -3.6746e-02,\n",
              "                       5.3163e-02,  6.5134e-02,  5.4491e-02,  7.6333e-02,  5.2666e-02,\n",
              "                       5.1123e-03,  4.9310e-02,  7.3270e-02,  7.8453e-02,  6.8943e-02,\n",
              "                       6.1913e-02,  5.4035e-02,  6.8710e-02,  4.6892e-02,  4.1056e-02,\n",
              "                       5.1735e-02,  6.5445e-02,  5.4108e-02,  5.8338e-02,  5.6911e-02,\n",
              "                       6.0418e-02,  5.3504e-02,  7.3144e-02,  6.4561e-02,  7.8491e-02,\n",
              "                       5.9075e-02,  6.5337e-02, -1.4330e-02,  4.8783e-02,  4.8000e-02,\n",
              "                       7.2201e-02,  4.7360e-02,  6.0169e-02,  5.7108e-02,  8.0284e-02,\n",
              "                       7.2731e-02,  6.4788e-02,  4.5373e-02,  5.7578e-02,  1.2722e-01,\n",
              "                       5.8342e-02,  8.1516e-02,  6.8360e-02,  6.0219e-02,  6.4224e-02,\n",
              "                       5.5538e-02,  6.3303e-02, -4.7700e-02,  5.9862e-02,  6.7834e-02,\n",
              "                       5.4814e-02,  6.3336e-02,  6.1474e-02,  6.6263e-02,  4.8622e-02,\n",
              "                       5.0778e-02,  5.4368e-02,  6.2008e-02,  6.6567e-02,  5.8299e-02,\n",
              "                       4.6754e-02,  6.1472e-02,  7.9918e-02,  6.3493e-02,  3.4859e-02,\n",
              "                       4.5348e-02,  6.0244e-02,  5.6106e-02,  5.3209e-02,  7.0440e-02,\n",
              "                       5.2813e-02,  6.8875e-02,  4.4196e-02,  5.7191e-02,  5.3689e-02,\n",
              "                       6.0546e-02,  6.0640e-02,  5.1359e-02,  6.3248e-02,  4.9697e-02,\n",
              "                       6.8240e-02,  7.1745e-02, -1.1597e-03,  6.2454e-02, -6.4607e-02,\n",
              "                       7.1741e-02,  5.1616e-02,  4.7583e-02,  5.0644e-02,  6.2872e-02,\n",
              "                       7.3662e-02,  5.7569e-02,  6.6205e-02,  5.4844e-02,  5.2868e-02,\n",
              "                       6.9537e-02,  7.0871e-02,  5.7801e-02,  5.6020e-02,  6.1588e-02,\n",
              "                       6.8234e-02,  4.3969e-02,  6.8655e-02,  7.2006e-02,  4.7374e-02,\n",
              "                       6.9326e-02,  5.4749e-02,  4.5105e-02,  7.1700e-02,  5.9284e-02,\n",
              "                       6.8247e-02,  6.5663e-02,  7.4254e-02,  5.3887e-02,  5.0580e-02,\n",
              "                       6.2064e-02,  5.7142e-02,  5.6761e-02,  4.7762e-02,  6.1747e-02,\n",
              "                       5.3787e-02,  5.9940e-02,  5.6503e-02,  5.9174e-02,  5.0425e-02,\n",
              "                       5.9517e-02,  6.7245e-02,  5.6097e-02,  6.4647e-02,  5.2431e-02,\n",
              "                       6.2434e-02,  5.6557e-02,  5.7300e-02,  5.0154e-02,  5.4667e-02,\n",
              "                       6.3336e-02,  6.4124e-02,  5.7170e-02,  5.7889e-02,  6.5488e-02,\n",
              "                       7.2277e-02,  5.6427e-02,  5.8733e-02,  1.6083e-01,  7.0337e-02,\n",
              "                       5.1743e-04,  6.8540e-02,  7.2334e-02, -6.7606e-03,  6.9284e-02,\n",
              "                       5.8064e-02,  4.4270e-02,  6.2970e-02,  5.5847e-02,  4.3456e-02,\n",
              "                       6.1896e-02,  5.2603e-02,  7.0838e-02,  4.2760e-02,  5.7712e-02,\n",
              "                       5.1652e-02,  5.1088e-02,  6.2691e-02,  6.8086e-02,  5.4792e-02,\n",
              "                       6.6865e-02,  5.6153e-02,  4.6613e-02,  6.4295e-02,  5.8643e-02,\n",
              "                       6.1121e-02,  5.9652e-02,  6.9601e-02,  3.9141e-04,  6.9001e-02,\n",
              "                      -6.3441e-02,  6.7993e-02,  6.1483e-02,  6.5701e-02,  4.9556e-02,\n",
              "                       3.9921e-02,  7.2635e-02,  1.1681e-01,  5.2277e-02,  6.2104e-02,\n",
              "                       6.3696e-02,  6.6750e-02,  7.0654e-02,  6.0487e-02,  5.4246e-02,\n",
              "                       7.5582e-02, -4.6609e-02,  6.6604e-02,  5.6596e-02,  6.6504e-02,\n",
              "                       6.3889e-02,  6.8406e-02,  5.5898e-02,  5.8355e-02,  6.4425e-02,\n",
              "                       5.8589e-02,  6.6013e-02,  6.3092e-02,  6.2605e-02,  4.3557e-02,\n",
              "                       4.5026e-02,  5.5961e-02,  6.9812e-02,  6.0060e-02,  5.1863e-04,\n",
              "                       5.2952e-02,  6.3649e-02,  6.2082e-02,  7.2259e-02,  5.2140e-02,\n",
              "                       6.9831e-02,  8.2552e-02,  6.8623e-02,  5.6034e-02,  6.8455e-02,\n",
              "                       5.4760e-02,  5.1193e-02,  4.8240e-02,  5.3543e-02,  5.9708e-02,\n",
              "                       6.7665e-02,  8.7004e-02,  6.0411e-02,  5.7245e-02,  6.7492e-02,\n",
              "                       6.4990e-02,  6.5083e-02,  6.3858e-02,  6.1286e-02,  6.8632e-02,\n",
              "                       6.1678e-02,  6.5529e-02,  4.4712e-02,  6.6849e-02,  6.4170e-02,\n",
              "                       6.4963e-02,  5.8146e-02,  5.2731e-02, -3.5223e-02,  6.6875e-02,\n",
              "                       6.2633e-02,  5.0957e-02,  8.3905e-02,  6.3981e-02,  4.6571e-02,\n",
              "                       5.5183e-02,  6.3896e-02,  6.1269e-02,  6.3556e-02,  7.5254e-02,\n",
              "                       4.9352e-02,  4.7080e-02,  4.9535e-02,  6.1496e-02,  6.3814e-02,\n",
              "                       6.4585e-02,  5.1895e-02,  4.9856e-02,  5.6579e-02,  5.6801e-02,\n",
              "                       6.2547e-02,  6.3504e-02,  6.2466e-02,  4.8316e-02,  5.6348e-02,\n",
              "                       4.8109e-02,  5.6100e-02,  5.9453e-02,  5.7916e-02,  5.5858e-02,\n",
              "                       4.5737e-02,  5.4071e-02,  6.9618e-02,  5.2520e-02,  6.6126e-02,\n",
              "                       6.2840e-02,  4.4869e-02,  5.1165e-02,  5.6538e-02,  5.5934e-02,\n",
              "                       5.8868e-02,  5.9736e-02,  7.3887e-03, -6.5803e-02,  5.9818e-02,\n",
              "                       6.1357e-02,  6.9065e-02,  5.4158e-02,  5.0904e-02,  6.4692e-02,\n",
              "                       7.3771e-02,  5.7719e-02,  5.9742e-02,  4.0174e-02,  4.7380e-02,\n",
              "                       4.7930e-02,  6.7803e-02,  7.2647e-02,  5.7632e-02, -1.7444e-04,\n",
              "                       5.6100e-02,  7.6275e-02,  4.9876e-02,  5.5848e-02,  6.9488e-02,\n",
              "                       7.0393e-02,  5.4712e-02,  4.7757e-02,  4.8995e-02,  5.8509e-02,\n",
              "                       6.5519e-02,  7.7860e-02,  6.4525e-02,  4.7568e-02,  5.1408e-02,\n",
              "                       5.6911e-02,  3.9921e-02,  6.0481e-02, -5.9507e-02,  5.8598e-02,\n",
              "                       5.1521e-02,  7.0370e-02,  7.1615e-02,  6.3451e-02,  5.1681e-02,\n",
              "                       5.8344e-02,  6.8337e-02,  5.2467e-02,  6.6688e-02,  5.8050e-02,\n",
              "                       5.6132e-02,  6.4812e-02,  6.1664e-02,  6.3790e-02,  4.5814e-02,\n",
              "                       6.4650e-02,  4.2479e-02,  1.4278e-01,  6.6146e-02,  6.1534e-02,\n",
              "                       6.9855e-02,  5.1013e-02,  6.5757e-02,  4.0914e-02,  6.4770e-02,\n",
              "                       5.9959e-02,  5.9798e-02,  5.0299e-02,  5.8008e-02,  5.0057e-02,\n",
              "                       6.9895e-02,  6.1907e-02,  5.4425e-02,  5.1520e-02,  6.1341e-02,\n",
              "                       5.5864e-02,  5.5816e-02,  5.2602e-02,  5.6754e-02,  6.4876e-02,\n",
              "                       4.9654e-02,  5.4662e-02,  6.0053e-02,  5.9143e-02,  3.6853e-02,\n",
              "                       5.4153e-02,  3.6002e-02,  5.9245e-02,  6.5049e-02,  6.9496e-02,\n",
              "                       5.6142e-02,  6.9913e-02,  6.3256e-02,  6.3029e-02,  7.6549e-02,\n",
              "                       3.5971e-02,  6.6660e-02,  4.3114e-02,  5.5292e-02,  5.7870e-02,\n",
              "                       5.8474e-02,  4.4527e-02,  5.5999e-02,  7.4960e-02,  6.0644e-02,\n",
              "                       6.5726e-02,  6.2844e-02,  5.9031e-02,  7.6464e-02,  6.3458e-02,\n",
              "                       6.3093e-02,  6.3252e-02,  6.2311e-02,  3.6653e-02,  5.9169e-02,\n",
              "                       6.2918e-02,  6.2822e-02,  5.8428e-02,  4.8907e-02,  6.0279e-02,\n",
              "                       6.3020e-02,  6.9395e-02,  5.5653e-02,  6.1178e-02,  6.2199e-02,\n",
              "                       5.2755e-02,  5.8614e-02,  4.4653e-02,  6.2985e-02,  5.0487e-02,\n",
              "                       7.2376e-02,  5.7514e-02, -4.5155e-02,  6.0680e-02,  6.6747e-02,\n",
              "                       5.2572e-02,  6.9644e-02,  6.6001e-02,  7.3920e-02,  5.8266e-02,\n",
              "                       6.2580e-02,  6.3790e-02,  4.8922e-02,  3.6346e-02,  6.5242e-02,\n",
              "                       6.0449e-02,  5.3440e-02, -4.4771e-02,  6.3201e-02,  6.4297e-02,\n",
              "                       5.3797e-02,  5.4116e-02,  5.5528e-02,  6.6659e-02, -3.1993e-02,\n",
              "                       1.0971e-01,  4.9012e-02,  7.2769e-02,  7.4240e-02, -5.1303e-02,\n",
              "                       6.1596e-02,  4.6422e-02,  5.3017e-02,  6.6364e-02,  6.8774e-02,\n",
              "                       4.2717e-02,  5.4444e-02,  5.5533e-02,  5.5287e-02,  5.9137e-02,\n",
              "                       5.9259e-02,  6.5116e-02,  7.2414e-02,  4.8688e-02,  6.7375e-02,\n",
              "                       6.4688e-02,  7.5663e-02,  5.1008e-02,  4.7527e-02,  5.8868e-02,\n",
              "                       4.7468e-02,  5.0152e-02,  7.1929e-02,  5.8698e-02,  6.3913e-02,\n",
              "                       5.4171e-02,  4.8140e-02,  5.7841e-02,  6.1802e-02,  4.7334e-02,\n",
              "                      -4.9476e-02,  3.8752e-02,  4.9400e-02,  5.7298e-02,  6.5367e-02,\n",
              "                       7.6185e-02,  4.4282e-02,  6.1112e-02,  5.0878e-02,  5.8790e-02,\n",
              "                       5.0838e-02,  5.7427e-02,  4.9266e-02,  5.4483e-02,  5.0809e-02,\n",
              "                       6.2232e-02,  6.9149e-02,  4.0151e-02], device='cuda:0')),\n",
              "             ('decoder.block.7.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.7193,  0.0863,  0.6655,  ...,  0.0461, -0.0868, -0.5711],\n",
              "                      [ 1.1046,  0.2575,  0.0981,  ...,  0.9314,  0.0298,  0.3789],\n",
              "                      [ 0.4644,  0.0847,  0.2453,  ..., -0.7329, -0.1213, -0.0599],\n",
              "                      ...,\n",
              "                      [-0.2501, -0.2341, -0.0915,  ...,  0.3371,  0.2504, -0.0097],\n",
              "                      [ 0.4903,  0.4014, -0.1014,  ..., -0.0356,  0.6331,  0.0651],\n",
              "                      [-0.0821,  0.0560, -0.0026,  ...,  0.6418, -0.5588, -0.4400]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.1317, -0.0865,  0.3036,  ..., -0.0441,  0.0997,  0.2727],\n",
              "                      [-0.2044,  0.0301,  0.0195,  ...,  0.1708,  0.0780, -0.2484],\n",
              "                      [ 0.2337,  0.0726,  0.0884,  ..., -0.1977, -0.0365,  0.1693],\n",
              "                      ...,\n",
              "                      [ 0.6441, -0.1149,  0.5435,  ..., -0.3445, -0.1018,  0.3159],\n",
              "                      [ 0.0328,  0.0160,  0.1086,  ...,  0.1949, -0.0601,  0.3932],\n",
              "                      [-0.2131, -0.0009,  0.0255,  ..., -0.0217,  0.1568,  0.2608]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.7.layer.2.layer_norm.weight',\n",
              "              tensor([ 3.4995e+00,  3.3324e+00,  3.3737e+00,  2.7840e+00,  3.4950e+00,\n",
              "                       3.2732e+00,  3.2952e+00,  3.8812e+00,  3.1733e+00,  3.4297e+00,\n",
              "                       3.8618e+00,  3.4880e+00,  4.0861e+00,  3.8178e+00,  3.4311e+00,\n",
              "                       3.8619e+00,  3.3454e+00,  2.9828e+00,  3.4914e+00,  3.6473e+00,\n",
              "                       3.4960e+00,  3.4754e+00,  3.5019e+00,  3.3754e+00,  3.4908e+00,\n",
              "                       3.2109e+00,  3.3538e+00,  3.6004e+00,  3.5406e+00,  3.5141e+00,\n",
              "                       3.6118e+00,  4.3012e+00,  3.6346e+00,  3.2857e+00,  3.8705e+00,\n",
              "                       3.4891e+00,  3.5667e+00,  3.3533e+00,  3.3089e+00,  3.7399e+00,\n",
              "                       3.2254e+00,  3.3658e+00,  3.4142e+00,  3.4924e+00,  3.5577e+00,\n",
              "                       3.5531e+00,  3.4677e+00,  3.4264e+00,  3.6078e+00,  3.4152e+00,\n",
              "                       3.2528e+00,  3.3702e+00,  3.6884e+00,  3.3844e+00,  4.5944e+00,\n",
              "                       3.6251e+00,  3.5664e+00,  3.4124e+00,  3.4564e+00,  3.5717e+00,\n",
              "                       3.4074e+00,  3.5577e+00,  3.5290e+00,  3.2602e+00,  3.4930e+00,\n",
              "                       4.2881e+00,  3.4986e+00,  3.5862e+00,  4.0860e+00,  3.3986e+00,\n",
              "                       3.5341e+00,  3.5700e+00,  3.4028e+00,  3.3497e+00,  3.6831e+00,\n",
              "                       3.4066e+00,  3.4702e+00,  3.5466e+00,  3.5762e+00,  3.4877e+00,\n",
              "                       3.4628e+00,  3.2513e+00,  3.3383e+00,  3.2945e+00,  3.4358e+00,\n",
              "                       3.4849e+00,  1.8560e+00,  3.5714e+00,  3.5361e+00,  3.6368e+00,\n",
              "                       3.2550e+00,  3.2302e+00,  3.3687e+00,  3.4394e+00,  3.6472e+00,\n",
              "                       3.6430e+00,  3.4465e+00,  3.4173e+00,  3.4953e+00,  3.3593e+00,\n",
              "                       3.8192e+00,  3.3601e+00,  4.3147e+00,  3.4306e+00,  3.3815e+00,\n",
              "                       3.1591e+00,  3.4346e+00,  3.3639e+00,  3.2619e+00,  3.5197e+00,\n",
              "                       3.4852e+00,  3.5291e+00,  3.4629e+00,  3.4228e+00,  3.3612e+00,\n",
              "                       3.3700e+00,  3.4515e+00,  3.6243e+00, -3.3018e-02,  3.3834e+00,\n",
              "                       3.4803e+00,  3.0649e+00,  3.4089e+00,  3.3917e+00,  3.4817e+00,\n",
              "                       3.2073e+00,  3.4901e+00,  3.2575e+00,  3.6972e+00,  3.5945e+00,\n",
              "                       4.4158e+00,  3.3721e+00,  3.5591e+00,  3.4426e+00,  2.8057e+00,\n",
              "                       3.2771e+00,  3.4743e+00,  3.4516e+00,  3.3175e+00,  3.4883e+00,\n",
              "                       3.5877e+00,  3.5025e+00,  3.5951e+00,  3.5853e+00,  3.3770e+00,\n",
              "                       3.3981e+00,  3.2890e+00,  3.2846e+00,  3.4472e+00,  3.4789e+00,\n",
              "                       3.4841e+00,  3.3288e+00,  3.4697e+00,  3.2239e+00,  3.5075e+00,\n",
              "                       3.4756e+00,  3.4249e+00,  3.6117e+00,  2.8839e+00,  3.3344e+00,\n",
              "                       3.2040e+00,  3.3690e+00,  3.3996e+00,  3.6413e+00,  3.2398e+00,\n",
              "                       3.5545e+00,  3.8274e+00,  3.4750e+00,  3.8742e+00,  3.2802e+00,\n",
              "                       4.0683e+00,  3.3469e+00,  3.2494e+00,  3.2507e+00,  3.4127e+00,\n",
              "                       3.2794e+00,  3.2809e+00,  3.1733e+00,  3.6138e+00,  3.0627e+00,\n",
              "                       3.4579e+00,  3.6908e+00,  3.4884e+00,  3.5358e+00,  3.9471e+00,\n",
              "                       3.5443e+00,  3.2888e+00,  1.9213e+00,  3.3795e+00,  3.1810e+00,\n",
              "                       3.3447e+00,  3.2571e+00,  3.2608e+00,  3.5435e+00,  3.1126e+00,\n",
              "                       3.3326e+00,  3.3389e+00,  3.5163e+00,  3.7484e+00,  3.1753e+00,\n",
              "                       3.4899e+00,  3.3367e+00,  3.5709e+00,  3.3561e+00,  3.4655e+00,\n",
              "                       3.2142e+00,  3.2670e+00,  3.4049e+00,  3.2393e+00,  3.6210e+00,\n",
              "                       3.4408e+00,  3.6219e+00,  3.2484e+00,  3.4741e+00,  3.4068e+00,\n",
              "                       3.6502e+00,  3.7687e+00,  3.3168e+00,  3.5426e+00,  8.6343e-01,\n",
              "                       3.8745e+00,  3.3059e+00,  3.4342e+00,  3.2632e+00,  3.4546e+00,\n",
              "                       3.3993e+00,  2.6746e+00,  3.4362e+00,  3.4671e+00,  3.4990e+00,\n",
              "                       3.3778e+00,  3.6471e+00,  3.2161e+00,  3.5337e+00,  3.4656e+00,\n",
              "                       3.4411e+00,  3.6816e+00,  3.3250e+00,  3.9108e+00,  3.6863e+00,\n",
              "                       5.0068e+00,  3.5108e+00,  3.3454e+00,  3.3041e+00,  3.5772e+00,\n",
              "                       3.2748e+00,  3.2573e+00,  3.5195e+00,  3.3285e+00,  3.4692e+00,\n",
              "                       3.4040e+00,  3.4319e+00,  3.6118e+00,  3.4530e+00,  3.4101e+00,\n",
              "                       3.1590e+00,  3.5517e+00,  3.6493e+00,  3.4336e+00,  3.5173e+00,\n",
              "                       3.7279e+00,  3.8431e+00,  3.5139e+00,  3.6492e+00,  3.4241e+00,\n",
              "                       3.6894e+00,  3.3071e+00,  3.3318e+00,  3.3500e+00,  3.6436e+00,\n",
              "                       3.4129e+00,  3.9497e+00,  3.5218e+00,  3.1308e+00,  3.8029e+00,\n",
              "                       3.5160e+00,  3.4792e+00,  3.5386e+00,  3.5390e+00,  3.4467e+00,\n",
              "                       5.9722e-01,  3.6364e+00,  3.5460e+00,  3.3473e+00,  3.4351e+00,\n",
              "                       3.3388e+00,  3.3668e+00,  3.6167e+00,  3.6543e+00,  3.5232e+00,\n",
              "                       3.5126e+00,  3.3168e+00,  3.1750e+00,  3.4829e+00,  3.4135e+00,\n",
              "                       3.4147e+00,  3.2626e+00,  3.5566e+00,  3.7559e+00,  3.9150e+00,\n",
              "                       3.3721e+00,  3.4327e+00,  1.0559e+00,  3.4219e+00,  3.3979e+00,\n",
              "                       3.5253e+00,  3.5762e+00,  3.5351e+00,  3.6929e+00,  3.3355e+00,\n",
              "                       3.1124e+00,  3.4328e+00,  3.3894e+00,  3.2204e+00,  2.9403e+00,\n",
              "                       3.5147e+00,  3.2539e+00,  3.8037e+00,  3.4438e+00,  3.4366e+00,\n",
              "                       3.1873e+00,  3.5064e+00,  3.3542e+00,  3.5011e+00,  3.2021e+00,\n",
              "                       3.3866e+00,  3.4121e+00,  3.4083e+00,  3.5255e+00,  3.4119e+00,\n",
              "                       3.4281e+00,  3.7662e+00,  3.3830e+00,  3.3359e+00,  3.4059e+00,\n",
              "                       3.5301e+00,  3.3756e+00,  3.3887e+00,  3.3104e+00,  3.3606e+00,\n",
              "                       3.7134e+00,  3.3628e+00,  3.3106e+00,  3.2786e+00,  3.4771e+00,\n",
              "                       3.2543e+00,  3.5258e+00,  3.8671e+00,  3.3012e+00,  3.8964e+00,\n",
              "                       3.1681e+00,  3.1431e+00,  3.0970e+00,  3.3907e+00,  3.4526e+00,\n",
              "                       3.4729e+00,  3.6551e+00, -1.2551e-03,  3.5670e+00,  3.8335e+00,\n",
              "                       3.5356e+00,  3.1728e+00,  3.9504e+00,  3.2764e+00,  3.3401e+00,\n",
              "                       3.4824e+00,  3.7482e+00,  3.2931e+00,  3.3622e+00,  3.4626e+00,\n",
              "                       3.7321e+00,  3.3214e+00,  3.4726e+00,  3.4622e+00,  3.5462e+00,\n",
              "                       3.4119e+00,  3.1753e+00,  3.3104e+00,  3.4889e+00,  3.4991e+00,\n",
              "                       3.4537e+00,  3.1695e+00,  3.8756e+00,  3.2790e+00,  3.6883e+00,\n",
              "                       3.6825e+00,  3.5306e+00,  3.7254e+00,  3.3442e+00,  3.3564e+00,\n",
              "                       3.4958e+00,  3.2219e+00,  3.3017e+00,  3.7683e+00,  3.6647e+00,\n",
              "                       3.4269e+00,  3.5448e+00,  3.2037e+00,  3.2964e+00,  3.6751e+00,\n",
              "                       3.3978e+00,  3.6050e+00,  3.3902e+00,  3.6034e+00,  3.1693e+00,\n",
              "                       3.2369e+00,  3.2533e+00,  3.3784e+00,  3.3378e+00,  3.2986e+00,\n",
              "                       3.2934e+00,  3.2410e+00,  3.4270e+00,  3.2613e+00,  3.4485e+00,\n",
              "                       3.3563e+00,  3.4636e+00,  3.4582e+00,  3.0349e+00,  3.3505e+00,\n",
              "                       6.4195e-01,  3.3579e+00,  3.4195e+00,  1.9716e+00,  3.6729e+00,\n",
              "                       3.5208e+00,  3.4834e+00,  3.4465e+00,  3.5247e+00,  3.7210e+00,\n",
              "                       3.3130e+00,  3.4429e+00,  3.6583e+00,  3.1303e+00,  3.2517e+00,\n",
              "                       3.2647e+00,  3.4569e+00,  3.3197e+00,  3.4657e+00,  3.5845e+00,\n",
              "                       3.2949e+00,  3.7092e+00,  3.0244e+00,  3.5604e+00,  3.2507e+00,\n",
              "                       3.1806e+00,  3.2960e+00,  3.3442e+00,  6.6354e-01,  3.4529e+00,\n",
              "                       3.3404e+00,  3.3003e+00,  3.4302e+00,  3.4142e+00,  3.3191e+00,\n",
              "                       3.4662e+00,  3.4700e+00,  3.6515e+00,  3.4465e+00,  3.5015e+00,\n",
              "                       3.4728e+00,  3.4730e+00,  3.6790e+00,  3.6069e+00,  3.4944e+00,\n",
              "                       3.7660e+00,  3.3939e+00,  3.4553e+00,  3.2240e+00,  3.2903e+00,\n",
              "                       3.5153e+00,  3.2771e+00,  3.8647e+00,  3.5432e+00,  3.2985e+00,\n",
              "                       3.3168e+00,  3.2663e+00,  3.5527e+00,  3.5420e+00,  3.2611e+00,\n",
              "                       3.4656e+00,  3.5380e+00,  3.4355e+00,  3.3019e+00,  1.0984e-01,\n",
              "                       3.3564e+00,  3.2404e+00,  6.0728e-01,  3.4777e+00,  3.4149e+00,\n",
              "                       3.6487e+00,  3.4224e+00,  3.4701e+00,  3.4352e+00,  3.7300e+00,\n",
              "                       5.5347e+00,  3.5227e+00,  3.3997e+00,  3.4619e+00,  3.6426e+00,\n",
              "                       3.4267e+00,  3.3097e+00,  3.4479e+00,  3.5383e+00,  3.4725e+00,\n",
              "                       3.5025e+00,  3.6430e+00,  3.3660e+00,  3.4587e+00,  3.4897e+00,\n",
              "                       3.1870e+00,  3.4427e+00,  3.6554e+00,  3.4821e+00,  3.2322e+00,\n",
              "                       3.4252e+00,  3.3006e+00,  3.1246e+00,  3.6492e+00,  3.4490e+00,\n",
              "                       3.3355e+00,  3.2800e+00,  3.5627e+00,  3.3720e+00,  3.5407e+00,\n",
              "                       3.2440e+00,  3.6647e+00,  3.5881e+00,  3.6885e+00,  3.1653e+00,\n",
              "                       3.1530e+00,  3.2953e+00,  3.2816e+00,  3.3409e+00,  3.3645e+00,\n",
              "                       3.5239e+00,  3.5360e+00,  3.3830e+00,  3.3308e+00,  3.4796e+00,\n",
              "                       3.2163e+00,  3.7157e+00,  3.2880e+00,  3.2534e+00,  3.3158e+00,\n",
              "                       3.4516e+00,  3.3537e+00,  3.4799e+00,  3.4250e+00,  3.4317e+00,\n",
              "                       3.3465e+00,  3.5727e+00,  3.4079e+00,  3.6980e+00,  3.3749e+00,\n",
              "                       3.4230e+00,  3.0849e+00,  3.6580e+00,  3.2483e+00,  3.4492e+00,\n",
              "                       3.4472e+00,  3.4845e+00,  8.8777e-01,  4.7405e+00,  3.2759e+00,\n",
              "                       3.6070e+00,  3.4796e+00,  3.0980e+00,  3.5558e+00,  3.3126e+00,\n",
              "                       3.3936e+00,  3.3326e+00,  3.5057e+00,  3.5603e+00,  3.7891e+00,\n",
              "                       3.3763e+00,  3.4100e+00,  3.4233e+00,  3.5646e+00, -3.0670e-02,\n",
              "                       3.3886e+00,  3.5117e+00,  3.3772e+00,  3.4219e+00,  3.7175e+00,\n",
              "                       3.3585e+00,  3.4543e+00,  3.5877e+00,  3.4683e+00,  3.4229e+00,\n",
              "                       3.4876e+00,  3.4749e+00,  3.5365e+00,  3.3707e+00,  3.1978e+00,\n",
              "                       3.4089e+00,  3.8499e+00,  3.5542e+00,  4.6283e+00,  3.6700e+00,\n",
              "                       3.1323e+00,  3.4140e+00,  3.3201e+00,  3.1780e+00,  3.6131e+00,\n",
              "                       3.2688e+00,  3.2613e+00,  3.7245e+00,  3.6188e+00,  3.5931e+00,\n",
              "                       3.3864e+00,  3.4005e+00,  3.4906e+00,  3.3431e+00,  3.3373e+00,\n",
              "                       3.5611e+00,  3.4569e+00,  3.0758e+00,  3.3855e+00,  3.3309e+00,\n",
              "                       3.2754e+00,  3.1438e+00,  3.5601e+00,  3.8971e+00,  3.4538e+00,\n",
              "                       3.4712e+00,  3.6604e+00,  3.5179e+00,  3.4675e+00,  3.2691e+00,\n",
              "                       3.1180e+00,  3.4864e+00,  3.2692e+00,  4.4599e+00,  3.3559e+00,\n",
              "                       3.4414e+00,  3.7082e+00,  3.5957e+00,  3.3140e+00,  3.3520e+00,\n",
              "                       3.5157e+00,  3.3448e+00,  3.4309e+00,  3.6192e+00,  3.2732e+00,\n",
              "                       3.7147e+00,  4.3278e+00,  3.2702e+00,  3.5854e+00,  3.6450e+00,\n",
              "                       2.9512e+00,  3.5580e+00,  3.2790e+00,  3.6000e+00,  3.4953e+00,\n",
              "                       3.6632e+00,  3.2464e+00,  3.4931e+00,  3.5289e+00,  3.8255e+00,\n",
              "                       3.4916e+00,  3.2163e+00,  3.1319e+00,  3.4831e+00,  3.3378e+00,\n",
              "                       3.3923e+00,  3.4646e+00,  3.4910e+00,  3.5135e+00,  3.4592e+00,\n",
              "                       3.3018e+00,  3.6165e+00,  3.8540e+00,  3.0686e+00,  3.4723e+00,\n",
              "                       3.4979e+00,  3.3183e+00,  3.4417e+00,  3.3989e+00,  3.5444e+00,\n",
              "                       3.3175e+00,  3.3809e+00,  3.6321e+00,  3.1601e+00,  3.3361e+00,\n",
              "                       3.4113e+00,  3.1622e+00,  3.2438e+00,  3.4993e+00,  3.3469e+00,\n",
              "                       3.7492e+00,  3.6351e+00,  3.0964e+00,  3.3031e+00,  3.2352e+00,\n",
              "                       3.3367e+00,  3.4962e+00,  3.5600e+00,  3.6389e+00,  3.2922e+00,\n",
              "                       3.2044e+00,  3.2404e+00,  3.2632e+00,  3.2102e+00,  3.3423e+00,\n",
              "                       3.5461e+00,  3.4112e+00,  3.3409e+00,  3.8359e+00,  3.4040e+00,\n",
              "                       3.4070e+00,  3.4218e+00,  3.4347e+00,  3.4890e+00,  2.9673e+00,\n",
              "                       3.1394e+00,  3.3309e+00,  3.4080e+00,  3.1936e+00,  3.3648e+00,\n",
              "                       3.3864e+00,  3.5136e+00,  4.2037e+00,  3.4505e+00,  3.4632e+00,\n",
              "                       3.2679e+00,  3.2661e+00,  3.3110e+00,  3.2472e+00,  3.5507e+00,\n",
              "                       3.3216e+00,  3.4868e+00,  3.4470e+00,  3.1226e+00,  3.2750e+00,\n",
              "                       3.4035e+00,  3.3060e+00,  3.4438e+00,  3.3165e+00,  3.5443e+00,\n",
              "                       3.3264e+00,  3.6049e+00,  3.4326e+00,  3.7522e+00,  3.4333e+00,\n",
              "                       3.1691e+00,  3.4415e+00,  3.2828e+00,  3.4233e+00,  3.8334e+00,\n",
              "                       3.5052e+00,  3.2886e+00,  3.6155e+00,  3.3150e+00,  3.6579e+00,\n",
              "                       3.5486e+00,  3.4507e+00,  3.2731e+00,  3.4536e+00,  3.4194e+00,\n",
              "                       3.5345e+00,  3.1996e+00,  3.2596e+00,  3.5168e+00,  3.2339e+00,\n",
              "                       3.1960e+00,  3.5524e+00,  3.8501e+00], device='cuda:0')),\n",
              "             ('decoder.block.8.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[ 0.0179,  0.0720, -0.0165,  ..., -0.0207,  0.0118, -0.0151],\n",
              "                      [ 0.0366,  0.0677,  0.0129,  ..., -0.0291, -0.0277, -0.0114],\n",
              "                      [ 0.0285, -0.0007, -0.0307,  ...,  0.0085,  0.0211,  0.0013],\n",
              "                      ...,\n",
              "                      [-0.1211, -0.0008,  0.0147,  ...,  0.0266,  0.0153, -0.0332],\n",
              "                      [-0.0271, -0.0383, -0.0125,  ...,  0.0028, -0.0468, -0.0344],\n",
              "                      [ 0.0910, -0.0003,  0.0430,  ..., -0.0534, -0.0646,  0.0036]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.2096, -0.0909, -0.1649,  ...,  0.3456,  0.3978,  0.1519],\n",
              "                      [ 0.3996,  0.3091, -0.2219,  ..., -0.5026, -0.0855,  0.0558],\n",
              "                      [-0.3732, -0.3581,  0.0177,  ...,  0.2699,  0.1524,  0.4719],\n",
              "                      ...,\n",
              "                      [-0.3693, -0.1618, -0.4342,  ..., -0.0836,  0.1683, -0.2222],\n",
              "                      [ 0.2334, -0.0351, -0.1148,  ..., -0.3743, -0.4179, -0.4321],\n",
              "                      [-0.6120, -0.2017, -0.0577,  ...,  0.0993,  0.4395, -0.2782]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.9026,  0.2249, -0.3559,  ...,  0.0175,  0.7135,  1.0732],\n",
              "                      [-1.0499, -0.2870,  0.0750,  ..., -0.6431,  0.5538, -0.5892],\n",
              "                      [-0.7941,  0.0577,  0.7379,  ..., -0.7958, -1.4058,  0.6265],\n",
              "                      ...,\n",
              "                      [-0.3067, -0.4296, -0.4595,  ...,  0.0685,  0.4668,  1.4870],\n",
              "                      [ 0.8006, -0.9744, -0.1308,  ...,  0.1442, -0.2250,  0.0887],\n",
              "                      [-0.0539,  1.0519, -0.0965,  ..., -0.6779, -1.0314,  0.4742]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 2.4803, -0.3937, -0.2982,  ..., -0.8123,  0.5909, -1.1594],\n",
              "                      [ 0.9352, -1.2107, -0.6709,  ..., -0.0876,  0.3434,  0.4686],\n",
              "                      [-0.4207,  0.4582,  0.1923,  ...,  0.4058,  0.0586,  0.8147],\n",
              "                      ...,\n",
              "                      [-0.4142, -2.4830, -1.6484,  ..., -0.4061,  0.6360, -1.1491],\n",
              "                      [ 1.5152,  2.7765, -1.2486,  ..., -0.4186, -0.6489, -1.1524],\n",
              "                      [ 1.0764,  0.4141,  1.8455,  ...,  0.0737, -0.0115, -0.5760]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2294,  0.1745,  0.2323,  0.1625,  0.2302,  0.2070,  0.2336,  0.2564,\n",
              "                       0.2282,  0.2418,  0.2068,  0.2295,  0.1962,  0.2004,  0.2238,  0.2403,\n",
              "                       0.2287,  0.2127,  0.2216,  0.2708,  0.2474,  0.2316,  0.2170,  0.2289,\n",
              "                       0.2201,  0.2559,  0.2344,  0.2137,  0.2406,  0.2535,  0.2436,  0.2842,\n",
              "                       0.2423,  0.2399,  0.2448,  0.2225,  0.2710,  0.2347,  0.2458,  0.2404,\n",
              "                       0.2010,  0.2326,  0.2453,  0.2344,  0.2499,  0.2353,  0.2520,  0.2440,\n",
              "                       0.2463,  0.2475,  0.2478,  0.2338,  0.2461,  0.2311,  0.3217,  0.2071,\n",
              "                       0.2112,  0.2336,  0.2423,  0.2303,  0.2349,  0.2293,  0.2448,  0.2482,\n",
              "                       0.2295,  0.2367,  0.2333,  0.2346,  0.2352,  0.2334,  0.2535,  0.2433,\n",
              "                       0.2437,  0.2278,  0.2577,  0.2398, -0.1969,  0.2337,  0.2432,  0.2614,\n",
              "                       0.2510,  0.2096,  0.2277,  0.2569,  0.2682,  0.2704, -0.0730,  0.2321,\n",
              "                       0.2376,  0.2377,  0.2138,  0.2298,  0.2325,  0.1935,  0.2317,  0.2525,\n",
              "                       0.2344,  0.2396,  0.2600,  0.2272,  0.2189,  0.2155,  0.2169,  0.2336,\n",
              "                       0.2307,  0.2348,  0.2357,  0.2351,  0.2355,  0.2272,  0.2592,  0.2426,\n",
              "                       0.2101,  0.2395,  0.2322,  0.2752,  0.2161,  0.2348,  0.0613,  0.2445,\n",
              "                       0.2339,  0.2086,  0.2552,  0.2341,  0.2606,  0.2401,  0.2476,  0.2091,\n",
              "                       0.2251,  0.2157,  0.2153,  0.2270,  0.2364,  0.2470,  0.1510,  0.2197,\n",
              "                       0.2279,  0.2247,  0.2117,  0.2118,  0.2271,  0.2308,  0.2406,  0.2275,\n",
              "                       0.2128,  0.2214,  0.2332,  0.2369,  0.2423,  0.2070,  0.2771,  0.2360,\n",
              "                       0.2490,  0.2383,  0.2441,  0.2442,  0.2350,  0.2531,  0.1011,  0.1851,\n",
              "                       0.2442,  0.2190,  0.2031,  0.2455,  0.2354,  0.2245,  0.2427,  0.2310,\n",
              "                       0.2387,  0.2620, -0.1828,  0.2372,  0.2506,  0.2318,  0.2363,  0.2225,\n",
              "                       0.2277,  0.2535,  0.1553,  0.2302,  0.2452,  0.2411,  0.2441,  0.2436,\n",
              "                       0.2252,  0.2720,  0.2276,  0.0602,  0.2220,  0.1960,  0.2233,  0.2396,\n",
              "                       0.2353,  0.2345,  0.2325,  0.2339,  0.2293,  0.2366,  0.2326,  0.2304,\n",
              "                       0.2343,  0.2044,  0.2436,  0.2315,  0.2366,  0.2028,  0.2270,  0.2345,\n",
              "                       0.2304,  0.2523,  0.2659,  0.2157,  0.2215,  0.2540,  0.2452,  0.2612,\n",
              "                       0.2328,  0.2325,  0.2334,  0.0180,  0.2190,  0.2496,  0.2573,  0.2255,\n",
              "                       0.2112,  0.2500,  0.5851,  0.2567,  0.2167,  0.2576,  0.2449,  0.2340,\n",
              "                       0.2273,  0.2500,  0.2560,  0.2136,  0.2192,  0.2154,  0.2231,  0.2555,\n",
              "                       0.2915,  0.2432,  0.2359,  0.2210,  0.2464,  0.2197,  0.2467,  0.2246,\n",
              "                       0.2405,  0.2314,  0.2249,  0.2395,  0.2274,  0.2338,  0.2311,  0.2350,\n",
              "                       0.2651, -0.1808,  0.2391,  0.2189,  0.2265,  0.1884,  0.2432,  0.2389,\n",
              "                       0.2375,  0.2315,  0.2450,  0.2511,  0.2395,  0.2409,  0.2201,  0.3138,\n",
              "                       0.2330,  0.2453, -0.1575,  0.2368,  0.2553,  0.2186,  0.2483,  0.2115,\n",
              "                       0.0603,  0.2349,  0.2350,  0.2367,  0.2116,  0.2293,  0.2377,  0.2508,\n",
              "                       0.2163,  0.1947,  0.2410,  0.2294,  0.2160,  0.2504,  0.2268,  0.2507,\n",
              "                       0.2156,  0.2329,  0.2450,  0.2620,  0.2333,  0.2364,  0.0638,  0.2319,\n",
              "                       0.2451,  0.2317,  0.2199,  0.2345,  0.2338,  0.2344,  0.2397,  0.2438,\n",
              "                       0.2205,  0.2100,  0.2683,  0.2367,  0.2514,  0.2697,  0.2367,  0.2378,\n",
              "                       0.2089,  0.2301,  0.2192,  0.2568,  0.2395,  0.2314,  0.2205,  0.2568,\n",
              "                       0.2524,  0.2176,  0.2327,  0.2239,  0.2220,  0.2424,  0.2402,  0.2182,\n",
              "                       0.2444,  0.2526,  0.2315,  0.1905,  0.2216,  0.2414,  0.2274,  0.2176,\n",
              "                       0.2451,  0.2227,  0.2337,  0.2162,  0.1894,  0.2174,  0.2603,  0.2393,\n",
              "                       0.2104,  0.2268,  0.2264,  0.2683,  0.2397,  0.0760,  0.2397,  0.2620,\n",
              "                       0.2490,  0.2084,  0.1619,  0.2159,  0.2371,  0.2944,  0.2366,  0.2267,\n",
              "                       0.2617,  0.2231,  0.2536,  0.2300,  0.2419,  0.2246,  0.2476,  0.2457,\n",
              "                       0.2320,  0.2589,  0.2498,  0.2099,  0.2442,  0.2182, -0.2123,  0.2327,\n",
              "                       0.2400,  0.2408,  0.2491,  0.2446,  0.2257,  0.2357,  0.2673,  0.2251,\n",
              "                       0.2188,  0.2273,  0.2427,  0.2510,  0.2608,  0.2184,  0.2167,  0.2338,\n",
              "                       0.2331,  0.2425,  0.2307,  0.2359,  0.2373,  0.2378,  0.1922,  0.2231,\n",
              "                       0.2455,  0.2236,  0.2391,  0.2477,  0.2572,  0.2263,  0.2305,  0.2334,\n",
              "                       0.2326,  0.2408,  0.2579,  0.2558, -0.0282,  0.2623,  0.2439,  0.1109,\n",
              "                       0.2506,  0.2407,  0.1739,  0.2434,  0.2312,  0.2141,  0.2401,  0.2325,\n",
              "                       0.2426,  0.2132,  0.2262,  0.2351,  0.2388,  0.2640,  0.2395,  0.2129,\n",
              "                       0.2611,  0.2403,  0.2328,  0.2691,  0.2335,  0.2264,  0.2163,  0.2308,\n",
              "                      -0.0227,  0.2485,  0.2181,  0.2423,  0.2348,  0.2460,  0.2331,  0.2077,\n",
              "                       0.2380,  0.4855,  0.2227,  0.2470,  0.2430,  0.2238,  0.2334,  0.2360,\n",
              "                       0.2349,  0.2533,  0.1959,  0.2253,  0.2424,  0.2207,  0.2452,  0.2507,\n",
              "                       0.2113,  0.2486,  0.2397,  0.2423,  0.2283,  0.2473,  0.2463,  0.2266,\n",
              "                       0.2167,  0.2374,  0.2389,  0.2298,  0.0908,  0.2332,  0.2226,  0.0097,\n",
              "                       0.2354,  0.2312,  0.2335,  0.2432,  0.2359,  0.2427,  0.2459, -0.1789,\n",
              "                       0.2340,  0.2153,  0.2360,  0.2020,  0.2231,  0.2688,  0.2430,  0.2311,\n",
              "                       0.2267,  0.2139,  0.2371,  0.2066,  0.2649,  0.2540,  0.2283,  0.2440,\n",
              "                       0.2338,  0.2245,  0.2457,  0.2417,  0.2076,  0.2384,  0.2006,  0.2310,\n",
              "                       0.2105,  0.2318,  0.2256,  0.2504,  0.2623,  0.2266,  0.2172,  0.2655,\n",
              "                       0.2453,  0.2241,  0.2081,  0.2410,  0.2158,  0.2428,  0.2367,  0.2557,\n",
              "                       0.2249,  0.2376,  0.2381,  0.2187,  0.2313,  0.2445,  0.2211,  0.2127,\n",
              "                       0.2166,  0.2289,  0.2302,  0.2235,  0.2252,  0.2389,  0.2254,  0.2496,\n",
              "                       0.2410,  0.2658,  0.2298,  0.2293,  0.2405,  0.2349,  0.2286,  0.2327,\n",
              "                       0.2306,  0.2106,  0.0649,  0.2835,  0.2514,  0.2802,  0.2510,  0.2207,\n",
              "                       0.2466,  0.2340,  0.2412,  0.2400,  0.2496,  0.2355,  0.2106,  0.2265,\n",
              "                       0.2349,  0.2495,  0.2401, -0.0063,  0.2327,  0.2447,  0.2401,  0.2259,\n",
              "                       0.2184,  0.2268,  0.2221,  0.2315,  0.2250,  0.2219,  0.2493,  0.2550,\n",
              "                       0.2540,  0.2275,  0.2252,  0.2253,  0.2590,  0.2292,  0.2248,  0.2225,\n",
              "                       0.2030,  0.2392,  0.2425,  0.2097,  0.2279,  0.2334,  0.2635,  0.1969,\n",
              "                       0.2255,  0.2390,  0.2103,  0.2312,  0.2400,  0.2514,  0.2277,  0.2424,\n",
              "                       0.2322,  0.2741,  0.2604,  0.2362,  0.2355,  0.2371,  0.2414,  0.2070,\n",
              "                       0.2336,  0.2361,  0.2145,  0.2249,  0.2221,  0.2223,  0.2367,  0.2387,\n",
              "                       0.2362,  0.3297,  0.2377,  0.2357,  0.2512,  0.2322,  0.2287,  0.2233,\n",
              "                       0.2049,  0.2595,  0.2269,  0.2370,  0.2006,  0.2384,  0.2173,  0.2346,\n",
              "                       0.2189,  0.2720,  0.1982,  0.2470,  0.2343,  0.2313,  0.2636,  0.2195,\n",
              "                       0.2399,  0.2281,  0.2315,  0.2370,  0.2549,  0.2076,  0.2195,  0.2474,\n",
              "                       0.2121,  0.2154,  0.2450,  0.2469,  0.2367,  0.2444,  0.2373,  0.2465,\n",
              "                       0.2427,  0.2169,  0.2273,  0.2406,  0.2285,  0.2469,  0.2323,  0.2472,\n",
              "                       0.2530,  0.2480,  0.2483,  0.2276,  0.2435,  0.2105,  0.2391,  0.2235,\n",
              "                       0.2567,  0.2436,  0.2606,  0.2219,  0.1977,  0.2264,  0.2452,  0.2419,\n",
              "                       0.2469,  0.2514,  0.2523,  0.2382,  0.2251,  0.2283,  0.2286, -0.1668,\n",
              "                       0.2451,  0.2393,  0.2502, -0.2125,  0.2845,  0.2393,  0.2255,  0.2350,\n",
              "                       0.2239,  0.2317,  0.1908,  0.2679,  0.2229,  0.2599,  0.2188,  0.2115,\n",
              "                       0.2342,  0.2374,  0.2264,  0.2379,  0.2240,  0.2330,  0.2216,  0.2259,\n",
              "                       0.2270,  0.2305,  0.2360,  0.2341,  0.2481,  0.1276,  0.2463,  0.2178,\n",
              "                       0.2562,  0.2228,  0.2259,  0.2193,  0.2365,  0.1618,  0.2399,  0.2193,\n",
              "                       0.2612,  0.2146,  0.2085,  0.2419,  0.2280,  0.1921,  0.2245,  0.2117,\n",
              "                       0.1943,  0.2183,  0.2539,  0.2683,  0.2528,  0.2080,  0.1897,  0.2479,\n",
              "                       0.2182,  0.2108,  0.2095,  0.2373,  0.2182,  0.2176,  0.2246,  0.2285],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0582,  0.1089,  0.0260,  ...,  0.0092,  0.0403, -0.0196],\n",
              "                      [-0.0514,  0.0084, -0.0154,  ...,  0.0482,  0.0111, -0.0315],\n",
              "                      [ 0.0026,  0.0135,  0.0465,  ...,  0.0217, -0.0294, -0.0112],\n",
              "                      ...,\n",
              "                      [ 0.0477,  0.0593,  0.0191,  ...,  0.0541,  0.0064,  0.0346],\n",
              "                      [ 0.0143, -0.0310, -0.0160,  ...,  0.0051,  0.0013,  0.0123],\n",
              "                      [ 0.0041, -0.0285, -0.0239,  ...,  0.0119, -0.0091,  0.0690]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[ 0.0111,  0.0360, -0.0531,  ...,  0.1359,  0.5720, -0.1673],\n",
              "                      [-0.3990, -0.0072, -0.0495,  ..., -0.5147, -0.0981, -0.2564],\n",
              "                      [-0.0011,  0.3243,  0.0505,  ..., -0.0940, -0.6879, -0.3225],\n",
              "                      ...,\n",
              "                      [-0.3163, -0.0127, -0.3324,  ...,  0.2778, -0.1432,  0.2551],\n",
              "                      [-0.4083, -0.4948,  0.6530,  ..., -0.4317, -0.3079, -0.0584],\n",
              "                      [-0.0902, -0.0048,  0.1903,  ..., -0.4904,  0.0612, -0.1082]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.5780,  0.1922,  0.3898,  ...,  0.7264,  0.9316, -0.7885],\n",
              "                      [ 0.3613,  0.3029, -0.9526,  ..., -0.2722,  0.0022,  0.2998],\n",
              "                      [-1.0019,  0.3640, -0.7203,  ...,  0.6452,  1.3977, -0.4302],\n",
              "                      ...,\n",
              "                      [ 0.5361, -0.3004, -0.2424,  ...,  0.4447, -0.4792,  0.7682],\n",
              "                      [ 0.5040, -0.1414,  0.3427,  ...,  0.8445,  0.7437, -0.2293],\n",
              "                      [-0.0108,  0.2812,  0.3320,  ..., -0.4224,  0.4198,  0.1609]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[ 0.5029,  1.5904, -0.8798,  ..., -0.4081,  0.9866, -0.3778],\n",
              "                      [-1.1879,  0.0818, -0.6766,  ...,  0.0445, -0.1754,  0.6851],\n",
              "                      [-0.3158, -0.5576,  0.7130,  ...,  0.8600, -0.5075,  1.0745],\n",
              "                      ...,\n",
              "                      [ 0.6017,  0.4507,  0.2939,  ...,  0.3969, -0.6068, -0.4593],\n",
              "                      [ 2.3396,  0.5763, -1.1029,  ..., -0.6855,  0.9278,  0.4095],\n",
              "                      [ 0.4618,  0.2164, -0.1723,  ...,  0.3426, -1.4908,  0.2148]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.1.layer_norm.weight',\n",
              "              tensor([ 5.1790e-02,  5.4393e-02,  6.6319e-02,  4.7809e-02,  6.0415e-02,\n",
              "                       5.2883e-02,  9.6109e-02,  7.6944e-02,  4.8716e-02,  7.2787e-02,\n",
              "                       5.6372e-02,  8.1752e-02,  5.9937e-02,  5.8892e-02,  6.6310e-02,\n",
              "                       7.3861e-02,  5.4953e-02,  6.0196e-02,  5.5622e-02,  9.3358e-02,\n",
              "                       7.2048e-02,  7.7001e-02,  7.6940e-02,  8.5449e-02,  9.0980e-02,\n",
              "                       8.0189e-02,  6.7806e-02,  4.8716e-02,  8.8920e-02,  7.1465e-02,\n",
              "                       7.4654e-02,  7.2543e-02,  6.7636e-02,  7.7256e-02,  8.1543e-02,\n",
              "                       7.5969e-02,  7.6070e-02,  6.6798e-02,  6.1371e-02,  8.2097e-02,\n",
              "                       5.2534e-02,  6.7080e-02,  7.4504e-02,  6.0799e-02,  7.6994e-02,\n",
              "                       7.6118e-02,  1.0025e-01,  8.6284e-02,  8.9112e-02,  6.6667e-02,\n",
              "                       8.1807e-02,  6.4971e-02,  7.9700e-02,  6.3936e-02,  7.3169e-02,\n",
              "                       4.7326e-02,  4.9446e-02,  6.2660e-02,  8.9330e-02,  6.2184e-02,\n",
              "                       6.3660e-02,  7.9021e-02,  7.6348e-02,  7.6721e-02,  7.5992e-02,\n",
              "                       1.0063e-01,  6.7512e-02,  6.6226e-02,  4.8556e-02,  7.7605e-02,\n",
              "                       7.9687e-02,  8.0440e-02,  7.9858e-02,  7.0124e-02,  8.1074e-02,\n",
              "                       6.4260e-02, -4.7608e-02,  6.3536e-02,  8.3816e-02,  7.3841e-02,\n",
              "                       7.6212e-02,  5.9162e-02,  6.5695e-02,  6.2904e-02,  9.8192e-02,\n",
              "                       8.2509e-02,  1.0058e-02,  7.6080e-02,  7.6689e-02,  7.1454e-02,\n",
              "                       7.1376e-02,  8.1791e-02,  6.3109e-02,  5.1926e-02,  7.2803e-02,\n",
              "                       7.6414e-02,  8.2197e-02,  8.4682e-02,  7.1880e-02,  5.8408e-02,\n",
              "                       5.0335e-02,  6.6968e-02,  5.8333e-02,  6.4108e-02,  7.6170e-02,\n",
              "                       5.8262e-02,  7.3892e-02,  7.2103e-02,  8.8253e-02,  7.9040e-02,\n",
              "                       7.2698e-02,  9.2874e-02,  5.8329e-02,  6.9755e-02,  5.7179e-02,\n",
              "                       1.0585e-01,  5.7074e-02,  6.1780e-02,  2.8399e-04,  6.3596e-02,\n",
              "                       7.9077e-02,  7.3864e-02,  7.2034e-02,  6.6326e-02,  7.8647e-02,\n",
              "                       6.3266e-02,  7.2195e-02,  5.8612e-02,  5.6205e-02, -5.3171e-02,\n",
              "                       5.3560e-02,  5.8366e-02,  6.2307e-02,  7.9491e-02,  4.7226e-02,\n",
              "                      -5.4916e-02,  5.6508e-02,  6.2547e-02,  6.6973e-02,  6.2370e-02,\n",
              "                       6.6308e-02,  7.8839e-02,  5.1786e-02,  6.3965e-02,  5.0825e-02,\n",
              "                       4.8868e-02,  9.3048e-02,  6.2785e-02,  6.8595e-02,  4.3800e-02,\n",
              "                       1.0555e-01,  6.1245e-02,  9.6920e-02, -5.6153e-02,  8.8650e-02,\n",
              "                       9.0148e-02,  6.2820e-02,  8.9346e-02,  1.2326e-01,  5.0167e-02,\n",
              "                       6.6626e-02,  6.7415e-02,  5.7074e-02,  7.7991e-02,  7.6744e-02,\n",
              "                       5.8384e-02,  9.6646e-02,  5.4461e-02,  6.6920e-02,  7.1364e-02,\n",
              "                      -4.4484e-02,  6.8780e-02,  9.4017e-02,  8.0909e-02,  7.7293e-02,\n",
              "                       6.5610e-02,  6.1959e-02,  8.4488e-02,  3.5748e-02,  7.0498e-02,\n",
              "                       7.4204e-02,  7.3593e-02,  8.2261e-02,  7.8036e-02,  5.3231e-02,\n",
              "                       8.4292e-02,  7.7833e-02,  7.3601e-02,  6.4275e-02,  4.9719e-02,\n",
              "                       8.0481e-02,  7.2051e-02,  8.2548e-02,  5.4642e-02,  6.0288e-02,\n",
              "                       6.5414e-02,  7.0067e-02,  8.6662e-02,  7.1641e-02,  7.7630e-02,\n",
              "                       7.7842e-02, -4.9368e-02,  8.8685e-02,  7.3689e-02,  6.6051e-02,\n",
              "                       5.8437e-02,  6.7828e-02,  7.3391e-02,  6.5127e-02,  8.2446e-02,\n",
              "                       8.1705e-02,  5.6896e-02,  5.7076e-02,  7.4800e-02,  6.9883e-02,\n",
              "                       7.3364e-02,  5.7259e-02,  7.5650e-02,  6.7353e-02,  1.3724e-03,\n",
              "                       5.1722e-02,  9.3853e-02,  7.6250e-02,  7.0774e-02,  6.1527e-02,\n",
              "                       7.5187e-02,  1.9689e-01,  8.3577e-02,  5.7790e-02,  7.6123e-02,\n",
              "                       7.2598e-02,  6.5958e-02,  6.1559e-02,  7.3078e-02,  7.9078e-02,\n",
              "                       6.9806e-02,  4.9376e-02,  5.8395e-02,  5.1117e-02,  7.5650e-02,\n",
              "                       6.3355e-02,  7.2606e-02,  7.7234e-02,  7.8741e-02,  7.9679e-02,\n",
              "                       6.6018e-02,  8.5741e-02,  5.1851e-02,  8.5301e-02,  6.2468e-02,\n",
              "                       6.2772e-02,  7.3613e-02,  8.1971e-02,  6.3060e-02,  7.1111e-02,\n",
              "                       6.0116e-02,  7.7468e-02,  4.6102e-02,  9.1603e-02,  8.8387e-02,\n",
              "                      -7.5759e-02, -5.0812e-02,  8.6809e-02,  7.1595e-02,  8.4651e-02,\n",
              "                       5.5706e-02,  7.2738e-02,  8.0215e-02,  6.3996e-02,  6.1415e-02,\n",
              "                       6.9384e-02,  8.3117e-02,  7.5096e-02,  6.3562e-02, -4.7304e-02,\n",
              "                       6.8626e-02,  7.9039e-02,  4.8087e-02,  8.1397e-02, -5.2446e-02,\n",
              "                       4.2225e-06,  6.6298e-02,  6.4106e-02,  7.1305e-02,  7.1388e-02,\n",
              "                       5.6734e-02,  7.1866e-02,  7.4555e-02,  5.1877e-02,  5.1531e-02,\n",
              "                       6.6101e-02,  6.2063e-02,  7.3462e-02,  7.4151e-02,  7.5622e-02,\n",
              "                       8.9720e-02,  6.0203e-02,  6.8704e-02,  8.2923e-02,  8.7276e-02,\n",
              "                       8.9212e-02,  7.3069e-02, -2.6538e-02,  5.4120e-02,  6.0974e-02,\n",
              "                       6.6310e-02,  6.6992e-02,  6.8613e-02,  6.2026e-02,  6.2893e-02,\n",
              "                       1.0668e-01,  7.7729e-02,  5.6288e-02,  5.3025e-02,  1.9611e-01,\n",
              "                       7.8965e-02,  1.1161e-01,  5.7356e-02,  7.1049e-02,  9.5455e-02,\n",
              "                       6.0150e-02,  7.5082e-02, -4.1092e-02,  8.2677e-02,  6.9802e-02,\n",
              "                       6.2214e-02,  6.7129e-02,  7.8998e-02,  8.1906e-02,  5.8377e-02,\n",
              "                       7.4409e-02,  5.9462e-02,  8.2036e-02,  6.9313e-02,  7.6454e-02,\n",
              "                       6.9424e-02,  8.0075e-02,  9.8523e-02,  7.1387e-02, -3.7284e-02,\n",
              "                       6.5514e-02,  7.2515e-02,  7.7903e-02,  6.2511e-02,  9.3833e-02,\n",
              "                       6.7368e-02,  8.4299e-02,  4.9875e-02,  5.4584e-02,  6.1551e-02,\n",
              "                       6.6755e-02,  8.8136e-02,  5.0712e-02,  8.6454e-02,  6.4116e-02,\n",
              "                       8.1108e-02,  7.9047e-02,  6.9477e-04,  7.8554e-02,  7.7236e-02,\n",
              "                       7.6369e-02,  6.6606e-02,  4.5356e-02,  5.7253e-02,  8.2887e-02,\n",
              "                       9.9248e-02,  6.1500e-02,  5.5635e-02,  5.8637e-02,  6.2912e-02,\n",
              "                       7.3060e-02,  7.6227e-02,  8.0706e-02, -5.2831e-02,  7.7341e-02,\n",
              "                       6.2383e-02,  6.6775e-02,  9.0873e-02,  7.5527e-02,  5.0059e-02,\n",
              "                       7.4072e-02,  6.7751e-02,  6.5065e-02,  6.7597e-02,  7.0920e-02,\n",
              "                       7.0108e-02,  7.5862e-02,  8.1476e-02,  6.7197e-02,  7.1622e-02,\n",
              "                       8.5871e-02,  6.8163e-02,  5.1817e-02,  5.0097e-02,  7.3303e-02,\n",
              "                       7.2040e-02,  7.4254e-02,  6.3997e-02,  7.0795e-02,  5.3452e-02,\n",
              "                       5.8030e-02,  7.1227e-02,  7.7416e-02,  7.6002e-02,  6.4705e-02,\n",
              "                       8.0690e-02,  5.2383e-02,  7.6496e-02,  5.5199e-02,  7.4197e-02,\n",
              "                       7.4941e-02,  8.3847e-02,  5.9460e-02,  6.4431e-02,  7.4787e-02,\n",
              "                       7.9484e-02,  6.4871e-02,  7.6323e-02,  2.2481e-01,  7.2018e-02,\n",
              "                      -1.3214e-03,  7.8284e-02,  7.9457e-02,  1.2937e-02,  6.8606e-02,\n",
              "                       7.9481e-02,  5.2313e-02,  7.5547e-02,  5.6562e-02, -3.4550e-02,\n",
              "                       8.3733e-02,  6.9352e-02,  7.9718e-02,  6.0127e-02,  6.8927e-02,\n",
              "                       5.3192e-02,  6.3454e-02,  7.4440e-02,  7.3596e-02,  5.2958e-02,\n",
              "                       8.6201e-02,  5.9820e-02,  7.1717e-02,  7.8224e-02,  8.0182e-02,\n",
              "                       7.0641e-02,  7.7862e-02,  6.2404e-02, -9.8779e-05,  7.1180e-02,\n",
              "                       6.9824e-02,  8.5686e-02,  7.2923e-02,  6.9993e-02,  6.3964e-02,\n",
              "                       6.0838e-02,  8.4605e-02,  1.6260e-01,  5.6512e-02,  7.8771e-02,\n",
              "                       6.5969e-02,  8.8920e-02,  7.6377e-02,  7.4345e-02,  6.7477e-02,\n",
              "                       6.8282e-02, -4.0407e-02,  6.2128e-02,  6.6262e-02,  6.0178e-02,\n",
              "                       7.5181e-02,  8.0323e-02,  9.0348e-02,  7.7671e-02,  6.7387e-02,\n",
              "                       8.5111e-02,  8.0032e-02,  7.9573e-02,  7.0384e-02,  5.9111e-02,\n",
              "                      -5.3000e-02,  6.3999e-02,  8.0863e-02,  6.8150e-02,  8.7255e-04,\n",
              "                       6.1167e-02,  6.4673e-02,  6.0066e-02,  7.8434e-02,  5.9930e-02,\n",
              "                       7.8021e-02,  8.1772e-02,  7.9721e-02,  8.5661e-02,  1.0320e-01,\n",
              "                       1.0236e-01,  6.4273e-02,  6.2354e-02,  7.3582e-02,  6.7905e-02,\n",
              "                       8.1281e-02,  1.2453e-01,  6.9469e-02,  5.7458e-02,  7.5428e-02,\n",
              "                       7.1641e-02,  7.2221e-02, -5.7490e-02,  7.4099e-02,  7.8945e-02,\n",
              "                       5.5793e-02,  7.2990e-02,  5.2160e-02,  8.4967e-02,  7.7919e-02,\n",
              "                       7.1654e-02,  6.9717e-02,  5.4229e-02,  5.6004e-02,  6.5326e-02,\n",
              "                       7.6742e-02,  7.0624e-02,  8.4475e-02,  6.7040e-02,  6.7722e-02,\n",
              "                       8.1092e-02,  7.3045e-02,  7.0305e-02,  6.7344e-02,  7.2678e-02,\n",
              "                       6.7552e-02,  6.4298e-02,  6.0985e-02,  6.5614e-02,  7.5665e-02,\n",
              "                       7.5220e-02,  6.1164e-02,  6.1060e-02,  7.4558e-02,  6.2223e-02,\n",
              "                       7.9068e-02,  8.3616e-02, -5.9978e-02,  5.6887e-02,  5.0246e-02,\n",
              "                       8.0500e-02,  6.9181e-02,  7.0386e-02,  6.2453e-02,  6.0069e-02,\n",
              "                       5.4591e-02,  9.0174e-02,  5.9273e-02,  7.1195e-02,  7.9121e-02,\n",
              "                       7.3069e-02,  5.2329e-02,  7.6952e-02,  7.1698e-02,  6.2688e-02,\n",
              "                       6.7320e-02,  5.5598e-02,  5.4139e-04,  6.7737e-02,  7.9550e-02,\n",
              "                       9.5904e-02,  8.7545e-02,  7.0352e-02,  7.3469e-02,  8.5934e-02,\n",
              "                       9.1099e-02,  6.4055e-02,  7.1028e-02,  6.2499e-02,  6.2423e-02,\n",
              "                       5.6576e-02,  8.3146e-02,  8.7634e-02,  6.3871e-02,  1.1615e-03,\n",
              "                       6.3500e-02,  8.5472e-02,  6.6180e-02,  6.4785e-02,  7.5447e-02,\n",
              "                       7.7898e-02,  7.4884e-02,  6.0522e-02,  6.3900e-02,  7.3341e-02,\n",
              "                       7.9018e-02,  7.6045e-02,  9.0769e-02,  7.1759e-02,  5.8183e-02,\n",
              "                       6.7395e-02,  6.9532e-02,  7.2073e-02, -5.5387e-02,  5.9069e-02,\n",
              "                       4.4990e-02,  8.5930e-02,  7.8386e-02,  6.8562e-02,  6.8042e-02,\n",
              "                       6.3391e-02,  8.6100e-02,  6.9661e-02,  8.1504e-02,  6.9557e-02,\n",
              "                       6.2189e-02,  6.5920e-02,  6.8161e-02,  8.1444e-02,  6.8716e-02,\n",
              "                       8.8027e-02,  6.8575e-02,  1.7321e-01,  9.2267e-02,  6.9618e-02,\n",
              "                       7.4173e-02,  6.7645e-02,  7.3823e-02,  5.7844e-02,  7.4417e-02,\n",
              "                       6.2771e-02,  7.1321e-02,  6.3698e-02,  7.3091e-02,  7.2840e-02,\n",
              "                       8.4987e-02,  7.5031e-02,  6.2914e-02,  7.6586e-02,  7.2457e-02,\n",
              "                       7.4290e-02,  6.1825e-02,  6.7428e-02,  7.2464e-02,  7.5635e-02,\n",
              "                      -6.3690e-02,  7.5532e-02,  8.3242e-02,  7.6342e-02,  5.4438e-02,\n",
              "                       5.8304e-02,  4.7178e-02,  7.5015e-02,  6.1663e-02,  8.6864e-02,\n",
              "                       5.9147e-02,  7.0498e-02,  5.4729e-02,  6.1723e-02,  7.4478e-02,\n",
              "                       4.8452e-02,  6.2566e-02, -5.1847e-02,  7.0840e-02,  6.5134e-02,\n",
              "                       8.7879e-02, -4.5424e-02,  4.1419e-02,  1.0858e-01,  6.0324e-02,\n",
              "                       5.3609e-02,  7.8539e-02,  7.1457e-02,  8.1639e-02,  8.0809e-02,\n",
              "                       6.6319e-02,  7.8760e-02,  7.5679e-02,  6.5080e-02,  8.4180e-02,\n",
              "                       8.1359e-02,  7.0171e-02,  8.3887e-02,  6.6440e-02,  6.8617e-02,\n",
              "                       7.2951e-02,  7.9761e-02,  6.5849e-02,  6.1061e-02,  6.7474e-02,\n",
              "                       4.9862e-02,  6.6337e-02,  6.7160e-02,  7.4459e-02,  6.9828e-02,\n",
              "                       6.9363e-02,  6.1895e-02,  4.8908e-02,  6.3146e-02,  7.5785e-02,\n",
              "                       6.5782e-02,  7.5761e-02,  8.3031e-02,  7.4861e-02,  7.0825e-02,\n",
              "                       8.1724e-02,  8.3170e-02,  6.7808e-02,  4.6727e-02,  9.5970e-02,\n",
              "                       6.6432e-02,  7.5568e-02, -4.6507e-02,  7.6813e-02,  7.4933e-02,\n",
              "                       6.2631e-02,  7.6044e-02,  9.5330e-02,  6.4570e-02,  4.2727e-02,\n",
              "                       1.3986e-01,  6.5073e-02,  9.6816e-02,  6.8043e-02,  5.3305e-02,\n",
              "                       8.5230e-02,  6.5714e-02,  4.7292e-02,  7.7627e-02,  8.0794e-02,\n",
              "                       5.9219e-02,  5.9743e-02,  7.4076e-02,  7.7166e-02, -6.9476e-02,\n",
              "                       8.2793e-02,  6.9221e-02,  8.5652e-02,  6.6836e-02,  1.0217e-01,\n",
              "                       8.0796e-02,  7.5407e-02,  7.0244e-02,  6.8901e-02,  6.3551e-02,\n",
              "                       7.2763e-02,  6.6946e-02,  6.8658e-02,  6.2561e-02,  7.6182e-02,\n",
              "                       6.3003e-02,  5.4467e-02,  8.0780e-02,  6.3359e-02,  5.7316e-02,\n",
              "                       6.5904e-02,  5.9604e-02, -4.7918e-02,  7.2545e-02,  7.0859e-02,\n",
              "                       8.7042e-02,  6.5084e-02,  6.8816e-02,  7.2700e-02,  6.7194e-02,\n",
              "                       6.4083e-02,  6.4597e-02,  5.7392e-02,  5.2993e-02,  7.9303e-02,\n",
              "                       6.3554e-02,  6.8523e-02,  5.9252e-02], device='cuda:0')),\n",
              "             ('decoder.block.8.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.2312,  0.0341,  0.0316,  ..., -0.3318, -0.2440, -0.1040],\n",
              "                      [ 0.4994,  0.3496,  0.3469,  ...,  0.1798, -0.2297,  0.5775],\n",
              "                      [ 0.1028,  0.9701, -0.7240,  ..., -0.0542,  0.6042, -0.0081],\n",
              "                      ...,\n",
              "                      [ 0.1712,  0.9394, -0.7659,  ...,  0.5416,  0.2097, -0.5785],\n",
              "                      [-0.2457,  0.2175, -0.4731,  ...,  0.0899, -0.0209,  0.1202],\n",
              "                      [ 0.2271,  0.1642,  0.0952,  ...,  0.4390,  0.4665,  1.0534]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.2501,  0.1584,  0.2118,  ..., -0.7528,  0.1506,  0.1424],\n",
              "                      [ 0.1293, -0.1212, -0.2457,  ..., -0.1866,  0.1146,  0.4261],\n",
              "                      [-0.0103,  0.1893, -0.1687,  ..., -0.0741,  0.1484,  0.3150],\n",
              "                      ...,\n",
              "                      [-0.0092, -0.1393, -0.4384,  ...,  0.4875, -0.0201, -0.4422],\n",
              "                      [-0.5123,  0.0609,  0.0170,  ...,  0.0832,  0.0281,  0.0241],\n",
              "                      [ 0.3923, -0.4841,  0.1431,  ..., -0.0771,  0.1473,  0.6007]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.8.layer.2.layer_norm.weight',\n",
              "              tensor([ 4.3613e+00,  4.6060e+00,  4.5514e+00,  3.3607e+00,  4.3135e+00,\n",
              "                       4.0324e+00,  4.2456e+00,  4.9849e+00,  4.0998e+00,  4.2277e+00,\n",
              "                       4.3918e+00,  4.4701e+00,  5.2761e+00,  4.6578e+00,  4.5579e+00,\n",
              "                       4.4382e+00,  4.4188e+00,  4.0670e+00,  4.2183e+00,  4.5395e+00,\n",
              "                       4.3346e+00,  4.3792e+00,  4.4671e+00,  4.1511e+00,  4.2567e+00,\n",
              "                       4.2027e+00,  4.2941e+00,  4.6864e+00,  4.6271e+00,  4.2803e+00,\n",
              "                       4.4136e+00,  5.5806e+00,  4.2880e+00,  4.1606e+00,  4.6942e+00,\n",
              "                       4.6919e+00,  4.4660e+00,  4.7970e+00,  4.0884e+00,  4.3279e+00,\n",
              "                       4.0215e+00,  4.1536e+00,  4.3867e+00,  4.5032e+00,  4.7702e+00,\n",
              "                       4.3445e+00,  4.4609e+00,  4.7052e+00,  4.4335e+00,  4.4716e+00,\n",
              "                       4.2999e+00,  4.1907e+00,  4.6877e+00,  4.2278e+00,  5.8094e+00,\n",
              "                       4.2184e+00,  4.2297e+00,  4.2475e+00,  4.4766e+00,  4.2459e+00,\n",
              "                       4.3896e+00,  4.3128e+00,  4.5606e+00,  4.3450e+00,  4.1853e+00,\n",
              "                       6.5931e+00,  4.1943e+00,  4.7211e+00,  5.5986e+00,  4.2110e+00,\n",
              "                       4.5545e+00,  4.3689e+00,  4.4680e+00,  4.2491e+00,  4.8810e+00,\n",
              "                       4.2703e+00,  4.3617e+00,  4.3180e+00,  4.4698e+00,  4.6179e+00,\n",
              "                       4.2499e+00,  4.1272e+00,  4.2809e+00,  4.4213e+00,  4.6143e+00,\n",
              "                       4.5164e+00,  1.5675e+00,  4.1380e+00,  4.1219e+00,  4.5353e+00,\n",
              "                       4.3311e+00,  4.1915e+00,  4.1428e+00,  4.2724e+00,  4.6339e+00,\n",
              "                       4.1791e+00,  4.2956e+00,  4.2854e+00,  4.2683e+00,  4.0935e+00,\n",
              "                       4.7083e+00,  4.1894e+00,  5.8831e+00,  4.2875e+00,  4.2566e+00,\n",
              "                       3.9930e+00,  4.2473e+00,  4.3535e+00,  4.3155e+00,  4.5340e+00,\n",
              "                       4.3613e+00,  4.1782e+00,  4.2229e+00,  4.1840e+00,  4.5006e+00,\n",
              "                       4.3621e+00,  4.4148e+00,  4.5024e+00, -3.1042e-03,  4.4417e+00,\n",
              "                       4.1280e+00,  4.0069e+00,  4.5417e+00,  4.0400e+00,  4.4399e+00,\n",
              "                       4.1656e+00,  4.2822e+00,  3.9544e+00,  4.4960e+00,  4.4402e+00,\n",
              "                       5.5891e+00,  4.4188e+00,  4.2691e+00,  4.1096e+00,  3.6272e+00,\n",
              "                       4.1235e+00,  4.2801e+00,  4.6446e+00,  4.3295e+00,  4.1305e+00,\n",
              "                       4.8541e+00,  4.3901e+00,  4.3481e+00,  4.5660e+00,  4.3299e+00,\n",
              "                       4.2119e+00,  4.3521e+00,  4.4214e+00,  4.3502e+00,  4.1564e+00,\n",
              "                       4.5334e+00,  4.4521e+00,  4.7883e+00,  4.3474e+00,  4.3414e+00,\n",
              "                       4.3206e+00,  4.3484e+00,  4.3470e+00,  3.7448e+00,  4.3521e+00,\n",
              "                       4.1219e+00,  4.4066e+00,  4.2594e+00,  4.7147e+00,  4.3448e+00,\n",
              "                       4.5769e+00,  4.7580e+00,  4.4656e+00,  4.9903e+00,  4.3773e+00,\n",
              "                       5.2175e+00,  4.3322e+00,  4.3752e+00,  4.2855e+00,  4.2754e+00,\n",
              "                       3.9521e+00,  4.1967e+00,  4.1910e+00,  4.8643e+00,  4.1287e+00,\n",
              "                       4.4089e+00,  4.6690e+00,  4.1970e+00,  4.5862e+00,  4.7191e+00,\n",
              "                       4.8105e+00,  4.1904e+00,  2.8374e+00,  4.4273e+00,  4.0767e+00,\n",
              "                       4.2742e+00,  4.2466e+00,  4.2257e+00,  4.2990e+00,  3.9826e+00,\n",
              "                       4.3163e+00,  4.0508e+00,  4.4357e+00,  4.6261e+00,  4.0998e+00,\n",
              "                       4.4033e+00,  4.1009e+00,  4.4967e+00,  4.3971e+00,  4.2039e+00,\n",
              "                       4.0086e+00,  3.8494e+00,  4.3491e+00,  4.3830e+00,  4.3592e+00,\n",
              "                       4.6971e+00,  4.2300e+00,  4.0163e+00,  4.5788e+00,  4.0705e+00,\n",
              "                       4.5341e+00,  4.7945e+00,  4.3609e+00,  4.3645e+00,  8.7508e-01,\n",
              "                       5.0252e+00,  4.2465e+00,  4.7492e+00,  4.2210e+00,  4.5827e+00,\n",
              "                       4.2232e+00,  3.9015e+00,  4.3149e+00,  4.2024e+00,  4.6635e+00,\n",
              "                       4.4845e+00,  4.4969e+00,  4.1917e+00,  4.4055e+00,  4.4400e+00,\n",
              "                       4.4554e+00,  4.4632e+00,  3.9461e+00,  4.7914e+00,  4.5079e+00,\n",
              "                       6.0922e+00,  4.1951e+00,  4.3584e+00,  4.3954e+00,  4.2923e+00,\n",
              "                       4.0074e+00,  4.3205e+00,  4.1021e+00,  4.2560e+00,  4.2300e+00,\n",
              "                       4.4834e+00,  4.5433e+00,  4.4421e+00,  4.4446e+00,  4.5704e+00,\n",
              "                       4.2949e+00,  4.5825e+00,  4.7818e+00,  4.2827e+00,  4.5880e+00,\n",
              "                       4.8787e+00,  4.6896e+00,  4.4909e+00,  4.3049e+00,  4.3426e+00,\n",
              "                       4.3537e+00,  4.4889e+00,  4.3234e+00,  4.2253e+00,  4.7536e+00,\n",
              "                       4.2456e+00,  5.5880e+00,  4.3292e+00,  4.4003e+00,  5.0774e+00,\n",
              "                       4.2839e+00,  4.5397e+00,  4.2934e+00,  4.5667e+00,  4.4064e+00,\n",
              "                       7.8246e-01,  5.3545e+00,  4.5103e+00,  4.2913e+00,  4.2470e+00,\n",
              "                       4.2915e+00,  4.2322e+00,  4.5739e+00,  4.5285e+00,  4.2829e+00,\n",
              "                       4.4976e+00,  4.2594e+00,  4.0022e+00,  4.3197e+00,  4.2647e+00,\n",
              "                       4.5722e+00,  4.4756e+00,  4.4654e+00,  4.6263e+00,  4.8752e+00,\n",
              "                       4.3030e+00,  4.3383e+00,  1.5423e+00,  4.2149e+00,  4.2288e+00,\n",
              "                       4.3995e+00,  4.3638e+00,  4.2315e+00,  4.6510e+00,  4.1891e+00,\n",
              "                       4.1345e+00,  4.4985e+00,  4.0334e+00,  4.0497e+00,  4.1613e+00,\n",
              "                       4.4941e+00,  4.2566e+00,  4.6862e+00,  4.4664e+00,  4.4137e+00,\n",
              "                       3.8712e+00,  4.5978e+00,  4.1572e+00,  4.5191e+00,  4.2107e+00,\n",
              "                       4.3955e+00,  4.0740e+00,  4.5712e+00,  4.3672e+00,  4.1566e+00,\n",
              "                       4.3578e+00,  4.7873e+00,  4.1592e+00,  4.2176e+00,  4.4340e+00,\n",
              "                       4.2792e+00,  4.2948e+00,  4.5146e+00,  4.2053e+00,  3.9749e+00,\n",
              "                       4.5127e+00,  4.5468e+00,  4.2544e+00,  3.9164e+00,  4.3104e+00,\n",
              "                       4.2785e+00,  4.1583e+00,  4.5099e+00,  4.4440e+00,  4.6544e+00,\n",
              "                       4.1596e+00,  4.2314e+00,  4.0745e+00,  4.2233e+00,  4.1529e+00,\n",
              "                       4.4059e+00,  4.5930e+00,  3.4451e-02,  4.4946e+00,  4.7469e+00,\n",
              "                       4.4662e+00,  4.1613e+00,  5.5650e+00,  4.0787e+00,  4.4205e+00,\n",
              "                       4.3788e+00,  4.7421e+00,  4.1151e+00,  4.2828e+00,  4.3849e+00,\n",
              "                       4.6671e+00,  4.2514e+00,  4.4265e+00,  4.3213e+00,  4.3507e+00,\n",
              "                       4.3709e+00,  4.0571e+00,  4.4236e+00,  4.6553e+00,  4.4856e+00,\n",
              "                       4.1545e+00,  4.2561e+00,  4.6771e+00,  4.0512e+00,  4.6537e+00,\n",
              "                       4.5983e+00,  4.1799e+00,  4.4751e+00,  4.2604e+00,  4.0843e+00,\n",
              "                       4.7077e+00,  4.0988e+00,  4.2833e+00,  4.3813e+00,  4.5547e+00,\n",
              "                       4.4828e+00,  4.6341e+00,  4.1552e+00,  4.3134e+00,  4.5613e+00,\n",
              "                       4.2824e+00,  4.4655e+00,  4.2473e+00,  4.6524e+00,  4.0953e+00,\n",
              "                       4.2372e+00,  4.3021e+00,  4.1223e+00,  4.1008e+00,  4.2275e+00,\n",
              "                       4.4445e+00,  4.3888e+00,  4.2078e+00,  4.1738e+00,  4.3691e+00,\n",
              "                       4.2565e+00,  4.7641e+00,  4.4225e+00,  4.6497e+00,  4.4475e+00,\n",
              "                       6.8158e-01,  4.3116e+00,  4.3095e+00,  2.4316e+00,  4.6056e+00,\n",
              "                       4.3428e+00,  4.1374e+00,  4.2240e+00,  4.5580e+00,  4.5342e+00,\n",
              "                       4.2423e+00,  4.4435e+00,  4.4769e+00,  4.2878e+00,  4.1021e+00,\n",
              "                       4.0884e+00,  4.1629e+00,  4.6000e+00,  4.6349e+00,  4.6695e+00,\n",
              "                       4.6019e+00,  5.1183e+00,  4.0412e+00,  4.4246e+00,  4.1282e+00,\n",
              "                       4.2634e+00,  4.1534e+00,  4.2776e+00,  6.9269e-01,  4.2933e+00,\n",
              "                       4.2393e+00,  4.2089e+00,  4.4258e+00,  4.4310e+00,  4.4698e+00,\n",
              "                       4.3362e+00,  4.5839e+00,  4.7466e+00,  4.1866e+00,  4.3817e+00,\n",
              "                       4.4926e+00,  4.5366e+00,  4.5307e+00,  4.5367e+00,  4.5946e+00,\n",
              "                       4.5363e+00,  4.3110e+00,  4.2600e+00,  4.0583e+00,  4.5210e+00,\n",
              "                       4.4658e+00,  4.0611e+00,  5.8315e+00,  4.3663e+00,  4.2320e+00,\n",
              "                       4.3951e+00,  4.1006e+00,  4.4317e+00,  4.4167e+00,  4.3505e+00,\n",
              "                       4.0927e+00,  4.4485e+00,  4.3584e+00,  4.4274e+00,  7.1946e-01,\n",
              "                       4.4418e+00,  4.0506e+00,  9.0970e-01,  4.4428e+00,  4.2831e+00,\n",
              "                       4.5597e+00,  4.3760e+00,  4.3345e+00,  4.4178e+00,  4.5989e+00,\n",
              "                       8.5633e+00,  4.6001e+00,  4.4420e+00,  4.3942e+00,  4.2819e+00,\n",
              "                       4.3996e+00,  4.3849e+00,  4.3981e+00,  4.4412e+00,  4.2736e+00,\n",
              "                       4.4364e+00,  4.6090e+00,  4.1249e+00,  4.2541e+00,  4.5336e+00,\n",
              "                       4.1988e+00,  4.2468e+00,  4.8029e+00,  4.4039e+00,  4.2786e+00,\n",
              "                       4.4524e+00,  4.3204e+00,  4.0310e+00,  4.6125e+00,  4.3117e+00,\n",
              "                       4.1019e+00,  4.2802e+00,  4.4975e+00,  4.3502e+00,  4.6084e+00,\n",
              "                       4.2290e+00,  4.4726e+00,  4.8285e+00,  4.8019e+00,  4.1636e+00,\n",
              "                       4.2172e+00,  4.2384e+00,  4.1040e+00,  4.1465e+00,  4.3795e+00,\n",
              "                       4.4039e+00,  4.2164e+00,  4.2196e+00,  4.1933e+00,  4.3113e+00,\n",
              "                       4.3549e+00,  4.6007e+00,  3.9654e+00,  4.0297e+00,  4.1406e+00,\n",
              "                       4.3284e+00,  4.3394e+00,  4.5610e+00,  4.2520e+00,  4.5053e+00,\n",
              "                       4.4630e+00,  4.9035e+00,  4.0987e+00,  4.8811e+00,  4.3923e+00,\n",
              "                       4.2244e+00,  4.1886e+00,  4.3684e+00,  4.3523e+00,  4.2482e+00,\n",
              "                       4.3505e+00,  4.3693e+00,  6.6679e-01,  5.8147e+00,  4.2442e+00,\n",
              "                       4.8790e+00,  4.3858e+00,  3.8889e+00,  4.4449e+00,  4.0711e+00,\n",
              "                       4.3114e+00,  4.3167e+00,  4.3760e+00,  4.3425e+00,  4.6914e+00,\n",
              "                       4.4175e+00,  4.3033e+00,  4.5793e+00,  4.5827e+00,  3.1405e-01,\n",
              "                       4.6634e+00,  4.3451e+00,  4.2792e+00,  4.4081e+00,  4.6414e+00,\n",
              "                       4.3411e+00,  4.3917e+00,  4.3713e+00,  4.2270e+00,  4.2495e+00,\n",
              "                       4.4360e+00,  4.5438e+00,  4.5305e+00,  4.2222e+00,  3.9851e+00,\n",
              "                       4.3408e+00,  5.3633e+00,  4.3716e+00,  5.0263e+00,  4.7047e+00,\n",
              "                       4.0932e+00,  4.3261e+00,  4.2266e+00,  4.2182e+00,  4.5660e+00,\n",
              "                       4.2840e+00,  4.2914e+00,  5.1443e+00,  4.3025e+00,  4.3220e+00,\n",
              "                       4.1166e+00,  4.3252e+00,  4.1329e+00,  4.3992e+00,  4.3506e+00,\n",
              "                       4.4386e+00,  4.1502e+00,  4.7527e+00,  4.4419e+00,  3.9974e+00,\n",
              "                       3.9949e+00,  4.2258e+00,  4.4134e+00,  4.5624e+00,  4.2174e+00,\n",
              "                       4.1958e+00,  4.3873e+00,  4.2907e+00,  4.3521e+00,  4.1264e+00,\n",
              "                       4.3305e+00,  4.4431e+00,  4.3630e+00,  5.6905e+00,  4.2787e+00,\n",
              "                       4.4435e+00,  4.6605e+00,  4.4650e+00,  4.2858e+00,  4.1772e+00,\n",
              "                       4.5649e+00,  4.1254e+00,  4.3844e+00,  4.5354e+00,  4.7222e+00,\n",
              "                       4.6829e+00,  5.8420e+00,  4.0850e+00,  4.4120e+00,  4.8525e+00,\n",
              "                       3.9046e+00,  4.3781e+00,  4.2535e+00,  4.4886e+00,  4.5351e+00,\n",
              "                       4.9351e+00,  4.0905e+00,  4.2326e+00,  4.1611e+00,  4.6434e+00,\n",
              "                       4.3001e+00,  3.9250e+00,  3.9956e+00,  4.8176e+00,  4.0940e+00,\n",
              "                       4.3129e+00,  4.4702e+00,  4.6300e+00,  4.2098e+00,  4.4416e+00,\n",
              "                       4.1064e+00,  4.3949e+00,  4.8048e+00,  4.0379e+00,  4.3247e+00,\n",
              "                       4.2794e+00,  4.1500e+00,  4.4219e+00,  4.1551e+00,  4.3393e+00,\n",
              "                       4.1333e+00,  4.2616e+00,  5.0504e+00,  4.1404e+00,  4.0391e+00,\n",
              "                       4.1771e+00,  4.1608e+00,  4.2328e+00,  4.4121e+00,  4.3029e+00,\n",
              "                       4.5276e+00,  4.3807e+00,  3.9517e+00,  4.1130e+00,  4.1094e+00,\n",
              "                       4.1196e+00,  4.5665e+00,  4.4634e+00,  4.6072e+00,  4.2470e+00,\n",
              "                       4.1030e+00,  4.1912e+00,  4.1904e+00,  4.4140e+00,  4.2079e+00,\n",
              "                       4.4445e+00,  4.3637e+00,  4.4105e+00,  5.1581e+00,  4.2590e+00,\n",
              "                       4.3909e+00,  4.3485e+00,  4.7224e+00,  4.4978e+00,  3.9799e+00,\n",
              "                       4.3432e+00,  4.2758e+00,  4.3181e+00,  3.9251e+00,  4.1825e+00,\n",
              "                       4.1917e+00,  4.3163e+00,  5.4316e+00,  4.3813e+00,  4.2597e+00,\n",
              "                       4.5473e+00,  4.2571e+00,  4.2855e+00,  4.1039e+00,  4.3129e+00,\n",
              "                       4.3384e+00,  4.4280e+00,  4.5067e+00,  4.6008e+00,  4.3201e+00,\n",
              "                       4.3464e+00,  4.2807e+00,  4.1497e+00,  4.1420e+00,  4.5722e+00,\n",
              "                       4.3854e+00,  4.6907e+00,  4.3829e+00,  4.6990e+00,  4.2497e+00,\n",
              "                       3.9325e+00,  4.4758e+00,  4.2912e+00,  4.3600e+00,  4.6139e+00,\n",
              "                       4.2451e+00,  4.2953e+00,  4.3553e+00,  4.2648e+00,  4.5980e+00,\n",
              "                       4.5240e+00,  4.5267e+00,  4.2245e+00,  4.5866e+00,  4.1895e+00,\n",
              "                       4.4823e+00,  4.0621e+00,  4.0794e+00,  4.0604e+00,  4.1675e+00,\n",
              "                       4.2123e+00,  4.3026e+00,  4.5447e+00], device='cuda:0')),\n",
              "             ('decoder.block.9.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0183, -0.0466, -0.0309,  ..., -0.0268, -0.0218, -0.0221],\n",
              "                      [-0.0109, -0.0209,  0.0067,  ..., -0.0139, -0.0022, -0.0241],\n",
              "                      [-0.0368,  0.0139, -0.0630,  ...,  0.0077,  0.0157, -0.0488],\n",
              "                      ...,\n",
              "                      [-0.0023, -0.0870,  0.0100,  ...,  0.0155,  0.0583, -0.0417],\n",
              "                      [-0.0073, -0.0452,  0.0258,  ..., -0.0586, -0.0101,  0.0815],\n",
              "                      [ 0.0067, -0.0110,  0.0414,  ...,  0.0510, -0.0593,  0.0157]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[ 0.1103,  0.2678, -0.5261,  ..., -0.1918,  0.1790,  0.4896],\n",
              "                      [-0.6990,  0.3415, -0.1637,  ...,  0.2393, -0.3236, -0.1845],\n",
              "                      [ 0.0165,  0.2651, -0.2919,  ..., -0.1170,  0.8511, -0.2998],\n",
              "                      ...,\n",
              "                      [ 0.3399, -0.3291, -0.3726,  ..., -0.7281, -0.2935, -0.0579],\n",
              "                      [-0.0032,  0.0900, -0.2763,  ...,  0.5194, -0.3791, -0.6519],\n",
              "                      [-0.0765, -0.4614,  0.0557,  ..., -0.2545,  0.1852, -0.0928]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 1.6562, -1.5216, -0.0794,  ...,  1.0922,  0.6011, -0.7554],\n",
              "                      [ 0.7557,  0.8387,  0.0030,  ...,  0.1316, -0.9566, -0.9710],\n",
              "                      [-0.8720,  0.5117,  0.4843,  ..., -0.7719, -0.2922,  0.7361],\n",
              "                      ...,\n",
              "                      [-0.0859, -0.9000, -0.8059,  ...,  0.6830, -0.1534,  0.2305],\n",
              "                      [ 0.4442, -0.3731, -0.7548,  ...,  0.7440,  0.6877,  0.2001],\n",
              "                      [-0.8221, -0.2710,  0.2875,  ...,  0.0667,  0.2308,  0.2098]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.0425, -0.8617, -0.0509,  ...,  0.6704, -0.4694,  0.2764],\n",
              "                      [-0.1308, -0.4041,  0.5225,  ...,  0.8215,  0.4651,  0.4402],\n",
              "                      [ 0.0646,  1.0454,  0.9614,  ..., -0.1664,  0.7150, -0.2925],\n",
              "                      ...,\n",
              "                      [ 1.5921,  0.7625,  0.2536,  ..., -0.8703, -1.4425, -0.0958],\n",
              "                      [ 0.4124,  0.4104,  1.3873,  ...,  0.1433,  0.5303,  0.8760],\n",
              "                      [-1.6739,  1.6563,  1.0040,  ...,  0.7670, -0.1582, -0.1746]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2477,  0.2306,  0.2858,  0.1836,  0.2532,  0.2504,  0.2941,  0.2632,\n",
              "                       0.2541,  0.2557,  0.2357,  0.2639,  0.2250,  0.2451,  0.2886,  0.2655,\n",
              "                       0.2479,  0.2819,  0.2385,  0.2787,  0.2636,  0.2552,  0.2603,  0.2710,\n",
              "                       0.2808,  0.2935,  0.2712,  0.2547,  0.2788,  0.2605,  0.2753,  0.3286,\n",
              "                       0.2795,  0.2547,  0.2842,  0.2565,  0.2741,  0.3256,  0.2603,  0.2564,\n",
              "                       0.2377,  0.2732,  0.2631,  0.2569,  0.2970,  0.2631,  0.2487,  0.2698,\n",
              "                       0.2909,  0.2641,  0.2926,  0.2631,  0.2734,  0.2495,  0.4013,  0.2377,\n",
              "                       0.2548,  0.2666,  0.2693,  0.2414,  0.2617,  0.2483,  0.2538,  0.2580,\n",
              "                       0.2504,  0.3631,  0.2561,  0.2605,  0.2963,  0.2565,  0.2677,  0.2876,\n",
              "                       0.2735,  0.2624,  0.2952,  0.2453,  0.2353,  0.2553,  0.2638,  0.2894,\n",
              "                       0.2718,  0.2562,  0.2470,  0.3175,  0.3056,  0.2887,  0.0568,  0.2600,\n",
              "                       0.2687,  0.2646,  0.2642,  0.2426,  0.2476,  0.2454,  0.2756,  0.2656,\n",
              "                       0.2669,  0.2494,  0.2780,  0.2655,  0.2521,  0.2556,  0.2967,  0.2451,\n",
              "                       0.2575,  0.2504,  0.2731,  0.2585,  0.2811,  0.2624,  0.2838,  0.2805,\n",
              "                       0.2393,  0.2741,  0.2581,  0.2946,  0.2720,  0.2761,  0.0724,  0.2789,\n",
              "                       0.2447,  0.2470,  0.3112,  0.2495,  0.2773,  0.2465,  0.2402,  0.2543,\n",
              "                       0.2564,  0.2507,  0.2491,  0.2667,  0.2631,  0.2614,  0.2114,  0.2566,\n",
              "                       0.2450,  0.2677,  0.2426,  0.2554,  0.2756,  0.2865,  0.2703,  0.2814,\n",
              "                       0.2556,  0.2284,  0.2800,  0.2630,  0.2786,  0.2338,  0.3023,  0.2640,\n",
              "                       0.2815,  0.2774,  0.2482,  0.2741,  0.2512,  0.2647,  0.1119,  0.2153,\n",
              "                       0.2404,  0.2563,  0.2390,  0.2982,  0.2847,  0.3037,  0.2801,  0.3025,\n",
              "                       0.3589,  0.2505, -0.2263,  0.2671,  0.2650,  0.2814,  0.2725,  0.2550,\n",
              "                       0.2603,  0.2893,  0.2030,  0.2892,  0.2790,  0.2687,  0.2665,  0.2825,\n",
              "                       0.2590,  0.3007,  0.2572,  0.1091,  0.2788,  0.2561,  0.2590,  0.2701,\n",
              "                       0.2539,  0.2760,  0.2400,  0.2793,  0.2398,  0.2774,  0.2783,  0.2579,\n",
              "                       0.2672,  0.2457,  0.2744,  0.2850,  0.2630,  0.2488,  0.2433,  0.2715,\n",
              "                       0.2565,  0.2901,  0.3049,  0.2475,  0.2460,  0.2908,  0.2611,  0.2680,\n",
              "                       0.2626,  0.2698,  0.2534, -0.0016,  0.2828,  0.2817,  0.2578,  0.2574,\n",
              "                       0.2526,  0.2831,  0.8283,  0.2703,  0.2481,  0.2840,  0.2944,  0.2703,\n",
              "                       0.2564,  0.2723,  0.2719,  0.2408,  0.2718,  0.2375,  0.2540,  0.2462,\n",
              "                       0.3759,  0.2630,  0.2571,  0.2621,  0.2472,  0.2590,  0.2725,  0.2361,\n",
              "                       0.2584,  0.2602,  0.2504,  0.2672,  0.2742,  0.2539,  0.2726,  0.2645,\n",
              "                       0.2855,  0.2300,  0.2683,  0.2633,  0.2460,  0.2437,  0.2695,  0.2649,\n",
              "                       0.2823,  0.2552,  0.2681,  0.2802,  0.2698,  0.2652,  0.2574,  0.4505,\n",
              "                       0.2628,  0.2731, -0.2068,  0.2502,  0.2735,  0.2599,  0.2646,  0.2549,\n",
              "                       0.0694,  0.2649,  0.2688,  0.2606,  0.2536,  0.2480,  0.2379,  0.2670,\n",
              "                       0.2871,  0.2343,  0.2742,  0.2635,  0.2536,  0.2595,  0.2587,  0.2702,\n",
              "                       0.2853,  0.2821,  0.2704,  0.2881,  0.2586,  0.2639, -0.0721,  0.2527,\n",
              "                       0.2787,  0.2651,  0.2494,  0.2497,  0.2768,  0.3098,  0.2820,  0.2900,\n",
              "                       0.2448,  0.2560,  0.3463,  0.2591,  0.2928,  0.2891,  0.2699,  0.2807,\n",
              "                       0.2434,  0.2480,  0.2498,  0.2798,  0.2984,  0.2541,  0.2553,  0.2877,\n",
              "                       0.2663,  0.2488,  0.2589,  0.2615,  0.2581,  0.2858,  0.2586,  0.2583,\n",
              "                       0.2742,  0.2678,  0.2581,  0.1815,  0.2414,  0.2715,  0.2646,  0.2241,\n",
              "                       0.2838,  0.2835,  0.2925,  0.2523,  0.2257,  0.2486,  0.2679,  0.2684,\n",
              "                       0.2506,  0.2740,  0.2491,  0.3008,  0.2548,  0.1020,  0.2662,  0.2857,\n",
              "                       0.2611,  0.2464,  0.2280,  0.2463,  0.2755,  0.3037,  0.2607,  0.2785,\n",
              "                       0.2645,  0.2368,  0.2785,  0.2599,  0.2874,  0.2525,  0.2785,  0.2598,\n",
              "                       0.2573,  0.2873,  0.2806,  0.2422,  0.2693,  0.2615,  0.2590,  0.2745,\n",
              "                       0.2609,  0.2660,  0.2569,  0.2700,  0.2551,  0.2848,  0.2790,  0.2587,\n",
              "                       0.2558, -0.2483,  0.2692,  0.2830,  0.3031,  0.2621,  0.2619,  0.2741,\n",
              "                       0.2601,  0.2764,  0.2436,  0.2667,  0.2500,  0.2710,  0.2742,  0.2535,\n",
              "                       0.2718,  0.2747,  0.2821,  0.2631,  0.2809,  0.2444,  0.2679,  0.2647,\n",
              "                       0.2587,  0.2810,  0.4029,  0.2771, -0.0025,  0.2793,  0.2715, -0.1391,\n",
              "                       0.2767,  0.2595,  0.2044,  0.2564,  0.2548,  0.2505,  0.2715,  0.2422,\n",
              "                       0.2711,  0.2704,  0.2629,  0.2626,  0.2677,  0.2652,  0.2793,  0.2823,\n",
              "                       0.2866,  0.2825,  0.2654,  0.2801,  0.2576,  0.2538,  0.2524,  0.2602,\n",
              "                      -0.0483,  0.2857,  0.2729,  0.2801,  0.2663,  0.2760,  0.2655,  0.2259,\n",
              "                       0.2595,  0.5850,  0.2368,  0.2860,  0.2611,  0.2586,  0.2755,  0.2529,\n",
              "                       0.2696,  0.2818,  0.2336,  0.2578,  0.2630,  0.2571,  0.2566,  0.2539,\n",
              "                       0.3196,  0.2824,  0.2663,  0.2625,  0.2483,  0.2855,  0.2680,  0.2474,\n",
              "                       0.2441,  0.2428,  0.2565,  0.2609,  0.0999,  0.2691,  0.2670, -0.0387,\n",
              "                       0.2514,  0.2371,  0.2779,  0.3043,  0.2699,  0.2657,  0.2897, -0.2103,\n",
              "                       0.2613,  0.2547,  0.2333,  0.2604,  0.2748,  0.3309,  0.2622,  0.2409,\n",
              "                       0.2362,  0.2756,  0.2832,  0.2514,  0.2973,  0.2722,  0.2641,  0.2690,\n",
              "                       0.2572,  0.2614,  0.2545,  0.2780,  0.2572,  0.2555,  0.2488,  0.2703,\n",
              "                       0.2552,  0.2582,  0.2678,  0.3026,  0.2624,  0.2625,  0.2645,  0.3200,\n",
              "                       0.2712,  0.2659,  0.2612,  0.2762,  0.2568,  0.2571,  0.2747,  0.2861,\n",
              "                       0.2421,  0.2723,  0.2725,  0.2578,  0.2834,  0.2725,  0.2645,  0.2560,\n",
              "                       0.2629,  0.2613,  0.2538,  0.2543,  0.2574,  0.2737,  0.2735,  0.2862,\n",
              "                       0.2359,  0.3117,  0.2640,  0.2631,  0.2524,  0.2603,  0.2514,  0.2617,\n",
              "                       0.2640,  0.2565,  0.0651,  0.3107,  0.2686,  0.3391,  0.2822,  0.2384,\n",
              "                       0.2766,  0.2648,  0.2789,  0.2580,  0.2972,  0.2755,  0.2508,  0.2660,\n",
              "                       0.2718,  0.2749,  0.2870, -0.0010,  0.2781,  0.2830,  0.2608,  0.2716,\n",
              "                       0.2679,  0.2554,  0.2655,  0.2661,  0.2553,  0.2597,  0.2531,  0.2950,\n",
              "                       0.3041,  0.2418,  0.2529,  0.2508,  0.3421,  0.2735,  0.1935,  0.2570,\n",
              "                       0.2497,  0.2591,  0.2768,  0.2500,  0.2852,  0.2504,  0.2714,  0.3185,\n",
              "                       0.2578,  0.2547,  0.2467,  0.2789,  0.2541,  0.2747,  0.2574,  0.2685,\n",
              "                       0.2616,  0.4007,  0.3033,  0.2576,  0.2537,  0.2652,  0.2537, -0.2599,\n",
              "                       0.2636,  0.2531,  0.2547,  0.2523,  0.2680,  0.2724,  0.2746,  0.2503,\n",
              "                       0.3126,  0.3477,  0.2607,  0.2771,  0.2687,  0.2589,  0.2750,  0.2508,\n",
              "                       0.2455,  0.2823,  0.2656,  0.2620,  0.2744,  0.2686,  0.3170,  0.2642,\n",
              "                       0.2574,  0.2774,  0.2766,  0.2808,  0.2610,  0.2612,  0.2657,  0.2641,\n",
              "                       0.2806,  0.2527,  0.2573,  0.2593,  0.2916,  0.2267,  0.2621,  0.3238,\n",
              "                       0.2653,  0.2490,  0.2834,  0.2845,  0.2573,  0.2627,  0.2672,  0.2680,\n",
              "                       0.2780,  0.2497,  0.2733,  0.2694,  0.2470,  0.2760,  0.2706,  0.2656,\n",
              "                       0.2774,  0.2756,  0.2761,  0.2599,  0.2466,  0.2238,  0.2691,  0.2488,\n",
              "                       0.2712,  0.2634,  0.2901,  0.2523,  0.2576,  0.2624,  0.2717,  0.2687,\n",
              "                       0.2898,  0.2844,  0.2852,  0.2714,  0.2614,  0.2593,  0.2538,  0.2254,\n",
              "                       0.3022,  0.2808,  0.2575,  0.2399,  0.3253,  0.2761,  0.2504,  0.2566,\n",
              "                       0.2708,  0.2759,  0.2447,  0.3605,  0.2723,  0.3010,  0.2667,  0.2363,\n",
              "                       0.2576,  0.2644,  0.2703,  0.2682,  0.2548,  0.3191,  0.2382,  0.2792,\n",
              "                       0.2742,  0.2397,  0.2877,  0.2463,  0.2767,  0.1509,  0.3032,  0.2731,\n",
              "                       0.2686,  0.2642,  0.2424,  0.2629,  0.2645,  0.2464,  0.2637,  0.2640,\n",
              "                       0.3055,  0.2645,  0.2225,  0.2737,  0.2734,  0.2214,  0.2348,  0.2575,\n",
              "                       0.2607,  0.2837,  0.2699,  0.2773,  0.2706,  0.2573,  0.2557,  0.2651,\n",
              "                       0.2512,  0.2265,  0.2413,  0.2276,  0.2750,  0.2466,  0.2518,  0.2645],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0192, -0.0406,  0.0411,  ...,  0.0408, -0.0002, -0.0075],\n",
              "                      [-0.0537,  0.0300, -0.0034,  ..., -0.0213, -0.0217,  0.0424],\n",
              "                      [ 0.0058,  0.0504, -0.0368,  ..., -0.0309,  0.0079, -0.0411],\n",
              "                      ...,\n",
              "                      [ 0.0318, -0.0387,  0.0369,  ..., -0.0017, -0.0951, -0.0148],\n",
              "                      [ 0.0626,  0.0346, -0.0132,  ...,  0.0584,  0.0270,  0.0184],\n",
              "                      [ 0.0002,  0.0834, -0.0135,  ...,  0.0002, -0.0229, -0.0233]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[-0.2362, -0.0107,  0.2837,  ..., -0.5512, -0.0061,  0.5923],\n",
              "                      [ 0.1947,  0.7196, -0.1468,  ...,  0.3833, -0.0662, -0.0726],\n",
              "                      [-0.4750,  0.0244,  0.6719,  ..., -0.3881,  0.3861, -0.2575],\n",
              "                      ...,\n",
              "                      [ 0.2604, -0.2261, -0.1492,  ...,  0.2825, -0.1046,  1.1230],\n",
              "                      [-0.0933, -0.1942,  0.3063,  ...,  0.7768, -0.1545,  0.1566],\n",
              "                      [-0.0962, -0.2045, -0.0188,  ..., -0.7532,  0.1296, -0.5479]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 3.0743e-01,  2.4662e-01, -6.2812e-01,  ...,  5.7983e-01,\n",
              "                        7.5432e-01,  9.2361e-01],\n",
              "                      [-9.4558e-01,  5.2009e-01, -1.7108e-01,  ...,  1.8685e-01,\n",
              "                        6.7509e-01,  4.0431e-01],\n",
              "                      [ 6.0707e-01, -3.9162e-01, -3.4982e-01,  ..., -7.8744e-01,\n",
              "                       -4.0611e-02,  5.4044e-01],\n",
              "                      ...,\n",
              "                      [-3.6901e-01,  7.1040e-01, -1.6911e-01,  ..., -9.6968e-01,\n",
              "                       -9.7565e-01, -1.1250e-03],\n",
              "                      [-1.6620e+00,  7.4863e-01, -4.0113e-01,  ...,  8.8488e-01,\n",
              "                       -2.2846e-01,  1.5758e+00],\n",
              "                      [-4.9734e-01,  1.1566e-01, -1.3619e+00,  ...,  1.3144e+00,\n",
              "                       -1.2373e+00,  7.0766e-01]], device='cuda:0')),\n",
              "             ('decoder.block.9.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[-6.0417e-01, -1.2552e+00, -4.6538e-01,  ..., -1.0742e+00,\n",
              "                       -1.9445e+00, -1.6589e+00],\n",
              "                      [-2.9081e-01,  1.0017e-01,  2.9832e-01,  ..., -2.1062e-03,\n",
              "                       -8.3460e-01,  2.5783e-01],\n",
              "                      [ 5.8090e-02, -5.1103e-01, -1.9827e-01,  ...,  4.3171e-01,\n",
              "                       -5.2788e-01, -4.4022e-01],\n",
              "                      ...,\n",
              "                      [ 7.8093e-01,  3.9617e-02, -1.2581e+00,  ..., -1.4367e+00,\n",
              "                        8.3402e-01,  1.5731e-01],\n",
              "                      [-4.6187e-01,  4.2448e-01,  9.9202e-01,  ..., -1.4823e+00,\n",
              "                       -4.2472e-01, -1.5146e+00],\n",
              "                      [-2.4255e-01,  1.1430e+00,  1.4748e+00,  ...,  7.6720e-01,\n",
              "                        2.2091e+00,  8.6321e-01]], device='cuda:0')),\n",
              "             ('decoder.block.9.layer.1.layer_norm.weight',\n",
              "              tensor([ 5.9781e-02,  7.1148e-02,  6.5050e-02,  3.0801e-02,  4.1325e-02,\n",
              "                       4.6287e-02,  9.4222e-02,  7.2086e-02,  6.9549e-02,  7.0594e-02,\n",
              "                       4.8791e-02,  8.0756e-02,  5.7816e-02,  4.4413e-02,  7.7993e-02,\n",
              "                       6.1184e-02,  6.7135e-02,  6.5768e-02,  4.4212e-02,  8.7088e-02,\n",
              "                       6.7549e-02,  6.4179e-02,  5.9916e-02,  6.7454e-02,  7.4614e-02,\n",
              "                       8.6066e-02,  8.4026e-02,  5.3849e-02,  7.0353e-02,  7.3930e-02,\n",
              "                       6.5948e-02,  6.4494e-02,  7.1568e-02,  7.2963e-02,  6.3021e-02,\n",
              "                       7.3609e-02,  8.2350e-02,  4.6853e-02,  5.8001e-02,  6.2481e-02,\n",
              "                       5.0494e-02,  5.7087e-02,  6.1656e-02,  6.1369e-02,  8.1563e-02,\n",
              "                       5.9185e-02,  7.4344e-02,  9.2983e-02,  6.9419e-02,  7.1478e-02,\n",
              "                       7.1193e-02,  6.5015e-02,  5.3806e-02,  6.9060e-02,  6.1436e-02,\n",
              "                       5.3778e-02,  4.8892e-02,  5.5573e-02,  8.7227e-02,  7.2253e-02,\n",
              "                       6.7574e-02,  5.1149e-02,  6.8472e-02,  7.3651e-02,  6.7094e-02,\n",
              "                       5.2074e-02,  6.4674e-02,  5.3941e-02,  4.7529e-02,  5.6346e-02,\n",
              "                       8.7081e-02,  8.3942e-02,  7.1653e-02,  7.4647e-02,  6.4783e-02,\n",
              "                       6.5486e-02, -4.2634e-02,  7.1253e-02,  7.6156e-02,  8.3862e-02,\n",
              "                       6.5161e-02,  6.4959e-02,  7.0721e-02,  6.4980e-02,  7.7662e-02,\n",
              "                       8.0183e-02,  3.3361e-03,  6.5984e-02,  7.2948e-02,  6.9230e-02,\n",
              "                       6.0350e-02,  6.8820e-02,  5.2047e-02,  5.6318e-02,  6.2303e-02,\n",
              "                       6.7370e-02,  6.0977e-02,  8.2901e-02,  7.5014e-02,  5.9530e-02,\n",
              "                       5.0934e-02,  6.0654e-02,  5.2243e-02,  5.7731e-02,  5.7818e-02,\n",
              "                       4.4628e-02,  6.0818e-02,  6.1332e-02,  8.5683e-02,  8.8130e-02,\n",
              "                       6.9224e-02,  6.3333e-02,  4.2164e-02,  6.4672e-02,  7.5514e-02,\n",
              "                       1.0627e-01,  4.9281e-02,  5.2099e-02, -5.8773e-04,  7.6012e-02,\n",
              "                       7.4804e-02,  9.8254e-02,  7.3006e-02,  5.9461e-02,  7.3364e-02,\n",
              "                       6.1225e-02,  6.2908e-02, -4.1128e-02,  5.5689e-02,  5.1144e-02,\n",
              "                       4.4622e-02,  7.2042e-02,  6.2718e-02,  6.8318e-02,  5.7351e-02,\n",
              "                       4.8320e-02,  6.0338e-02,  5.2692e-02,  6.7970e-02, -5.1600e-02,\n",
              "                       6.9245e-02,  8.2464e-02,  5.0150e-02,  5.6373e-02,  5.5217e-02,\n",
              "                      -5.2179e-02,  6.7922e-02,  5.3220e-02,  7.3523e-02, -4.5859e-02,\n",
              "                       8.7944e-02,  5.2107e-02,  9.5995e-02,  6.0137e-02,  7.9539e-02,\n",
              "                       8.5562e-02,  5.3429e-02,  8.1734e-02,  8.5930e-02,  4.4514e-02,\n",
              "                       6.7209e-02,  5.5475e-02,  5.5988e-02,  5.4213e-02,  7.8655e-02,\n",
              "                       5.8431e-02,  7.9326e-02,  5.0948e-02,  5.4313e-02,  7.1175e-02,\n",
              "                      -5.5888e-02,  5.7544e-02,  8.6076e-02,  7.0612e-02,  8.3517e-02,\n",
              "                       6.0847e-02,  5.1228e-02,  8.9094e-02,  3.9975e-02,  7.0688e-02,\n",
              "                       8.0618e-02,  6.4967e-02,  6.5743e-02,  7.2377e-02,  4.1547e-02,\n",
              "                       6.7172e-02,  7.4262e-02,  4.7915e-02,  5.6742e-02,  4.9169e-02,\n",
              "                       7.6246e-02,  7.2558e-02,  7.6074e-02,  5.6350e-02,  5.8893e-02,\n",
              "                       5.9846e-02,  6.0277e-02,  8.5472e-02,  7.2748e-02,  6.6044e-02,\n",
              "                       7.0117e-02, -4.3899e-02,  7.0526e-02,  7.9899e-02,  5.7773e-02,\n",
              "                      -3.5944e-02,  6.1906e-02,  7.7784e-02,  6.5880e-02,  7.7968e-02,\n",
              "                       7.7041e-02,  6.1148e-02,  5.9051e-02,  6.6838e-02,  6.4175e-02,\n",
              "                       6.6190e-02,  6.2238e-02,  8.1223e-02,  5.9711e-02,  7.5562e-05,\n",
              "                       5.7118e-02,  8.8828e-02,  7.2832e-02,  6.7534e-02,  5.3917e-02,\n",
              "                       6.7534e-02,  1.9635e-01,  7.7352e-02,  5.0215e-02,  6.6507e-02,\n",
              "                       8.8555e-02,  5.2926e-02,  6.4928e-02,  6.2782e-02,  7.3804e-02,\n",
              "                      -6.4878e-02, -5.0200e-02,  5.5559e-02,  5.1116e-02,  5.2472e-02,\n",
              "                      -6.8595e-02,  8.0786e-02,  7.3917e-02,  7.6043e-02,  7.3587e-02,\n",
              "                       5.6717e-02,  8.6644e-02, -5.2952e-02,  6.7734e-02,  5.8852e-02,\n",
              "                       5.5723e-02,  6.9991e-02,  8.1692e-02,  6.0817e-02,  6.2676e-02,\n",
              "                       7.2616e-02,  6.4844e-02,  4.0948e-02,  7.0862e-02,  7.3387e-02,\n",
              "                      -5.5581e-02,  4.2709e-02,  8.9769e-02,  6.5995e-02,  6.7415e-02,\n",
              "                       5.1476e-02,  7.2662e-02,  6.3451e-02,  5.6569e-02,  6.0193e-02,\n",
              "                       7.2469e-02,  6.5992e-02,  7.2602e-02,  6.4991e-02,  3.8067e-02,\n",
              "                       5.5894e-02,  7.7222e-02,  5.6868e-02,  7.0904e-02,  4.3972e-02,\n",
              "                       2.5406e-03,  6.8109e-02,  6.8928e-02,  6.1102e-02,  5.1089e-02,\n",
              "                       7.1535e-02,  6.1444e-02,  7.6186e-02,  6.4183e-02, -4.6040e-02,\n",
              "                       5.9553e-02,  6.0137e-02,  6.2617e-02,  6.6261e-02,  4.8189e-02,\n",
              "                       6.9268e-02,  6.2126e-02,  7.5340e-02,  7.7460e-02,  8.1824e-02,\n",
              "                       8.4425e-02,  6.9506e-02, -2.5311e-02,  5.7429e-02,  5.3226e-02,\n",
              "                       6.1223e-02,  4.9799e-02,  5.7168e-02,  4.1383e-02,  7.5169e-02,\n",
              "                       9.6956e-02,  6.6643e-02,  5.5443e-02, -5.4926e-02,  2.1983e-01,\n",
              "                       6.3721e-02,  1.0594e-01,  5.0250e-02,  7.0307e-02,  8.5956e-02,\n",
              "                       6.8129e-02,  8.7617e-02, -4.5402e-02,  8.0948e-02,  6.4032e-02,\n",
              "                       5.9562e-02,  4.8719e-02,  7.3052e-02,  6.6513e-02,  7.2747e-02,\n",
              "                       6.2852e-02,  6.4664e-02,  6.5603e-02,  6.8291e-02,  7.9450e-02,\n",
              "                       6.3990e-02,  7.3929e-02,  9.6686e-02,  6.6346e-02, -2.9465e-02,\n",
              "                       6.3514e-02,  6.7298e-02,  7.9692e-02,  5.7209e-02,  7.1000e-02,\n",
              "                       7.2519e-02,  7.7365e-02,  4.4919e-02,  4.8500e-02,  5.0634e-02,\n",
              "                       6.1432e-02,  7.2884e-02,  5.8911e-02,  7.6198e-02,  6.0370e-02,\n",
              "                       9.2820e-02,  6.8992e-02,  1.3327e-03,  7.5017e-02,  5.6496e-02,\n",
              "                       5.8295e-02,  6.3819e-02,  3.4903e-02,  5.3335e-02,  7.6420e-02,\n",
              "                       8.2059e-02,  4.7362e-02,  6.9405e-02,  7.1792e-02,  5.7758e-02,\n",
              "                       7.3756e-02,  7.6027e-02,  6.8714e-02,  5.3954e-02,  7.3869e-02,\n",
              "                       6.4007e-02,  6.2595e-02,  8.8501e-02,  7.6023e-02,  5.0680e-02,\n",
              "                       6.5680e-02,  5.2357e-02,  4.8204e-02,  5.7428e-02,  6.2892e-02,\n",
              "                       7.5669e-02,  7.5409e-02,  5.0451e-02,  5.4456e-02,  8.1456e-02,\n",
              "                       7.4199e-02,  6.6270e-02,  5.4742e-02, -5.5817e-02,  6.7175e-02,\n",
              "                      -6.6737e-02,  8.9040e-02,  6.5901e-02,  5.7552e-02,  5.5623e-02,\n",
              "                       6.9164e-02,  7.5217e-02,  6.9323e-02,  8.0370e-02,  6.8967e-02,\n",
              "                       7.2970e-02,  4.9372e-02,  6.7943e-02,  6.0772e-02,  7.3327e-02,\n",
              "                       7.2993e-02,  8.4297e-02,  5.5450e-02,  6.0328e-02,  6.9407e-02,\n",
              "                       7.3770e-02,  6.8225e-02,  6.4417e-02,  2.2664e-01,  5.6487e-02,\n",
              "                       3.3882e-04,  6.2460e-02,  8.1542e-02,  1.0961e-02,  7.0577e-02,\n",
              "                       7.1559e-02,  4.6823e-02,  7.4536e-02,  5.4175e-02,  4.9981e-02,\n",
              "                       7.5477e-02,  6.4384e-02,  5.9940e-02,  6.1563e-02,  6.3113e-02,\n",
              "                       6.9311e-02,  5.5547e-02,  7.8792e-02,  6.8070e-02,  5.4954e-02,\n",
              "                       8.0319e-02,  5.7333e-02,  6.2972e-02,  7.9167e-02,  6.2162e-02,\n",
              "                       5.8241e-02,  6.6483e-02,  5.7658e-02,  2.2315e-04,  6.6306e-02,\n",
              "                       7.1983e-02,  6.6488e-02,  6.5345e-02,  6.6664e-02,  6.0203e-02,\n",
              "                       5.6129e-02,  5.8660e-02,  1.6200e-01,  4.9091e-02,  6.6211e-02,\n",
              "                       7.0858e-02,  6.9571e-02,  6.8626e-02,  7.0916e-02,  6.1839e-02,\n",
              "                       7.9169e-02, -3.9087e-02,  6.0665e-02,  6.1512e-02,  6.1499e-02,\n",
              "                       6.9133e-02,  7.3485e-02,  9.6492e-02,  7.6377e-02,  7.1683e-02,\n",
              "                       7.1489e-02,  6.5356e-02,  7.5088e-02,  6.0301e-02,  6.1533e-02,\n",
              "                      -4.6411e-02,  5.5904e-02,  7.6943e-02,  5.2167e-02, -2.5274e-04,\n",
              "                       6.6406e-02,  7.4012e-02,  3.9979e-02,  8.5542e-02,  5.0670e-02,\n",
              "                       6.8975e-02,  9.0976e-02,  7.0062e-02,  7.9975e-02,  8.2832e-02,\n",
              "                       9.5302e-02,  5.6646e-02,  7.0009e-02,  6.6310e-02,  5.4714e-02,\n",
              "                       7.0193e-02,  1.1611e-01,  6.5484e-02,  5.9905e-02,  6.6436e-02,\n",
              "                       6.4400e-02,  7.0527e-02,  5.8424e-02,  6.6590e-02,  6.8480e-02,\n",
              "                       6.0373e-02,  7.9116e-02,  5.2842e-02,  6.9725e-02,  7.6234e-02,\n",
              "                       6.4397e-02, -6.1197e-02,  6.3462e-02,  4.3923e-02,  7.2806e-02,\n",
              "                       6.4017e-02,  7.2391e-02,  7.7198e-02,  7.7756e-02,  8.5265e-02,\n",
              "                       7.4679e-02,  4.5815e-02,  9.0154e-02,  6.1646e-02,  6.4191e-02,\n",
              "                       4.5217e-02,  6.2612e-02,  6.1687e-02,  7.2999e-02,  7.0852e-02,\n",
              "                       6.6870e-02,  5.4589e-02,  7.0105e-02, -5.4554e-02,  6.6894e-02,\n",
              "                       8.7948e-02,  6.9950e-02,  5.7111e-02, -5.0730e-02,  6.2475e-02,\n",
              "                       5.9639e-02,  7.6457e-02,  5.6253e-02,  6.5784e-02,  6.6192e-02,\n",
              "                       5.4341e-02,  8.1777e-02,  6.9321e-02,  7.7840e-02,  7.4043e-02,\n",
              "                       7.2364e-02,  5.3172e-02,  6.3656e-02,  6.4783e-02,  5.4439e-02,\n",
              "                       7.3592e-02,  5.1568e-02,  7.0570e-04,  5.1399e-02,  7.0374e-02,\n",
              "                       9.4001e-02,  8.2291e-02,  6.6954e-02,  5.9201e-02,  8.1305e-02,\n",
              "                       8.5380e-02,  6.1793e-02,  6.2210e-02,  6.3183e-02,  5.4729e-02,\n",
              "                       6.4938e-02,  5.9310e-02,  7.7729e-02,  8.2747e-02,  1.1155e-03,\n",
              "                       7.9374e-02,  8.8965e-02,  5.8115e-02,  6.5760e-02,  5.6401e-02,\n",
              "                       6.6227e-02,  5.7154e-02,  6.1967e-02,  6.0866e-02,  6.5912e-02,\n",
              "                       7.1204e-02,  8.6953e-02,  7.1906e-02,  5.7028e-02, -5.5032e-02,\n",
              "                       6.2828e-02,  6.3888e-02,  7.2148e-02, -4.9462e-02,  7.1637e-02,\n",
              "                       4.3928e-02,  6.8724e-02,  6.2321e-02,  6.6970e-02,  6.0844e-02,\n",
              "                       5.1999e-02,  7.5687e-02,  6.7862e-02,  6.3330e-02,  5.5030e-02,\n",
              "                      -4.6852e-02,  5.6254e-02,  6.7241e-02,  9.6376e-02,  6.0453e-02,\n",
              "                       6.8889e-02,  5.2469e-02,  1.5498e-01,  8.3271e-02,  6.3850e-02,\n",
              "                       6.8225e-02,  5.8418e-02,  6.6903e-02,  3.0725e-02,  7.1344e-02,\n",
              "                       5.5369e-02,  6.6245e-02,  6.2314e-02,  7.2133e-02,  7.2397e-02,\n",
              "                       6.6079e-02,  7.7410e-02,  6.7361e-02,  6.8175e-02,  6.5358e-02,\n",
              "                       7.2873e-02,  5.5239e-02,  6.6831e-02,  6.2697e-02,  6.2964e-02,\n",
              "                       5.3687e-02,  6.5672e-02,  6.6889e-02,  7.4745e-02,  6.3020e-02,\n",
              "                       5.0616e-02,  4.4286e-02,  6.8858e-02,  5.2097e-02,  7.4014e-02,\n",
              "                       6.8042e-02,  6.9647e-02,  5.7279e-02,  5.3286e-02,  6.6623e-02,\n",
              "                       4.3535e-02,  6.2239e-02,  5.3680e-02,  6.4015e-02,  5.2835e-02,\n",
              "                       8.4662e-02, -5.7667e-02,  5.4014e-02,  1.0779e-01,  6.0463e-02,\n",
              "                       6.8320e-02,  7.4054e-02,  6.7931e-02,  7.5322e-02,  6.0745e-02,\n",
              "                       7.1026e-02,  7.7794e-02,  7.1132e-02,  5.8767e-02, -7.1762e-02,\n",
              "                       7.4881e-02,  7.1469e-02,  8.5564e-02,  6.4971e-02,  5.6552e-02,\n",
              "                       6.5438e-02,  7.3460e-02,  5.7351e-02,  5.2043e-02,  5.7396e-02,\n",
              "                       5.5680e-02,  6.3583e-02,  5.9894e-02,  8.5680e-02,  5.9431e-02,\n",
              "                       7.2410e-02,  5.9511e-02, -5.4254e-02,  5.6972e-02,  6.4771e-02,\n",
              "                       5.4672e-02,  7.0814e-02,  8.4400e-02,  5.8090e-02,  5.6214e-02,\n",
              "                       6.5165e-02,  7.8913e-02,  5.3868e-02,  4.9406e-02,  8.7733e-02,\n",
              "                       7.8109e-02,  6.6332e-02, -3.6796e-02,  6.8964e-02,  6.7440e-02,\n",
              "                       5.2208e-02,  6.8591e-02,  6.5179e-02,  6.9978e-02,  4.2246e-02,\n",
              "                       1.2685e-01,  5.3912e-02,  8.9822e-02,  6.1619e-02, -5.6158e-02,\n",
              "                       7.5548e-02,  7.6436e-02,  4.3382e-02,  5.9490e-02,  6.3444e-02,\n",
              "                       5.6521e-02,  5.8896e-02,  6.8244e-02,  5.9216e-02,  5.0552e-02,\n",
              "                       6.4253e-02,  5.7892e-02,  7.5311e-02,  6.2512e-02,  9.3301e-02,\n",
              "                       7.5983e-02,  6.8567e-02,  6.2952e-02,  5.7158e-02,  6.0282e-02,\n",
              "                       5.8704e-02,  4.9542e-02,  7.0597e-02,  6.4612e-02,  7.9402e-02,\n",
              "                       5.8593e-02,  4.7616e-02,  6.7616e-02,  6.0301e-02,  5.8993e-02,\n",
              "                      -4.9884e-02,  6.5976e-02,  5.1461e-02,  5.1084e-02,  6.1305e-02,\n",
              "                       9.3415e-02,  5.6093e-02,  5.2650e-02,  6.2054e-02,  5.6987e-02,\n",
              "                       5.8621e-02,  5.7230e-02,  5.2802e-02, -5.1139e-02,  8.3127e-02,\n",
              "                       5.7687e-02,  5.9431e-02,  4.5374e-02], device='cuda:0')),\n",
              "             ('decoder.block.9.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[-0.2074,  0.0861,  0.6346,  ...,  0.4770,  0.0984, -0.1019],\n",
              "                      [ 0.4725, -0.1430,  0.0848,  ..., -0.6150, -0.3078,  0.2644],\n",
              "                      [-0.1842, -0.3708,  0.2549,  ..., -0.4236,  0.1366,  0.1451],\n",
              "                      ...,\n",
              "                      [ 0.3738,  0.0615, -0.2916,  ..., -0.6360,  0.2655,  0.6836],\n",
              "                      [ 0.1734,  0.4238,  0.2467,  ..., -0.4422,  0.0782,  0.7269],\n",
              "                      [-0.2972,  0.1478, -0.5341,  ..., -0.1613, -0.0817,  0.7320]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[ 0.5598, -0.0678,  0.1439,  ..., -0.0324,  0.2660, -0.1076],\n",
              "                      [ 0.1736,  0.2738,  0.1093,  ...,  0.2981,  0.2411,  0.1396],\n",
              "                      [ 0.2296,  0.0832,  0.0441,  ..., -0.3392,  0.0638, -0.0593],\n",
              "                      ...,\n",
              "                      [ 0.3011,  0.0446,  0.2081,  ...,  0.3803, -0.3006, -0.0746],\n",
              "                      [-0.0371,  0.3209,  0.2217,  ...,  0.1275,  0.0461,  0.0188],\n",
              "                      [ 0.6715, -0.0067,  0.0386,  ..., -0.0685,  0.2287,  0.4559]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.9.layer.2.layer_norm.weight',\n",
              "              tensor([ 4.6345,  5.3363,  5.4131,  3.0156,  4.6281,  4.3133,  4.7164,  5.0646,\n",
              "                       4.8870,  4.5356,  4.6393,  4.7052,  6.1272,  4.9436,  4.8181,  4.4431,\n",
              "                       4.6785,  4.7232,  4.6232,  4.8198,  4.6482,  4.6223,  4.7446,  3.9446,\n",
              "                       4.3581,  4.8290,  4.7646,  5.4745,  5.0367,  4.6238,  4.6672,  6.0433,\n",
              "                       4.5397,  4.4886,  5.1216,  5.1941,  4.7904,  5.9526,  4.3940,  4.5554,\n",
              "                       4.2613,  4.8312,  4.7785,  4.8086,  5.7230,  4.5018,  4.9410,  4.9015,\n",
              "                       4.4318,  4.7360,  5.0451,  4.4016,  4.9014,  4.4608,  6.9030,  4.5457,\n",
              "                       4.9376,  4.5188,  4.7459,  4.5072,  4.9092,  4.5068,  4.7792,  4.9734,\n",
              "                       4.5356,  8.5158,  4.3915,  5.1368,  7.1860,  4.4073,  5.2543,  4.5175,\n",
              "                       4.8807,  4.7116,  5.1712,  4.3830,  4.9569,  4.3577,  4.7208,  5.2844,\n",
              "                       4.4211,  4.5453,  4.3887,  5.2171,  4.9638,  4.9891,  1.3292,  4.4770,\n",
              "                       4.3521,  4.5333,  4.6407,  4.5662,  4.2452,  4.5381,  4.9193,  4.5517,\n",
              "                       4.5712,  4.4481,  4.7597,  4.2164,  4.8179,  4.4971,  6.6604,  4.6872,\n",
              "                       4.6253,  4.5306,  4.3671,  4.7198,  4.7954,  5.0329,  4.7288,  4.6933,\n",
              "                       4.3031,  4.5493,  4.8780,  5.2187,  4.6207,  4.6963,  0.0189,  4.8303,\n",
              "                       4.5244,  4.4303,  5.4625,  4.4147,  4.8498,  4.5576,  4.5151,  4.4144,\n",
              "                       4.6397,  4.9715,  6.1316,  4.8702,  4.6575,  4.5353,  4.4376,  4.7559,\n",
              "                       4.2812,  5.4476,  4.4057,  4.7516,  5.8994,  4.6531,  4.3715,  4.8743,\n",
              "                       4.6253,  4.4661,  4.8812,  5.2335,  4.7352,  4.3686,  4.6880,  4.6885,\n",
              "                       5.7747,  5.1391,  4.6803,  4.8761,  4.4275,  4.8185,  4.4375,  4.5546,\n",
              "                       4.4089,  4.6982,  4.6939,  5.3490,  4.6782,  5.3083,  4.9157,  5.0864,\n",
              "                       6.3622,  4.6368,  6.4438,  4.5583,  5.0254,  4.8477,  4.7107,  4.2860,\n",
              "                       4.6776,  4.7878,  6.1021,  4.7751,  4.9934,  4.6644,  4.6009,  4.8144,\n",
              "                       4.8736,  5.4092,  4.5754,  3.0147,  4.8846,  4.5766,  4.8000,  4.6087,\n",
              "                       4.8413,  4.4361,  4.2812,  4.7906,  4.4453,  4.9428,  4.5724,  4.5385,\n",
              "                       4.5569,  4.4415,  4.7360,  4.8519,  4.6825,  4.2204,  4.2261,  4.6027,\n",
              "                       4.6761,  4.5218,  5.3263,  4.4785,  4.3363,  5.0110,  4.3476,  5.0806,\n",
              "                       4.8754,  4.7620,  4.4390,  1.4705,  5.7876,  4.8597,  5.2057,  4.3396,\n",
              "                       4.9440,  4.6176,  4.2698,  4.5658,  4.5655,  4.9994,  4.6225,  4.4509,\n",
              "                       4.8890,  4.3330,  4.7954,  4.5860,  4.9046,  4.2495,  5.2011,  4.4595,\n",
              "                       7.4693,  4.5051,  4.5614,  4.5118,  4.0088,  4.2527,  4.6601,  4.1659,\n",
              "                       4.4653,  4.3801,  5.0122,  4.6427,  4.7471,  4.9594,  4.7215,  4.9664,\n",
              "                       4.8380,  5.3449,  4.4647,  4.9450,  5.1717,  5.2868,  4.4679,  4.3181,\n",
              "                       4.9587,  4.4552,  4.7643,  4.6744,  4.4067,  4.8800,  4.5644,  8.2732,\n",
              "                       4.5273,  4.8609,  5.9681,  4.2799,  4.9398,  4.6211,  4.7828,  4.6281,\n",
              "                       1.2188,  6.4144,  4.6401,  4.5995,  4.2236,  4.5808,  4.3866,  4.8204,\n",
              "                       5.5946,  4.7566,  4.8070,  4.6718,  4.4766,  4.5595,  4.6320,  4.7370,\n",
              "                       5.4922,  4.7063,  4.9458,  4.9823,  4.9982,  4.7442,  2.0882,  4.4208,\n",
              "                       4.5346,  4.7487,  4.3650,  4.4283,  4.8754,  4.5628,  4.7455,  4.9071,\n",
              "                       4.2484,  4.3518,  5.1559,  4.7547,  4.8627,  4.9534,  4.5889,  4.5612,\n",
              "                       4.2243,  5.1026,  4.3388,  4.8110,  4.7458,  4.7314,  4.2934,  5.5477,\n",
              "                       4.6150,  4.4747,  4.7627,  5.4119,  4.5299,  4.5015,  4.8206,  4.6266,\n",
              "                       4.9529,  4.7478,  4.6352,  4.3732,  4.7229,  5.0594,  4.5843,  4.1839,\n",
              "                       4.7395,  4.8364,  4.6622,  4.8462,  5.2772,  5.0604,  4.5410,  4.4973,\n",
              "                       4.5191,  4.6797,  4.3736,  4.7701,  4.5906, -0.0333,  4.7493,  4.6255,\n",
              "                       4.7034,  4.6478,  6.9698,  4.3725,  4.7534,  4.8141,  4.9868,  4.6584,\n",
              "                       4.6710,  4.6561,  4.9016,  4.5489,  5.0992,  4.3788,  4.4979,  4.6019,\n",
              "                       4.5661,  4.8807,  5.2517,  5.2016,  4.6668,  4.6646,  5.4702,  4.3877,\n",
              "                       4.8811,  4.3888,  4.4515,  4.5532,  4.5964,  4.5665,  5.0403,  4.6600,\n",
              "                       4.6392,  4.7284,  4.7362,  4.3828,  5.1709,  4.6768,  4.4353,  4.6598,\n",
              "                       4.4368,  4.9450,  4.4622,  4.6232,  4.1772,  4.7601,  5.0250,  4.3831,\n",
              "                       4.7773,  4.4018,  4.9476,  4.7756,  4.5320,  4.4691,  4.8435,  4.7393,\n",
              "                       5.2780,  4.4995,  6.0096,  4.8397,  0.0372,  4.4154,  4.5766,  3.2714,\n",
              "                       4.5823,  4.8886,  4.3152,  4.4611,  4.9090,  4.8968,  4.6026,  4.9461,\n",
              "                       4.2669,  4.8090,  4.5976,  4.7602,  4.4039,  5.1308,  5.2344,  5.4053,\n",
              "                       5.2618,  5.9949,  4.7563,  4.6782,  4.5056,  4.6339,  4.3698,  4.4135,\n",
              "                      -0.0172,  4.6844,  4.6209,  4.6725,  4.4923,  4.8457,  4.7766,  4.7188,\n",
              "                       5.4265,  5.5997,  4.5922,  4.8107,  4.7448,  4.5376,  4.7469,  4.9662,\n",
              "                       4.7901,  4.8182,  4.7453,  4.4924,  4.2208,  4.6831,  4.4115,  4.5249,\n",
              "                       8.1272,  4.8090,  4.5258,  4.9183,  4.3774,  5.0190,  4.8145,  4.3767,\n",
              "                       4.4643,  4.8479,  4.7008,  4.6570,  1.8044,  4.7234,  4.5002,  1.2000,\n",
              "                       5.0953,  4.2710,  4.6160,  4.6865,  4.6390,  4.6405,  4.8054, 11.8169,\n",
              "                       5.0372,  4.5567,  4.3903,  4.5020,  4.6857,  5.2561,  4.6399,  4.7489,\n",
              "                       4.6890,  4.8758,  4.9260,  4.3516,  4.6421,  4.7508,  4.5852,  4.5318,\n",
              "                       4.9601,  4.8077,  4.9728,  4.6610,  4.3496,  4.3948,  5.1232,  4.5559,\n",
              "                       4.4683,  4.4134,  4.5029,  4.8967,  4.8831,  4.7867,  4.5547,  5.8709,\n",
              "                       4.9058,  4.6327,  4.7905,  4.6635,  4.3023,  4.3297,  4.6848,  4.8299,\n",
              "                       4.3818,  4.4888,  4.5113,  4.3241,  4.6577,  4.8462,  4.3192,  4.5763,\n",
              "                       4.4038,  4.5413,  5.0235,  4.6752,  4.7288,  4.8177,  5.2317,  5.6255,\n",
              "                       4.3895,  6.0813,  4.4747,  4.7956,  4.8969,  4.5057,  4.6305,  4.5291,\n",
              "                       4.6702,  5.0681,  0.9425,  5.4206,  4.5193,  5.9397,  4.7112,  4.4037,\n",
              "                       4.7836,  4.4800,  4.7600,  4.4953,  4.6504,  4.5582,  4.7892,  4.9476,\n",
              "                       4.5701,  4.8830,  4.9625,  0.9818,  4.9979,  4.7194,  4.6970,  4.9609,\n",
              "                       4.3452,  4.6258,  4.8429,  4.5697,  4.4768,  4.6567,  4.6594,  4.9093,\n",
              "                       5.2498,  4.6531,  4.2214,  4.5979,  6.2753,  4.6337,  4.4337,  5.0453,\n",
              "                       4.5662,  4.6541,  4.2981,  4.6024,  4.6355,  4.6663,  4.6458,  6.2424,\n",
              "                       4.3302,  4.4712,  4.5927,  4.8689,  4.3452,  4.9192,  4.4965,  4.5070,\n",
              "                       4.4736,  6.4860,  4.9647,  4.3699,  4.5047,  4.6472,  4.9424,  5.5062,\n",
              "                       4.3694,  4.7179,  4.4130,  4.2777,  4.7849,  4.5435,  4.6720,  4.6262,\n",
              "                       5.0337,  7.0721,  4.7534,  4.9324,  4.8002,  4.7169,  4.6987,  4.5005,\n",
              "                       4.9819,  4.9032,  4.4861,  5.1650,  5.5905,  4.6231,  7.0898,  4.4298,\n",
              "                       4.0887,  5.0065,  4.6209,  4.6249,  4.4026,  4.4051,  4.9372,  5.9258,\n",
              "                       4.5679,  4.5054,  4.1928,  4.6401,  4.9694,  4.7547,  4.4324,  5.6477,\n",
              "                       4.6044,  4.6138,  4.6593,  4.7430,  4.4324,  4.4782,  4.8770,  4.5254,\n",
              "                       4.7694,  4.3619,  4.6557,  4.5736,  4.5885,  4.8103,  4.7798,  4.5410,\n",
              "                       4.5814,  4.7895,  6.0103,  4.4999,  4.4195,  4.4698,  4.3091,  4.4451,\n",
              "                       4.7119,  4.6352,  4.6670,  4.5205,  4.6630,  4.5901,  4.6837,  4.3425,\n",
              "                       4.7435,  4.9958,  4.9350,  4.5482,  4.3180,  4.6563,  4.7049,  5.1456,\n",
              "                       4.9024,  4.6265,  4.6079,  5.0094,  6.3893,  4.5404,  4.9409,  4.7858,\n",
              "                       4.7734,  5.1642,  5.2102,  5.0662,  4.7207,  5.0970,  4.2217,  4.4424,\n",
              "                       4.5362,  4.6617,  6.0353,  4.7226,  4.5140,  5.7179,  4.6256,  4.7860,\n",
              "                       4.5536,  4.4421,  4.3929,  4.5007,  4.9040,  5.8886,  4.7566,  4.7447,\n",
              "                       4.4127,  4.4633,  4.3243,  4.9846,  4.8797,  5.1523,  4.8518,  5.4942,\n",
              "                       4.7197,  4.6234,  5.0721,  4.5608,  4.6842,  5.0042,  4.1974,  4.5216,\n",
              "                       4.6677,  4.6033,  4.8440,  4.9678,  4.5322,  4.5034,  5.2236,  4.4566,\n",
              "                       5.0559,  4.5670,  4.1477,  4.2595,  4.6490,  4.4053,  4.1709,  4.4999],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0100, -0.0403, -0.0174,  ...,  0.0409, -0.0233, -0.0166],\n",
              "                      [ 0.0039, -0.0198,  0.0277,  ..., -0.0347, -0.0350,  0.0626],\n",
              "                      [-0.0271, -0.0293, -0.0105,  ..., -0.0131,  0.0559,  0.0323],\n",
              "                      ...,\n",
              "                      [ 0.0076,  0.0109, -0.0403,  ..., -0.0011,  0.0140, -0.0462],\n",
              "                      [ 0.0779, -0.0117, -0.0388,  ..., -0.0512,  0.0244,  0.0198],\n",
              "                      [ 0.0334, -0.0402, -0.0056,  ...,  0.0052, -0.0028, -0.0134]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.0127,  0.1796, -0.0307,  ...,  0.1377,  0.1221, -0.2767],\n",
              "                      [-0.2965,  0.3004,  0.3115,  ...,  0.3020, -0.0527,  0.1421],\n",
              "                      [ 0.0038,  0.1900,  0.1669,  ...,  0.1196,  0.1134,  0.0298],\n",
              "                      ...,\n",
              "                      [-0.2209,  0.0375, -0.3566,  ..., -0.3584, -0.2070, -0.3326],\n",
              "                      [ 0.2405, -0.5029, -0.1193,  ..., -0.3145,  0.1488, -0.2133],\n",
              "                      [ 0.1972, -0.5291,  0.0251,  ..., -0.4769,  0.0582, -0.0991]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[ 0.1142, -0.1739,  0.7961,  ...,  0.2999,  0.0048,  0.3685],\n",
              "                      [-0.7732,  1.2232, -1.1968,  ..., -0.5221, -0.3054,  0.0470],\n",
              "                      [-1.2961, -0.6497,  0.4092,  ..., -0.4341,  0.6765,  0.9110],\n",
              "                      ...,\n",
              "                      [-0.7349, -1.3668,  0.4668,  ..., -0.8052, -0.0306, -1.3400],\n",
              "                      [-0.5731,  1.1626,  1.7251,  ...,  0.8147,  0.0377,  0.6962],\n",
              "                      [-0.0027, -1.5468,  0.4291,  ...,  0.4878,  1.0600, -0.9368]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[-0.5414, -1.8414,  0.1361,  ...,  0.3604,  0.5169, -0.2422],\n",
              "                      [ 0.2588, -0.0077, -0.0915,  ..., -0.0996, -0.6120,  0.2505],\n",
              "                      [-0.1365, -0.9189, -0.0150,  ...,  0.2794,  0.8425, -0.8368],\n",
              "                      ...,\n",
              "                      [-0.5316, -1.0287, -0.5723,  ..., -0.7663, -1.0858,  1.1829],\n",
              "                      [ 0.0482, -1.5079,  1.7946,  ..., -0.6592, -0.2840, -1.1898],\n",
              "                      [ 0.3857,  1.6357,  1.5444,  ...,  0.1834, -1.6466,  0.2001]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.0.layer_norm.weight',\n",
              "              tensor([ 0.2990,  0.3078,  0.3761, -0.1398,  0.2975,  0.2762,  0.3324,  0.3095,\n",
              "                       0.3062,  0.2904,  0.2726,  0.3202,  0.2465,  0.2780,  0.2955,  0.2813,\n",
              "                       0.2978,  0.3258, -0.2762,  0.2972,  0.2762,  0.2885,  0.2916,  0.2691,\n",
              "                       0.2877,  0.3361,  0.2986,  0.3170,  0.3379,  0.3022,  0.3108,  0.3334,\n",
              "                       0.2945,  0.3298,  0.2899,  0.3279,  0.3246,  0.3121,  0.3081,  0.2889,\n",
              "                       0.2708,  0.3411,  0.3082,  0.3193,  0.4070,  0.2951,  0.3045,  0.2981,\n",
              "                       0.3089,  0.2897,  0.3521,  0.2954,  0.3183,  0.2883,  0.4590,  0.2765,\n",
              "                       0.3148,  0.2981,  0.3103,  0.2990,  0.3254,  0.3021,  0.2943,  0.3238,\n",
              "                       0.3118,  0.2954,  0.2935,  0.3173,  0.3009,  0.2905,  0.3074,  0.3273,\n",
              "                       0.3109,  0.3048,  0.3338,  0.3102, -0.2828,  0.2751,  0.3316,  0.3433,\n",
              "                       0.3062,  0.2832,  0.2803,  0.3746,  0.3377,  0.3351,  0.0495,  0.2989,\n",
              "                       0.2973,  0.3090,  0.3052,  0.3041,  0.2841,  0.2751,  0.3147,  0.3056,\n",
              "                       0.2989,  0.3153,  0.3221,  0.2956,  0.2740,  0.2848,  0.3668,  0.3080,\n",
              "                       0.3198,  0.3207,  0.2945,  0.3197,  0.3297,  0.3125,  0.3203,  0.3118,\n",
              "                       0.2671,  0.3178,  0.3297,  0.3653,  0.3349,  0.2759, -0.0651,  0.3154,\n",
              "                       0.2875,  0.2964,  0.3847,  0.3267,  0.3236,  0.3226,  0.2916,  0.2923,\n",
              "                       0.2818,  0.2871, -0.3076,  0.3205,  0.3183,  0.2829,  0.2426,  0.2791,\n",
              "                       0.2906,  0.3304,  0.2802,  0.2992,  0.3288,  0.3047,  0.2825,  0.3252,\n",
              "                       0.2847,  0.2844,  0.3281,  0.3184,  0.3269,  0.2770,  0.3293,  0.2975,\n",
              "                       0.3607,  0.3253,  0.3192,  0.3119,  0.2751,  0.3105,  0.1265,  0.2682,\n",
              "                       0.2998,  0.2931,  0.2756,  0.3720,  0.3442,  0.3839,  0.3124,  0.3454,\n",
              "                       0.4156,  0.3058,  0.2816,  0.3065,  0.3146,  0.3245,  0.2993,  0.3035,\n",
              "                       0.2924,  0.3310, -0.2451,  0.3146,  0.3174,  0.2855,  0.2896,  0.3165,\n",
              "                       0.2906,  0.3551,  0.2932,  0.0958,  0.2983,  0.2923,  0.2864,  0.2887,\n",
              "                       0.3169,  0.2711,  0.3046,  0.2969,  0.2962,  0.3311,  0.3017,  0.2954,\n",
              "                       0.2849,  0.2677,  0.3114,  0.3440,  0.3234,  0.2871,  0.2814,  0.2774,\n",
              "                       0.3251,  0.3092,  0.3628,  0.2829,  0.2645,  0.3335,  0.2824,  0.3291,\n",
              "                       0.3205,  0.3128,  0.2852, -0.0122,  0.3300,  0.3158,  0.3153,  0.2886,\n",
              "                       0.3057,  0.3143,  0.7681,  0.3176,  0.2942,  0.3260,  0.3453,  0.2608,\n",
              "                       0.3214,  0.2978,  0.3185,  0.2982,  0.2912,  0.2801,  0.3126,  0.2792,\n",
              "                       0.4564,  0.3001,  0.3138,  0.3121,  0.2751,  0.2741,  0.3217,  0.2674,\n",
              "                       0.3244,  0.3046,  0.2860,  0.2946,  0.2933,  0.3110,  0.3104,  0.3209,\n",
              "                       0.3237,  0.2626,  0.3252,  0.2897, -0.2644,  0.2836,  0.3055,  0.2984,\n",
              "                       0.3208,  0.3160,  0.3186,  0.3314,  0.3111,  0.3176,  0.2852,  0.5253,\n",
              "                       0.3074,  0.3117, -0.2216,  0.2701,  0.3161,  0.2795,  0.3253,  0.2720,\n",
              "                       0.0491,  0.3946,  0.3294,  0.3041,  0.2725,  0.2898,  0.2898,  0.3119,\n",
              "                       0.3366,  0.2892,  0.3144,  0.3173,  0.3016,  0.3035,  0.3109,  0.3224,\n",
              "                       0.3051,  0.2996,  0.3034,  0.2983,  0.3134,  0.3083,  0.0958,  0.2738,\n",
              "                       0.3077,  0.3245,  0.2632,  0.2754,  0.2907,  0.3192,  0.3313,  0.3289,\n",
              "                       0.2732,  0.2621,  0.4239,  0.3085,  0.3422,  0.2799,  0.3231,  0.3098,\n",
              "                       0.2773,  0.3264,  0.2951,  0.3235,  0.3108,  0.3061,  0.2715,  0.3573,\n",
              "                       0.3025,  0.2933,  0.3009,  0.2991,  0.2988,  0.3264,  0.3284,  0.2908,\n",
              "                       0.3293,  0.3075,  0.3117, -0.1854,  0.2957,  0.2983,  0.3120,  0.2711,\n",
              "                       0.3322,  0.3152,  0.3115,  0.2754,  0.2823,  0.2901,  0.3130,  0.3075,\n",
              "                       0.2892,  0.3172,  0.2528,  0.3397,  0.3175,  0.1831,  0.3061,  0.2863,\n",
              "                       0.2739,  0.2971,  0.2429,  0.2940,  0.3291,  0.3472,  0.2950,  0.3454,\n",
              "                       0.3054,  0.2828,  0.3128,  0.2992,  0.3447,  0.2616,  0.3001,  0.3019,\n",
              "                       0.2872,  0.3376,  0.3203,  0.2825,  0.3250,  0.3061,  0.3092,  0.3023,\n",
              "                       0.3114,  0.3117,  0.2855,  0.3076,  0.3343,  0.3182,  0.3349,  0.2927,\n",
              "                       0.2838, -0.2812,  0.3062,  0.2806,  0.3709,  0.3142,  0.2928,  0.2992,\n",
              "                       0.3074,  0.2961,  0.3020,  0.2985,  0.2759,  0.2972,  0.3167,  0.3083,\n",
              "                       0.3185,  0.3200,  0.3063,  0.3361,  0.3101,  0.2856,  0.3058,  0.3073,\n",
              "                       0.3215,  0.3059,  0.3992,  0.3506,  0.0272,  0.2869,  0.2777, -0.1642,\n",
              "                       0.2974,  0.3345, -0.2510,  0.3114,  0.2938,  0.2763,  0.2931,  0.3025,\n",
              "                       0.2902,  0.3240,  0.3141,  0.3336,  0.2962,  0.3188,  0.3372,  0.3200,\n",
              "                       0.3507,  0.3390,  0.3231,  0.3112,  0.3011,  0.2837,  0.2842,  0.2690,\n",
              "                       0.0814,  0.3100,  0.2764,  0.3275,  0.3159,  0.3218,  0.3157,  0.2668,\n",
              "                      -0.3242,  0.6121,  0.2789,  0.3175,  0.3139,  0.2942,  0.2971,  0.3106,\n",
              "                       0.3054,  0.3092,  0.2976,  0.2756,  0.3032,  0.2884,  0.2878,  0.2994,\n",
              "                       0.5012,  0.3103,  0.2833,  0.3217,  0.2822,  0.3308,  0.3115,  0.2802,\n",
              "                       0.2802,  0.3121,  0.3001,  0.3076, -0.1181,  0.2919,  0.3054,  0.0501,\n",
              "                       0.3189,  0.2634,  0.3008,  0.3265,  0.2957,  0.3198,  0.3324, -0.2227,\n",
              "                       0.2951,  0.2898,  0.2722,  0.2878,  0.3111,  0.3667,  0.2973,  0.2976,\n",
              "                       0.3088,  0.3097,  0.3346,  0.2811,  0.3289,  0.3232,  0.3014,  0.3125,\n",
              "                       0.2882,  0.3079,  0.3164,  0.3114,  0.2797,  0.2948,  0.2940,  0.3028,\n",
              "                       0.2812,  0.2787,  0.3099,  0.3637,  0.3197,  0.3329,  0.2821,  0.4287,\n",
              "                       0.3174,  0.3162,  0.3060,  0.3081,  0.2752,  0.3166,  0.3160,  0.3289,\n",
              "                       0.2798,  0.2810,  0.3041,  0.2996,  0.3063,  0.3061,  0.2953,  0.2792,\n",
              "                       0.2776,  0.3263,  0.3243,  0.3172,  0.2958,  0.3150,  0.3224,  0.3327,\n",
              "                       0.2885,  0.3592,  0.2847,  0.3093, -0.2995,  0.2963,  0.3256,  0.2770,\n",
              "                       0.3089,  0.3084,  0.1376, -0.3186,  0.2922,  0.3687,  0.3043,  0.3054,\n",
              "                       0.2808,  0.3273,  0.3133,  0.2992,  0.3011,  0.2990,  0.2912,  0.3036,\n",
              "                       0.3173,  0.3391,  0.3465,  0.0237,  0.3581,  0.3258,  0.2885,  0.3060,\n",
              "                       0.2774,  0.3010,  0.2935,  0.2780,  0.3174,  0.3138,  0.2876,  0.3071,\n",
              "                       0.3802,  0.3165,  0.2631,  0.3031,  0.3878,  0.3239, -0.1538,  0.3257,\n",
              "                       0.2955,  0.3050,  0.2938,  0.2978,  0.3003,  0.2935,  0.3153,  0.3583,\n",
              "                       0.2875,  0.2894,  0.2975,  0.2998,  0.2923,  0.3363,  0.2793,  0.3084,\n",
              "                       0.2787,  0.3656,  0.3350,  0.3028,  0.2955,  0.3091,  0.3113,  0.2886,\n",
              "                       0.2951,  0.3110,  0.2850,  0.2678,  0.3054,  0.3172,  0.3302,  0.3112,\n",
              "                       0.3522,  0.4393,  0.3270,  0.3066,  0.3024,  0.3094,  0.3153,  0.2846,\n",
              "                       0.2916,  0.3512,  0.2903,  0.3158,  0.3427,  0.2996,  0.3301,  0.3088,\n",
              "                       0.2840,  0.3212,  0.3035,  0.3178,  0.2934,  0.2806,  0.3346,  0.3491,\n",
              "                       0.3046,  0.2778,  0.2716,  0.2773,  0.3416,  0.2799,  0.2899,  0.3448,\n",
              "                       0.2898,  0.2756,  0.3209,  0.3034,  0.3026,  0.3214,  0.3147,  0.3065,\n",
              "                       0.2966,  0.3022,  0.3024,  0.3223,  0.2964,  0.3149,  0.3135,  0.3013,\n",
              "                       0.3154,  0.3145,  0.3442,  0.3182,  0.2959,  0.2706,  0.2985,  0.2959,\n",
              "                       0.3035,  0.3027,  0.2995,  0.2884,  0.2911,  0.3184,  0.3132,  0.2853,\n",
              "                       0.3194,  0.3371,  0.3228,  0.2976,  0.2963,  0.3162,  0.2970,  0.2413,\n",
              "                       0.3502,  0.3297,  0.2882,  0.2736,  0.3984,  0.3054,  0.3174,  0.3109,\n",
              "                       0.3052,  0.3145, -0.3152,  0.4212,  0.2992,  0.3589,  0.2859,  0.2628,\n",
              "                       0.2982,  0.2989,  0.3017,  0.3053,  0.2987,  0.3793,  0.2807,  0.3080,\n",
              "                       0.3024,  0.2759,  0.3277,  0.2964,  0.3274, -0.1730,  0.3638,  0.2915,\n",
              "                       0.3015,  0.2759,  0.2867,  0.3208,  0.3224,  0.2694,  0.3087,  0.2895,\n",
              "                       0.3279,  0.2959,  0.2748,  0.3167,  0.2885,  0.2475,  0.2684,  0.3039,\n",
              "                       0.2966,  0.3212,  0.3132,  0.3528,  0.3088,  0.2907,  0.2858,  0.3061,\n",
              "                       0.2756,  0.2866,  0.2802,  0.2816,  0.3243,  0.2922,  0.2711,  0.2625],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[ 0.0439, -0.0007,  0.0673,  ...,  0.0075,  0.0832, -0.0094],\n",
              "                      [ 0.0350, -0.0485,  0.0047,  ...,  0.0091, -0.0005,  0.0171],\n",
              "                      [-0.0614,  0.0558,  0.0153,  ..., -0.0105, -0.0163, -0.0035],\n",
              "                      ...,\n",
              "                      [-0.0435,  0.0010, -0.0171,  ...,  0.0357,  0.0505, -0.0323],\n",
              "                      [ 0.0371, -0.0388,  0.0053,  ...,  0.0312, -0.0665,  0.0707],\n",
              "                      [-0.0316, -0.0515, -0.0047,  ...,  0.0266,  0.0359,  0.0150]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[ 0.6709, -0.5569, -0.1375,  ...,  0.3229, -0.1538,  0.4280],\n",
              "                      [ 0.0925,  0.0803,  0.3155,  ..., -0.1839, -0.0619,  0.1318],\n",
              "                      [-0.2979, -0.0010,  0.2213,  ...,  0.4600,  0.1525,  0.2787],\n",
              "                      ...,\n",
              "                      [-0.0844,  0.2579, -0.1519,  ...,  0.4488,  0.3649,  0.1408],\n",
              "                      [ 0.3324,  0.0641,  0.3818,  ..., -0.0152, -0.3213, -0.1189],\n",
              "                      [-0.1413, -0.3242, -0.2066,  ..., -0.0715,  0.3385,  0.3638]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.4184, -0.4067,  1.3666,  ...,  0.2955, -2.0698, -1.5886],\n",
              "                      [ 0.1325, -1.1292,  0.0075,  ..., -1.9148, -0.3398, -0.3616],\n",
              "                      [-0.3872, -0.1793, -0.0117,  ..., -0.9389,  0.2071, -0.0214],\n",
              "                      ...,\n",
              "                      [ 0.1862, -0.0368, -0.8718,  ..., -0.2537,  0.1513, -0.3470],\n",
              "                      [ 1.9175,  0.6201,  0.4033,  ...,  0.5026,  0.7538, -0.3884],\n",
              "                      [ 2.3782, -0.4379, -0.7308,  ...,  0.6978, -0.0865,  0.2250]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[-0.4536, -1.0914,  1.8504,  ..., -1.0944, -0.0594, -0.6253],\n",
              "                      [ 0.3327,  0.1041,  1.1766,  ...,  0.1241,  0.0642, -0.6230],\n",
              "                      [-0.5891,  0.7690,  0.4238,  ..., -0.3625,  0.1199, -0.1723],\n",
              "                      ...,\n",
              "                      [ 0.6660, -0.5662, -0.5117,  ...,  0.6087, -0.3207,  1.0140],\n",
              "                      [ 0.3325, -1.1193,  0.4073,  ...,  0.4849,  0.5234, -0.2828],\n",
              "                      [ 0.0879, -0.4049,  0.2128,  ...,  1.7600, -0.4423,  0.5851]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.1.layer_norm.weight',\n",
              "              tensor([ 5.9385e-02,  8.8825e-02,  7.1394e-02, -3.9910e-02,  5.8751e-02,\n",
              "                       4.7864e-02,  1.1137e-01,  7.3873e-02,  6.6252e-02,  7.6982e-02,\n",
              "                       5.2006e-02,  7.6594e-02,  6.2017e-02,  5.1672e-02,  8.8692e-02,\n",
              "                       6.7164e-02,  5.6281e-02,  5.7954e-02, -5.5791e-02,  8.2658e-02,\n",
              "                       6.6441e-02,  6.7677e-02,  6.7030e-02,  6.0796e-02,  8.0018e-02,\n",
              "                       7.6197e-02,  8.3881e-02,  4.8398e-02,  8.3622e-02,  8.5037e-02,\n",
              "                       7.7918e-02,  7.9792e-02,  8.2317e-02,  7.6689e-02,  5.8248e-02,\n",
              "                       9.1111e-02,  8.5128e-02,  4.5725e-02,  5.9873e-02,  8.2760e-02,\n",
              "                       5.8108e-02,  6.4785e-02,  5.7179e-02,  5.7522e-02,  9.8307e-02,\n",
              "                       6.9842e-02,  9.0850e-02,  8.5256e-02,  6.9048e-02,  7.5041e-02,\n",
              "                       8.6383e-02,  5.1167e-02,  6.7161e-02,  7.1091e-02,  1.0145e-01,\n",
              "                       4.6015e-02,  6.0426e-02,  5.9395e-02,  9.9054e-02,  7.5655e-02,\n",
              "                       6.6119e-02,  7.4276e-02,  7.4077e-02,  8.4571e-02,  7.0401e-02,\n",
              "                       5.6458e-02,  8.3968e-02,  6.4075e-02,  5.6439e-02,  5.9515e-02,\n",
              "                       9.1059e-02,  9.1058e-02,  7.6439e-02,  6.1981e-02,  8.0449e-02,\n",
              "                       7.1492e-02,  4.9616e-02,  7.1521e-02,  7.9595e-02,  8.7782e-02,\n",
              "                       6.9773e-02,  6.5986e-02, -6.3499e-02,  7.2717e-02,  8.0297e-02,\n",
              "                       8.1056e-02,  4.2113e-04,  6.7988e-02,  7.7353e-02,  7.5510e-02,\n",
              "                       6.3508e-02,  8.0552e-02,  6.2172e-02,  6.2556e-02,  9.0883e-02,\n",
              "                       8.0056e-02,  7.1140e-02,  7.9533e-02,  6.7478e-02,  6.3626e-02,\n",
              "                      -5.5717e-02,  6.9956e-02,  5.1484e-02,  7.2102e-02,  7.3392e-02,\n",
              "                       5.8066e-02,  6.0811e-02,  6.2254e-02,  9.3338e-02,  9.4196e-02,\n",
              "                       8.0971e-02,  7.1908e-02, -5.0398e-02,  7.2790e-02,  6.5326e-02,\n",
              "                       1.2137e-01,  6.4288e-02,  7.2579e-02, -1.1559e-03,  7.3960e-02,\n",
              "                       5.8674e-02,  9.2577e-02,  9.0756e-02,  5.6082e-02,  7.5958e-02,\n",
              "                       7.3042e-02,  6.5405e-02,  5.4574e-02,  5.0706e-02, -5.6793e-02,\n",
              "                      -6.0118e-02,  6.8605e-02,  7.6294e-02,  7.8026e-02,  7.1302e-02,\n",
              "                      -3.9359e-02, -6.4434e-02,  6.4904e-02,  6.2501e-02,  5.0622e-02,\n",
              "                       6.6322e-02,  9.0542e-02,  5.6189e-02,  6.6110e-02,  5.2181e-02,\n",
              "                       5.3968e-02,  8.9362e-02,  5.5057e-02,  8.2613e-02,  5.6450e-02,\n",
              "                       1.0251e-01,  6.8392e-02,  1.0353e-01,  5.4202e-02,  8.5105e-02,\n",
              "                       9.5294e-02,  5.5197e-02,  9.5152e-02,  1.0369e-01,  5.0007e-02,\n",
              "                       6.1305e-02,  5.1882e-02,  4.6878e-02,  6.7258e-02,  8.4377e-02,\n",
              "                       6.1216e-02,  8.1214e-02,  7.3823e-02,  4.9326e-02,  7.8204e-02,\n",
              "                       4.5651e-02,  7.3227e-02,  9.2874e-02,  8.1650e-02,  8.2746e-02,\n",
              "                       6.0519e-02,  6.5457e-02,  9.8422e-02,  5.0499e-02,  8.4564e-02,\n",
              "                       8.1427e-02,  7.5959e-02,  7.6240e-02,  8.5130e-02,  5.5743e-02,\n",
              "                       7.2642e-02,  8.0058e-02,  6.3828e-02,  7.3946e-02,  5.9997e-02,\n",
              "                      -7.9695e-02,  5.9333e-02,  6.9586e-02,  5.2339e-02,  6.2413e-02,\n",
              "                       5.7946e-02,  6.5290e-02,  8.4760e-02,  6.9821e-02,  7.5305e-02,\n",
              "                       6.8414e-02,  3.6742e-02,  7.6818e-02,  8.7618e-02,  6.5418e-02,\n",
              "                      -5.1516e-02,  5.5903e-02,  6.8074e-02,  7.4030e-02,  7.1054e-02,\n",
              "                       8.3106e-02,  6.6410e-02,  6.3226e-02,  7.8982e-02,  7.0332e-02,\n",
              "                       8.2390e-02,  5.3672e-02,  7.9779e-02,  6.3785e-02, -1.6173e-05,\n",
              "                       5.4330e-02,  1.2696e-01,  7.5391e-02, -7.1065e-02,  6.2961e-02,\n",
              "                       8.9033e-02,  2.6214e-01,  7.6276e-02,  6.3221e-02,  7.8332e-02,\n",
              "                       8.0556e-02,  6.1870e-02,  6.1970e-02,  7.1443e-02,  7.5010e-02,\n",
              "                       5.2732e-02, -4.8608e-02,  5.8148e-02,  5.4766e-02,  6.8274e-02,\n",
              "                       9.1415e-02,  7.5406e-02,  7.0591e-02,  7.2277e-02,  6.3074e-02,\n",
              "                       6.7012e-02,  9.4111e-02,  5.8645e-02,  6.3365e-02,  6.6991e-02,\n",
              "                       7.2724e-02,  7.3493e-02,  8.1883e-02,  6.9597e-02,  7.2123e-02,\n",
              "                       7.0143e-02,  7.7023e-02,  4.4591e-02,  7.5797e-02,  6.4859e-02,\n",
              "                       5.8381e-02,  5.9342e-02,  8.3865e-02,  6.4543e-02,  7.5367e-02,\n",
              "                       7.6588e-02,  7.4446e-02,  7.7223e-02,  6.8932e-02, -6.2107e-02,\n",
              "                       6.5506e-02,  7.2545e-02,  7.4180e-02,  7.8359e-02,  5.1633e-02,\n",
              "                       6.8213e-02,  8.3478e-02,  5.2611e-02,  7.0398e-02,  5.0780e-02,\n",
              "                      -1.5946e-03,  9.1479e-02,  7.6421e-02,  5.9736e-02,  7.0432e-02,\n",
              "                       6.4005e-02,  6.4230e-02,  8.0316e-02,  7.6801e-02,  5.5530e-02,\n",
              "                       7.4355e-02,  7.3844e-02,  6.8847e-02,  6.6927e-02,  5.2107e-02,\n",
              "                       7.7664e-02,  5.1165e-02,  7.3258e-02,  7.1217e-02,  8.1490e-02,\n",
              "                       8.3716e-02,  7.6395e-02,  3.7911e-02,  7.0649e-02,  6.2387e-02,\n",
              "                       7.2446e-02,  5.9045e-02,  6.6381e-02,  5.3326e-02,  6.3325e-02,\n",
              "                       1.1043e-01,  7.8960e-02,  5.5247e-02,  5.1756e-02,  2.9628e-01,\n",
              "                      -7.2316e-02,  1.2506e-01,  6.9540e-02,  7.7621e-02,  9.1526e-02,\n",
              "                       7.2350e-02,  8.6961e-02,  5.0693e-02,  8.5425e-02,  6.2960e-02,\n",
              "                       6.9788e-02,  6.0092e-02,  9.7697e-02,  5.8590e-02,  6.4250e-02,\n",
              "                       7.7818e-02,  7.8414e-02,  5.9401e-02,  7.2065e-02,  8.7140e-02,\n",
              "                       6.0340e-02,  9.6394e-02,  9.5119e-02,  7.3354e-02, -2.7857e-02,\n",
              "                       7.0908e-02,  8.0879e-02,  8.0872e-02,  5.9667e-02,  8.0764e-02,\n",
              "                       8.4610e-02,  8.3922e-02,  5.0397e-02,  5.6768e-02,  5.0668e-02,\n",
              "                       7.7297e-02,  8.2889e-02,  6.6616e-02,  9.0177e-02,  6.5662e-02,\n",
              "                       8.6478e-02,  8.1373e-02, -8.3663e-04,  7.5015e-02,  7.4479e-02,\n",
              "                       6.4468e-02,  5.6786e-02,  3.6469e-02,  6.1594e-02,  8.4060e-02,\n",
              "                       9.2255e-02,  4.9519e-02,  6.3831e-02,  6.3764e-02,  5.5561e-02,\n",
              "                       6.4077e-02,  6.9069e-02,  7.0385e-02,  5.0007e-02,  7.5229e-02,\n",
              "                       6.9359e-02,  6.2633e-02,  1.0948e-01,  7.2599e-02,  5.8737e-02,\n",
              "                       7.7367e-02,  6.5154e-02,  5.0111e-02,  7.2303e-02,  7.7102e-02,\n",
              "                       6.9466e-02,  7.3354e-02,  6.2090e-02,  7.4029e-02,  8.2975e-02,\n",
              "                       7.9072e-02,  5.3611e-02,  5.6318e-02,  4.8474e-02,  7.2511e-02,\n",
              "                       5.7309e-02,  8.3092e-02,  7.3057e-02,  6.5738e-02,  5.4227e-02,\n",
              "                       6.6390e-02,  6.3661e-02,  7.3107e-02,  7.1207e-02,  6.2217e-02,\n",
              "                       7.5451e-02,  6.6495e-02,  7.9281e-02,  7.0729e-02,  7.8302e-02,\n",
              "                       8.0494e-02,  8.0299e-02,  6.0708e-02,  5.8113e-02,  7.3235e-02,\n",
              "                       6.9010e-02,  8.0103e-02,  6.0944e-02,  2.9114e-01,  7.9379e-02,\n",
              "                       1.3401e-03,  5.8130e-02,  7.6284e-02, -4.6174e-03,  7.4292e-02,\n",
              "                       7.5279e-02,  3.7168e-02,  8.3809e-02,  5.5489e-02,  4.9456e-02,\n",
              "                       7.3465e-02,  6.6728e-02,  6.1376e-02,  6.0820e-02,  7.6853e-02,\n",
              "                       7.1464e-02,  6.3260e-02,  8.1505e-02,  7.0232e-02,  5.3866e-02,\n",
              "                       9.6556e-02,  7.2388e-02,  7.9173e-02,  8.3003e-02,  7.2496e-02,\n",
              "                       7.0571e-02,  7.2995e-02,  6.5840e-02,  3.3601e-04,  6.7784e-02,\n",
              "                      -6.9172e-02,  7.3027e-02,  6.1977e-02,  7.2154e-02,  6.9554e-02,\n",
              "                       5.0172e-02,  6.0627e-02,  1.7531e-01,  5.7220e-02,  6.9309e-02,\n",
              "                       7.3393e-02,  7.3805e-02,  7.3422e-02,  7.2853e-02,  6.6436e-02,\n",
              "                       7.7219e-02,  4.9611e-02,  5.6602e-02,  6.7935e-02,  5.6675e-02,\n",
              "                       6.7724e-02,  7.4523e-02,  1.0564e-01,  7.2111e-02,  6.8989e-02,\n",
              "                       7.8725e-02,  6.9395e-02,  9.4468e-02,  6.9732e-02,  6.2525e-02,\n",
              "                       4.4521e-02,  6.3506e-02,  8.1017e-02,  6.7987e-02,  1.3585e-03,\n",
              "                       7.5152e-02,  6.5861e-02,  4.0096e-02,  9.4190e-02, -6.5803e-02,\n",
              "                       6.3449e-02,  9.6970e-02,  6.1825e-02,  9.0742e-02,  8.2471e-02,\n",
              "                       1.5928e-01,  5.3073e-02,  7.2141e-02,  7.4369e-02,  6.3715e-02,\n",
              "                       7.7076e-02,  1.3477e-01,  6.7461e-02,  5.1275e-02,  8.2909e-02,\n",
              "                       7.6942e-02,  6.6886e-02,  5.7185e-02,  7.2558e-02,  7.0890e-02,\n",
              "                       6.7679e-02,  8.1941e-02,  5.2046e-02,  8.9894e-02,  7.7070e-02,\n",
              "                       7.7202e-02,  6.4611e-02,  5.3691e-02,  5.8477e-02,  6.7454e-02,\n",
              "                       8.1345e-02,  6.7465e-02,  7.7824e-02,  8.8485e-02,  7.3423e-02,\n",
              "                       7.5904e-02,  6.4894e-02,  9.9948e-02,  7.4378e-02,  5.1623e-02,\n",
              "                       5.5102e-02,  6.8455e-02,  6.5580e-02,  7.7301e-02,  6.1175e-02,\n",
              "                       7.2146e-02,  6.4466e-02,  6.1546e-02,  5.0725e-02,  6.6606e-02,\n",
              "                       9.5861e-02,  7.0884e-02,  4.5444e-02,  7.0483e-02,  5.2934e-02,\n",
              "                       7.3599e-02,  6.9021e-02,  6.2395e-02,  7.0029e-02,  7.4056e-02,\n",
              "                       5.8983e-02,  1.1601e-01,  7.1191e-02,  9.8045e-02,  7.1767e-02,\n",
              "                       8.8541e-02,  5.1846e-02,  7.0412e-02,  8.2027e-02,  5.1898e-02,\n",
              "                       6.9242e-02,  5.8048e-02,  2.2236e-04,  5.0075e-02,  6.7613e-02,\n",
              "                       9.6127e-02,  8.7102e-02,  6.8095e-02,  4.8274e-02,  7.0673e-02,\n",
              "                       7.5655e-02,  6.8979e-02,  6.7813e-02,  5.0924e-02,  6.1436e-02,\n",
              "                       6.8708e-02,  7.3999e-02,  8.5035e-02,  8.9954e-02,  5.4859e-04,\n",
              "                       6.7704e-02,  7.6729e-02,  6.3779e-02,  6.1627e-02,  6.4565e-02,\n",
              "                       6.9692e-02,  6.3565e-02,  6.0801e-02,  6.7993e-02,  7.8980e-02,\n",
              "                       7.2962e-02,  7.5801e-02,  1.0107e-01,  7.3650e-02,  5.7955e-02,\n",
              "                       7.2694e-02,  9.1047e-02,  7.0723e-02,  3.3834e-02,  5.9123e-02,\n",
              "                       5.8177e-02,  7.8709e-02,  5.7409e-02,  6.4151e-02,  6.8118e-02,\n",
              "                       6.7241e-02,  7.5705e-02,  5.5036e-02,  6.5595e-02,  5.3607e-02,\n",
              "                       5.4284e-02,  6.2285e-02,  6.1815e-02,  1.0512e-01,  6.1394e-02,\n",
              "                       7.3664e-02,  6.7305e-02,  1.8044e-01,  9.7993e-02,  5.6396e-02,\n",
              "                       7.6728e-02,  5.8324e-02,  7.1977e-02,  5.5198e-02,  5.6284e-02,\n",
              "                       6.4914e-02,  5.7514e-02,  5.7837e-02,  7.0042e-02,  7.0104e-02,\n",
              "                       7.2752e-02,  6.8474e-02,  7.7829e-02,  1.0269e-01,  7.0421e-02,\n",
              "                       6.1097e-02,  6.0579e-02,  6.8625e-02,  6.2575e-02,  6.9675e-02,\n",
              "                       6.5949e-02,  7.7994e-02,  6.6204e-02,  6.0824e-02,  5.4672e-02,\n",
              "                      -5.4609e-02,  5.1012e-02,  8.0101e-02,  5.9273e-02,  8.1283e-02,\n",
              "                       6.6362e-02,  6.7915e-02, -6.3249e-02,  5.8832e-02,  8.1507e-02,\n",
              "                       4.6937e-02,  5.7280e-02,  5.4203e-02,  5.8128e-02,  4.9868e-02,\n",
              "                       1.0253e-01, -6.2987e-02,  6.0173e-02,  1.3516e-01,  5.3840e-02,\n",
              "                       6.3820e-02,  8.3801e-02,  6.5098e-02,  7.6949e-02,  6.5362e-02,\n",
              "                       7.5105e-02,  8.3194e-02,  6.5044e-02,  6.3071e-02,  6.4586e-02,\n",
              "                       8.4519e-02,  6.7271e-02,  8.7053e-02,  6.3590e-02,  6.8376e-02,\n",
              "                       7.3485e-02,  7.9523e-02,  7.0171e-02,  6.2010e-02,  6.3153e-02,\n",
              "                       5.6200e-02,  7.5026e-02,  6.2190e-02,  7.9245e-02,  7.2527e-02,\n",
              "                       7.7240e-02,  5.7093e-02, -5.7663e-02,  8.3957e-02,  7.2449e-02,\n",
              "                       6.6146e-02,  8.7274e-02,  7.3252e-02,  6.4811e-02,  5.3503e-02,\n",
              "                       7.1485e-02,  8.9532e-02,  6.5488e-02,  4.8913e-02,  9.1772e-02,\n",
              "                       8.5518e-02,  6.3100e-02,  4.9083e-02,  8.1530e-02,  7.6528e-02,\n",
              "                       7.5004e-02,  6.1550e-02,  6.8917e-02,  6.6591e-02,  4.3077e-02,\n",
              "                       1.7199e-01,  6.2428e-02,  9.7066e-02, -6.9576e-02,  5.3214e-02,\n",
              "                       8.5782e-02,  7.3098e-02,  4.7170e-02,  8.5726e-02,  7.0941e-02,\n",
              "                       7.4776e-02,  6.4936e-02,  7.1549e-02,  6.3857e-02,  6.0086e-02,\n",
              "                       7.0377e-02,  6.0024e-02,  9.1212e-02,  7.6623e-02,  1.2200e-01,\n",
              "                       8.1012e-02,  6.7584e-02,  6.2377e-02,  7.0156e-02,  6.3574e-02,\n",
              "                       6.7599e-02, -5.6388e-02,  7.4354e-02,  6.2045e-02,  7.4161e-02,\n",
              "                       6.5422e-02,  6.2846e-02,  8.3121e-02,  5.8642e-02, -5.3707e-02,\n",
              "                      -5.0103e-02,  6.4912e-02, -5.8764e-02,  6.4402e-02,  7.2910e-02,\n",
              "                       9.2582e-02,  5.7569e-02,  6.6238e-02,  7.6688e-02,  5.2317e-02,\n",
              "                       6.2121e-02,  6.6685e-02, -5.5889e-02, -5.5918e-02,  7.1200e-02,\n",
              "                       5.1036e-02,  5.7351e-02,  5.5687e-02], device='cuda:0')),\n",
              "             ('decoder.block.10.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.3925,  0.8680, -0.0134,  ..., -0.0721,  0.1900,  0.0736],\n",
              "                      [-0.5354,  1.1752, -0.4899,  ...,  0.0511, -0.6231, -0.1341],\n",
              "                      [ 1.0549,  0.2499, -0.0360,  ..., -0.5354,  0.3905,  0.4624],\n",
              "                      ...,\n",
              "                      [-0.3930, -0.0030, -0.4432,  ...,  0.2228,  0.5155, -0.2773],\n",
              "                      [ 0.1539, -0.1480,  0.4579,  ..., -0.1247, -0.6468,  0.4123],\n",
              "                      [-0.0338, -0.4480, -1.4543,  ...,  0.7638, -0.5034, -0.6553]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.1329, -0.0719, -0.2038,  ...,  0.3675, -0.7423, -0.3558],\n",
              "                      [-0.3353, -0.0008,  0.1876,  ..., -0.1893, -0.0287, -0.2571],\n",
              "                      [-0.2092, -0.1579,  0.1605,  ...,  0.2568,  0.5096,  0.1787],\n",
              "                      ...,\n",
              "                      [-0.2038, -0.0565, -0.1579,  ..., -0.2644, -0.1042,  0.1280],\n",
              "                      [-0.1897,  0.1078, -0.3210,  ...,  0.0627, -0.2530,  0.1917],\n",
              "                      [-0.1337,  0.4715,  0.2776,  ..., -0.2243, -0.0723, -0.0671]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.10.layer.2.layer_norm.weight',\n",
              "              tensor([ 4.5629e+00,  5.4858e+00,  5.9099e+00,  2.5351e+00,  4.6603e+00,\n",
              "                       4.6223e+00,  5.0957e+00,  4.8146e+00,  5.2355e+00,  4.7966e+00,\n",
              "                       4.6988e+00,  4.9421e+00,  6.2839e+00,  5.1617e+00,  4.7748e+00,\n",
              "                       4.3785e+00,  4.6379e+00,  5.0920e+00,  5.0730e+00,  4.5913e+00,\n",
              "                       4.9148e+00,  4.5687e+00,  5.3431e+00,  4.2766e+00,  4.6342e+00,\n",
              "                       5.2679e+00,  5.2392e+00,  5.9527e+00,  5.1543e+00,  4.7589e+00,\n",
              "                       4.6242e+00,  6.1645e+00,  4.6549e+00,  4.7147e+00,  4.8976e+00,\n",
              "                       5.5731e+00,  4.9544e+00,  7.7849e+00,  4.6511e+00,  4.8139e+00,\n",
              "                       4.6624e+00,  5.1926e+00,  4.8324e+00,  4.9747e+00,  6.7516e+00,\n",
              "                       4.6526e+00,  5.2505e+00,  4.9037e+00,  4.6055e+00,  4.8717e+00,\n",
              "                       5.5259e+00,  4.5001e+00,  5.0213e+00,  4.5862e+00,  8.5007e+00,\n",
              "                       4.8762e+00,  5.4614e+00,  4.6480e+00,  4.9110e+00,  4.8837e+00,\n",
              "                       5.2314e+00,  4.8908e+00,  4.7097e+00,  5.1929e+00,  4.7602e+00,\n",
              "                       1.3495e+01,  4.6989e+00,  5.2776e+00,  8.7918e+00,  4.6267e+00,\n",
              "                       5.3865e+00,  4.8759e+00,  5.1118e+00,  4.6278e+00,  5.5623e+00,\n",
              "                       4.4848e+00,  5.3722e+00,  4.3813e+00,  4.9022e+00,  5.8782e+00,\n",
              "                       4.7292e+00,  4.8578e+00,  4.5624e+00,  5.8871e+00,  5.0368e+00,\n",
              "                       5.1414e+00,  8.8416e-02,  4.5959e+00,  4.5810e+00,  4.6018e+00,\n",
              "                       4.7629e+00,  4.6462e+00,  4.5084e+00,  4.5686e+00,  4.8394e+00,\n",
              "                       4.6807e+00,  4.8723e+00,  4.7566e+00,  4.6892e+00,  4.5407e+00,\n",
              "                       4.4982e+00,  4.6274e+00,  7.4159e+00,  4.9372e+00,  4.9267e+00,\n",
              "                       5.0115e+00,  4.3379e+00,  5.0314e+00,  5.3210e+00,  5.0993e+00,\n",
              "                       4.8839e+00,  4.7315e+00,  4.6059e+00,  4.5941e+00,  5.1862e+00,\n",
              "                       5.5958e+00,  4.8029e+00,  4.6498e+00,  9.2150e-03,  4.9497e+00,\n",
              "                       4.5918e+00,  4.9003e+00,  6.2420e+00,  4.5904e+00,  4.8750e+00,\n",
              "                       4.7633e+00,  4.6939e+00,  4.5260e+00,  4.8537e+00,  5.5274e+00,\n",
              "                       6.6129e+00,  5.0587e+00,  4.5733e+00,  4.5506e+00,  4.8235e+00,\n",
              "                       4.9449e+00,  4.6838e+00,  6.0326e+00,  4.4506e+00,  4.9901e+00,\n",
              "                       6.0989e+00,  4.9786e+00,  4.4322e+00,  5.3158e+00,  4.7515e+00,\n",
              "                       4.8796e+00,  5.0639e+00,  5.7372e+00,  4.9825e+00,  4.4394e+00,\n",
              "                       4.9796e+00,  5.1336e+00,  6.1317e+00,  5.4230e+00,  4.7235e+00,\n",
              "                       4.8075e+00,  4.6885e+00,  5.0670e+00,  5.0453e+00,  4.7604e+00,\n",
              "                       4.6934e+00,  4.7928e+00,  4.7876e+00,  5.7611e+00,  5.0672e+00,\n",
              "                       6.0965e+00,  4.8812e+00,  5.4746e+00,  7.3615e+00,  4.8171e+00,\n",
              "                       7.4571e+00,  4.8146e+00,  5.3095e+00,  5.0232e+00,  4.9674e+00,\n",
              "                       4.6515e+00,  4.7868e+00,  4.9942e+00,  6.9475e+00,  5.4103e+00,\n",
              "                       4.9152e+00,  4.6628e+00,  4.6834e+00,  4.8034e+00,  4.9606e+00,\n",
              "                       5.7039e+00,  4.6758e+00,  3.3311e+00,  4.9859e+00,  4.7487e+00,\n",
              "                       4.5786e+00,  4.5582e+00,  5.1566e+00,  4.5429e+00,  4.8425e+00,\n",
              "                       5.1527e+00,  4.6347e+00,  4.7698e+00,  4.9124e+00,  4.8104e+00,\n",
              "                       4.5416e+00,  4.4377e+00,  4.9956e+00,  5.2607e+00,  4.9754e+00,\n",
              "                       4.6006e+00,  4.3400e+00,  4.7242e+00,  4.8736e+00,  4.6760e+00,\n",
              "                       6.0996e+00,  4.6430e+00,  4.5378e+00,  5.2908e+00,  4.6796e+00,\n",
              "                       4.9836e+00,  4.6643e+00,  5.0069e+00,  4.6847e+00, -2.8546e-01,\n",
              "                       6.1955e+00,  5.0437e+00,  5.5363e+00,  4.6005e+00,  5.4693e+00,\n",
              "                       4.6727e+00,  4.6520e+00,  4.9898e+00,  4.5659e+00,  5.3242e+00,\n",
              "                       4.8700e+00,  4.2770e+00,  4.9018e+00,  4.6855e+00,  4.9859e+00,\n",
              "                       4.8810e+00,  5.2531e+00,  4.5651e+00,  5.5353e+00,  4.5329e+00,\n",
              "                       9.4378e+00,  4.7473e+00,  4.9049e+00,  5.0707e+00,  4.2148e+00,\n",
              "                       4.3831e+00,  5.1284e+00,  4.3732e+00,  4.6611e+00,  4.7428e+00,\n",
              "                       5.3579e+00,  4.6611e+00,  4.7567e+00,  5.0635e+00,  4.9117e+00,\n",
              "                       5.3185e+00,  4.9077e+00,  5.8020e+00,  4.6809e+00,  4.8980e+00,\n",
              "                       5.5149e+00,  5.7671e+00,  4.7559e+00,  4.6486e+00,  5.0617e+00,\n",
              "                       4.7084e+00,  5.0554e+00,  4.8697e+00,  4.5302e+00,  4.9108e+00,\n",
              "                       4.6808e+00,  1.1134e+01,  4.8211e+00,  5.0008e+00,  6.3961e+00,\n",
              "                       4.6917e+00,  5.1287e+00,  4.7102e+00,  4.9646e+00,  4.7437e+00,\n",
              "                       1.3527e+00,  7.8779e+00,  5.0466e+00,  5.0071e+00,  4.3988e+00,\n",
              "                       4.8710e+00,  4.6359e+00,  5.1279e+00,  5.4094e+00,  5.3606e+00,\n",
              "                       4.8826e+00,  4.7796e+00,  4.6849e+00,  4.9628e+00,  4.9656e+00,\n",
              "                       4.8132e+00,  6.5999e+00,  4.8121e+00,  4.9568e+00,  5.1572e+00,\n",
              "                       5.1601e+00,  4.9243e+00,  2.6546e+00,  4.6063e+00,  4.7813e+00,\n",
              "                       4.7796e+00,  4.3772e+00,  4.4999e+00,  5.0512e+00,  4.7788e+00,\n",
              "                       5.2490e+00,  5.2947e+00,  4.3960e+00,  4.6978e+00,  5.8245e+00,\n",
              "                       4.5956e+00,  5.1509e+00,  5.6526e+00,  4.7873e+00,  4.8189e+00,\n",
              "                       4.3767e+00,  5.3860e+00,  4.5122e+00,  5.0400e+00,  4.9900e+00,\n",
              "                       5.1614e+00,  4.6051e+00,  6.3974e+00,  4.6723e+00,  4.5965e+00,\n",
              "                       4.7117e+00,  6.3149e+00,  4.6401e+00,  4.7543e+00,  4.9857e+00,\n",
              "                       4.6039e+00,  5.1436e+00,  4.9528e+00,  4.9457e+00,  4.5008e+00,\n",
              "                       5.0513e+00,  5.3249e+00,  4.8841e+00,  4.4013e+00,  5.1037e+00,\n",
              "                       5.1220e+00,  4.7778e+00,  4.7467e+00,  5.8930e+00,  5.1955e+00,\n",
              "                       5.1949e+00,  4.8739e+00,  4.9240e+00,  4.9332e+00,  4.5404e+00,\n",
              "                       5.0314e+00,  4.8535e+00, -1.6717e-02,  4.9855e+00,  4.6076e+00,\n",
              "                       4.8783e+00,  5.0657e+00,  9.2504e+00,  4.5635e+00,  5.0512e+00,\n",
              "                       4.8273e+00,  5.0491e+00,  4.7751e+00,  4.7916e+00,  4.7145e+00,\n",
              "                       4.9101e+00,  4.8475e+00,  5.2855e+00,  4.7298e+00,  4.5591e+00,\n",
              "                       4.9060e+00,  4.8033e+00,  4.8086e+00,  5.3299e+00,  5.9605e+00,\n",
              "                       4.7853e+00,  5.0006e+00,  6.0055e+00,  4.7639e+00,  5.0587e+00,\n",
              "                       4.6045e+00,  4.4238e+00,  4.7149e+00,  5.0072e+00,  4.8186e+00,\n",
              "                       5.3305e+00,  4.7168e+00,  4.9549e+00,  5.0923e+00,  4.9876e+00,\n",
              "                       4.5578e+00,  5.4326e+00,  5.0990e+00,  4.9054e+00,  4.5659e+00,\n",
              "                       4.7151e+00,  4.9207e+00,  4.6339e+00,  4.8436e+00,  4.5721e+00,\n",
              "                       4.7955e+00,  5.5955e+00,  4.7005e+00,  4.9677e+00,  4.6162e+00,\n",
              "                       5.1180e+00,  5.1274e+00,  4.6825e+00,  4.5153e+00,  4.6848e+00,\n",
              "                       4.9697e+00,  5.3265e+00,  4.4849e+00,  7.1720e+00,  5.4659e+00,\n",
              "                      -2.9178e-02,  4.5588e+00,  4.5294e+00,  4.4719e+00,  4.6613e+00,\n",
              "                       4.9985e+00,  4.4190e+00,  4.6490e+00,  5.2253e+00,  5.2459e+00,\n",
              "                       4.9479e+00,  5.1739e+00,  4.3411e+00,  4.8852e+00,  5.1750e+00,\n",
              "                       5.0734e+00,  4.4354e+00,  5.1569e+00,  5.2380e+00,  5.9519e+00,\n",
              "                       5.6396e+00,  6.6024e+00,  5.1342e+00,  4.6284e+00,  4.7274e+00,\n",
              "                       4.8842e+00,  4.6288e+00,  4.6359e+00, -1.8154e-02,  4.7696e+00,\n",
              "                       4.5562e+00,  4.9176e+00,  4.7480e+00,  4.9706e+00,  5.1890e+00,\n",
              "                       4.6608e+00,  6.6736e+00,  6.5734e+00,  4.7788e+00,  4.8756e+00,\n",
              "                       4.9213e+00,  4.6998e+00,  4.8825e+00,  5.0501e+00,  4.9114e+00,\n",
              "                       4.9402e+00,  5.3204e+00,  4.4510e+00,  4.6331e+00,  4.6960e+00,\n",
              "                       4.5348e+00,  4.8724e+00,  1.0583e+01,  4.6304e+00,  4.6874e+00,\n",
              "                       4.9766e+00,  4.5103e+00,  5.1543e+00,  5.0871e+00,  4.6964e+00,\n",
              "                       4.5112e+00,  5.0713e+00,  4.9074e+00,  4.8107e+00,  2.9705e+00,\n",
              "                       4.6058e+00,  5.0515e+00,  1.1707e+00,  5.3820e+00,  4.2499e+00,\n",
              "                       4.5993e+00,  5.0212e+00,  4.6702e+00,  4.7181e+00,  5.0474e+00,\n",
              "                       1.6249e+01,  5.2274e+00,  4.7351e+00,  4.4601e+00,  4.5084e+00,\n",
              "                       4.8507e+00,  5.8229e+00,  4.9371e+00,  4.7574e+00,  4.7985e+00,\n",
              "                       5.0652e+00,  5.1857e+00,  4.7875e+00,  4.6203e+00,  4.8776e+00,\n",
              "                       4.7656e+00,  4.6311e+00,  5.0144e+00,  4.9957e+00,  5.2584e+00,\n",
              "                       4.7181e+00,  4.8058e+00,  4.6237e+00,  5.6039e+00,  4.6293e+00,\n",
              "                       4.4472e+00,  4.8941e+00,  4.6405e+00,  5.4355e+00,  4.9422e+00,\n",
              "                       5.0997e+00,  4.4993e+00,  7.1996e+00,  5.1930e+00,  4.7077e+00,\n",
              "                       5.2118e+00,  4.8116e+00,  4.5115e+00,  4.7879e+00,  5.0533e+00,\n",
              "                       4.9938e+00,  4.6054e+00,  4.6580e+00,  4.8701e+00,  4.5142e+00,\n",
              "                       4.8118e+00,  4.7276e+00,  4.5974e+00,  4.7663e+00,  4.6843e+00,\n",
              "                       4.6491e+00,  5.2603e+00,  4.7869e+00,  4.9350e+00,  5.2812e+00,\n",
              "                       5.5762e+00,  6.3127e+00,  4.5364e+00,  6.6161e+00,  4.6178e+00,\n",
              "                       4.9783e+00,  5.5464e+00,  4.6768e+00,  5.1963e+00,  4.7211e+00,\n",
              "                       5.1906e+00,  5.2842e+00,  1.8021e+00,  6.0629e+00,  4.5968e+00,\n",
              "                       6.8333e+00,  5.1041e+00,  4.6390e+00,  4.8988e+00,  4.5657e+00,\n",
              "                       4.7918e+00,  5.2163e+00,  5.0633e+00,  4.5688e+00,  5.2218e+00,\n",
              "                       5.3275e+00,  4.6881e+00,  5.1337e+00,  5.5355e+00,  1.0808e+00,\n",
              "                       5.4363e+00,  5.0255e+00,  4.7190e+00,  5.1224e+00,  4.5084e+00,\n",
              "                       4.7081e+00,  5.0030e+00,  4.6566e+00,  4.6529e+00,  4.7814e+00,\n",
              "                       4.7164e+00,  5.1709e+00,  5.7892e+00,  5.0324e+00,  4.2906e+00,\n",
              "                       4.8678e+00,  7.2168e+00,  5.0188e+00,  3.4731e+00,  5.3489e+00,\n",
              "                       5.0694e+00,  4.9767e+00,  4.4769e+00,  4.9831e+00,  4.6879e+00,\n",
              "                       4.6643e+00,  4.7891e+00,  7.6515e+00,  4.4747e+00,  4.4417e+00,\n",
              "                       4.7232e+00,  4.6315e+00,  4.3661e+00,  5.0911e+00,  4.6973e+00,\n",
              "                       4.7686e+00,  4.5548e+00,  1.0140e+01,  5.1595e+00,  4.4862e+00,\n",
              "                       4.6371e+00,  5.0593e+00,  4.9761e+00,  5.8594e+00,  4.5298e+00,\n",
              "                       4.8021e+00,  4.4493e+00,  4.5296e+00,  4.9817e+00,  5.0634e+00,\n",
              "                       5.1505e+00,  4.6941e+00,  5.7936e+00,  9.1024e+00,  5.0982e+00,\n",
              "                       4.9461e+00,  5.0879e+00,  4.9412e+00,  5.0576e+00,  4.8944e+00,\n",
              "                       5.2132e+00,  5.2468e+00,  4.5976e+00,  5.5947e+00,  6.5939e+00,\n",
              "                       4.7076e+00,  8.0576e+00,  4.7165e+00,  4.2827e+00,  5.2938e+00,\n",
              "                       4.9311e+00,  4.8747e+00,  4.5159e+00,  4.5239e+00,  5.2245e+00,\n",
              "                       7.4358e+00,  4.8537e+00,  4.5651e+00,  4.4955e+00,  4.6690e+00,\n",
              "                       5.0053e+00,  5.0125e+00,  4.9979e+00,  6.0592e+00,  4.8692e+00,\n",
              "                       5.0417e+00,  4.8846e+00,  4.9071e+00,  4.6802e+00,  4.7109e+00,\n",
              "                       4.9429e+00,  4.9095e+00,  4.8477e+00,  4.5907e+00,  4.7588e+00,\n",
              "                       4.9216e+00,  5.0607e+00,  5.1874e+00,  4.8987e+00,  4.7125e+00,\n",
              "                       4.7994e+00,  5.0202e+00,  6.7057e+00,  4.8563e+00,  4.8614e+00,\n",
              "                       4.6906e+00,  4.6154e+00,  4.8502e+00,  4.8199e+00,  4.9982e+00,\n",
              "                       4.6037e+00,  4.5704e+00,  5.1566e+00,  4.7444e+00,  4.7457e+00,\n",
              "                       4.7643e+00,  5.0740e+00,  5.2733e+00,  5.0328e+00,  4.7871e+00,\n",
              "                       4.6163e+00,  4.7171e+00,  5.0401e+00,  5.6778e+00,  5.1636e+00,\n",
              "                       4.7491e+00,  4.9126e+00,  5.3089e+00,  6.6042e+00,  4.7530e+00,\n",
              "                       5.1953e+00,  5.0452e+00,  4.9508e+00,  5.1409e+00,  6.7487e+00,\n",
              "                       5.5084e+00,  5.0108e+00,  5.4134e+00,  4.4959e+00,  4.7125e+00,\n",
              "                       4.7229e+00,  5.0451e+00,  6.7726e+00,  4.8286e+00,  4.6986e+00,\n",
              "                       6.7352e+00,  5.0210e+00,  4.9986e+00,  4.7380e+00,  4.5746e+00,\n",
              "                       4.5906e+00,  4.4982e+00,  5.4669e+00,  6.5316e+00,  5.2774e+00,\n",
              "                       5.0560e+00,  4.8091e+00,  4.6348e+00,  4.5068e+00,  5.3011e+00,\n",
              "                       5.1785e+00,  6.0997e+00,  4.9406e+00,  6.2109e+00,  4.7476e+00,\n",
              "                       4.9448e+00,  5.5896e+00,  4.9422e+00,  5.0327e+00,  5.2490e+00,\n",
              "                       4.3842e+00,  4.6898e+00,  4.9053e+00,  4.8941e+00,  5.0479e+00,\n",
              "                       5.2213e+00,  4.7636e+00,  4.6180e+00,  5.5630e+00,  4.5920e+00,\n",
              "                       5.5171e+00,  4.9808e+00,  4.4231e+00,  4.3409e+00,  4.7606e+00,\n",
              "                       4.7226e+00,  4.3311e+00,  4.5601e+00], device='cuda:0')),\n",
              "             ('decoder.block.11.layer.0.SelfAttention.q.weight',\n",
              "              tensor([[-0.0418,  0.0133,  0.0100,  ..., -0.0302, -0.0039, -0.0296],\n",
              "                      [ 0.0132,  0.0467, -0.0241,  ..., -0.0501,  0.0338, -0.0247],\n",
              "                      [ 0.0281, -0.0091,  0.0282,  ...,  0.0084, -0.0097, -0.0183],\n",
              "                      ...,\n",
              "                      [ 0.0023, -0.0085, -0.0185,  ...,  0.0286, -0.0106, -0.0313],\n",
              "                      [-0.0023,  0.0517, -0.0205,  ..., -0.0509, -0.0658,  0.0088],\n",
              "                      [-0.0598, -0.0242,  0.0047,  ...,  0.0510, -0.0224, -0.0148]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.0.SelfAttention.k.weight',\n",
              "              tensor([[-0.2550,  0.1966, -0.0025,  ..., -0.1233,  0.3740, -0.2538],\n",
              "                      [ 0.0158, -0.0123, -0.1105,  ..., -0.0464, -0.3593,  0.2236],\n",
              "                      [-0.1661,  0.1485,  0.0077,  ...,  0.4477,  0.1544, -0.2217],\n",
              "                      ...,\n",
              "                      [-0.5125,  0.1342, -0.0613,  ..., -0.4020,  0.0577,  0.0248],\n",
              "                      [-0.0855, -0.2756, -0.2435,  ...,  0.6144, -0.3247, -0.3276],\n",
              "                      [-0.1087, -0.1099,  0.1823,  ..., -0.3404, -0.5241,  0.2791]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.0.SelfAttention.v.weight',\n",
              "              tensor([[-1.1476,  0.4773, -1.1880,  ...,  0.3671, -0.0277,  0.3399],\n",
              "                      [ 2.0010,  0.7097,  0.8224,  ...,  0.1708,  0.8709,  0.7542],\n",
              "                      [-1.2835,  0.1777, -0.3743,  ..., -0.6188, -0.5272,  0.7216],\n",
              "                      ...,\n",
              "                      [-0.0682,  1.0136,  0.3023,  ..., -1.1580,  0.1042, -0.6667],\n",
              "                      [ 0.1509, -2.4719, -0.5736,  ..., -1.2137, -0.3424, -0.0479],\n",
              "                      [ 0.1613, -0.1435,  0.3494,  ...,  0.0432, -0.4300,  0.1072]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.0.SelfAttention.o.weight',\n",
              "              tensor([[ 1.7921, -0.3128, -1.1305,  ..., -1.0141,  0.3514,  0.9725],\n",
              "                      [ 0.0170, -0.3178, -0.0888,  ..., -0.3606,  0.1635,  0.4403],\n",
              "                      [-0.1266,  1.1795,  0.2082,  ...,  0.7643, -0.6303, -0.1310],\n",
              "                      ...,\n",
              "                      [-0.1364, -0.1024,  0.6471,  ...,  1.3421, -0.5497,  0.4750],\n",
              "                      [-0.5902,  0.3410, -0.2144,  ..., -0.8289,  0.1268,  0.2858],\n",
              "                      [-0.7904, -0.1223,  0.3070,  ...,  0.9258,  0.0826,  1.1843]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.0.layer_norm.weight',\n",
              "              tensor([ 3.1507e-01,  3.5364e-01,  6.0152e-01,  2.8015e-01,  3.1535e-01,\n",
              "                       3.4670e-01,  3.9256e-01,  3.4332e-01,  4.3734e-01,  3.7208e-01,\n",
              "                       3.2072e-01,  3.2865e-01,  3.5284e-01,  3.9650e-01,  3.2575e-01,\n",
              "                       3.2518e-01,  3.7028e-01,  4.1107e-01,  4.5885e-01,  3.8757e-01,\n",
              "                       3.1256e-01,  3.2125e-01,  4.8643e-01,  3.5463e-01,  3.0230e-01,\n",
              "                       4.7740e-01,  3.0919e-01,  5.2254e-01,  3.5393e-01,  3.1119e-01,\n",
              "                       3.1953e-01,  4.2817e-01,  3.6833e-01,  3.7667e-01,  3.5087e-01,\n",
              "                       3.5171e-01,  3.5400e-01,  1.0430e+00,  3.2089e-01,  3.4694e-01,\n",
              "                       3.9902e-01,  4.3140e-01,  3.8352e-01,  3.4360e-01,  6.4268e-01,\n",
              "                       3.5943e-01,  4.6340e-01,  3.4706e-01,  3.6866e-01,  3.1916e-01,\n",
              "                       4.9376e-01,  3.3340e-01,  3.9659e-01,  3.0931e-01,  8.7192e-01,\n",
              "                       3.9399e-01,  4.7473e-01,  3.8103e-01,  3.4208e-01,  3.4958e-01,\n",
              "                       3.3464e-01,  3.1982e-01,  3.3423e-01,  3.1187e-01,  3.2420e-01,\n",
              "                       1.5469e+00,  3.0271e-01,  3.5453e-01,  4.9918e-01,  3.2940e-01,\n",
              "                       3.6786e-01,  3.2992e-01,  3.0772e-01,  3.4677e-01,  4.1075e-01,\n",
              "                       3.2365e-01,  4.3538e-01,  3.2417e-01,  3.1643e-01,  4.0179e-01,\n",
              "                       3.4038e-01,  3.3500e-01,  3.3335e-01,  5.5400e-01,  4.5551e-01,\n",
              "                       3.4685e-01, -9.9167e-02,  3.3270e-01,  3.1151e-01,  3.0952e-01,\n",
              "                       3.4082e-01,  3.3267e-01,  3.5099e-01,  3.4419e-01,  3.2866e-01,\n",
              "                       3.1570e-01,  3.1278e-01,  3.0840e-01,  3.3626e-01,  3.6913e-01,\n",
              "                       3.7278e-01,  3.4598e-01,  7.3910e-01,  3.6291e-01,  3.3382e-01,\n",
              "                       5.2301e-01,  3.5733e-01,  3.3258e-01,  3.2848e-01,  3.3106e-01,\n",
              "                       3.6746e-01,  3.6533e-01,  3.0706e-01,  3.2075e-01,  3.5894e-01,\n",
              "                       4.2433e-01,  4.2939e-01,  3.5347e-01,  7.0215e-02,  3.1446e-01,\n",
              "                       3.1457e-01,  3.3236e-01,  6.1129e-01,  3.3389e-01,  3.7761e-01,\n",
              "                       3.4133e-01,  3.4926e-01,  3.1303e-01,  3.2514e-01,  4.8457e-01,\n",
              "                       5.1189e-01,  3.4235e-01,  3.7075e-01,  3.0745e-01,  4.1720e-01,\n",
              "                       5.1696e-01,  3.3277e-01,  3.8493e-01,  3.2333e-01,  4.4516e-01,\n",
              "                       4.6307e-01,  3.0451e-01,  4.0939e-01,  4.8842e-01,  3.9356e-01,\n",
              "                       3.8420e-01,  3.4455e-01,  3.9269e-01,  3.7668e-01,  3.3429e-01,\n",
              "                       4.0551e-01,  4.0484e-01,  4.0012e-01,  5.2805e-01,  3.4540e-01,\n",
              "                       3.4200e-01,  3.4591e-01,  3.1227e-01, -1.9376e-01,  3.4603e-01,\n",
              "                       2.7965e-01,  3.5492e-01,  3.5170e-01,  5.4952e-01,  3.5455e-01,\n",
              "                       6.4455e-01,  3.0592e-01,  6.0071e-01,  8.5884e-01,  3.1123e-01,\n",
              "                       4.8725e-01,  3.5397e-01,  3.2952e-01,  3.4892e-01,  3.5502e-01,\n",
              "                       3.4696e-01,  3.0273e-01,  4.1633e-01,  4.0881e-01,  3.3469e-01,\n",
              "                       3.4860e-01,  3.9584e-01,  3.7466e-01,  3.3782e-01,  3.9741e-01,\n",
              "                       5.3027e-01,  3.7901e-01,  1.3416e-01,  3.9467e-01,  4.0437e-01,\n",
              "                       3.1824e-01,  3.5236e-01,  3.4212e-01,  3.3224e-01,  3.3345e-01,\n",
              "                       3.9847e-01,  3.1668e-01,  3.4663e-01,  4.0649e-01,  3.0644e-01,\n",
              "                       3.3312e-01,  3.8260e-01,  3.9433e-01,  3.5365e-01,  3.3879e-01,\n",
              "                       4.0084e-01,  3.4400e-01,  3.5911e-01,  3.8608e-01,  3.8293e-01,\n",
              "                       7.0687e-01,  3.5227e-01,  3.2763e-01,  3.8341e-01,  3.1057e-01,\n",
              "                       3.6290e-01,  3.4336e-01,  3.5713e-01,  4.1384e-01, -3.7637e-02,\n",
              "                       5.7303e-01,  3.9831e-01,  3.3344e-01,  3.2505e-01,  3.9967e-01,\n",
              "                       3.6415e-01,  1.8864e+00,  3.4403e-01,  3.0874e-01,  4.1015e-01,\n",
              "                       3.4856e-01,  3.4877e-01,  3.6105e-01,  2.9796e-01,  3.0095e-01,\n",
              "                       3.9937e-01, -4.3929e-01,  3.4507e-01,  4.5365e-01,  3.4574e-01,\n",
              "                       7.8786e-01,  3.6405e-01,  3.2100e-01,  3.4224e-01,  2.8876e-01,\n",
              "                       3.3908e-01,  3.3650e-01,  3.1320e-01,  3.2617e-01,  4.5565e-01,\n",
              "                       3.6372e-01,  3.3189e-01,  3.0935e-01,  3.4254e-01,  3.4454e-01,\n",
              "                       4.5757e-01,  2.9853e-01,  3.6679e-01,  3.7094e-01,  3.7713e-01,\n",
              "                       3.2720e-01,  3.9605e-01,  3.2325e-01,  3.5261e-01,  3.8334e-01,\n",
              "                       3.4517e-01,  3.6114e-01,  3.4026e-01,  3.1160e-01,  3.6384e-01,\n",
              "                       3.9707e-01,  1.2147e+00,  3.5566e-01,  3.6423e-01, -3.6382e-01,\n",
              "                       3.4791e-01,  3.2607e-01,  3.3359e-01,  3.3015e-01,  3.6390e-01,\n",
              "                      -6.7070e-02,  6.4442e-01,  3.0789e-01,  3.3278e-01,  3.1143e-01,\n",
              "                       3.4371e-01,  3.0332e-01,  3.2868e-01,  4.4528e-01,  5.5472e-01,\n",
              "                       3.2225e-01,  3.1971e-01,  2.8591e-01,  3.7767e-01,  3.2037e-01,\n",
              "                       3.0309e-01,  5.1270e-01,  3.2707e-01,  3.8269e-01,  2.9014e-01,\n",
              "                       4.0881e-01,  3.1073e-01,  1.5933e-01,  3.6021e-01,  3.6824e-01,\n",
              "                       3.2696e-01,  3.4987e-01,  3.3056e-01,  4.3363e-01,  5.0698e-01,\n",
              "                       4.1866e-01,  3.9465e-01,  3.1146e-01,  4.1276e-01,  5.8681e-01,\n",
              "                       3.3576e-01,  4.0610e-01,  5.3692e-01,  3.4029e-01,  3.1818e-01,\n",
              "                       2.9902e-01,  3.5572e-01,  3.8645e-01,  3.5257e-01,  4.6346e-01,\n",
              "                       3.8541e-01,  3.8917e-01,  5.8420e-01,  4.4258e-01,  2.8827e-01,\n",
              "                       3.0873e-01,  4.5183e-01,  3.6723e-01,  3.4939e-01,  3.3778e-01,\n",
              "                       2.8041e-01,  3.2600e-01,  3.6476e-01,  3.5596e-01, -2.6468e-01,\n",
              "                       3.5234e-01,  3.6163e-01,  3.4440e-01,  3.1842e-01,  3.4692e-01,\n",
              "                       3.9585e-01,  3.0670e-01,  3.6818e-01,  3.3065e-01,  3.4233e-01,\n",
              "                       4.1538e-01,  3.4876e-01,  3.0882e-01,  3.0910e-01,  3.3142e-01,\n",
              "                       4.5813e-01,  3.5266e-01,  1.2689e-01,  3.9497e-01,  3.9221e-01,\n",
              "                       2.9738e-01,  4.2442e-01, -8.5202e-01,  3.4317e-01,  3.4155e-01,\n",
              "                       4.3083e-01,  3.9221e-01,  3.6916e-01,  3.0973e-01,  3.4647e-01,\n",
              "                       3.2012e-01,  2.9461e-01,  3.8653e-01,  3.8133e-01,  4.0478e-01,\n",
              "                       3.1955e-01,  3.4906e-01,  3.7680e-01,  3.4879e-01,  5.0993e-01,\n",
              "                       3.6465e-01,  3.0606e-01,  4.5463e-01,  3.8712e-01,  3.1609e-01,\n",
              "                       3.3286e-01,  3.3862e-01,  4.0064e-01,  3.5267e-01,  3.6556e-01,\n",
              "                       3.7354e-01,  3.7369e-01,  3.6964e-01,  4.8513e-01,  4.0947e-01,\n",
              "                       3.0635e-01,  3.9935e-01,  3.6272e-01,  3.2258e-01,  3.2169e-01,\n",
              "                       3.6960e-01,  3.5973e-01,  2.8991e-01,  3.3095e-01,  3.2939e-01,\n",
              "                       3.5970e-01,  4.5961e-01,  3.2135e-01,  3.4958e-01,  2.9039e-01,\n",
              "                       3.4153e-01,  3.6476e-01,  3.7759e-01,  3.7378e-01,  3.2251e-01,\n",
              "                       3.1613e-01,  4.0076e-01,  3.3970e-01,  9.0384e-01,  3.4676e-01,\n",
              "                       4.2038e-02,  3.6516e-01,  3.2866e-01, -2.1817e-01,  3.5898e-01,\n",
              "                       3.6195e-01,  3.4239e-01,  3.4465e-01,  3.1934e-01,  4.0692e-01,\n",
              "                       3.6189e-01,  3.2704e-01,  3.2419e-01,  3.3742e-01,  4.1957e-01,\n",
              "                       3.4553e-01,  3.2984e-01,  3.3104e-01,  3.4040e-01,  5.3762e-01,\n",
              "                       3.6360e-01,  4.2288e-01,  3.9516e-01,  3.3783e-01,  3.0231e-01,\n",
              "                       3.6133e-01,  3.1799e-01,  3.3068e-01, -1.1307e-01,  4.5995e-01,\n",
              "                       4.8313e-01,  3.3110e-01,  3.1020e-01,  3.5369e-01,  3.4674e-01,\n",
              "                       3.4688e-01,  5.9127e-01,  1.1263e+00,  4.1216e-01,  3.6905e-01,\n",
              "                       3.1280e-01,  3.2502e-01,  3.3487e-01,  3.2229e-01,  3.2340e-01,\n",
              "                       3.1284e-01,  4.5199e-01,  3.0899e-01,  3.5471e-01,  2.8933e-01,\n",
              "                       3.1686e-01,  3.2227e-01,  6.1135e-01,  3.6392e-01,  3.0211e-01,\n",
              "                       3.4462e-01,  3.2077e-01,  3.4737e-01,  3.6670e-01,  2.9234e-01,\n",
              "                       4.1380e-01,  3.5303e-01,  3.2651e-01,  3.0728e-01, -1.6880e-01,\n",
              "                       3.3405e-01,  3.3574e-01,  7.0601e-02,  3.2154e-01,  2.7479e-01,\n",
              "                       3.3071e-01,  3.9181e-01,  3.2301e-01,  3.2132e-01,  3.9760e-01,\n",
              "                       5.8081e-01,  3.2472e-01,  3.4149e-01,  2.9385e-01,  3.1794e-01,\n",
              "                       3.2071e-01,  6.1366e-01,  3.0450e-01,  3.4911e-01,  3.3354e-01,\n",
              "                       4.2968e-01,  3.8873e-01,  3.6550e-01,  3.4980e-01,  3.7540e-01,\n",
              "                       3.2516e-01,  3.1055e-01,  3.1222e-01,  3.4039e-01,  4.1017e-01,\n",
              "                       3.4418e-01,  4.0955e-01,  3.3652e-01,  4.3108e-01,  3.0315e-01,\n",
              "                       2.7423e-01,  3.3637e-01,  3.4558e-01,  4.7019e-01,  3.4017e-01,\n",
              "                       3.5055e-01,  3.7726e-01,  7.1723e-01,  3.4481e-01,  3.9429e-01,\n",
              "                       4.0607e-01,  3.2593e-01,  3.3451e-01,  2.9869e-01,  3.8388e-01,\n",
              "                       3.1344e-01,  2.8158e-01,  3.2843e-01,  4.3121e-01,  3.9100e-01,\n",
              "                       4.1605e-01,  3.7857e-01,  3.9765e-01,  3.7603e-01,  3.1712e-01,\n",
              "                       3.2874e-01,  3.8354e-01,  3.1387e-01,  2.8953e-01,  3.8990e-01,\n",
              "                       5.5626e-01,  6.2049e-01,  3.0694e-01,  6.0543e-01,  3.4824e-01,\n",
              "                       3.3408e-01,  5.1589e-01,  3.0836e-01,  4.7452e-01,  3.8053e-01,\n",
              "                       3.6295e-01,  4.2594e-01, -1.2260e-03,  5.5365e-01,  2.9631e-01,\n",
              "                       5.9523e-01,  3.5174e-01,  3.4626e-01,  4.7786e-01,  3.0242e-01,\n",
              "                       3.5536e-01,  3.8099e-01,  3.4005e-01,  4.0854e-01,  3.6897e-01,\n",
              "                       4.4554e-01,  3.1710e-01,  4.5954e-01,  3.6270e-01, -3.0088e-02,\n",
              "                       4.3621e-01,  3.2146e-01,  3.1238e-01,  3.6412e-01,  3.1241e-01,\n",
              "                       3.3305e-01,  2.9365e-01,  3.1758e-01,  3.2126e-01,  3.0320e-01,\n",
              "                       3.0274e-01,  3.5037e-01,  4.2436e-01,  3.4860e-01,  3.4447e-01,\n",
              "                       3.3430e-01,  7.4074e-01,  3.1591e-01, -1.6049e-01,  3.5218e-01,\n",
              "                       4.4656e-01,  3.7041e-01,  3.3998e-01,  3.2788e-01,  3.9308e-01,\n",
              "                       3.0452e-01,  3.0713e-01,  1.0355e+00,  3.1238e-01,  3.4112e-01,\n",
              "                       3.0567e-01,  4.3409e-01,  3.0227e-01,  3.5544e-01,  3.6325e-01,\n",
              "                       3.5839e-01,  3.6827e-01,  1.4379e+00,  4.0592e-01,  3.7477e-01,\n",
              "                       3.6515e-01,  3.6466e-01,  3.2054e-01,  4.9395e-01,  3.3874e-01,\n",
              "                       3.2079e-01,  3.5671e-01,  3.1971e-01,  3.6890e-01,  4.0987e-01,\n",
              "                       5.0185e-01,  3.0809e-01,  5.1553e-01,  8.6500e-01,  3.4079e-01,\n",
              "                       3.5732e-01,  4.3074e-01,  3.1972e-01,  3.2054e-01,  3.3532e-01,\n",
              "                       4.1973e-01,  3.6816e-01,  3.5478e-01,  3.4581e-01,  5.5327e-01,\n",
              "                       3.9124e-01, -6.0200e-01,  3.0792e-01,  3.7951e-01,  3.9404e-01,\n",
              "                       5.1662e-01,  3.7413e-01,  3.4574e-01,  3.6281e-01,  3.1836e-01,\n",
              "                       5.3226e-01,  3.9603e-01,  4.0157e-01,  3.1256e-01,  3.8748e-01,\n",
              "                       3.6375e-01,  4.1712e-01,  5.2725e-01,  5.3615e-01,  4.0998e-01,\n",
              "                       4.0081e-01,  3.4534e-01,  3.3147e-01,  3.4917e-01,  2.9893e-01,\n",
              "                       3.4910e-01,  3.5581e-01,  3.4260e-01,  3.1346e-01,  3.5127e-01,\n",
              "                       3.2337e-01,  3.5478e-01,  3.8164e-01,  3.4994e-01,  2.9716e-01,\n",
              "                       3.5392e-01,  3.7810e-01,  4.4492e-01,  3.5051e-01,  3.1703e-01,\n",
              "                       3.9121e-01,  3.8428e-01,  3.7059e-01,  3.3787e-01,  3.5865e-01,\n",
              "                       3.0584e-01,  3.2854e-01,  4.6705e-01,  3.3052e-01,  3.3266e-01,\n",
              "                       3.8111e-01,  3.7308e-01,  3.8238e-01,  3.2322e-01,  3.6007e-01,\n",
              "                       2.9539e-01,  3.1026e-01,  3.6274e-01,  4.4115e-01,  3.6736e-01,\n",
              "                       3.3532e-01,  3.1998e-01,  4.7698e-01,  6.6657e-01,  3.2562e-01,\n",
              "                       5.0778e-01,  3.2214e-01,  3.2172e-01,  3.2197e-01,  4.0641e-01,\n",
              "                       5.8600e-01,  3.9282e-01,  4.5623e-01,  3.5583e-01,  4.1139e-01,\n",
              "                       4.0149e-01,  3.3554e-01,  4.6077e-01,  3.2022e-01,  3.0655e-01,\n",
              "                       7.9356e-01,  3.8187e-01,  3.8443e-01,  3.0634e-01,  3.5545e-01,\n",
              "                       4.2370e-01,  3.1014e-01,  3.5410e-01,  3.3086e-01,  3.9969e-01,\n",
              "                       3.1786e-01,  3.4055e-01,  3.0990e-01,  3.4541e-01,  4.0026e-01,\n",
              "                       3.8943e-01,  4.2828e-01,  3.2940e-01,  5.4040e-01,  3.9127e-01,\n",
              "                       4.8511e-01,  3.4957e-01,  3.1074e-01,  4.4044e-01,  3.5574e-01,\n",
              "                       3.4613e-01,  3.3630e-01,  4.9203e-01,  3.1999e-01,  3.4924e-01,\n",
              "                       3.5368e-01,  4.4657e-01,  2.9522e-01, -4.2317e-01,  3.5767e-01,\n",
              "                       3.2553e-01,  3.1052e-01,  3.0862e-01,  3.0484e-01,  3.2847e-01,\n",
              "                       3.1526e-01,  3.0708e-01,  3.8711e-01], device='cuda:0')),\n",
              "             ('decoder.block.11.layer.1.EncDecAttention.q.weight',\n",
              "              tensor([[-0.0406,  0.0166, -0.0125,  ...,  0.0627,  0.0887,  0.1033],\n",
              "                      [ 0.0121, -0.0340, -0.0014,  ...,  0.0400,  0.0604,  0.0532],\n",
              "                      [ 0.0626, -0.0243, -0.0257,  ..., -0.0263, -0.0416, -0.0755],\n",
              "                      ...,\n",
              "                      [ 0.0394,  0.0373, -0.0119,  ...,  0.0863, -0.0474,  0.0720],\n",
              "                      [ 0.0674,  0.0211, -0.0386,  ..., -0.0080,  0.0046,  0.0071],\n",
              "                      [-0.0129,  0.0048, -0.0267,  ..., -0.0250,  0.0139,  0.0080]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.1.EncDecAttention.k.weight',\n",
              "              tensor([[-0.5262, -0.0714,  0.2519,  ...,  0.2808, -0.1035, -0.2133],\n",
              "                      [ 0.0469,  0.0466, -0.3909,  ...,  0.3273, -0.1896,  0.2202],\n",
              "                      [-0.1320, -0.4638,  0.1414,  ...,  0.0518,  0.5463, -0.0452],\n",
              "                      ...,\n",
              "                      [-0.0089,  0.1052, -0.8149,  ...,  0.0872,  0.5682,  0.3263],\n",
              "                      [ 0.3625,  0.6378, -0.0944,  ...,  0.4244, -0.0539,  0.1305],\n",
              "                      [ 0.1219, -0.1660, -0.6697,  ..., -0.2799, -0.2739,  0.4670]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.1.EncDecAttention.v.weight',\n",
              "              tensor([[ 0.3156,  0.4019, -0.6469,  ..., -1.7567, -0.7038, -0.5635],\n",
              "                      [-0.9120, -0.2223,  0.2201,  ...,  1.4765, -1.5411, -1.1822],\n",
              "                      [ 2.2815, -1.4571, -0.5745,  ...,  0.3984, -0.3300,  1.3044],\n",
              "                      ...,\n",
              "                      [-0.7320,  0.8514,  0.7123,  ..., -0.8318,  1.0584,  0.9504],\n",
              "                      [-0.9728,  0.3359,  0.2954,  ...,  0.3348, -0.1637, -0.7096],\n",
              "                      [ 0.2524, -1.2621,  0.5303,  ..., -1.6085, -1.4773, -1.9071]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.1.EncDecAttention.o.weight',\n",
              "              tensor([[ 0.1074, -0.4977,  1.1262,  ..., -1.3657,  0.5323,  0.2307],\n",
              "                      [ 0.0128,  0.0677,  0.8035,  ..., -0.3226, -0.0117, -0.3793],\n",
              "                      [-0.3527,  0.3920,  0.8803,  ...,  0.0517,  0.9082, -0.0121],\n",
              "                      ...,\n",
              "                      [-1.8941,  1.4501, -0.2501,  ..., -0.7237,  1.0574, -0.4866],\n",
              "                      [-1.4208, -1.5441, -1.8259,  ..., -0.9334, -0.8557, -0.7552],\n",
              "                      [-1.0057, -0.1342, -0.6514,  ...,  0.2308,  1.2625, -0.6799]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.1.layer_norm.weight',\n",
              "              tensor([ 7.4585e-02,  1.3743e-01,  1.3799e-01,  2.7850e-02,  8.9319e-02,\n",
              "                      -6.5773e-02,  2.1089e-01,  7.7594e-02,  8.0172e-02,  1.0575e-01,\n",
              "                      -7.0380e-02,  9.3325e-02,  7.1645e-02,  7.3722e-02,  8.1603e-02,\n",
              "                       8.1596e-02,  5.9044e-02,  1.0459e-01,  7.0597e-02,  1.0548e-01,\n",
              "                       9.4336e-02,  7.5775e-02,  8.0024e-02,  9.9297e-02,  9.8197e-02,\n",
              "                       1.1635e-01,  9.1261e-02, -6.1481e-02,  9.7424e-02,  9.8092e-02,\n",
              "                       1.0079e-01,  6.3004e-02,  1.1345e-01,  1.2018e-01,  7.2693e-02,\n",
              "                       1.1025e-01,  1.1243e-01,  8.4305e-02,  7.4564e-02,  8.7570e-02,\n",
              "                       7.5134e-02,  9.2740e-02,  7.8963e-02,  7.6586e-02,  2.8124e-01,\n",
              "                       7.5610e-02,  1.0792e-01,  1.3681e-01,  8.9909e-02,  7.7237e-02,\n",
              "                       1.4242e-01,  7.5352e-02,  7.5744e-02,  8.1714e-02,  1.1219e-01,\n",
              "                       6.5263e-02,  5.7943e-02,  7.3116e-02,  1.4993e-01,  9.1778e-02,\n",
              "                       8.9153e-02,  8.8630e-02,  9.4688e-02,  1.0511e-01,  9.4296e-02,\n",
              "                       7.4249e-02,  8.9349e-02,  9.0100e-02,  7.1076e-02,  7.6007e-02,\n",
              "                       1.1575e-01,  1.0637e-01,  1.1686e-01,  8.4986e-02,  9.9884e-02,\n",
              "                       9.1635e-02,  6.4879e-02,  7.5783e-02,  1.0662e-01,  1.2578e-01,\n",
              "                       8.8008e-02,  7.9751e-02,  9.0067e-02,  8.2976e-02,  1.0503e-01,\n",
              "                       1.1596e-01,  2.3247e-03,  8.2184e-02,  8.4547e-02,  8.2094e-02,\n",
              "                       7.7800e-02,  1.1033e-01,  7.6572e-02,  6.2206e-02,  9.6999e-02,\n",
              "                       8.2808e-02,  9.8568e-02,  9.5171e-02,  1.1751e-01,  6.4647e-02,\n",
              "                       5.2023e-02,  9.4985e-02,  7.6594e-02,  8.5245e-02,  9.2689e-02,\n",
              "                      -6.9567e-02,  8.9124e-02,  8.5995e-02,  1.2458e-01,  1.1068e-01,\n",
              "                       1.3501e-01,  9.2301e-02,  6.3397e-02,  7.7984e-02,  1.0631e-01,\n",
              "                       1.9623e-01,  7.4339e-02, -6.4534e-02, -2.4651e-02,  9.6182e-02,\n",
              "                       7.8020e-02,  1.2666e-01,  1.1771e-01,  8.4986e-02,  1.0463e-01,\n",
              "                       8.9674e-02,  8.3058e-02,  6.8379e-02,  6.9877e-02, -6.1422e-02,\n",
              "                       7.8696e-02,  1.0364e-01,  7.5700e-02,  9.8225e-02,  1.1554e-01,\n",
              "                      -5.5584e-02,  7.1990e-02,  8.2596e-02,  6.6253e-02,  7.3124e-02,\n",
              "                       8.8505e-02,  1.1708e-01,  6.8864e-02,  8.5225e-02,  6.8653e-02,\n",
              "                      -6.6834e-02,  1.3051e-01,  8.2036e-02,  9.2596e-02, -6.1686e-02,\n",
              "                       1.6246e-01,  9.4446e-02,  1.6471e-01,  9.8699e-02,  1.0924e-01,\n",
              "                       1.1952e-01,  7.3294e-02,  1.2716e-01,  1.4009e-01,  6.3531e-02,\n",
              "                       8.8495e-02,  7.8961e-02,  7.3846e-02,  8.7481e-02,  1.0421e-01,\n",
              "                       1.4894e-01,  9.5178e-02,  9.1414e-02,  1.2733e-01,  9.6916e-02,\n",
              "                      -7.1211e-02,  9.4804e-02,  1.4234e-01,  1.0366e-01,  1.1273e-01,\n",
              "                       8.8802e-02,  8.5037e-02,  1.3790e-01, -7.9896e-02,  1.0980e-01,\n",
              "                       9.2019e-02,  8.7265e-02, -1.0012e-01,  1.1917e-01,  7.3281e-02,\n",
              "                       1.2720e-01,  8.2107e-02,  9.4532e-02,  7.3478e-02,  8.3764e-02,\n",
              "                       1.0135e-01,  9.8444e-02,  1.0208e-01, -6.3811e-02,  7.9992e-02,\n",
              "                       9.8319e-02,  8.9278e-02,  1.1396e-01,  8.4385e-02,  9.6206e-02,\n",
              "                       9.6740e-02, -6.7128e-02,  9.3948e-02,  1.2596e-01,  9.6917e-02,\n",
              "                       6.7949e-02,  8.8802e-02,  1.1107e-01,  9.6321e-02,  1.0809e-01,\n",
              "                       1.5539e-01, -6.7126e-02, -7.5928e-02,  1.0491e-01,  9.7212e-02,\n",
              "                       1.1637e-01,  6.8172e-02,  1.1073e-01,  7.6530e-02,  3.0413e-02,\n",
              "                      -7.9183e-02,  1.7920e-01,  1.4224e-01, -8.0642e-02,  7.9700e-02,\n",
              "                       1.0602e-01,  5.1452e-01,  1.1312e-01,  7.5929e-02,  1.0917e-01,\n",
              "                       1.2052e-01,  7.0739e-02,  9.0116e-02,  8.7253e-02,  9.8939e-02,\n",
              "                       8.2450e-02,  6.7888e-02,  6.6033e-02,  8.2965e-02,  6.9606e-02,\n",
              "                       9.3332e-02,  9.7972e-02,  9.3555e-02,  1.0357e-01,  7.8826e-02,\n",
              "                       7.5402e-02,  1.1921e-01,  7.9772e-02,  9.6320e-02,  9.3925e-02,\n",
              "                       7.7660e-02,  9.2075e-02,  1.0572e-01,  8.4723e-02,  8.4778e-02,\n",
              "                       1.3197e-01,  8.2812e-02,  6.2258e-02,  1.1831e-01,  1.1309e-01,\n",
              "                       6.9358e-02,  7.0980e-02,  1.0057e-01,  9.2930e-02,  1.1451e-01,\n",
              "                       7.9784e-02,  8.3486e-02,  9.0435e-02,  8.2042e-02,  7.5084e-02,\n",
              "                       8.1684e-02,  1.3091e-01,  9.4424e-02,  9.1453e-02, -7.3230e-02,\n",
              "                       8.3168e-02,  1.0900e-01,  7.5064e-02,  1.0343e-01,  6.7514e-02,\n",
              "                       5.6505e-04,  1.1912e-01,  9.5351e-02,  8.2723e-02,  7.0993e-02,\n",
              "                       9.0316e-02,  8.5552e-02,  1.0894e-01,  9.4660e-02,  6.8622e-02,\n",
              "                       7.7925e-02,  1.0195e-01,  8.4778e-02,  8.5575e-02,  8.9183e-02,\n",
              "                       1.0016e-01,  7.6352e-02,  9.4589e-02,  8.7625e-02,  9.2589e-02,\n",
              "                       1.3696e-01,  9.9664e-02, -5.0856e-02,  8.8496e-02,  8.2748e-02,\n",
              "                       9.3969e-02,  6.1014e-02,  9.3591e-02,  6.5398e-02,  1.1487e-01,\n",
              "                       1.7050e-01,  1.0501e-01,  7.4486e-02, -6.5513e-02,  7.0019e-01,\n",
              "                       6.8551e-02,  2.0325e-01,  6.8341e-02,  1.1644e-01,  1.1295e-01,\n",
              "                       9.5504e-02,  1.0783e-01,  6.4662e-02,  1.2026e-01,  8.8604e-02,\n",
              "                       7.8188e-02,  6.9101e-02,  1.2577e-01,  7.6354e-02,  7.8600e-02,\n",
              "                       1.1477e-01,  9.9050e-02,  9.0052e-02,  1.0598e-01,  1.0999e-01,\n",
              "                       8.0548e-02,  1.1166e-01,  1.4332e-01,  9.7334e-02, -4.1128e-02,\n",
              "                       8.5979e-02,  1.0798e-01,  1.1934e-01,  7.0805e-02,  1.2349e-01,\n",
              "                       1.1687e-01,  1.0125e-01,  5.1997e-02,  6.3255e-02,  6.5833e-02,\n",
              "                       1.0268e-01,  1.1467e-01,  1.0701e-01,  1.0635e-01, -7.8927e-02,\n",
              "                       1.2973e-01,  9.3503e-02,  2.2988e-03,  9.5091e-02,  7.9241e-02,\n",
              "                       9.3097e-02,  7.6181e-02, -4.0226e-02,  9.3363e-02,  1.1358e-01,\n",
              "                       1.2774e-01,  6.6814e-02,  1.0874e-01,  8.8406e-02,  7.2767e-02,\n",
              "                       8.2530e-02,  9.8915e-02,  1.0438e-01,  7.1684e-02,  1.1447e-01,\n",
              "                       8.7719e-02,  8.1166e-02,  1.5571e-01,  1.0494e-01,  7.3977e-02,\n",
              "                       9.6954e-02,  8.4295e-02,  6.1467e-02,  1.1902e-01,  8.7360e-02,\n",
              "                       9.0810e-02,  8.9107e-02,  8.1897e-02,  9.2920e-02,  8.9816e-02,\n",
              "                       9.9117e-02,  8.7429e-02, -5.6595e-02, -5.6874e-02,  8.8299e-02,\n",
              "                      -7.9918e-02,  1.1898e-01,  8.7392e-02,  1.0227e-01,  6.9336e-02,\n",
              "                      -8.0479e-02,  9.3662e-02,  9.2961e-02,  9.6703e-02,  7.2975e-02,\n",
              "                       1.0164e-01,  7.4200e-02,  9.6133e-02,  8.5632e-02,  9.6026e-02,\n",
              "                       9.8187e-02,  1.1035e-01,  7.4495e-02,  8.9710e-02,  1.0413e-01,\n",
              "                       1.1365e-01,  9.2424e-02,  7.4260e-02,  6.0921e-01,  1.2909e-01,\n",
              "                       8.2466e-05,  8.6833e-02,  1.0127e-01, -5.7305e-05,  9.0188e-02,\n",
              "                       1.0923e-01,  5.7954e-02,  1.0376e-01,  7.2143e-02,  7.7187e-02,\n",
              "                       8.6119e-02,  9.7741e-02,  8.8601e-02,  8.7441e-02,  1.0870e-01,\n",
              "                       9.3976e-02,  9.4797e-02,  1.1225e-01,  8.8405e-02,  6.9864e-02,\n",
              "                       1.4458e-01,  1.0760e-01,  1.0642e-01,  1.0867e-01,  1.0124e-01,\n",
              "                       8.4157e-02,  9.9442e-02,  7.5215e-02,  2.5653e-03,  8.1769e-02,\n",
              "                       8.3087e-02,  1.2062e-01,  8.5183e-02,  8.9661e-02,  1.0033e-01,\n",
              "                       7.6957e-02,  6.1468e-02,  3.3264e-01,  7.8807e-02,  8.3729e-02,\n",
              "                       9.2917e-02,  1.1223e-01,  1.0199e-01,  8.0852e-02,  8.4356e-02,\n",
              "                       8.2665e-02, -6.8272e-02,  7.5101e-02,  7.8166e-02,  8.8333e-02,\n",
              "                       7.6677e-02,  9.0211e-02,  2.2117e-01,  1.0438e-01,  9.7646e-02,\n",
              "                       1.0082e-01,  9.0629e-02,  1.1690e-01,  8.3664e-02,  6.6286e-02,\n",
              "                       6.3252e-02,  9.4017e-02,  1.0451e-01,  7.9062e-02,  8.1844e-05,\n",
              "                       8.5918e-02,  9.6837e-02,  3.7467e-02,  1.0664e-01,  6.3065e-02,\n",
              "                       8.8182e-02,  1.1568e-01,  9.6436e-02,  1.1759e-01,  1.2183e-01,\n",
              "                       1.9855e-01,  7.0377e-02,  8.4525e-02,  6.4537e-02,  8.0510e-02,\n",
              "                       1.1270e-01,  1.9410e-01,  8.3199e-02,  6.6650e-02,  9.7397e-02,\n",
              "                       9.1907e-02,  8.7058e-02, -7.3969e-02,  8.9394e-02,  1.0085e-01,\n",
              "                       9.6597e-02,  9.3409e-02, -7.9971e-02,  1.0978e-01,  1.0862e-01,\n",
              "                       9.6821e-02,  7.7023e-02,  9.0039e-02,  5.4596e-02,  9.5937e-02,\n",
              "                       7.7533e-02,  8.8099e-02,  1.1699e-01,  1.0600e-01,  8.5616e-02,\n",
              "                       9.7563e-02,  6.8353e-02,  2.1674e-01,  1.0417e-01,  8.6167e-02,\n",
              "                       9.1203e-02,  9.0717e-02,  9.7552e-02,  1.0998e-01,  1.0349e-01,\n",
              "                       1.0029e-01,  7.5376e-02,  1.0100e-01, -8.6148e-02,  7.5231e-02,\n",
              "                       1.2912e-01,  8.2652e-02,  6.6784e-02,  6.9382e-02,  8.4999e-02,\n",
              "                       9.5161e-02,  8.6979e-02,  7.8828e-02,  9.3439e-02,  8.9525e-02,\n",
              "                       8.5107e-02,  1.5001e-01,  7.6849e-02,  1.0271e-01,  8.6575e-02,\n",
              "                       9.7008e-02,  8.0510e-02,  1.0268e-01,  1.0645e-01,  7.9095e-02,\n",
              "                       9.8689e-02,  7.3863e-02, -7.7705e-04, -6.9098e-02,  9.1239e-02,\n",
              "                       1.2569e-01,  8.1489e-02,  9.0496e-02,  7.4159e-02,  1.0442e-01,\n",
              "                       1.1611e-01,  7.8754e-02,  1.0138e-01,  8.4434e-02,  8.5724e-02,\n",
              "                       8.1850e-02,  1.1704e-01,  9.5908e-02,  1.2145e-01,  2.2198e-02,\n",
              "                       1.0268e-01,  1.1010e-01,  7.8964e-02,  8.8746e-02,  8.1551e-02,\n",
              "                       1.0012e-01,  8.1286e-02,  7.9362e-02,  9.4214e-02,  1.0179e-01,\n",
              "                       9.1039e-02,  1.1165e-01,  1.2573e-01,  8.2367e-02, -8.2062e-02,\n",
              "                       1.0379e-01,  1.3072e-01,  9.2446e-02,  2.4513e-02,  7.5406e-02,\n",
              "                      -8.3509e-02,  9.3206e-02,  7.5078e-02,  7.9712e-02,  8.3256e-02,\n",
              "                       7.0061e-02,  9.2909e-02,  1.2725e-01,  7.9314e-02,  8.2258e-02,\n",
              "                       8.2376e-02,  8.0677e-02,  8.1625e-02,  1.2921e-01,  8.2363e-02,\n",
              "                       1.0188e-01,  8.0307e-02,  2.3749e-01,  1.7397e-01,  8.0637e-02,\n",
              "                       9.7605e-02,  9.1782e-02,  8.2963e-02,  7.6309e-02,  7.8703e-02,\n",
              "                       9.6945e-02, -6.3116e-02,  7.1837e-02,  8.6607e-02,  9.5835e-02,\n",
              "                       1.1133e-01,  9.9913e-02,  8.6717e-02,  8.9249e-02,  8.8098e-02,\n",
              "                       8.2223e-02,  7.6769e-02,  1.0250e-01,  9.1442e-02,  8.5014e-02,\n",
              "                       6.5700e-02,  1.0450e-01,  9.2608e-02,  8.4840e-02,  8.3396e-02,\n",
              "                       7.9087e-02,  6.6471e-02,  9.2825e-02,  7.5544e-02,  1.1164e-01,\n",
              "                       1.1602e-01,  9.0061e-02, -6.8548e-02,  7.4775e-02,  1.1463e-01,\n",
              "                       6.5093e-02,  8.9510e-02, -6.5946e-02,  7.7790e-02,  6.9149e-02,\n",
              "                       1.6459e-01,  5.4185e-02,  8.1704e-02,  1.9888e-01,  8.5789e-02,\n",
              "                       7.6863e-02,  1.1844e-01,  8.8553e-02,  1.0829e-01,  9.6465e-02,\n",
              "                       9.9233e-02,  1.0346e-01,  9.2298e-02,  8.4191e-02, -8.1927e-02,\n",
              "                       1.1376e-01,  8.3888e-02,  1.2911e-01,  8.4139e-02,  8.6194e-02,\n",
              "                       1.0049e-01,  1.3527e-01,  8.0619e-02,  7.7619e-02,  7.4021e-02,\n",
              "                       7.1514e-02,  9.4606e-02,  7.2210e-02,  1.0969e-01,  8.8826e-02,\n",
              "                       9.3726e-02,  5.8171e-02,  8.2183e-02,  9.2932e-02,  8.8099e-02,\n",
              "                       7.7630e-02,  1.1010e-01,  1.1267e-01,  8.6759e-02,  7.1913e-02,\n",
              "                       8.3263e-02,  9.7964e-02,  7.8331e-02,  8.5043e-02,  1.4652e-01,\n",
              "                       1.0726e-01,  8.6295e-02, -6.8555e-02,  1.6838e-01,  9.0344e-02,\n",
              "                       8.4581e-02,  9.1091e-02,  9.5001e-02,  1.0832e-01,  4.2727e-02,\n",
              "                       3.8652e-01,  8.3210e-02,  1.3368e-01,  7.9711e-02,  6.6847e-02,\n",
              "                       9.2211e-02,  9.2274e-02,  7.6510e-02,  1.0207e-01,  9.2494e-02,\n",
              "                       1.1875e-01,  7.0593e-02,  9.9368e-02,  9.6885e-02,  7.5610e-02,\n",
              "                       9.3620e-02,  8.0233e-02,  1.2560e-01, -8.8931e-02,  2.1821e-01,\n",
              "                       1.0349e-01,  9.0470e-02,  8.1687e-02,  8.7847e-02,  7.0759e-02,\n",
              "                       7.6083e-02,  8.6498e-02,  7.3528e-02,  8.2575e-02,  9.6096e-02,\n",
              "                       8.4119e-02,  7.3586e-02,  1.0536e-01,  6.5083e-02, -6.8027e-02,\n",
              "                       6.2959e-02,  8.3866e-02, -6.6813e-02,  9.1326e-02,  1.1034e-01,\n",
              "                       1.5032e-01,  1.0329e-01,  8.3366e-02,  1.1881e-01,  7.8943e-02,\n",
              "                       5.4912e-02,  8.5968e-02,  7.2432e-02,  7.6143e-02,  8.3399e-02,\n",
              "                       8.0871e-02,  6.7952e-02,  8.5280e-02], device='cuda:0')),\n",
              "             ('decoder.block.11.layer.2.DenseReluDense.wi.weight',\n",
              "              tensor([[ 0.4030, -0.0129,  0.0033,  ..., -0.4464, -0.3414, -1.0705],\n",
              "                      [ 0.9927,  1.0166,  0.6968,  ..., -0.2952, -0.6216,  0.3009],\n",
              "                      [-0.2200,  0.9696, -0.1419,  ..., -1.1547,  0.1103,  0.9739],\n",
              "                      ...,\n",
              "                      [ 0.7373,  0.8247, -0.3148,  ..., -0.4393,  0.2720, -0.7322],\n",
              "                      [-0.5293,  0.3771,  0.1664,  ..., -0.4340, -0.5864, -0.2654],\n",
              "                      [ 0.0987,  0.7430, -0.7657,  ...,  0.2815,  0.8830,  0.1101]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.2.DenseReluDense.wo.weight',\n",
              "              tensor([[-0.0716, -0.3386, -0.1602,  ..., -0.3575,  0.1811, -0.3995],\n",
              "                      [ 0.2035,  0.1046, -0.1128,  ..., -0.4817,  0.0653,  0.0441],\n",
              "                      [-0.1271,  0.1482, -0.2012,  ..., -0.3061,  0.1072, -0.1432],\n",
              "                      ...,\n",
              "                      [ 0.1694,  0.0669, -0.2162,  ...,  0.4178, -0.2357,  0.2205],\n",
              "                      [ 0.5184, -0.2822,  0.1627,  ...,  0.4891, -0.2647, -0.2945],\n",
              "                      [ 0.1217, -0.4311, -0.1932,  ...,  0.0963,  0.2863,  0.1815]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.block.11.layer.2.layer_norm.weight',\n",
              "              tensor([ 4.4472e+00,  5.4333e+00,  6.1352e+00,  2.1048e+00,  4.5779e+00,\n",
              "                       4.5417e+00,  5.0280e+00,  4.2828e+00,  5.5042e+00,  4.5817e+00,\n",
              "                       4.4335e+00,  4.7536e+00,  5.0578e+00,  5.0101e+00,  4.3616e+00,\n",
              "                       4.3149e+00,  4.6668e+00,  5.1815e+00,  5.1643e+00,  4.3474e+00,\n",
              "                       4.3821e+00,  4.3519e+00,  5.5142e+00,  4.3210e+00,  4.5201e+00,\n",
              "                       5.3410e+00,  4.6933e+00,  6.3690e+00,  5.0422e+00,  4.5229e+00,\n",
              "                       4.4784e+00,  5.4182e+00,  4.4960e+00,  4.4726e+00,  4.7583e+00,\n",
              "                       5.2103e+00,  4.8666e+00,  9.9877e+00,  4.3862e+00,  4.5062e+00,\n",
              "                       4.9526e+00,  5.1915e+00,  4.6697e+00,  4.4876e+00,  7.0509e+00,\n",
              "                       4.6363e+00,  5.3119e+00,  4.6395e+00,  4.3675e+00,  4.7627e+00,\n",
              "                       5.7887e+00,  4.2203e+00,  4.8451e+00,  4.5862e+00,  9.1125e+00,\n",
              "                       4.8064e+00,  5.3325e+00,  4.4392e+00,  4.7151e+00,  4.7845e+00,\n",
              "                       4.7217e+00,  4.4718e+00,  4.3779e+00,  4.7753e+00,  4.6376e+00,\n",
              "                       1.8389e+01,  4.5095e+00,  4.8413e+00,  9.5435e+00,  4.4296e+00,\n",
              "                       4.9588e+00,  4.9326e+00,  4.7772e+00,  4.7355e+00,  5.2269e+00,\n",
              "                       4.3828e+00,  5.5038e+00,  4.2885e+00,  4.7946e+00,  5.5758e+00,\n",
              "                       4.5505e+00,  4.6919e+00,  4.3941e+00,  6.1728e+00,  4.9306e+00,\n",
              "                       4.9394e+00,  9.0566e-01,  4.3929e+00,  4.4730e+00,  4.3780e+00,\n",
              "                       4.6634e+00,  4.4390e+00,  4.4343e+00,  4.4901e+00,  4.7111e+00,\n",
              "                       4.4379e+00,  4.3999e+00,  4.6150e+00,  4.8051e+00,  4.5329e+00,\n",
              "                       4.4842e+00,  4.6005e+00,  7.3800e+00,  4.5339e+00,  4.8153e+00,\n",
              "                       5.8149e+00,  4.4632e+00,  4.8445e+00,  5.2286e+00,  4.8539e+00,\n",
              "                       4.6157e+00,  4.7655e+00,  4.4126e+00,  4.4830e+00,  5.0605e+00,\n",
              "                       5.2128e+00,  4.8816e+00,  4.6022e+00,  1.2422e+00,  4.6431e+00,\n",
              "                       4.3947e+00,  4.9040e+00,  6.3899e+00,  4.4916e+00,  4.8148e+00,\n",
              "                       4.6279e+00,  4.6401e+00,  4.4155e+00,  4.5922e+00,  5.4949e+00,\n",
              "                       6.1535e+00,  5.0062e+00,  4.3137e+00,  4.2713e+00,  4.9537e+00,\n",
              "                       5.1332e+00,  4.4700e+00,  5.7618e+00,  4.1511e+00,  5.1297e+00,\n",
              "                       5.8117e+00,  4.7910e+00,  4.4767e+00,  5.4696e+00,  4.7161e+00,\n",
              "                       4.7587e+00,  4.8617e+00,  5.2570e+00,  4.7618e+00,  4.4837e+00,\n",
              "                       4.9403e+00,  5.2178e+00,  5.5523e+00,  6.0178e+00,  4.5415e+00,\n",
              "                       4.7258e+00,  4.5889e+00,  4.6453e+00,  5.0894e+00,  4.9356e+00,\n",
              "                       4.3761e+00,  4.5352e+00,  4.6846e+00,  5.4066e+00,  4.9989e+00,\n",
              "                       6.6064e+00,  4.4829e+00,  5.6602e+00,  8.0761e+00,  4.6540e+00,\n",
              "                       7.5259e+00,  4.6760e+00,  4.9440e+00,  4.8523e+00,  4.7569e+00,\n",
              "                       4.7415e+00,  4.8169e+00,  4.9811e+00,  6.5255e+00,  5.2417e+00,\n",
              "                       4.6789e+00,  4.3947e+00,  4.3906e+00,  4.6056e+00,  5.0769e+00,\n",
              "                       5.8970e+00,  4.4762e+00,  3.6336e+00,  4.8202e+00,  4.8754e+00,\n",
              "                       4.5971e+00,  4.5368e+00,  5.0754e+00,  4.4373e+00,  4.7545e+00,\n",
              "                       5.5037e+00,  4.4741e+00,  4.5428e+00,  4.7315e+00,  4.7481e+00,\n",
              "                       4.3416e+00,  4.3695e+00,  4.7252e+00,  4.8647e+00,  4.8356e+00,\n",
              "                       4.6323e+00,  4.3125e+00,  4.4471e+00,  4.9990e+00,  4.2892e+00,\n",
              "                       6.6191e+00,  4.4652e+00,  4.5882e+00,  4.8684e+00,  4.4388e+00,\n",
              "                       5.0087e+00,  4.5935e+00,  5.0982e+00,  4.6082e+00,  1.1467e+00,\n",
              "                       5.8351e+00,  5.0007e+00,  5.5757e+00,  4.5554e+00,  5.2022e+00,\n",
              "                       4.4682e+00,  4.9437e+00,  4.9454e+00,  4.4772e+00,  5.0998e+00,\n",
              "                       4.9798e+00,  4.2213e+00,  4.8763e+00,  4.4927e+00,  4.7330e+00,\n",
              "                       4.9501e+00,  5.4417e+00,  4.3033e+00,  5.4173e+00,  4.4486e+00,\n",
              "                       9.6283e+00,  4.7736e+00,  4.7962e+00,  4.7489e+00,  4.2926e+00,\n",
              "                       4.4462e+00,  4.9752e+00,  4.3221e+00,  4.6555e+00,  4.8566e+00,\n",
              "                       5.0890e+00,  4.5992e+00,  4.4907e+00,  4.9985e+00,  4.8408e+00,\n",
              "                       5.2927e+00,  4.6059e+00,  5.2376e+00,  4.8836e+00,  4.8840e+00,\n",
              "                       4.9558e+00,  5.4062e+00,  4.4154e+00,  4.3766e+00,  4.9086e+00,\n",
              "                       4.4919e+00,  4.9362e+00,  4.8143e+00,  4.3923e+00,  4.4649e+00,\n",
              "                       4.7332e+00,  1.3199e+01,  4.6357e+00,  4.9673e+00,  6.0078e+00,\n",
              "                       4.5570e+00,  4.9157e+00,  4.6071e+00,  5.0199e+00,  4.6216e+00,\n",
              "                      -1.5258e+00,  7.5969e+00,  4.7516e+00,  4.9393e+00,  4.5837e+00,\n",
              "                       4.6879e+00,  4.4540e+00,  4.5982e+00,  4.8738e+00,  5.4439e+00,\n",
              "                       4.6326e+00,  4.5843e+00,  4.4077e+00,  4.7009e+00,  4.7513e+00,\n",
              "                       4.4307e+00,  6.8020e+00,  4.5044e+00,  4.7182e+00,  4.7814e+00,\n",
              "                       4.7827e+00,  4.9722e+00,  3.8231e+00,  4.5595e+00,  4.7479e+00,\n",
              "                       4.5729e+00,  4.3266e+00,  4.3906e+00,  4.9158e+00,  4.7917e+00,\n",
              "                       4.9169e+00,  5.0482e+00,  4.1606e+00,  4.8555e+00,  5.4325e+00,\n",
              "                       4.5948e+00,  4.9004e+00,  6.1258e+00,  4.4994e+00,  4.6570e+00,\n",
              "                       4.3451e+00,  5.0074e+00,  4.6317e+00,  4.9421e+00,  5.0939e+00,\n",
              "                       5.0197e+00,  4.6316e+00,  6.4202e+00,  4.7188e+00,  4.5356e+00,\n",
              "                       4.5609e+00,  5.8382e+00,  4.5647e+00,  4.7182e+00,  4.7291e+00,\n",
              "                       4.6641e+00,  5.1224e+00,  4.8599e+00,  4.7499e+00,  4.3307e+00,\n",
              "                       4.7634e+00,  4.8879e+00,  4.7457e+00,  4.2640e+00,  4.8991e+00,\n",
              "                       5.0179e+00,  4.5425e+00,  4.3507e+00,  5.2677e+00,  5.1770e+00,\n",
              "                       5.5413e+00,  4.9762e+00,  4.9471e+00,  4.7979e+00,  4.6621e+00,\n",
              "                       4.9161e+00,  4.8163e+00,  1.5784e-02,  4.8716e+00,  4.4945e+00,\n",
              "                       4.4730e+00,  5.0285e+00,  1.3289e+01,  4.8247e+00,  4.9477e+00,\n",
              "                       4.6225e+00,  4.9897e+00,  4.8750e+00,  4.6561e+00,  4.4721e+00,\n",
              "                       4.6108e+00,  4.6250e+00,  5.3746e+00,  4.6635e+00,  4.5861e+00,\n",
              "                       4.7953e+00,  4.8530e+00,  4.9071e+00,  5.0005e+00,  5.9043e+00,\n",
              "                       4.8266e+00,  4.9157e+00,  5.8048e+00,  4.8457e+00,  4.7636e+00,\n",
              "                       4.5282e+00,  4.2595e+00,  4.6880e+00,  4.8364e+00,  4.6294e+00,\n",
              "                       5.0307e+00,  4.5849e+00,  4.7301e+00,  5.3829e+00,  4.9112e+00,\n",
              "                       4.4143e+00,  5.1178e+00,  4.9622e+00,  4.7286e+00,  4.4963e+00,\n",
              "                       4.9032e+00,  4.8793e+00,  4.3200e+00,  4.6875e+00,  4.6550e+00,\n",
              "                       4.7257e+00,  5.7157e+00,  4.7119e+00,  4.8473e+00,  4.4413e+00,\n",
              "                       4.8107e+00,  5.1926e+00,  4.7877e+00,  4.6275e+00,  4.5677e+00,\n",
              "                       4.8556e+00,  5.2852e+00,  4.2950e+00,  1.1246e+01,  5.1017e+00,\n",
              "                      -1.0612e+00,  4.5860e+00,  4.6283e+00,  4.0204e+00,  4.7816e+00,\n",
              "                       4.8541e+00,  4.4492e+00,  4.7104e+00,  5.0465e+00,  4.8399e+00,\n",
              "                       4.8529e+00,  4.7868e+00,  4.2753e+00,  4.7345e+00,  5.0873e+00,\n",
              "                       4.8838e+00,  4.2336e+00,  5.0127e+00,  4.9642e+00,  6.4054e+00,\n",
              "                       5.2877e+00,  6.5204e+00,  5.2278e+00,  4.7222e+00,  4.6629e+00,\n",
              "                       4.8188e+00,  4.5999e+00,  4.5244e+00, -1.1488e-02,  4.5324e+00,\n",
              "                       4.5686e+00,  4.6248e+00,  4.6004e+00,  5.0070e+00,  5.1090e+00,\n",
              "                       4.4555e+00,  7.1140e+00,  7.9166e+00,  4.6926e+00,  4.9538e+00,\n",
              "                       4.7545e+00,  4.5202e+00,  4.6900e+00,  4.7830e+00,  4.8482e+00,\n",
              "                       4.5786e+00,  5.1582e+00,  4.5071e+00,  4.4414e+00,  4.4785e+00,\n",
              "                       4.3131e+00,  4.6879e+00,  1.0485e+01,  4.6530e+00,  4.5914e+00,\n",
              "                       5.1121e+00,  4.3193e+00,  5.2698e+00,  4.8957e+00,  4.6003e+00,\n",
              "                       4.5492e+00,  4.9068e+00,  4.7208e+00,  4.6824e+00,  2.3930e+00,\n",
              "                       4.6572e+00,  4.6353e+00,  1.7848e+00,  5.0043e+00,  4.3590e+00,\n",
              "                       4.5480e+00,  4.7226e+00,  4.4717e+00,  4.6173e+00,  4.9859e+00,\n",
              "                       2.0993e+01,  5.1207e+00,  4.4748e+00,  4.2564e+00,  4.3122e+00,\n",
              "                       4.7110e+00,  6.2618e+00,  4.9134e+00,  4.6469e+00,  4.7202e+00,\n",
              "                       5.1903e+00,  5.0751e+00,  4.6194e+00,  4.6727e+00,  4.6339e+00,\n",
              "                       4.6288e+00,  4.5304e+00,  4.5014e+00,  4.7442e+00,  5.0642e+00,\n",
              "                       4.6037e+00,  4.5997e+00,  4.7280e+00,  4.9519e+00,  4.5326e+00,\n",
              "                       4.3065e+00,  4.5845e+00,  4.6278e+00,  5.4832e+00,  4.5995e+00,\n",
              "                       5.0572e+00,  4.4327e+00,  7.8453e+00,  4.8720e+00,  4.7037e+00,\n",
              "                       5.3430e+00,  4.7186e+00,  4.4144e+00,  4.6939e+00,  5.1305e+00,\n",
              "                       4.9328e+00,  4.4507e+00,  4.5680e+00,  4.6687e+00,  4.4220e+00,\n",
              "                       5.0119e+00,  4.8844e+00,  4.7218e+00,  4.6097e+00,  4.4889e+00,\n",
              "                       4.7222e+00,  5.1630e+00,  4.5481e+00,  4.6063e+00,  5.1720e+00,\n",
              "                       5.8217e+00,  6.6500e+00,  4.4719e+00,  7.1575e+00,  4.5012e+00,\n",
              "                       4.9293e+00,  5.8048e+00,  4.6321e+00,  5.2866e+00,  4.4973e+00,\n",
              "                       5.0135e+00,  5.0953e+00,  1.3141e-02,  6.0754e+00,  4.4060e+00,\n",
              "                       6.7811e+00,  5.0297e+00,  4.7106e+00,  5.1089e+00,  4.5265e+00,\n",
              "                       4.6948e+00,  5.1622e+00,  4.7856e+00,  4.3610e+00,  4.9775e+00,\n",
              "                       5.5400e+00,  4.6689e+00,  5.1775e+00,  5.0604e+00,  1.4377e+00,\n",
              "                       5.5499e+00,  4.7028e+00,  4.5241e+00,  4.8210e+00,  4.1908e+00,\n",
              "                       4.4607e+00,  4.7522e+00,  4.4639e+00,  4.5453e+00,  4.7811e+00,\n",
              "                       4.6516e+00,  4.8238e+00,  5.6483e+00,  4.9208e+00,  4.4051e+00,\n",
              "                       4.6635e+00,  7.3452e+00,  4.5671e+00,  2.2911e+00,  5.0764e+00,\n",
              "                       5.2463e+00,  4.9138e+00,  4.4997e+00,  5.0047e+00,  4.4348e+00,\n",
              "                       4.3948e+00,  4.5973e+00,  1.1448e+01,  4.4254e+00,  4.2517e+00,\n",
              "                       4.6050e+00,  4.4588e+00,  4.5042e+00,  4.7872e+00,  4.3476e+00,\n",
              "                       4.9019e+00,  4.4181e+00,  1.3364e+01,  5.1073e+00,  4.5683e+00,\n",
              "                       4.6679e+00,  4.6241e+00,  4.9343e+00,  5.6916e+00,  4.4488e+00,\n",
              "                       4.7807e+00,  4.4727e+00,  4.3988e+00,  5.0640e+00,  5.1439e+00,\n",
              "                       5.3746e+00,  4.5139e+00,  5.8194e+00,  1.1186e+01,  5.0658e+00,\n",
              "                       4.8924e+00,  4.8238e+00,  4.8009e+00,  4.9307e+00,  4.8190e+00,\n",
              "                       5.2540e+00,  5.3837e+00,  4.3699e+00,  5.3204e+00,  6.8384e+00,\n",
              "                       4.5651e+00,  6.4769e+00,  4.4775e+00,  4.2483e+00,  5.0059e+00,\n",
              "                       4.8536e+00,  4.7827e+00,  4.6037e+00,  4.6285e+00,  4.9544e+00,\n",
              "                       7.7692e+00,  4.6490e+00,  4.6921e+00,  4.5154e+00,  4.5279e+00,\n",
              "                       5.0448e+00,  5.0037e+00,  5.0555e+00,  6.4644e+00,  4.9202e+00,\n",
              "                       4.6870e+00,  4.7103e+00,  4.6398e+00,  4.5992e+00,  4.4447e+00,\n",
              "                       4.8449e+00,  4.7729e+00,  4.4968e+00,  4.6646e+00,  4.7326e+00,\n",
              "                       4.8479e+00,  4.7655e+00,  4.8957e+00,  4.8553e+00,  4.6956e+00,\n",
              "                       4.7342e+00,  4.8172e+00,  6.0012e+00,  4.9368e+00,  4.6968e+00,\n",
              "                       4.6260e+00,  4.4969e+00,  4.9372e+00,  4.5587e+00,  4.8148e+00,\n",
              "                       4.5396e+00,  4.3469e+00,  5.5486e+00,  4.8212e+00,  4.7817e+00,\n",
              "                       4.8513e+00,  4.9708e+00,  5.0841e+00,  4.7808e+00,  4.6284e+00,\n",
              "                       4.5601e+00,  4.6816e+00,  4.8618e+00,  5.9313e+00,  5.0983e+00,\n",
              "                       4.7830e+00,  4.6314e+00,  5.1935e+00,  6.9944e+00,  4.5301e+00,\n",
              "                       5.3836e+00,  4.7777e+00,  4.6542e+00,  4.9487e+00,  6.0890e+00,\n",
              "                       5.3912e+00,  4.8271e+00,  5.4098e+00,  4.6317e+00,  4.5562e+00,\n",
              "                       4.6292e+00,  4.9447e+00,  6.0428e+00,  4.9055e+00,  4.3795e+00,\n",
              "                       7.7062e+00,  4.8726e+00,  4.8489e+00,  4.6246e+00,  4.6853e+00,\n",
              "                       4.7784e+00,  4.2092e+00,  5.0636e+00,  7.0422e+00,  4.9538e+00,\n",
              "                       4.6415e+00,  4.7349e+00,  4.5444e+00,  4.8156e+00,  5.1683e+00,\n",
              "                       4.8978e+00,  6.2935e+00,  4.9326e+00,  5.8838e+00,  4.9655e+00,\n",
              "                       5.0763e+00,  5.2832e+00,  4.8211e+00,  4.9662e+00,  4.4312e+00,\n",
              "                       4.1550e+00,  4.6842e+00,  5.1792e+00,  4.8583e+00,  5.1098e+00,\n",
              "                       4.8622e+00,  4.7470e+00,  4.5813e+00,  6.1624e+00,  4.3515e+00,\n",
              "                       5.2570e+00,  4.8471e+00,  4.5278e+00,  4.1235e+00,  4.9351e+00,\n",
              "                       4.6024e+00,  4.2572e+00,  4.5716e+00], device='cuda:0')),\n",
              "             ('decoder.final_layer_norm.weight',\n",
              "              tensor([0.1913, 0.3537, 0.3533, 0.0242, 0.1444, 0.2148, 0.1997, 0.1861, 0.3064,\n",
              "                      0.1717, 0.1921, 0.1916, 0.4418, 0.2872, 0.1385, 0.1615, 0.2067, 0.2503,\n",
              "                      0.2875, 0.1590, 0.1567, 0.1706, 0.3235, 0.1810, 0.1630, 0.2662, 0.1624,\n",
              "                      0.3202, 0.1873, 0.1722, 0.1691, 0.6509, 0.1837, 0.1717, 0.2159, 0.2055,\n",
              "                      0.1978, 0.5383, 0.1519, 0.2073, 0.2710, 0.1988, 0.2152, 0.1772, 0.5164,\n",
              "                      0.1942, 0.2658, 0.1649, 0.1759, 0.1765, 0.2720, 0.1939, 0.2100, 0.1521,\n",
              "                      4.5275, 0.2115, 0.4018, 0.1861, 0.1553, 0.1646, 0.1984, 0.1394, 0.1701,\n",
              "                      0.1682, 0.1693, 0.8439, 0.1691, 0.1840, 1.5686, 0.1522, 0.1896, 0.2079,\n",
              "                      0.1693, 0.1931, 0.1517, 0.1538, 0.3024, 0.1834, 0.1608, 0.1986, 0.1634,\n",
              "                      0.1873, 0.1774, 0.3690, 0.1886, 0.1773, 0.5339, 0.1884, 0.1728, 0.1575,\n",
              "                      0.1981, 0.1593, 0.1816, 0.1980, 0.1425, 0.1520, 0.1710, 0.1592, 0.1548,\n",
              "                      0.1746, 0.2241, 0.2038, 0.3185, 0.1639, 0.1718, 0.5061, 0.1699, 0.1834,\n",
              "                      0.1728, 0.2239, 0.1887, 0.1963, 0.1820, 0.1721, 0.1729, 0.1851, 0.1926,\n",
              "                      0.1667, 0.0238, 0.1723, 0.1477, 0.1647, 0.3941, 0.1725, 0.2139, 0.2083,\n",
              "                      0.1839, 0.2067, 0.2123, 0.3924, 0.5301, 0.2217, 0.1598, 0.1518, 0.2109,\n",
              "                      0.2755, 0.2127, 0.2480, 0.1945, 0.2295, 0.2212, 0.2197, 0.2282, 0.3535,\n",
              "                      0.2373, 0.2391, 0.2010, 0.3500, 0.1819, 0.1975, 0.1624, 0.1894, 0.1995,\n",
              "                      0.3528, 0.1505, 0.1614, 0.2117, 0.1618, 0.3248, 0.2284, 0.1568, 0.1915,\n",
              "                      0.2360, 0.3724, 0.1771, 0.2392, 0.1749, 0.3147, 0.3500, 0.2097, 0.4419,\n",
              "                      0.1638, 0.1699, 0.2216, 0.1694, 0.1935, 0.2090, 0.2664, 0.4114, 0.2499,\n",
              "                      0.1677, 0.1562, 0.1715, 0.1465, 0.3015, 0.3056, 0.1523, 0.2170, 0.1707,\n",
              "                      0.2395, 0.1767, 0.1691, 0.1626, 0.1599, 0.1753, 0.1861, 0.1743, 0.2030,\n",
              "                      0.2010, 0.1779, 0.1406, 0.2000, 0.1808, 0.1844, 0.1664, 0.2808, 0.1873,\n",
              "                      0.1704, 0.1969, 0.1603, 0.3249, 0.2026, 0.2056, 0.2099, 0.1645, 0.1884,\n",
              "                      0.1737, 0.1879, 0.2073, 0.6684, 0.2673, 0.1962, 0.1943, 0.1779, 0.2356,\n",
              "                      0.1715, 0.0520, 0.2273, 0.1929, 0.2320, 0.2036, 0.1720, 0.2325, 0.1469,\n",
              "                      0.1459, 0.1782, 0.2947, 0.2114, 0.2695, 0.1997, 4.5692, 0.2082, 0.1722,\n",
              "                      0.1816, 0.1700, 0.1669, 0.1908, 0.1920, 0.1599, 0.2383, 0.2212, 0.1695,\n",
              "                      0.1717, 0.1643, 0.1571, 0.2337, 0.1516, 0.2462, 0.2001, 0.1782, 0.3509,\n",
              "                      0.2903, 0.1392, 0.1606, 0.1788, 0.1891, 0.1885, 0.1852, 0.1816, 0.1616,\n",
              "                      0.1625, 0.8470, 0.2192, 0.1902, 0.5584, 0.1888, 0.1755, 0.2086, 0.1817,\n",
              "                      0.2278, 0.9390, 0.4680, 0.1726, 0.2127, 0.1938, 0.2159, 0.1571, 0.1543,\n",
              "                      0.2706, 0.3660, 0.1591, 0.1792, 0.1679, 0.1508, 0.1762, 0.1441, 0.4452,\n",
              "                      0.1646, 0.1617, 0.1849, 0.2148, 0.1719, 0.3405, 0.2093, 0.1928, 0.1547,\n",
              "                      0.1883, 0.1582, 0.2234, 0.2235, 0.1744, 0.2373, 0.1605, 0.2674, 0.2164,\n",
              "                      0.1809, 0.2023, 1.4365, 0.1818, 0.1633, 0.1547, 0.2014, 0.2096, 0.1505,\n",
              "                      0.2751, 0.1956, 0.2189, 0.2906, 0.2080, 0.1691, 0.1620, 0.2820, 0.1888,\n",
              "                      0.1869, 0.1894, 0.1609, 0.1774, 0.1559, 0.1989, 0.6407, 0.1854, 0.1895,\n",
              "                      0.1845, 0.1660, 0.1910, 0.2055, 0.2027, 0.2012, 0.3503, 0.2270, 0.2756,\n",
              "                      0.1741, 0.2018, 0.1743, 0.2273, 0.1705, 0.1742, 0.0143, 0.1619, 0.2066,\n",
              "                      0.1642, 0.2944, 0.6065, 0.1670, 0.1485, 0.1630, 0.2503, 0.2053, 0.1646,\n",
              "                      0.1655, 0.1850, 0.2400, 0.2721, 0.1963, 0.2141, 0.1502, 0.2463, 0.1574,\n",
              "                      0.2173, 0.4669, 0.1934, 0.2162, 0.5283, 0.1820, 0.1570, 0.2015, 0.1699,\n",
              "                      0.1983, 0.1681, 0.2034, 0.1803, 0.2455, 0.2187, 0.4974, 0.2215, 0.1697,\n",
              "                      0.1918, 0.1717, 0.1860, 0.1550, 0.1885, 0.2055, 0.1465, 0.1607, 0.1852,\n",
              "                      0.1789, 0.3607, 0.1782, 0.1798, 0.1627, 0.1759, 0.1740, 0.2066, 0.2164,\n",
              "                      0.1558, 0.1698, 0.1975, 0.1545, 0.2059, 0.2199, 0.4793, 0.1881, 0.1535,\n",
              "                      0.5443, 0.1799, 0.1758, 0.2228, 0.1482, 0.1973, 0.2108, 0.2236, 0.1720,\n",
              "                      0.2165, 0.1751, 0.2981, 0.2056, 0.1795, 0.1670, 0.2114, 0.3355, 0.1952,\n",
              "                      0.2817, 0.3089, 0.2126, 0.1595, 0.2223, 0.1596, 0.2059, 0.0286, 0.1926,\n",
              "                      0.1739, 0.1578, 0.1783, 0.1628, 0.2077, 0.2500, 0.7912, 0.1791, 0.2278,\n",
              "                      0.1628, 0.1614, 0.1535, 0.1707, 0.1826, 0.1886, 0.1770, 0.2648, 0.2022,\n",
              "                      0.1736, 0.1512, 0.1607, 0.1504, 0.4554, 0.1504, 0.1830, 0.1707, 0.1558,\n",
              "                      0.1839, 0.1982, 0.1909, 0.2251, 0.2424, 0.1688, 0.1826, 0.4751, 0.1662,\n",
              "                      0.1654, 0.1182, 0.1603, 0.1941, 0.1584, 0.2117, 0.1783, 0.1669, 0.1870,\n",
              "                      3.7155, 0.2116, 0.1855, 0.1608, 0.1484, 0.1564, 0.4053, 0.1909, 0.2078,\n",
              "                      0.1722, 0.2446, 0.2152, 0.2244, 0.1527, 0.2140, 0.2001, 0.1541, 0.1878,\n",
              "                      0.1785, 0.2536, 0.1360, 0.1960, 0.2153, 0.5340, 0.1778, 0.1622, 0.1893,\n",
              "                      0.1377, 0.2159, 0.1808, 0.2443, 0.2036, 0.4506, 0.1903, 0.2294, 0.3197,\n",
              "                      0.1790, 0.2083, 0.1729, 0.2411, 0.1826, 0.1935, 0.1689, 0.2377, 0.2057,\n",
              "                      0.2200, 0.1535, 0.2216, 0.2367, 0.1741, 0.1650, 0.2494, 0.1722, 0.1680,\n",
              "                      0.2056, 0.3651, 0.4125, 0.1527, 0.7075, 0.1676, 0.1694, 0.2564, 0.1567,\n",
              "                      0.2938, 0.2233, 0.2180, 0.2346, 0.0113, 2.8856, 0.1625, 0.3450, 0.1836,\n",
              "                      0.2152, 0.2571, 0.1743, 0.2012, 0.2256, 0.1549, 0.1793, 0.2038, 0.2688,\n",
              "                      0.1536, 0.2488, 0.1699, 0.1377, 0.2878, 0.1409, 0.1761, 0.1977, 0.1482,\n",
              "                      0.1337, 0.1649, 0.1611, 0.1570, 0.1671, 0.1818, 0.2006, 0.1877, 0.1951,\n",
              "                      0.2005, 0.1647, 0.3920, 0.1696, 0.5354, 0.1982, 0.3358, 0.1735, 0.1770,\n",
              "                      0.2063, 0.2043, 0.1544, 0.1473, 0.6623, 0.2047, 0.1799, 0.1976, 0.1751,\n",
              "                      0.1973, 0.1680, 0.1847, 0.2054, 0.1779, 0.3691, 0.1898, 0.1837, 0.1841,\n",
              "                      0.1777, 0.1760, 0.3111, 0.1720, 0.1763, 0.1837, 0.2266, 0.2126, 0.2394,\n",
              "                      0.2507, 0.1762, 0.3228, 3.6245, 0.1658, 0.2645, 0.2061, 0.1794, 0.2293,\n",
              "                      0.1797, 0.2775, 0.2051, 0.1680, 0.1816, 0.3491, 0.2008, 0.4080, 0.1583,\n",
              "                      0.1600, 0.1583, 0.2063, 0.1707, 0.1951, 0.2094, 0.1855, 0.6151, 0.1952,\n",
              "                      0.2282, 0.1734, 0.2243, 0.2124, 0.2245, 0.2225, 0.3637, 0.1816, 0.2290,\n",
              "                      0.1863, 0.1563, 0.1761, 0.1586, 0.2043, 0.2037, 0.1807, 0.1990, 0.1873,\n",
              "                      0.1615, 0.2049, 0.1738, 0.1793, 0.1673, 0.1812, 0.1659, 0.1968, 0.1686,\n",
              "                      0.2302, 0.2046, 0.1815, 0.2304, 0.1467, 0.2069, 0.1624, 0.1910, 0.4094,\n",
              "                      0.1709, 0.1884, 0.2012, 0.1897, 0.1572, 0.1949, 0.1922, 0.2013, 0.1632,\n",
              "                      0.2163, 0.2222, 0.1937, 0.1573, 0.1697, 0.3335, 0.6315, 0.1613, 0.2521,\n",
              "                      0.2038, 0.1780, 0.1859, 0.7451, 0.2075, 0.1853, 0.2434, 0.2043, 0.2504,\n",
              "                      0.1804, 0.2031, 0.3871, 0.1525, 0.1981, 0.4906, 0.2210, 0.1887, 0.1791,\n",
              "                      0.2134, 0.1911, 0.1699, 0.1836, 0.2841, 0.1939, 0.1806, 0.1737, 0.1914,\n",
              "                      0.1738, 0.2455, 0.1896, 0.3308, 0.2103, 0.3497, 0.1593, 0.3257, 0.2577,\n",
              "                      0.1731, 0.2633, 0.2911, 0.1869, 0.1948, 0.3051, 0.2065, 0.1959, 0.1685,\n",
              "                      0.2213, 0.1613, 0.4130, 0.1992, 0.2709, 0.1836, 0.1946, 0.1512, 0.2028,\n",
              "                      0.2157, 0.1526, 0.2161], device='cuda:0')),\n",
              "             ('lm_head.weight',\n",
              "              tensor([[ -0.7576,   0.6001,  -2.4332,  ...,   1.2522,  -0.7822,   3.5235],\n",
              "                      [ 11.3739,  -4.8733,   9.0615,  ...,   4.8424,  14.3902,  -5.7711],\n",
              "                      [-16.6135,  11.0992, -20.8572,  ...,  10.6604,  22.2536,  24.9938],\n",
              "                      ...,\n",
              "                      [  2.2344,   6.7500, -11.0625,  ..., -11.3125,  13.5625,  16.6250],\n",
              "                      [  4.2500,   5.1250, -12.2500,  ..., -11.9375,  13.5000,  17.0000],\n",
              "                      [  4.0625,   6.9688, -12.2500,  ..., -11.3750,  11.9375,  16.6250]],\n",
              "                     device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgZIpUjRDPtg"
      },
      "source": [
        "### Experiment with generating summaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CVGKN1bCesc"
      },
      "source": [
        "# First, read a text from the file\n",
        "\n",
        "t5_prepared_Text = \"summarize: \" + preprocess_text\n",
        "tokenized_text = tokenizer.encode(t5_prepared_Text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# summmarize \n",
        "summary_ids = model.generate(tokenized_text,\n",
        "                                    num_beams=4,\n",
        "                                    no_repeat_ngram_size=2,\n",
        "                                    min_length=70,\n",
        "                                    max_length=120,\n",
        "                                    early_stopping=True)\n",
        "\n",
        "final_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUii0u22PDUx"
      },
      "source": [
        "print(final_summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKY6gL8GWRpw"
      },
      "source": [
        "'''\n",
        "# save the trained pytorch model\n",
        "model_name = \"pubmed-BART\"\n",
        "model_path = f\"pytorch_models\"\n",
        "os.makedirs(model_path, exist_ok=True)\n",
        "\n",
        "# Specify a path\n",
        "model_path = f\"pytorch_models/{model_name}/{model_name}.pt\"\n",
        "\n",
        "# Save\n",
        "#torch.save(net, PATH)\n",
        "torch.save(model, model_path)\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfEPDsxFYVjv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN3yYXIz4bRf"
      },
      "source": [
        "def writer(predictions, actuals):\n",
        "    # output_path = r'/content/drive/My Drive/Colab Notebooks/'\n",
        "    # pred_file = output_path+'preds.txt'\n",
        "    # actual_file = output_path+'actuals.txt'\n",
        "    # with open(pred_file, 'w') as f:\n",
        "    #     for pred in predictions:\n",
        "    #         f.write('%s\\n' % pred)\n",
        "\n",
        "    # with open(actual_file, 'w') as f:\n",
        "    #     for actual in actuals:\n",
        "    #         f.write('%s\\n' % actual)\n",
        "    my_dict = {\n",
        "        'Actual Headline': actuals,\n",
        "        'Prediction': predictions       \n",
        "        }\n",
        "    final_output = pd.DataFrame(my_dict)\n",
        "\n",
        "    return final_output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0-QGqoAZCxf"
      },
      "source": [
        "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "# model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "# input_ids = tokenizer.encode(\"Hello, my dog is cute\", return_tensors=\"pt\")  # Batch size 1\n",
        "# outputs = model(input_ids=input_ids, decoder_input_ids=input_ids, lm_labels=input_ids)\n",
        "# loss, prediction_scores = outputs[:2]\n",
        "\n",
        "# tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
        "# model = T5ForConditionalGeneration.from_pretrained('t5-small')\n",
        "# input_ids = tokenizer.encode_plus(\"summarize: Hello, my dog is cute\", return_tensors=\"pt\")  # Batch size 1\n",
        "# outputs = model.generate(input_ids['input_ids'])\n",
        "# pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in outputs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFHWrt0xZLhu"
      },
      "source": [
        "# print(f'The loss is: {loss}')\n",
        "# print(f'The Prediction score is {prediction_scores}')\n",
        "# print(f'The output is {outputs}')\n",
        "# print(f'The final output is {pred}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}