{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS0BC5oErcAP",
        "outputId": "d53ef00a-cf30-40e7-863f-a110c49c08da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpwu5vlhZyoI",
        "outputId": "5e53a94c-14ed-4b41-caeb-021b5cf24a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-5e028c07-beab-aa4b-1d93-73c1f1b1f681)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT8qQNCSreSW",
        "outputId": "0631adaa-2c94-4686-c32d-53c89a03af42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/apex-codes/entity_sum\n"
          ]
        }
      ],
      "source": [
        "%cd drive/My\\ Drive/Colab\\ Notebooks/apex-codes/entity_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIJopRLim9Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e290673-2e19-40e3-cc66-9eb228f5fe49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4 MB 8.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 73.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 73.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 73.5 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip3 install -q transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TwH09T_ZVzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eecf5a5-33d5-45ac-f7c9-7398db34e0de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 748.9 MB 653 bytes/s \n",
            "\u001b[K     |████████████████████████████████| 123 kB 92.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 90.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 64.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 88.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 102.5 MB/s \n",
            "\u001b[?25h  Building wheel for biobert-embedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.2.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.2.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.2.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -q biobert-embedding\n",
        "!pip3 install -q gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaDRjfTmey1o",
        "outputId": "aebe24be-3c87-408f-a6cc-6a4731282747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  \n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_gaD66LKu3f"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle as pk\n",
        "import torch\n",
        "from scipy.spatial.distance import cosine\n",
        "import scipy.spatial as sp\n",
        "from gensim.test.utils import common_texts\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knl9L-qzZf1i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pk\n",
        "import os\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import metrics\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from biobert_embedding.embedding import BiobertEmbedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHmBq4siqPb6"
      },
      "outputs": [],
      "source": [
        "biobert = BiobertEmbedding()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Hq3708bqTJ"
      },
      "source": [
        "## Semantic Equivalence between summaries and abstracts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnDw_82NaUeO"
      },
      "outputs": [],
      "source": [
        "# This one uses BioBERT\n",
        "def _compute_cosine_score(gen_summary, human_summary):\n",
        "  gen_summary_embeddings = biobert.word_vector(gen_summary)\n",
        "  human_summary_embeddings = biobert.word_vector(human_summary)\n",
        "\n",
        "  lst_gen_summary_embed = [x.numpy() for x in gen_summary_embeddings]  # conversion into numpy array for each tensor\n",
        "  lst_human_summary_embed = [x.numpy() for x in human_summary_embeddings]    # conversion into numpy array\n",
        "\n",
        "  cosine = sp.distance.cdist(lst_gen_summary_embed, lst_human_summary_embed, 'cosine')\n",
        "\n",
        "  avg_cosine = np.sum(cosine.flatten()) / (len(lst_gen_summary_embed) * len(lst_human_summary_embed))\n",
        "\n",
        "  return avg_cosine\n",
        "\n",
        "  \n",
        "  '''\n",
        "  total_combinations = len(gen_summary_embeddings) * len(human_summary_embeddings)\n",
        "  cosine_sum = 0.0\n",
        "\n",
        "  for gen_summary_embedding in gen_summary_embeddings:\n",
        "    for human_summary_embedding in human_summary_embeddings:\n",
        "      cosine_sum += cosine(gen_summary_embedding, human_summary_embedding)\n",
        "\n",
        "  avg_cosine_sum = cosine_sum / float(total_combinations)\n",
        "\n",
        "  return avg_cosine_sum\n",
        "  '''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEaCmZGxYXx5"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  lst_modelName = [\"BART\"]\n",
        "  lst_model_type = [\"vanilla\", \"w_named_entities\"]\n",
        "  \n",
        "\n",
        "  dict_cosine_scores = defaultdict(list)\n",
        "\n",
        "  for modelName in lst_modelName:\n",
        "    for model_type in lst_model_type:\n",
        "      SUMMARY_PATH = f\"pubmed-FINAL-SUMMARIES/{modelName}\"\n",
        "      input_filename_path = f\"{SUMMARY_PATH}/pubmed-summaries-{model_type}.jsonl\"\n",
        "\n",
        "      cosine_sum = 0.0   # initialize all cumulative scores to zero\n",
        "      total_no_summaries = 0\n",
        "      with open(input_filename_path) as fp:\n",
        "        for iter, line in enumerate(fp):\n",
        "          if iter % 2000 == 0:\n",
        "            print(\"Iteration: \", iter)\n",
        "          dict_data = json.loads(line)\n",
        "\n",
        "          generated_summary = dict_data[\"abstractive_summary\"]    # generated summary\n",
        "          ground_truth_summary = dict_data[\"article_abstract\"]   # human-like summary\n",
        "\n",
        "          try:\n",
        "            gen_summary_embed = biobert.word_vector(generated_summary)\n",
        "            human_summary_embed = biobert.word_vector(ground_truth_summary)\n",
        "\n",
        "            # call to the semantic equivalence computing method\n",
        "          \n",
        "            cosine_score = _compute_cosine_score(generated_summary, ground_truth_summary)\n",
        "\n",
        "            cosine_sum += cosine_score\n",
        "            \n",
        "            total_no_summaries += 1\n",
        "\n",
        "          except:\n",
        "            continue\n",
        "\n",
        "      fp.close()\n",
        "\n",
        "      avg_cosine = cosine_sum/float(total_no_summaries) * 100\n",
        "\n",
        "      dict_cosine_scores[\"training-config\"].append(f\"{modelName}-{model_type}\")\n",
        "      dict_cosine_scores[\"cosine-score\"].append(avg_cosine)\n",
        "\n",
        "      print(dict_cosine_scores)\n",
        "\n",
        "  df_cosine_scores = pd.DataFrame(dict_cosine_scores)\n",
        "\n",
        "  print(df_cosine_scores)\n",
        "\n",
        "  df_cosine_scores.to_excel(\"cosine_scores.xlsx\")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mI0k7owrcENA",
        "outputId": "03015c3a-2456-4b05-cb65-9e434baa7bc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  0\n",
            "Iteration:  2000\n",
            "Iteration:  4000\n",
            "defaultdict(<class 'list'>, {'training-config': ['BART-vanilla'], 'cosine-score': [51.799856080051434]})\n",
            "Iteration:  0\n",
            "Iteration:  2000\n",
            "Iteration:  4000\n",
            "defaultdict(<class 'list'>, {'training-config': ['BART-vanilla', 'BART-w_named_entities'], 'cosine-score': [51.799856080051434, 51.783337061770574]})\n",
            "         training-config  cosine-score\n",
            "0           BART-vanilla     51.799856\n",
            "1  BART-w_named_entities     51.783337\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6SJOmMDpeAF"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BioBERT_Semantic_Equivalence_Evaluation-PubMed-50k_ICD-11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}